2020-10-12 17:11:44,350	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_019fc_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=65175)[0m 2020-10-12 17:11:47,076	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=65162)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65162)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65173)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65173)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65098)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65098)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65138)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65138)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65109)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65109)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65149)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65149)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65145)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65145)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65059)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65059)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65157)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65157)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65127)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65127)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65117)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65117)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65056)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65056)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65050)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65050)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65083)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65083)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65144)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65144)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65183)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65183)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65047)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65047)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65122)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65122)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65131)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65131)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65139)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65139)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65069)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65069)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65048)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65048)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65101)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65101)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65044)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65044)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65148)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65148)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65169)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65169)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65128)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65128)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65123)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65123)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65141)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65141)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65115)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65115)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65170)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65170)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65146)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65146)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65159)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65159)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65112)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65112)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65046)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65046)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65126)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65126)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65113)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65113)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65119)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65119)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65065)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65065)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65082)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65082)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65161)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65161)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65055)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65055)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65053)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65053)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65063)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65063)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65134)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65134)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65052)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65052)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65185)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65185)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65152)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65152)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65061)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65061)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65062)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65062)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65077)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65077)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65075)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65075)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65057)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65057)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65150)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65150)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65060)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65060)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65121)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65121)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65164)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65164)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65129)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65129)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65085)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65085)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65132)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65132)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65087)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65087)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65124)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65124)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65072)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65072)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65104)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65104)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65045)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65045)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65136)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65136)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65049)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65049)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65172)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65172)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65125)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65125)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65079)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65079)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65067)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65067)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65142)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65142)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65166)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65166)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65051)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65051)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65116)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65116)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65064)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65064)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65120)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65120)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65100)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65100)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65108)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65108)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_019fc_00000:
  custom_metrics:
    time_step_max: 4040
    time_step_mean: 3708.8660714285716
    time_step_min: 3400
  date: 2020-10-12_17-12-20
  done: false
  episode_len_mean: 905.6582278481013
  episode_reward_max: 262.01010101010036
  episode_reward_mean: 216.4606188466943
  episode_reward_min: 164.28282828282764
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 232032c5182a4eb494f4d07bfae64854
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.162174016237259
        entropy_coeff: 0.009999999999999998
        kl: 0.007400489489858349
        model: {}
        policy_loss: -0.009219911764375865
        total_loss: 407.50214131673175
        vf_explained_var: 0.5518081784248352
        vf_loss: 407.52150472005206
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.136363636363637
    gpu_util_percent0: 0.3478787878787879
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.563636363636364
    vram_util_percent0: 0.0858478189570351
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65175
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16474443808423403
    mean_env_wait_ms: 1.1584871968725428
    mean_inference_ms: 5.543977364083433
    mean_raw_obs_processing_ms: 0.4371118619140926
  time_since_restore: 28.048161506652832
  time_this_iter_s: 28.048161506652832
  time_total_s: 28.048161506652832
  timers:
    learn_throughput: 8529.262
    learn_time_ms: 18969.049
    sample_throughput: 17983.026
    sample_time_ms: 8996.928
    update_time_ms: 46.927
  timestamp: 1602522740
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 019fc_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_019fc_00000 | RUNNING  | 172.17.0.4:65175 |      1 |          28.0482 | 161792 |  216.461 |               262.01 |              164.283 |            905.658 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_019fc_00000:
  custom_metrics:
    time_step_max: 4043
    time_step_mean: 3710.4925925925927
    time_step_min: 3400
  date: 2020-10-12_17-12-47
  done: false
  episode_len_mean: 903.3006329113924
  episode_reward_max: 262.01010101010036
  episode_reward_mean: 214.62277841708175
  episode_reward_min: 150.64646464646424
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 232032c5182a4eb494f4d07bfae64854
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1330784956614177
        entropy_coeff: 0.009999999999999998
        kl: 0.009566687668363253
        model: {}
        policy_loss: -0.0110923479514895
        total_loss: 103.45531781514485
        vf_explained_var: 0.8093557357788086
        vf_loss: 103.47582626342773
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.89032258064516
    gpu_util_percent0: 0.3041935483870968
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7548387096774185
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65175
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16176346208792847
    mean_env_wait_ms: 1.1605525292427514
    mean_inference_ms: 5.383108455818749
    mean_raw_obs_processing_ms: 0.4302257655366547
  time_since_restore: 54.62761116027832
  time_this_iter_s: 26.57944965362549
  time_total_s: 54.62761116027832
  timers:
    learn_throughput: 8598.11
    learn_time_ms: 18817.159
    sample_throughput: 19233.702
    sample_time_ms: 8411.901
    update_time_ms: 43.583
  timestamp: 1602522767
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 019fc_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_019fc_00000 | RUNNING  | 172.17.0.4:65175 |      2 |          54.6276 | 323584 |  214.623 |               262.01 |              150.646 |            903.301 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_019fc_00000:
  custom_metrics:
    time_step_max: 4156
    time_step_mean: 3715.070093457944
    time_step_min: 3400
  date: 2020-10-12_17-13-13
  done: false
  episode_len_mean: 900.331223628692
  episode_reward_max: 262.01010101010036
  episode_reward_mean: 213.5015982610915
  episode_reward_min: 146.70707070707016
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 232032c5182a4eb494f4d07bfae64854
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1226665278275807
        entropy_coeff: 0.009999999999999998
        kl: 0.010082878250007829
        model: {}
        policy_loss: -0.013937005324199466
        total_loss: 51.853111267089844
        vf_explained_var: 0.8928160667419434
        vf_loss: 51.876258532206215
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.28000000000001
    gpu_util_percent0: 0.3616666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65175
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1594810323971942
    mean_env_wait_ms: 1.1629969750956464
    mean_inference_ms: 5.2330367252188426
    mean_raw_obs_processing_ms: 0.4237479623177129
  time_since_restore: 80.8160080909729
  time_this_iter_s: 26.18839693069458
  time_total_s: 80.8160080909729
  timers:
    learn_throughput: 8589.711
    learn_time_ms: 18835.558
    sample_throughput: 20182.965
    sample_time_ms: 8016.265
    update_time_ms: 42.953
  timestamp: 1602522793
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 019fc_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_019fc_00000 | RUNNING  | 172.17.0.4:65175 |      3 |           80.816 | 485376 |  213.502 |               262.01 |              146.707 |            900.331 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_019fc_00000:
  custom_metrics:
    time_step_max: 4156
    time_step_mean: 3717.4590443686006
    time_step_min: 3400
  date: 2020-10-12_17-13-38
  done: false
  episode_len_mean: 897.4667721518987
  episode_reward_max: 262.01010101010036
  episode_reward_mean: 213.17834995524828
  episode_reward_min: 143.22222222222166
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 232032c5182a4eb494f4d07bfae64854
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.101429561773936
        entropy_coeff: 0.009999999999999998
        kl: 0.011301174371813735
        model: {}
        policy_loss: -0.01197636368063589
        total_loss: 39.29661146799723
        vf_explained_var: 0.9200734496116638
        vf_loss: 39.31734116872152
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.849999999999998
    gpu_util_percent0: 0.2723333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65175
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.157797039505449
    mean_env_wait_ms: 1.1652709889566073
    mean_inference_ms: 5.115602243853429
    mean_raw_obs_processing_ms: 0.4183022662458976
  time_since_restore: 106.41978240013123
  time_this_iter_s: 25.603774309158325
  time_total_s: 106.41978240013123
  timers:
    learn_throughput: 8612.491
    learn_time_ms: 18785.737
    sample_throughput: 20926.341
    sample_time_ms: 7731.5
    update_time_ms: 41.023
  timestamp: 1602522818
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 019fc_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_019fc_00000 | RUNNING  | 172.17.0.4:65175 |      4 |           106.42 | 647168 |  213.178 |               262.01 |              143.222 |            897.467 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_019fc_00000:
  custom_metrics:
    time_step_max: 4211
    time_step_mean: 3715.9771505376343
    time_step_min: 3379
  date: 2020-10-12_17-14-04
  done: false
  episode_len_mean: 895.120253164557
  episode_reward_max: 264.4343434343425
  episode_reward_mean: 212.89272471550908
  episode_reward_min: 138.3737373737373
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 232032c5182a4eb494f4d07bfae64854
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0757438838481903
        entropy_coeff: 0.009999999999999998
        kl: 0.010865512226397792
        model: {}
        policy_loss: -0.013012423102433482
        total_loss: 30.801881631215412
        vf_explained_var: 0.938795804977417
        vf_loss: 30.823479334513348
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.293103448275858
    gpu_util_percent0: 0.3410344827586207
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.768965517241379
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65175
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15651392229393984
    mean_env_wait_ms: 1.16736911653024
    mean_inference_ms: 5.0241174164060105
    mean_raw_obs_processing_ms: 0.41382545143453225
  time_since_restore: 132.05403995513916
  time_this_iter_s: 25.634257555007935
  time_total_s: 132.05403995513916
  timers:
    learn_throughput: 8611.586
    learn_time_ms: 18787.712
    sample_throughput: 21481.836
    sample_time_ms: 7531.572
    update_time_ms: 40.932
  timestamp: 1602522844
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 019fc_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_019fc_00000 | RUNNING  | 172.17.0.4:65175 |      5 |          132.054 | 808960 |  212.893 |              264.434 |              138.374 |             895.12 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_019fc_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3722.8161683277963
    time_step_min: 3379
  date: 2020-10-12_17-14-30
  done: false
  episode_len_mean: 893.1970495258166
  episode_reward_max: 264.4343434343425
  episode_reward_mean: 212.187800023416
  episode_reward_min: 135.6464646464643
  episodes_this_iter: 159
  episodes_total: 949
  experiment_id: 232032c5182a4eb494f4d07bfae64854
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0390450457731883
        entropy_coeff: 0.009999999999999998
        kl: 0.00938648753799498
        model: {}
        policy_loss: -0.01245904503351388
        total_loss: 30.00705560048421
        vf_explained_var: 0.9519290328025818
        vf_loss: 30.028028170267742
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.40666666666667
    gpu_util_percent0: 0.31566666666666665
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7633333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65175
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15550013925717698
    mean_env_wait_ms: 1.1694761683721706
    mean_inference_ms: 4.950884945226718
    mean_raw_obs_processing_ms: 0.41015316179911254
  time_since_restore: 157.6344816684723
  time_this_iter_s: 25.58044171333313
  time_total_s: 157.6344816684723
  timers:
    learn_throughput: 8617.074
    learn_time_ms: 18775.746
    sample_throughput: 21845.53
    sample_time_ms: 7406.183
    update_time_ms: 40.491
  timestamp: 1602522870
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 019fc_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_019fc_00000 | RUNNING  | 172.17.0.4:65175 |      6 |          157.634 | 970752 |  212.188 |              264.434 |              135.646 |            893.197 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_019fc_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3723.126878130217
    time_step_min: 3379
  date: 2020-10-12_17-14-56
  done: false
  episode_len_mean: 888.8167202572347
  episode_reward_max: 264.4343434343425
  episode_reward_mean: 212.31325310987648
  episode_reward_min: 130.34343434343387
  episodes_this_iter: 295
  episodes_total: 1244
  experiment_id: 232032c5182a4eb494f4d07bfae64854
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.03912286957105
        entropy_coeff: 0.009999999999999998
        kl: 0.008623252583978077
        model: {}
        policy_loss: -0.011956422570316741
        total_loss: 34.7660935719808
        vf_explained_var: 0.954240620136261
        vf_loss: 34.7867161432902
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.363333333333337
    gpu_util_percent0: 0.4056666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666657
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65175
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15414166343050775
    mean_env_wait_ms: 1.1729435873057235
    mean_inference_ms: 4.8525993625715556
    mean_raw_obs_processing_ms: 0.4053974474225456
  time_since_restore: 183.39965772628784
  time_this_iter_s: 25.76517605781555
  time_total_s: 183.39965772628784
  timers:
    learn_throughput: 8604.484
    learn_time_ms: 18803.219
    sample_throughput: 22149.164
    sample_time_ms: 7304.655
    update_time_ms: 41.421
  timestamp: 1602522896
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 019fc_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_019fc_00000 | RUNNING  | 172.17.0.4:65175 |      7 |            183.4 | 1132544 |  212.313 |              264.434 |              130.343 |            888.817 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_019fc_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3721.186046511628
    time_step_min: 3379
  date: 2020-10-12_17-15-21
  done: false
  episode_len_mean: 885.9254571026723
  episode_reward_max: 266.2525252525249
  episode_reward_mean: 212.5494608532579
  episode_reward_min: 130.34343434343387
  episodes_this_iter: 178
  episodes_total: 1422
  experiment_id: 232032c5182a4eb494f4d07bfae64854
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.050705720980962
        entropy_coeff: 0.009999999999999998
        kl: 0.00926402397453785
        model: {}
        policy_loss: -0.012792842094010362
        total_loss: 22.575383186340332
        vf_explained_var: 0.9612322449684143
        vf_loss: 22.596829732259113
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.993103448275868
    gpu_util_percent0: 0.36931034482758623
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7793103448275853
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65175
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1535390922492395
    mean_env_wait_ms: 1.1747022329793202
    mean_inference_ms: 4.808087055318662
    mean_raw_obs_processing_ms: 0.4033483629835233
  time_since_restore: 208.85298418998718
  time_this_iter_s: 25.45332646369934
  time_total_s: 208.85298418998718
  timers:
    learn_throughput: 8614.393
    learn_time_ms: 18781.59
    sample_throughput: 22365.967
    sample_time_ms: 7233.848
    update_time_ms: 38.78
  timestamp: 1602522921
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 019fc_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_019fc_00000 | RUNNING  | 172.17.0.4:65175 |      8 |          208.853 | 1294336 |  212.549 |              266.253 |              130.343 |            885.925 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_019fc_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3717.8142112125165
    time_step_min: 3379
  date: 2020-10-12_17-15-47
  done: false
  episode_len_mean: 881.8284810126582
  episode_reward_max: 266.2525252525249
  episode_reward_mean: 213.28685590077953
  episode_reward_min: 130.34343434343387
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 232032c5182a4eb494f4d07bfae64854
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0393874049186707
        entropy_coeff: 0.009999999999999998
        kl: 0.008519890640551845
        model: {}
        policy_loss: -0.012283071070366228
        total_loss: 21.654701550801594
        vf_explained_var: 0.9587955474853516
        vf_loss: 21.675674756368
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.133333333333333
    gpu_util_percent0: 0.32999999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7799999999999994
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65175
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1530695847518519
    mean_env_wait_ms: 1.176420755843434
    mean_inference_ms: 4.773885794375439
    mean_raw_obs_processing_ms: 0.40171089111469804
  time_since_restore: 234.49847650527954
  time_this_iter_s: 25.64549231529236
  time_total_s: 234.49847650527954
  timers:
    learn_throughput: 8612.776
    learn_time_ms: 18785.115
    sample_throughput: 22538.192
    sample_time_ms: 7178.57
    update_time_ms: 39.261
  timestamp: 1602522947
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 019fc_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_019fc_00000 | RUNNING  | 172.17.0.4:65175 |      9 |          234.498 | 1456128 |  213.287 |              266.253 |              130.343 |            881.828 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_019fc_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3713.306146572104
    time_step_min: 3379
  date: 2020-10-12_17-16-12
  done: false
  episode_len_mean: 878.0293440736478
  episode_reward_max: 267.0101010101003
  episode_reward_mean: 214.00255140588814
  episode_reward_min: 130.34343434343387
  episodes_this_iter: 158
  episodes_total: 1738
  experiment_id: 232032c5182a4eb494f4d07bfae64854
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0202158788839977
        entropy_coeff: 0.009999999999999998
        kl: 0.008901316983004412
        model: {}
        policy_loss: -0.013215057173511013
        total_loss: 18.585407098134358
        vf_explained_var: 0.9630387425422668
        vf_loss: 18.607044378916424
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.05517241379311
    gpu_util_percent0: 0.3875862068965517
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7724137931034485
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65175
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15265443498053424
    mean_env_wait_ms: 1.178143837486674
    mean_inference_ms: 4.743592131972131
    mean_raw_obs_processing_ms: 0.4002290439333137
  time_since_restore: 259.9763524532318
  time_this_iter_s: 25.47787594795227
  time_total_s: 259.9763524532318
  timers:
    learn_throughput: 8620.908
    learn_time_ms: 18767.398
    sample_throughput: 22665.726
    sample_time_ms: 7138.178
    update_time_ms: 39.138
  timestamp: 1602522972
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 019fc_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_019fc_00000 | RUNNING  | 172.17.0.4:65175 |     10 |          259.976 | 1617920 |  214.003 |               267.01 |              130.343 |            878.029 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_019fc_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3706.444326052211
    time_step_min: 3350
  date: 2020-10-12_17-16-38
  done: false
  episode_len_mean: 874.0109204368175
  episode_reward_max: 268.8282828282828
  episode_reward_mean: 215.10714004317708
  episode_reward_min: 130.34343434343387
  episodes_this_iter: 185
  episodes_total: 1923
  experiment_id: 232032c5182a4eb494f4d07bfae64854
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9695546974738439
        entropy_coeff: 0.009999999999999998
        kl: 0.008646589277001718
        model: {}
        policy_loss: -0.014577006172961168
        total_loss: 19.239712556203205
        vf_explained_var: 0.9686432480812073
        vf_loss: 19.262255509694416
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.33
    gpu_util_percent0: 0.3333333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.753333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65175
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15224139259265704
    mean_env_wait_ms: 1.18016571118188
    mean_inference_ms: 4.712162394659616
    mean_raw_obs_processing_ms: 0.3987055562094946
  time_since_restore: 285.45403957366943
  time_this_iter_s: 25.477687120437622
  time_total_s: 285.45403957366943
  timers:
    learn_throughput: 8640.058
    learn_time_ms: 18725.801
    sample_throughput: 23393.836
    sample_time_ms: 6916.01
    update_time_ms: 36.374
  timestamp: 1602522998
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 019fc_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_019fc_00000 | RUNNING  | 172.17.0.4:65175 |     11 |          285.454 | 1779712 |  215.107 |              268.828 |              130.343 |            874.011 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_019fc_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3698.054654932839
    time_step_min: 3350
  date: 2020-10-12_17-17-04
  done: false
  episode_len_mean: 869.1201814058957
  episode_reward_max: 268.8282828282828
  episode_reward_mean: 216.45743145743106
  episode_reward_min: 130.34343434343387
  episodes_this_iter: 282
  episodes_total: 2205
  experiment_id: 232032c5182a4eb494f4d07bfae64854
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9747825115919113
        entropy_coeff: 0.009999999999999998
        kl: 0.008606105965251723
        model: {}
        policy_loss: -0.01135684282053262
        total_loss: 22.06595786412557
        vf_explained_var: 0.9677631855010986
        vf_loss: 22.085340976715088
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.620689655172416
    gpu_util_percent0: 0.3596551724137931
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.762068965517241
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65175
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15168904016165152
    mean_env_wait_ms: 1.1828893708304835
    mean_inference_ms: 4.672708191194397
    mean_raw_obs_processing_ms: 0.39675158862632237
  time_since_restore: 311.09507298469543
  time_this_iter_s: 25.641033411026
  time_total_s: 311.09507298469543
  timers:
    learn_throughput: 8636.083
    learn_time_ms: 18734.42
    sample_throughput: 23744.107
    sample_time_ms: 6813.985
    update_time_ms: 35.642
  timestamp: 1602523024
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 019fc_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_019fc_00000 | RUNNING  | 172.17.0.4:65175 |     12 |          311.095 | 1941504 |  216.457 |              268.828 |              130.343 |             869.12 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_019fc_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3692.724612736661
    time_step_min: 3350
  date: 2020-10-12_17-17-30
  done: false
  episode_len_mean: 867.1658227848101
  episode_reward_max: 268.8282828282828
  episode_reward_mean: 217.25258918296853
  episode_reward_min: 130.34343434343387
  episodes_this_iter: 165
  episodes_total: 2370
  experiment_id: 232032c5182a4eb494f4d07bfae64854
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9705509394407272
        entropy_coeff: 0.009999999999999998
        kl: 0.008934468030929565
        model: {}
        policy_loss: -0.015075437435977316
        total_loss: 17.009426434834797
        vf_explained_var: 0.968177855014801
        vf_loss: 17.03242031733195
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.19333333333333
    gpu_util_percent0: 0.2953333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7866666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65175
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15142099481330798
    mean_env_wait_ms: 1.1842993875071046
    mean_inference_ms: 4.6529605850866025
    mean_raw_obs_processing_ms: 0.39578605005997647
  time_since_restore: 337.03858757019043
  time_this_iter_s: 25.943514585494995
  time_total_s: 337.03858757019043
  timers:
    learn_throughput: 8633.607
    learn_time_ms: 18739.792
    sample_throughput: 23854.009
    sample_time_ms: 6782.592
    update_time_ms: 35.704
  timestamp: 1602523050
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 019fc_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_019fc_00000 | RUNNING  | 172.17.0.4:65175 |     13 |          337.039 | 2103296 |  217.253 |              268.828 |              130.343 |            867.166 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_019fc_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3687.4278807413375
    time_step_min: 3350
  date: 2020-10-12_17-17-55
  done: false
  episode_len_mean: 865.0134493670886
  episode_reward_max: 273.97979797979764
  episode_reward_mean: 217.9994446042702
  episode_reward_min: 130.34343434343387
  episodes_this_iter: 158
  episodes_total: 2528
  experiment_id: 232032c5182a4eb494f4d07bfae64854
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9585684984922409
        entropy_coeff: 0.009999999999999998
        kl: 0.009476205023626486
        model: {}
        policy_loss: -0.012030964406828085
        total_loss: 15.066752195358276
        vf_explained_var: 0.9694556593894958
        vf_loss: 15.08647354443868
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.386666666666667
    gpu_util_percent0: 0.292
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65175
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15118511425604853
    mean_env_wait_ms: 1.185645592904114
    mean_inference_ms: 4.635674566871135
    mean_raw_obs_processing_ms: 0.3949400318037833
  time_since_restore: 362.4808669090271
  time_this_iter_s: 25.44227933883667
  time_total_s: 362.4808669090271
  timers:
    learn_throughput: 8633.049
    learn_time_ms: 18741.003
    sample_throughput: 23914.655
    sample_time_ms: 6765.391
    update_time_ms: 35.392
  timestamp: 1602523075
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 019fc_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_019fc_00000 | RUNNING  | 172.17.0.4:65175 |     14 |          362.481 | 2265088 |  217.999 |               273.98 |              130.343 |            865.013 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_019fc_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3679.831951770912
    time_step_min: 3350
  date: 2020-10-12_17-18-21
  done: false
  episode_len_mean: 861.9048148148148
  episode_reward_max: 273.97979797979764
  episode_reward_mean: 219.19292929292888
  episode_reward_min: 130.34343434343387
  episodes_this_iter: 172
  episodes_total: 2700
  experiment_id: 232032c5182a4eb494f4d07bfae64854
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9148590217034022
        entropy_coeff: 0.009999999999999998
        kl: 0.00842777465004474
        model: {}
        policy_loss: -0.01287808952232202
        total_loss: 13.500814835230509
        vf_explained_var: 0.9740374684333801
        vf_loss: 13.521155754725138
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.37931034482759
    gpu_util_percent0: 0.4165517241379311
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7689655172413787
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65175
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15094852650833976
    mean_env_wait_ms: 1.1871217697975303
    mean_inference_ms: 4.618613206713509
    mean_raw_obs_processing_ms: 0.3940934487159959
  time_since_restore: 387.9457712173462
  time_this_iter_s: 25.464904308319092
  time_total_s: 387.9457712173462
  timers:
    learn_throughput: 8643.012
    learn_time_ms: 18719.4
    sample_throughput: 23897.13
    sample_time_ms: 6770.353
    update_time_ms: 35.122
  timestamp: 1602523101
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 019fc_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_019fc_00000 | RUNNING  | 172.17.0.4:65175 |     15 |          387.946 | 2426880 |  219.193 |               273.98 |              130.343 |            861.905 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_019fc_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3667.601766904519
    time_step_min: 3350
  date: 2020-10-12_17-18-47
  done: false
  episode_len_mean: 856.7892271662763
  episode_reward_max: 278.67676767676693
  episode_reward_mean: 220.89986854155435
  episode_reward_min: 130.34343434343387
  episodes_this_iter: 289
  episodes_total: 2989
  experiment_id: 232032c5182a4eb494f4d07bfae64854
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9031053980191549
        entropy_coeff: 0.009999999999999998
        kl: 0.007541363826021552
        model: {}
        policy_loss: -0.012638927650793145
        total_loss: 17.4014474550883
        vf_explained_var: 0.9740064144134521
        vf_loss: 17.42160924275716
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.44666666666667
    gpu_util_percent0: 0.33333333333333337
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.763333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65175
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1506066955066367
    mean_env_wait_ms: 1.1895104353494164
    mean_inference_ms: 4.593120921700944
    mean_raw_obs_processing_ms: 0.39286810786388626
  time_since_restore: 413.5625286102295
  time_this_iter_s: 25.6167573928833
  time_total_s: 413.5625286102295
  timers:
    learn_throughput: 8644.252
    learn_time_ms: 18716.715
    sample_throughput: 23874.203
    sample_time_ms: 6776.854
    update_time_ms: 33.52
  timestamp: 1602523127
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 019fc_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_019fc_00000 | RUNNING  | 172.17.0.4:65175 |     16 |          413.563 | 2588672 |    220.9 |              278.677 |              130.343 |            856.789 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_019fc_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3660.9646756583174
    time_step_min: 3350
  date: 2020-10-12_17-19-12
  done: false
  episode_len_mean: 854.3661392405063
  episode_reward_max: 278.67676767676693
  episode_reward_mean: 221.70932425520996
  episode_reward_min: 130.34343434343387
  episodes_this_iter: 171
  episodes_total: 3160
  experiment_id: 232032c5182a4eb494f4d07bfae64854
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9115153650442759
        entropy_coeff: 0.009999999999999998
        kl: 0.007609127710262935
        model: {}
        policy_loss: -0.01140438144405683
        total_loss: 13.55315351486206
        vf_explained_var: 0.9727904796600342
        vf_loss: 13.57215150197347
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.562068965517245
    gpu_util_percent0: 0.36862068965517253
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775862068965517
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65175
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15042515295148223
    mean_env_wait_ms: 1.1908445515633381
    mean_inference_ms: 4.579879823932666
    mean_raw_obs_processing_ms: 0.39223234700598353
  time_since_restore: 439.19854283332825
  time_this_iter_s: 25.636014223098755
  time_total_s: 439.19854283332825
  timers:
    learn_throughput: 8654.488
    learn_time_ms: 18694.579
    sample_throughput: 23839.282
    sample_time_ms: 6786.782
    update_time_ms: 32.705
  timestamp: 1602523152
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 019fc_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_019fc_00000 | RUNNING  | 172.17.0.4:65175 |     17 |          439.199 | 2750464 |  221.709 |              278.677 |              130.343 |            854.366 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_019fc_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3656.164119804401
    time_step_min: 3300
  date: 2020-10-12_17-19-38
  done: false
  episode_len_mean: 852.8167570825799
  episode_reward_max: 278.67676767676693
  episode_reward_mean: 222.44185982793545
  episode_reward_min: 130.34343434343387
  episodes_this_iter: 158
  episodes_total: 3318
  experiment_id: 232032c5182a4eb494f4d07bfae64854
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8936979273955027
        entropy_coeff: 0.009999999999999998
        kl: 0.008412747411057353
        model: {}
        policy_loss: -0.01464560276751096
        total_loss: 11.321987867355347
        vf_explained_var: 0.9756448864936829
        vf_loss: 11.34388780593872
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.279999999999998
    gpu_util_percent0: 0.3293333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.79
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65175
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15027065459063313
    mean_env_wait_ms: 1.1920347750908273
    mean_inference_ms: 4.568492676196952
    mean_raw_obs_processing_ms: 0.39167507782487954
  time_since_restore: 464.80402541160583
  time_this_iter_s: 25.605482578277588
  time_total_s: 464.80402541160583
  timers:
    learn_throughput: 8654.138
    learn_time_ms: 18695.333
    sample_throughput: 23792.485
    sample_time_ms: 6800.13
    update_time_ms: 34.429
  timestamp: 1602523178
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 019fc_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_019fc_00000 | RUNNING  | 172.17.0.4:65175 |     18 |          464.804 | 2912256 |  222.442 |              278.677 |              130.343 |            852.817 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_019fc_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3651.4125469788955
    time_step_min: 3300
  date: 2020-10-12_17-20-04
  done: false
  episode_len_mean: 850.7124108416548
  episode_reward_max: 278.67676767676693
  episode_reward_mean: 223.18642919926765
  episode_reward_min: 130.34343434343387
  episodes_this_iter: 187
  episodes_total: 3505
  experiment_id: 232032c5182a4eb494f4d07bfae64854
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8656516224145889
        entropy_coeff: 0.009999999999999998
        kl: 0.008265468757599592
        model: {}
        policy_loss: -0.014240417687688023
        total_loss: 13.028841654459635
        vf_explained_var: 0.9772016406059265
        vf_loss: 13.050085306167603
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.716666666666665
    gpu_util_percent0: 0.32433333333333336
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.77
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65175
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1501043817385768
    mean_env_wait_ms: 1.193400935277629
    mean_inference_ms: 4.556018636976437
    mean_raw_obs_processing_ms: 0.3910664802878972
  time_since_restore: 490.43418765068054
  time_this_iter_s: 25.630162239074707
  time_total_s: 490.43418765068054
  timers:
    learn_throughput: 8659.662
    learn_time_ms: 18683.409
    sample_throughput: 23753.597
    sample_time_ms: 6811.263
    update_time_ms: 32.563
  timestamp: 1602523204
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 019fc_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_019fc_00000 | RUNNING  | 172.17.0.4:65175 |     19 |          490.434 | 3074048 |  223.186 |              278.677 |              130.343 |            850.712 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_019fc_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3642.600321457273
    time_step_min: 3282
  date: 2020-10-12_17-20-30
  done: false
  episode_len_mean: 847.8338184704949
  episode_reward_max: 279.1313131313132
  episode_reward_mean: 224.53149114858527
  episode_reward_min: 130.34343434343387
  episodes_this_iter: 274
  episodes_total: 3779
  experiment_id: 232032c5182a4eb494f4d07bfae64854
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8639080425103506
        entropy_coeff: 0.009999999999999998
        kl: 0.00700389186386019
        model: {}
        policy_loss: -0.01394031745439861
        total_loss: 13.400090058644613
        vf_explained_var: 0.9786996841430664
        vf_loss: 13.421268622080484
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.23103448275862
    gpu_util_percent0: 0.356896551724138
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7620689655172406
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65175
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14987972996011653
    mean_env_wait_ms: 1.1952552997891228
    mean_inference_ms: 4.539499318665609
    mean_raw_obs_processing_ms: 0.39026175797188545
  time_since_restore: 515.9642579555511
  time_this_iter_s: 25.530070304870605
  time_total_s: 515.9642579555511
  timers:
    learn_throughput: 8657.288
    learn_time_ms: 18688.532
    sample_throughput: 23753.041
    sample_time_ms: 6811.423
    update_time_ms: 32.321
  timestamp: 1602523230
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 019fc_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_019fc_00000 | RUNNING  | 172.17.0.4:65175 |     20 |          515.964 | 3235840 |  224.531 |              279.131 |              130.343 |            847.834 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_019fc_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3637.4912909836066
    time_step_min: 3282
  date: 2020-10-12_17-20-55
  done: false
  episode_len_mean: 846.5035443037974
  episode_reward_max: 279.1313131313132
  episode_reward_mean: 225.25705152793728
  episode_reward_min: 130.34343434343387
  episodes_this_iter: 171
  episodes_total: 3950
  experiment_id: 232032c5182a4eb494f4d07bfae64854
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8559486120939255
        entropy_coeff: 0.009999999999999998
        kl: 0.008568892255425453
        model: {}
        policy_loss: -0.013337126118130982
        total_loss: 9.105780919392904
        vf_explained_var: 0.9812491536140442
        vf_loss: 9.12596352895101
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.123333333333335
    gpu_util_percent0: 0.323
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65175
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14974876967640643
    mean_env_wait_ms: 1.1963412534448317
    mean_inference_ms: 4.530131107247385
    mean_raw_obs_processing_ms: 0.3898121032528024
  time_since_restore: 541.6337945461273
  time_this_iter_s: 25.669536590576172
  time_total_s: 541.6337945461273
  timers:
    learn_throughput: 8650.378
    learn_time_ms: 18703.459
    sample_throughput: 23726.451
    sample_time_ms: 6819.056
    update_time_ms: 34.38
  timestamp: 1602523255
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 019fc_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_019fc_00000 | RUNNING  | 172.17.0.4:65175 |     21 |          541.634 | 3397632 |  225.257 |              279.131 |              130.343 |            846.504 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_019fc_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3633.2539995077527
    time_step_min: 3282
  date: 2020-10-12_17-21-21
  done: false
  episode_len_mean: 845.16208323193
  episode_reward_max: 279.1313131313132
  episode_reward_mean: 225.90450870348624
  episode_reward_min: 130.34343434343387
  episodes_this_iter: 159
  episodes_total: 4109
  experiment_id: 232032c5182a4eb494f4d07bfae64854
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8445842067400614
        entropy_coeff: 0.009999999999999998
        kl: 0.007905828882940114
        model: {}
        policy_loss: -0.013556821329984814
        total_loss: 10.571261723836264
        vf_explained_var: 0.9769544005393982
        vf_loss: 10.591683228810629
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.663333333333338
    gpu_util_percent0: 0.31466666666666665
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7866666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65175
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14963632380089598
    mean_env_wait_ms: 1.1973228940588314
    mean_inference_ms: 4.521949573276206
    mean_raw_obs_processing_ms: 0.3894131145046871
  time_since_restore: 567.3359732627869
  time_this_iter_s: 25.702178716659546
  time_total_s: 567.3359732627869
  timers:
    learn_throughput: 8649.977
    learn_time_ms: 18704.326
    sample_throughput: 23740.642
    sample_time_ms: 6814.98
    update_time_ms: 34.656
  timestamp: 1602523281
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 019fc_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_019fc_00000 | RUNNING  | 172.17.0.4:65175 |     22 |          567.336 | 3559424 |  225.905 |              279.131 |              130.343 |            845.162 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_019fc_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3628.1491803278686
    time_step_min: 3282
  date: 2020-10-12_17-21-47
  done: false
  episode_len_mean: 843.6895273401298
  episode_reward_max: 279.1313131313132
  episode_reward_mean: 226.61990385785535
  episode_reward_min: 130.34343434343387
  episodes_this_iter: 207
  episodes_total: 4316
  experiment_id: 232032c5182a4eb494f4d07bfae64854
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8053185840447744
        entropy_coeff: 0.009999999999999998
        kl: 0.00746390405887117
        model: {}
        policy_loss: -0.011889462223431716
        total_loss: 13.387895186742147
        vf_explained_var: 0.9773516058921814
        vf_loss: 13.406344970067343
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.886206896551727
    gpu_util_percent0: 0.3255172413793104
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.768965517241379
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65175
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1495033706341457
    mean_env_wait_ms: 1.198512178510707
    mean_inference_ms: 4.512007977584389
    mean_raw_obs_processing_ms: 0.3889174018108545
  time_since_restore: 592.8355693817139
  time_this_iter_s: 25.499596118927002
  time_total_s: 592.8355693817139
  timers:
    learn_throughput: 8663.104
    learn_time_ms: 18675.985
    sample_throughput: 23793.535
    sample_time_ms: 6799.83
    update_time_ms: 33.892
  timestamp: 1602523307
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 019fc_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_019fc_00000 | RUNNING  | 172.17.0.4:65175 |     23 |          592.836 | 3721216 |   226.62 |              279.131 |              130.343 |             843.69 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_019fc_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3622.492929739284
    time_step_min: 3282
  date: 2020-10-12_17-22-12
  done: true
  episode_len_mean: 841.8650481189851
  episode_reward_max: 280.34343434343396
  episode_reward_mean: 227.47578143641104
  episode_reward_min: 130.34343434343387
  episodes_this_iter: 256
  episodes_total: 4572
  experiment_id: 232032c5182a4eb494f4d07bfae64854
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.809807538986206
        entropy_coeff: 0.009999999999999998
        kl: 0.007413982219683628
        model: {}
        policy_loss: -0.012492029733645419
        total_loss: 13.598761399586996
        vf_explained_var: 0.9782752394676208
        vf_loss: 13.617869059244791
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.373333333333335
    gpu_util_percent0: 0.35633333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65175
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14934866399924757
    mean_env_wait_ms: 1.1999160753799112
    mean_inference_ms: 4.500656196166928
    mean_raw_obs_processing_ms: 0.38837151011227977
  time_since_restore: 618.2450640201569
  time_this_iter_s: 25.409494638442993
  time_total_s: 618.2450640201569
  timers:
    learn_throughput: 8671.885
    learn_time_ms: 18657.074
    sample_throughput: 23769.561
    sample_time_ms: 6806.689
    update_time_ms: 34.008
  timestamp: 1602523332
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: 019fc_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_019fc_00000 | TERMINATED |       |     24 |          618.245 | 3883008 |  227.476 |              280.343 |              130.343 |            841.865 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_019fc_00000 | TERMINATED |       |     24 |          618.245 | 3883008 |  227.476 |              280.343 |              130.343 |            841.865 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


