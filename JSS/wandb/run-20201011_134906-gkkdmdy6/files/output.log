2020-10-11 13:49:09,954	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_8aa5e_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=74115)[0m 2020-10-11 13:49:12,665	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=74105)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74105)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73975)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73975)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74104)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74104)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74111)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74111)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74069)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74069)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73995)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73995)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74033)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74033)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73980)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73980)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74112)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74112)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73985)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73985)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74006)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74006)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74041)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74041)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73982)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73982)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74068)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74068)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74000)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74000)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74026)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74026)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74058)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74058)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74054)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74054)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74048)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74048)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74060)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74060)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74109)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74109)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74108)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74108)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74078)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74078)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74099)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74099)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74056)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74056)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73978)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73978)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74096)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74096)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73987)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73987)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74053)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74053)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74061)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74061)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73974)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73974)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74009)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74009)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73976)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73976)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74063)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74063)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74014)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74014)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74050)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74050)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74116)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74116)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74065)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74065)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74047)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74047)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73992)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73992)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73981)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73981)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74091)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74091)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73989)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73989)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74082)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74082)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74005)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74005)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74057)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74057)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74092)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74092)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74052)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74052)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74046)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74046)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73990)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73990)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74075)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74075)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74031)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74031)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74072)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74072)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73979)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73979)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74012)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74012)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74008)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74008)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74059)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74059)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74066)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74066)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73986)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73986)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74064)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74064)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74101)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74101)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74029)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74029)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73997)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73997)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74117)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74117)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73998)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73998)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74083)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74083)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73993)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73993)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73991)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73991)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73977)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73977)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74062)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74062)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74094)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74094)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74049)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74049)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74084)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74084)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74016)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74016)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74087)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74087)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74113)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74113)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74003)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74003)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73988)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73988)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74090)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74090)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_8aa5e_00000:
  custom_metrics:
    time_step_max: 4030
    time_step_mean: 3584.5733333333333
    time_step_min: 3342
  date: 2020-10-11_13-50-23
  done: false
  episode_len_mean: 890.4599156118144
  episode_reward_max: 265.262626262626
  episode_reward_mean: 220.14243702851277
  episode_reward_min: 128.4444444444439
  episodes_this_iter: 237
  episodes_total: 237
  experiment_id: e4cd25b71e7c4145a301f82edbbc5692
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 4.999999999999999e-05
        entropy: 1.1812323435493137
        entropy_coeff: 9.999999999999998e-05
        kl: 0.005443207838613054
        model: {}
        policy_loss: -0.012100203489155872
        total_loss: 546.6396351689878
        vf_explained_var: 0.6722603440284729
        vf_loss: 546.6507780655571
    num_steps_sampled: 364032
    num_steps_trained: 364032
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.080519480519484
    gpu_util_percent0: 0.3205194805194805
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.901298701298702
    vram_util_percent0: 0.09605981096633767
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74115
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1879541666759073
    mean_env_wait_ms: 1.6313353357137323
    mean_inference_ms: 5.998513289042923
    mean_raw_obs_processing_ms: 0.5689072139466006
  time_since_restore: 65.23315048217773
  time_this_iter_s: 65.23315048217773
  time_total_s: 65.23315048217773
  timers:
    learn_throughput: 7224.792
    learn_time_ms: 50386.499
    sample_throughput: 24639.45
    sample_time_ms: 14774.356
    update_time_ms: 38.074
  timestamp: 1602424223
  timesteps_since_restore: 0
  timesteps_total: 364032
  training_iteration: 1
  trial_id: 8aa5e_00000
  
== Status ==
Memory usage on this node: 30.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8aa5e_00000 | RUNNING  | 172.17.0.4:74115 |      1 |          65.2332 | 364032 |  220.142 |              265.263 |              128.444 |             890.46 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8aa5e_00000:
  custom_metrics:
    time_step_max: 4194
    time_step_mean: 3613.4647435897436
    time_step_min: 3297
  date: 2020-10-11_13-51-25
  done: false
  episode_len_mean: 889.2180028129395
  episode_reward_max: 269.35353535353505
  episode_reward_mean: 219.49780505476684
  episode_reward_min: 128.4444444444439
  episodes_this_iter: 474
  episodes_total: 711
  experiment_id: e4cd25b71e7c4145a301f82edbbc5692
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 4.999999999999999e-05
        entropy: 1.1449830739394478
        entropy_coeff: 9.999999999999998e-05
        kl: 0.006840863042389569
        model: {}
        policy_loss: -0.011217107834375423
        total_loss: 89.270577803902
        vf_explained_var: 0.8847726583480835
        vf_loss: 89.28054146144702
    num_steps_sampled: 728064
    num_steps_trained: 728064
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.15616438356164
    gpu_util_percent0: 0.31602739726027396
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.364383561643836
    vram_util_percent0: 0.10946211872745161
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74115
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.18306390199729614
    mean_env_wait_ms: 1.6422069762134202
    mean_inference_ms: 5.449246780380361
    mean_raw_obs_processing_ms: 0.5471838866160077
  time_since_restore: 127.21302962303162
  time_this_iter_s: 61.97987914085388
  time_total_s: 127.21302962303162
  timers:
    learn_throughput: 7254.2
    learn_time_ms: 50182.237
    sample_throughput: 27330.717
    sample_time_ms: 13319.519
    update_time_ms: 39.249
  timestamp: 1602424285
  timesteps_since_restore: 0
  timesteps_total: 728064
  training_iteration: 2
  trial_id: 8aa5e_00000
  
== Status ==
Memory usage on this node: 31.9/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8aa5e_00000 | RUNNING  | 172.17.0.4:74115 |      2 |          127.213 | 728064 |  219.498 |              269.354 |              128.444 |            889.218 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8aa5e_00000:
  custom_metrics:
    time_step_max: 4194
    time_step_mean: 3602.8624772313296
    time_step_min: 3297
  date: 2020-10-11_13-52-27
  done: false
  episode_len_mean: 885.1831223628692
  episode_reward_max: 269.35353535353505
  episode_reward_mean: 221.32924178493778
  episode_reward_min: 128.4444444444439
  episodes_this_iter: 474
  episodes_total: 1185
  experiment_id: e4cd25b71e7c4145a301f82edbbc5692
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 4.999999999999999e-05
        entropy: 1.1266924246497776
        entropy_coeff: 9.999999999999998e-05
        kl: 0.007777576031082351
        model: {}
        policy_loss: -0.013149646890309194
        total_loss: 34.91895227846892
        vf_explained_var: 0.948970377445221
        vf_loss: 34.93066008194633
    num_steps_sampled: 1092096
    num_steps_trained: 1092096
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.05890410958904
    gpu_util_percent0: 0.29958904109589035
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.397260273972603
    vram_util_percent0: 0.10946211872745161
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74115
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1808869177383984
    mean_env_wait_ms: 1.6470594540772212
    mean_inference_ms: 5.219341407995214
    mean_raw_obs_processing_ms: 0.5376188471847679
  time_since_restore: 188.7992880344391
  time_this_iter_s: 61.58625841140747
  time_total_s: 188.7992880344391
  timers:
    learn_throughput: 7260.447
    learn_time_ms: 50139.063
    sample_throughput: 28705.879
    sample_time_ms: 12681.444
    update_time_ms: 39.569
  timestamp: 1602424347
  timesteps_since_restore: 0
  timesteps_total: 1092096
  training_iteration: 3
  trial_id: 8aa5e_00000
  
== Status ==
Memory usage on this node: 32.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8aa5e_00000 | RUNNING  | 172.17.0.4:74115 |      3 |          188.799 | 1092096 |  221.329 |              269.354 |              128.444 |            885.183 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8aa5e_00000:
  custom_metrics:
    time_step_max: 4194
    time_step_mean: 3591.3257629524487
    time_step_min: 3297
  date: 2020-10-11_13-53-29
  done: false
  episode_len_mean: 882.2105614973262
  episode_reward_max: 269.35353535353505
  episode_reward_mean: 222.652332144979
  episode_reward_min: 128.4444444444439
  episodes_this_iter: 311
  episodes_total: 1496
  experiment_id: e4cd25b71e7c4145a301f82edbbc5692
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 4.999999999999999e-05
        entropy: 1.110515138377314
        entropy_coeff: 9.999999999999998e-05
        kl: 0.008099187590667734
        model: {}
        policy_loss: -0.01251817560430778
        total_loss: 21.248673231705375
        vf_explained_var: 0.9646619558334351
        vf_loss: 21.259682696798574
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.886301369863013
    gpu_util_percent0: 0.2715068493150685
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.391780821917807
    vram_util_percent0: 0.10946211872745161
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74115
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1799334531605524
    mean_env_wait_ms: 1.6491185788036966
    mean_inference_ms: 5.1165176688828256
    mean_raw_obs_processing_ms: 0.5328415835466389
  time_since_restore: 251.0295057296753
  time_this_iter_s: 62.230217695236206
  time_total_s: 251.0295057296753
  timers:
    learn_throughput: 7242.908
    learn_time_ms: 50260.476
    sample_throughput: 29403.66
    sample_time_ms: 12380.5
    update_time_ms: 38.123
  timestamp: 1602424409
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 4
  trial_id: 8aa5e_00000
  
== Status ==
Memory usage on this node: 32.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8aa5e_00000 | RUNNING  | 172.17.0.4:74115 |      4 |           251.03 | 1456128 |  222.652 |              269.354 |              128.444 |            882.211 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8aa5e_00000:
  custom_metrics:
    time_step_max: 4194
    time_step_mean: 3577.8778330569376
    time_step_min: 3221
  date: 2020-10-11_13-54-31
  done: false
  episode_len_mean: 878.209388185654
  episode_reward_max: 277.98989898989817
  episode_reward_mean: 224.53933320547222
  episode_reward_min: 128.4444444444439
  episodes_this_iter: 400
  episodes_total: 1896
  experiment_id: e4cd25b71e7c4145a301f82edbbc5692
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 4.999999999999999e-05
        entropy: 1.117929458618164
        entropy_coeff: 9.999999999999998e-05
        kl: 0.008258434417455093
        model: {}
        policy_loss: -0.01420458345471517
        total_loss: 15.847244884656822
        vf_explained_var: 0.9673294425010681
        vf_loss: 15.859909596650496
    num_steps_sampled: 1820160
    num_steps_trained: 1820160
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.041095890410954
    gpu_util_percent0: 0.28931506849315064
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.342465753424657
    vram_util_percent0: 0.10946211872745161
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74115
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.178919045206437
    mean_env_wait_ms: 1.6502266500581562
    mean_inference_ms: 5.016181752525861
    mean_raw_obs_processing_ms: 0.5278112285292267
  time_since_restore: 312.8770568370819
  time_this_iter_s: 61.847551107406616
  time_total_s: 312.8770568370819
  timers:
    learn_throughput: 7246.278
    learn_time_ms: 50237.102
    sample_throughput: 29790.51
    sample_time_ms: 12219.73
    update_time_ms: 38.014
  timestamp: 1602424471
  timesteps_since_restore: 0
  timesteps_total: 1820160
  training_iteration: 5
  trial_id: 8aa5e_00000
  
== Status ==
Memory usage on this node: 31.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8aa5e_00000 | RUNNING  | 172.17.0.4:74115 |      5 |          312.877 | 1820160 |  224.539 |               277.99 |              128.444 |            878.209 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8aa5e_00000:
  custom_metrics:
    time_step_max: 4194
    time_step_mean: 3560.568112133158
    time_step_min: 3221
  date: 2020-10-11_13-55-33
  done: false
  episode_len_mean: 873.7616033755274
  episode_reward_max: 277.98989898989817
  episode_reward_mean: 226.8768699654774
  episode_reward_min: 128.4444444444439
  episodes_this_iter: 474
  episodes_total: 2370
  experiment_id: e4cd25b71e7c4145a301f82edbbc5692
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 4.999999999999999e-05
        entropy: 1.0834074694177378
        entropy_coeff: 9.999999999999998e-05
        kl: 0.007797047880518696
        model: {}
        policy_loss: -0.014023793749916165
        total_loss: 17.573253051094387
        vf_explained_var: 0.9736023545265198
        vf_loss: 17.58582604449728
    num_steps_sampled: 2184192
    num_steps_trained: 2184192
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.927397260273974
    gpu_util_percent0: 0.2882191780821918
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.384931506849314
    vram_util_percent0: 0.10946211872745161
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74115
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17805316849850444
    mean_env_wait_ms: 1.6522471398711582
    mean_inference_ms: 4.928430008596241
    mean_raw_obs_processing_ms: 0.5235254309165815
  time_since_restore: 374.5583016872406
  time_this_iter_s: 61.68124485015869
  time_total_s: 374.5583016872406
  timers:
    learn_throughput: 7246.53
    learn_time_ms: 50235.352
    sample_throughput: 30162.968
    sample_time_ms: 12068.839
    update_time_ms: 37.805
  timestamp: 1602424533
  timesteps_since_restore: 0
  timesteps_total: 2184192
  training_iteration: 6
  trial_id: 8aa5e_00000
  
== Status ==
Memory usage on this node: 31.9/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8aa5e_00000 | RUNNING  | 172.17.0.4:74115 |      6 |          374.558 | 2184192 |  226.877 |               277.99 |              128.444 |            873.762 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8aa5e_00000:
  custom_metrics:
    time_step_max: 4194
    time_step_mean: 3546.76169749728
    time_step_min: 3216
  date: 2020-10-11_13-56-35
  done: false
  episode_len_mean: 869.3199718706048
  episode_reward_max: 279.95959595959584
  episode_reward_mean: 229.1915782295527
  episode_reward_min: 128.4444444444439
  episodes_this_iter: 474
  episodes_total: 2844
  experiment_id: e4cd25b71e7c4145a301f82edbbc5692
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 4.999999999999999e-05
        entropy: 1.0596461607062297
        entropy_coeff: 9.999999999999998e-05
        kl: 0.0076266242110210915
        model: {}
        policy_loss: -0.013157146031279926
        total_loss: 15.461358526478643
        vf_explained_var: 0.9761604070663452
        vf_loss: 15.473096184108568
    num_steps_sampled: 2548224
    num_steps_trained: 2548224
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.0
    gpu_util_percent0: 0.26794520547945205
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.378082191780821
    vram_util_percent0: 0.10946211872745161
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74115
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17738980913433028
    mean_env_wait_ms: 1.6543609034552893
    mean_inference_ms: 4.862310539468071
    mean_raw_obs_processing_ms: 0.5203692801904108
  time_since_restore: 436.77010130882263
  time_this_iter_s: 62.21179962158203
  time_total_s: 436.77010130882263
  timers:
    learn_throughput: 7239.283
    learn_time_ms: 50285.643
    sample_throughput: 30378.499
    sample_time_ms: 11983.212
    update_time_ms: 38.551
  timestamp: 1602424595
  timesteps_since_restore: 0
  timesteps_total: 2548224
  training_iteration: 7
  trial_id: 8aa5e_00000
  
== Status ==
Memory usage on this node: 31.9/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8aa5e_00000 | RUNNING  | 172.17.0.4:74115 |      7 |           436.77 | 2548224 |  229.192 |               279.96 |              128.444 |             869.32 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8aa5e_00000:
  custom_metrics:
    time_step_max: 4194
    time_step_mean: 3532.530650154799
    time_step_min: 3212
  date: 2020-10-11_13-57-37
  done: false
  episode_len_mean: 864.6747060596925
  episode_reward_max: 280.86868686868667
  episode_reward_mean: 231.5234406165969
  episode_reward_min: 128.4444444444439
  episodes_this_iter: 473
  episodes_total: 3317
  experiment_id: e4cd25b71e7c4145a301f82edbbc5692
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 4.999999999999999e-05
        entropy: 1.0343353437340779
        entropy_coeff: 9.999999999999998e-05
        kl: 0.00758415883730935
        model: {}
        policy_loss: -0.014724571622260239
        total_loss: 14.608098403267238
        vf_explained_var: 0.9764426946640015
        vf_loss: 14.621409499126932
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.75945945945946
    gpu_util_percent0: 0.31175675675675674
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.358108108108107
    vram_util_percent0: 0.10946211872745162
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74115
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17687541737431792
    mean_env_wait_ms: 1.6563153879662271
    mean_inference_ms: 4.810274556153322
    mean_raw_obs_processing_ms: 0.5178983872426692
  time_since_restore: 498.87730264663696
  time_this_iter_s: 62.10720133781433
  time_total_s: 498.87730264663696
  timers:
    learn_throughput: 7236.427
    learn_time_ms: 50305.489
    sample_throughput: 30548.742
    sample_time_ms: 11916.432
    update_time_ms: 38.874
  timestamp: 1602424657
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 8
  trial_id: 8aa5e_00000
  
== Status ==
Memory usage on this node: 32.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8aa5e_00000 | RUNNING  | 172.17.0.4:74115 |      8 |          498.877 | 2912256 |  231.523 |              280.869 |              128.444 |            864.675 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8aa5e_00000:
  custom_metrics:
    time_step_max: 4194
    time_step_mean: 3520.2287581699347
    time_step_min: 3197
  date: 2020-10-11_13-58-40
  done: false
  episode_len_mean: 860.4368183027401
  episode_reward_max: 291.1717171717168
  episode_reward_mean: 233.28934194297307
  episode_reward_min: 128.4444444444439
  episodes_this_iter: 442
  episodes_total: 3759
  experiment_id: e4cd25b71e7c4145a301f82edbbc5692
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 4.999999999999999e-05
        entropy: 1.0131662151087886
        entropy_coeff: 9.999999999999998e-05
        kl: 0.0073463687592226525
        model: {}
        policy_loss: -0.013647499484131518
        total_loss: 14.04838752746582
        vf_explained_var: 0.9773040413856506
        vf_loss: 14.060667037963867
    num_steps_sampled: 3276288
    num_steps_trained: 3276288
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.078082191780823
    gpu_util_percent0: 0.30876712328767125
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.398630136986301
    vram_util_percent0: 0.10946211872745161
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74115
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17648448839514022
    mean_env_wait_ms: 1.6581916483258525
    mean_inference_ms: 4.770656933695576
    mean_raw_obs_processing_ms: 0.5160265596752591
  time_since_restore: 561.2566437721252
  time_this_iter_s: 62.37934112548828
  time_total_s: 561.2566437721252
  timers:
    learn_throughput: 7232.109
    learn_time_ms: 50335.526
    sample_throughput: 30626.85
    sample_time_ms: 11886.041
    update_time_ms: 39.149
  timestamp: 1602424720
  timesteps_since_restore: 0
  timesteps_total: 3276288
  training_iteration: 9
  trial_id: 8aa5e_00000
  
== Status ==
Memory usage on this node: 32.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8aa5e_00000 | RUNNING  | 172.17.0.4:74115 |      9 |          561.257 | 3276288 |  233.289 |              291.172 |              128.444 |            860.437 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8aa5e_00000:
  custom_metrics:
    time_step_max: 4194
    time_step_mean: 3512.8443609022556
    time_step_min: 3191
  date: 2020-10-11_13-59-42
  done: true
  episode_len_mean: 857.7637969094923
  episode_reward_max: 291.1717171717168
  episode_reward_mean: 234.40775674329743
  episode_reward_min: 128.4444444444439
  episodes_this_iter: 318
  episodes_total: 4077
  experiment_id: e4cd25b71e7c4145a301f82edbbc5692
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 4.999999999999999e-05
        entropy: 0.9943146005920742
        entropy_coeff: 9.999999999999998e-05
        kl: 0.007421842938208062
        model: {}
        policy_loss: -0.014674707204508393
        total_loss: 11.134782293568486
        vf_explained_var: 0.979915201663971
        vf_loss: 11.148072242736816
    num_steps_sampled: 3640320
    num_steps_trained: 3640320
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.891780821917806
    gpu_util_percent0: 0.3104109589041096
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.395890410958904
    vram_util_percent0: 0.10946211872745161
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74115
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1762298834114013
    mean_env_wait_ms: 1.6594820296857125
    mean_inference_ms: 4.745897275801867
    mean_raw_obs_processing_ms: 0.5148157475608238
  time_since_restore: 623.6569635868073
  time_this_iter_s: 62.40031981468201
  time_total_s: 623.6569635868073
  timers:
    learn_throughput: 7230.116
    learn_time_ms: 50349.402
    sample_throughput: 30658.51
    sample_time_ms: 11873.767
    update_time_ms: 39.274
  timestamp: 1602424782
  timesteps_since_restore: 0
  timesteps_total: 3640320
  training_iteration: 10
  trial_id: 8aa5e_00000
  
== Status ==
Memory usage on this node: 31.9/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8aa5e_00000 | TERMINATED |       |     10 |          623.657 | 3640320 |  234.408 |              291.172 |              128.444 |            857.764 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 31.9/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8aa5e_00000 | TERMINATED |       |     10 |          623.657 | 3640320 |  234.408 |              291.172 |              128.444 |            857.764 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


