2020-10-12 16:50:25,708	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_07807_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=15686)[0m 2020-10-12 16:50:28,455	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=15708)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15708)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15681)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15681)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15657)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15657)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15675)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15675)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15646)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15646)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15670)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15670)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15669)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15669)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15647)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15647)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15685)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15685)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15663)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15663)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15698)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15698)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15673)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15673)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15700)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15700)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15655)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15655)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15664)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15664)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15658)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15658)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15711)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15711)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15684)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15684)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15660)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15660)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15659)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15659)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15593)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15593)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15614)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15614)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15584)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15584)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15690)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15690)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15695)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15695)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15650)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15650)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15591)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15591)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15590)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15590)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15639)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15639)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15607)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15607)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15580)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15580)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15705)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15705)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15635)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15635)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15609)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15609)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15665)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15665)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15644)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15644)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15680)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15680)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15687)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15687)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15577)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15577)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15653)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15653)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15617)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15617)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15575)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15575)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15676)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15676)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15597)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15597)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15651)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15651)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15583)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15583)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15605)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15605)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15654)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15654)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15648)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15648)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15641)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15641)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15643)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15643)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15692)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15692)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15587)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15587)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15578)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15578)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15589)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15589)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15642)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15642)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15574)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15574)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15672)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15672)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15652)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15652)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15610)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15610)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15579)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15579)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15588)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15588)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15592)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15592)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15649)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15649)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15661)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15661)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15636)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15636)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15603)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15603)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15585)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15585)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15656)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15656)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15600)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15600)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15682)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15682)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15576)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15576)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15615)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15615)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15677)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15677)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15613)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15613)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15668)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15668)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15581)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15581)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15601)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15601)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15645)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15645)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_07807_00000:
  custom_metrics:
    time_step_max: 3941
    time_step_mean: 3510.563025210084
    time_step_min: 3241
  date: 2020-10-12_16-51-02
  done: false
  episode_len_mean: 895.2911392405064
  episode_reward_max: 255.28282828282772
  episode_reward_mean: 213.63438179260947
  episode_reward_min: 147.70707070707059
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 8629eaf0f2b44862b9e6aec4798c2701
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.169875721136729
        entropy_coeff: 0.009999999999999998
        kl: 0.008586584512765208
        model: {}
        policy_loss: -0.010982867776571462
        total_loss: 415.61239369710285
        vf_explained_var: 0.5660186409950256
        vf_loss: 415.63336181640625
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.647058823529413
    gpu_util_percent0: 0.3350000000000001
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5647058823529414
    vram_util_percent0: 0.08636872262844136
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15686
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16409954637537474
    mean_env_wait_ms: 1.1474889971364166
    mean_inference_ms: 5.703665122974062
    mean_raw_obs_processing_ms: 0.4355417000139595
  time_since_restore: 28.995835065841675
  time_this_iter_s: 28.995835065841675
  time_total_s: 28.995835065841675
  timers:
    learn_throughput: 8281.802
    learn_time_ms: 19535.845
    sample_throughput: 17234.161
    sample_time_ms: 9387.866
    update_time_ms: 26.196
  timestamp: 1602521462
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 07807_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_07807_00000 | RUNNING  | 172.17.0.4:15686 |      1 |          28.9958 | 161792 |  213.634 |              255.283 |              147.707 |            895.291 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_07807_00000:
  custom_metrics:
    time_step_max: 3941
    time_step_mean: 3527.1119133574007
    time_step_min: 3241
  date: 2020-10-12_16-51-29
  done: false
  episode_len_mean: 899.9367088607595
  episode_reward_max: 255.28282828282772
  episode_reward_mean: 211.10561309295468
  episode_reward_min: 147.70707070707059
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 8629eaf0f2b44862b9e6aec4798c2701
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1434311270713806
        entropy_coeff: 0.009999999999999998
        kl: 0.00766704767011106
        model: {}
        policy_loss: -0.010375477014652764
        total_loss: 99.00930913289388
        vf_explained_var: 0.8373656868934631
        vf_loss: 99.0295861562093
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.670967741935485
    gpu_util_percent0: 0.3835483870967742
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7580645161290316
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15686
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1604406792103414
    mean_env_wait_ms: 1.1468707442551247
    mean_inference_ms: 5.449396965505654
    mean_raw_obs_processing_ms: 0.4250963646419572
  time_since_restore: 56.01600170135498
  time_this_iter_s: 27.020166635513306
  time_total_s: 56.01600170135498
  timers:
    learn_throughput: 8338.695
    learn_time_ms: 19402.556
    sample_throughput: 18955.957
    sample_time_ms: 8535.153
    update_time_ms: 23.015
  timestamp: 1602521489
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 07807_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_07807_00000 | RUNNING  | 172.17.0.4:15686 |      2 |           56.016 | 323584 |  211.106 |              255.283 |              147.707 |            899.937 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_07807_00000:
  custom_metrics:
    time_step_max: 3975
    time_step_mean: 3530.4275862068966
    time_step_min: 3241
  date: 2020-10-12_16-51-56
  done: false
  episode_len_mean: 897.4198312236286
  episode_reward_max: 255.28282828282772
  episode_reward_mean: 210.15368878660004
  episode_reward_min: 142.55555555555537
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 8629eaf0f2b44862b9e6aec4798c2701
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1356730063756306
        entropy_coeff: 0.009999999999999998
        kl: 0.010440192883834243
        model: {}
        policy_loss: -0.01421508384282788
        total_loss: 44.57171090443929
        vf_explained_var: 0.9117375016212463
        vf_loss: 44.59519608815511
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.583870967741937
    gpu_util_percent0: 0.35677419354838713
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7741935483870965
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15686
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15805721739872225
    mean_env_wait_ms: 1.1482561641185236
    mean_inference_ms: 5.265778140171677
    mean_raw_obs_processing_ms: 0.41809759183896694
  time_since_restore: 82.47431015968323
  time_this_iter_s: 26.458308458328247
  time_total_s: 82.47431015968323
  timers:
    learn_throughput: 8360.941
    learn_time_ms: 19350.931
    sample_throughput: 20048.551
    sample_time_ms: 8070.01
    update_time_ms: 21.609
  timestamp: 1602521516
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 07807_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_07807_00000 | RUNNING  | 172.17.0.4:15686 |      3 |          82.4743 | 485376 |  210.154 |              255.283 |              142.556 |             897.42 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_07807_00000:
  custom_metrics:
    time_step_max: 3975
    time_step_mean: 3525.2360876897133
    time_step_min: 3220
  date: 2020-10-12_16-52-23
  done: false
  episode_len_mean: 893.9240506329114
  episode_reward_max: 256.9494949494951
  episode_reward_mean: 211.35614051911503
  episode_reward_min: 142.55555555555537
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 8629eaf0f2b44862b9e6aec4798c2701
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1133362551530201
        entropy_coeff: 0.009999999999999998
        kl: 0.010817148179436723
        model: {}
        policy_loss: -0.014024624814434597
        total_loss: 30.81566095352173
        vf_explained_var: 0.934317409992218
        vf_loss: 30.838656584421795
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.096774193548388
    gpu_util_percent0: 0.24709677419354836
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774193548387097
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15686
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15639631538554857
    mean_env_wait_ms: 1.1501959380789466
    mean_inference_ms: 5.134670061313615
    mean_raw_obs_processing_ms: 0.41278309653195366
  time_since_restore: 108.90818238258362
  time_this_iter_s: 26.43387222290039
  time_total_s: 108.90818238258362
  timers:
    learn_throughput: 8351.937
    learn_time_ms: 19371.794
    sample_throughput: 20795.886
    sample_time_ms: 7780.0
    update_time_ms: 26.571
  timestamp: 1602521543
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 07807_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_07807_00000 | RUNNING  | 172.17.0.4:15686 |      4 |          108.908 | 647168 |  211.356 |              256.949 |              142.556 |            893.924 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_07807_00000:
  custom_metrics:
    time_step_max: 3975
    time_step_mean: 3512.6005326231693
    time_step_min: 3220
  date: 2020-10-12_16-52-49
  done: false
  episode_len_mean: 888.5430379746836
  episode_reward_max: 256.9494949494951
  episode_reward_mean: 213.1186549034649
  episode_reward_min: 142.55555555555537
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 8629eaf0f2b44862b9e6aec4798c2701
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0988987584908803
        entropy_coeff: 0.009999999999999998
        kl: 0.00873963829750816
        model: {}
        policy_loss: -0.014397160654577116
        total_loss: 21.862969557444256
        vf_explained_var: 0.9500541090965271
        vf_loss: 21.886607964833576
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.45161290322581
    gpu_util_percent0: 0.3764516129032258
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15686
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15517662553718672
    mean_env_wait_ms: 1.1527456719700213
    mean_inference_ms: 5.03684337747497
    mean_raw_obs_processing_ms: 0.40863980110435577
  time_since_restore: 135.4663999080658
  time_this_iter_s: 26.558217525482178
  time_total_s: 135.4663999080658
  timers:
    learn_throughput: 8348.527
    learn_time_ms: 19379.705
    sample_throughput: 21186.364
    sample_time_ms: 7636.61
    update_time_ms: 28.022
  timestamp: 1602521569
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 07807_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_07807_00000 | RUNNING  | 172.17.0.4:15686 |      5 |          135.466 | 808960 |  213.119 |              256.949 |              142.556 |            888.543 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_07807_00000:
  custom_metrics:
    time_step_max: 3975
    time_step_mean: 3492.2255859375
    time_step_min: 3186
  date: 2020-10-12_16-53-16
  done: false
  episode_len_mean: 876.3471307619943
  episode_reward_max: 262.1010101010101
  episode_reward_mean: 215.60424565504516
  episode_reward_min: 142.55555555555537
  episodes_this_iter: 273
  episodes_total: 1063
  experiment_id: 8629eaf0f2b44862b9e6aec4798c2701
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0610859890778859
        entropy_coeff: 0.009999999999999998
        kl: 0.009997644849742452
        model: {}
        policy_loss: -0.013604718221661946
        total_loss: 28.10504388809204
        vf_explained_var: 0.9585136771202087
        vf_loss: 28.127259890238445
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.096774193548388
    gpu_util_percent0: 0.32
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.761290322580645
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15686
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15370887246747236
    mean_env_wait_ms: 1.1587012365962208
    mean_inference_ms: 4.920754445633204
    mean_raw_obs_processing_ms: 0.40377604155624813
  time_since_restore: 162.09298014640808
  time_this_iter_s: 26.626580238342285
  time_total_s: 162.09298014640808
  timers:
    learn_throughput: 8346.248
    learn_time_ms: 19384.998
    sample_throughput: 21416.639
    sample_time_ms: 7554.5
    update_time_ms: 26.803
  timestamp: 1602521596
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 07807_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_07807_00000 | RUNNING  | 172.17.0.4:15686 |      6 |          162.093 | 970752 |  215.604 |              262.101 |              142.556 |            876.347 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_07807_00000:
  custom_metrics:
    time_step_max: 3975
    time_step_mean: 3477.138775510204
    time_step_min: 3181
  date: 2020-10-12_16-53-42
  done: false
  episode_len_mean: 867.5981012658228
  episode_reward_max: 269.6767676767672
  episode_reward_mean: 217.8793232962536
  episode_reward_min: 142.55555555555537
  episodes_this_iter: 201
  episodes_total: 1264
  experiment_id: 8629eaf0f2b44862b9e6aec4798c2701
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0649357040723164
        entropy_coeff: 0.009999999999999998
        kl: 0.009841294415916005
        model: {}
        policy_loss: -0.014191708876751363
        total_loss: 16.985084851582844
        vf_explained_var: 0.9650461077690125
        vf_loss: 17.007957617441814
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.083870967741937
    gpu_util_percent0: 0.3270967741935483
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.783870967741935
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15686
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15294029604128956
    mean_env_wait_ms: 1.1622188438767642
    mean_inference_ms: 4.85860836211672
    mean_raw_obs_processing_ms: 0.40138211764387066
  time_since_restore: 188.55146169662476
  time_this_iter_s: 26.458481550216675
  time_total_s: 188.55146169662476
  timers:
    learn_throughput: 8346.238
    learn_time_ms: 19385.022
    sample_throughput: 21642.993
    sample_time_ms: 7475.491
    update_time_ms: 25.602
  timestamp: 1602521622
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 07807_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_07807_00000 | RUNNING  | 172.17.0.4:15686 |      7 |          188.551 | 1132544 |  217.879 |              269.677 |              142.556 |            867.598 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_07807_00000:
  custom_metrics:
    time_step_max: 3975
    time_step_mean: 3464.5864063629792
    time_step_min: 3136
  date: 2020-10-12_16-54-09
  done: false
  episode_len_mean: 861.3410689170183
  episode_reward_max: 269.67676767676767
  episode_reward_mean: 219.50926991433312
  episode_reward_min: 142.55555555555537
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 8629eaf0f2b44862b9e6aec4798c2701
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.043693333864212
        entropy_coeff: 0.009999999999999998
        kl: 0.010389981558546424
        model: {}
        policy_loss: -0.01672380777017679
        total_loss: 12.815481662750244
        vf_explained_var: 0.9701972603797913
        vf_loss: 12.840564330418905
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.60333333333333
    gpu_util_percent0: 0.3003333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7733333333333325
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15686
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15243830257895824
    mean_env_wait_ms: 1.164831690404316
    mean_inference_ms: 4.818607892910361
    mean_raw_obs_processing_ms: 0.39975827737634295
  time_since_restore: 214.78793334960938
  time_this_iter_s: 26.23647165298462
  time_total_s: 214.78793334960938
  timers:
    learn_throughput: 8356.524
    learn_time_ms: 19361.16
    sample_throughput: 21831.391
    sample_time_ms: 7410.98
    update_time_ms: 26.33
  timestamp: 1602521649
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 07807_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_07807_00000 | RUNNING  | 172.17.0.4:15686 |      8 |          214.788 | 1294336 |  219.509 |              269.677 |              142.556 |            861.341 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_07807_00000:
  custom_metrics:
    time_step_max: 3975
    time_step_mean: 3454.9811810512656
    time_step_min: 3136
  date: 2020-10-12_16-54-35
  done: false
  episode_len_mean: 855.1803797468355
  episode_reward_max: 269.67676767676767
  episode_reward_mean: 221.07243319268628
  episode_reward_min: 142.55555555555537
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 8629eaf0f2b44862b9e6aec4798c2701
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0012520551681519
        entropy_coeff: 0.009999999999999998
        kl: 0.009553081666429838
        model: {}
        policy_loss: -0.014334791475751748
        total_loss: 13.045639673868815
        vf_explained_var: 0.9696617722511292
        vf_loss: 13.068076610565186
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.164516129032258
    gpu_util_percent0: 0.2841935483870967
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.77741935483871
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15686
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15200854511418116
    mean_env_wait_ms: 1.1675553095501654
    mean_inference_ms: 4.783746058002277
    mean_raw_obs_processing_ms: 0.39827762524561466
  time_since_restore: 241.43186950683594
  time_this_iter_s: 26.643936157226562
  time_total_s: 241.43186950683594
  timers:
    learn_throughput: 8347.253
    learn_time_ms: 19382.665
    sample_throughput: 21970.278
    sample_time_ms: 7364.131
    update_time_ms: 28.658
  timestamp: 1602521675
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 07807_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_07807_00000 | RUNNING  | 172.17.0.4:15686 |      9 |          241.432 | 1456128 |  221.072 |              269.677 |              142.556 |             855.18 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_07807_00000:
  custom_metrics:
    time_step_max: 3975
    time_step_mean: 3435.700053850296
    time_step_min: 3119
  date: 2020-10-12_16-55-02
  done: false
  episode_len_mean: 844.4372362869199
  episode_reward_max: 272.25252525252523
  episode_reward_mean: 224.05744150364401
  episode_reward_min: 142.55555555555537
  episodes_this_iter: 316
  episodes_total: 1896
  experiment_id: 8629eaf0f2b44862b9e6aec4798c2701
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9644764512777328
        entropy_coeff: 0.009999999999999998
        kl: 0.008954003220424056
        model: {}
        policy_loss: -0.013493084872607142
        total_loss: 15.182947476704916
        vf_explained_var: 0.9757793545722961
        vf_loss: 15.204294522603353
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.970967741935485
    gpu_util_percent0: 0.3787096774193549
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15686
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15131160803334312
    mean_env_wait_ms: 1.172941416171292
    mean_inference_ms: 4.727383055406805
    mean_raw_obs_processing_ms: 0.39597446919642754
  time_since_restore: 267.77437925338745
  time_this_iter_s: 26.342509746551514
  time_total_s: 267.77437925338745
  timers:
    learn_throughput: 8349.493
    learn_time_ms: 19377.464
    sample_throughput: 22101.934
    sample_time_ms: 7320.265
    update_time_ms: 28.446
  timestamp: 1602521702
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 07807_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_07807_00000 | RUNNING  | 172.17.0.4:15686 |     10 |          267.774 | 1617920 |  224.057 |              272.253 |              142.556 |            844.437 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_07807_00000:
  custom_metrics:
    time_step_max: 3975
    time_step_mean: 3428.0516129032258
    time_step_min: 3119
  date: 2020-10-12_16-55-28
  done: false
  episode_len_mean: 840.309152872444
  episode_reward_max: 272.25252525252523
  episode_reward_mean: 225.25324815831144
  episode_reward_min: 142.55555555555537
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 8629eaf0f2b44862b9e6aec4798c2701
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.96255591015021
        entropy_coeff: 0.009999999999999998
        kl: 0.008941442395250002
        model: {}
        policy_loss: -0.01287941460032016
        total_loss: 11.461668411890665
        vf_explained_var: 0.9738096594810486
        vf_loss: 11.482385079065958
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.223333333333336
    gpu_util_percent0: 0.3016666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15686
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1510248892327325
    mean_env_wait_ms: 1.1752222333487095
    mean_inference_ms: 4.704296945373054
    mean_raw_obs_processing_ms: 0.395000318223251
  time_since_restore: 294.03288221359253
  time_this_iter_s: 26.258502960205078
  time_total_s: 294.03288221359253
  timers:
    learn_throughput: 8356.893
    learn_time_ms: 19360.305
    sample_throughput: 22907.939
    sample_time_ms: 7062.704
    update_time_ms: 28.479
  timestamp: 1602521728
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 07807_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_07807_00000 | RUNNING  | 172.17.0.4:15686 |     11 |          294.033 | 1779712 |  225.253 |              272.253 |              142.556 |            840.309 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_07807_00000:
  custom_metrics:
    time_step_max: 3975
    time_step_mean: 3420.482742751956
    time_step_min: 3119
  date: 2020-10-12_16-55-55
  done: false
  episode_len_mean: 836.4647377938517
  episode_reward_max: 272.70707070707084
  episode_reward_mean: 226.36795623504483
  episode_reward_min: 142.55555555555537
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 8629eaf0f2b44862b9e6aec4798c2701
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9433284004529318
        entropy_coeff: 0.009999999999999998
        kl: 0.00915271796596547
        model: {}
        policy_loss: -0.016452860824453335
        total_loss: 10.803847630818685
        vf_explained_var: 0.9729583859443665
        vf_loss: 10.827903270721436
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.187096774193545
    gpu_util_percent0: 0.3670967741935484
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.787096774193548
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15686
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15076822762744976
    mean_env_wait_ms: 1.177398036924077
    mean_inference_ms: 4.68338554405726
    mean_raw_obs_processing_ms: 0.3940841699930706
  time_since_restore: 320.48033261299133
  time_this_iter_s: 26.447450399398804
  time_total_s: 320.48033261299133
  timers:
    learn_throughput: 8348.914
    learn_time_ms: 19378.809
    sample_throughput: 23158.047
    sample_time_ms: 6986.427
    update_time_ms: 28.456
  timestamp: 1602521755
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 07807_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_07807_00000 | RUNNING  | 172.17.0.4:15686 |     12 |           320.48 | 1941504 |  226.368 |              272.707 |              142.556 |            836.465 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_07807_00000:
  custom_metrics:
    time_step_max: 3975
    time_step_mean: 3406.453915171289
    time_step_min: 3072
  date: 2020-10-12_16-56-21
  done: false
  episode_len_mean: 830.2468887996788
  episode_reward_max: 279.37373737373713
  episode_reward_mean: 228.4816774732471
  episode_reward_min: 142.55555555555537
  episodes_this_iter: 279
  episodes_total: 2491
  experiment_id: 8629eaf0f2b44862b9e6aec4798c2701
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.885526696840922
        entropy_coeff: 0.009999999999999998
        kl: 0.009026464462901155
        model: {}
        policy_loss: -0.013321156012049565
        total_loss: 15.117031415303549
        vf_explained_var: 0.9745559096336365
        vf_loss: 15.137402852376303
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.190322580645166
    gpu_util_percent0: 0.3374193548387097
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15686
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15037824925935794
    mean_env_wait_ms: 1.181128322276034
    mean_inference_ms: 4.651567779964636
    mean_raw_obs_processing_ms: 0.39266296316135735
  time_since_restore: 346.9755265712738
  time_this_iter_s: 26.49519395828247
  time_total_s: 346.9755265712738
  timers:
    learn_throughput: 8340.931
    learn_time_ms: 19397.355
    sample_throughput: 23210.855
    sample_time_ms: 6970.532
    update_time_ms: 28.895
  timestamp: 1602521781
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 07807_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_07807_00000 | RUNNING  | 172.17.0.4:15686 |     13 |          346.976 | 2103296 |  228.482 |              279.374 |              142.556 |            830.247 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_07807_00000:
  custom_metrics:
    time_step_max: 3975
    time_step_mean: 3399.2077823951645
    time_step_min: 3072
  date: 2020-10-12_16-56-48
  done: false
  episode_len_mean: 826.5487714072971
  episode_reward_max: 279.37373737373713
  episode_reward_mean: 229.6864136525343
  episode_reward_min: 142.55555555555537
  episodes_this_iter: 195
  episodes_total: 2686
  experiment_id: 8629eaf0f2b44862b9e6aec4798c2701
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.891442542274793
        entropy_coeff: 0.009999999999999998
        kl: 0.007918225058043996
        model: {}
        policy_loss: -0.011229118489306225
        total_loss: 8.98637318611145
        vf_explained_var: 0.9800209999084473
        vf_loss: 9.00493335723877
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.229032258064517
    gpu_util_percent0: 0.2983870967741935
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.787096774193548
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15686
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15014498855786199
    mean_env_wait_ms: 1.183474353087495
    mean_inference_ms: 4.632135034832948
    mean_raw_obs_processing_ms: 0.39186827951733794
  time_since_restore: 373.4653515815735
  time_this_iter_s: 26.489825010299683
  time_total_s: 373.4653515815735
  timers:
    learn_throughput: 8338.76
    learn_time_ms: 19402.406
    sample_throughput: 23214.233
    sample_time_ms: 6969.517
    update_time_ms: 28.98
  timestamp: 1602521808
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 07807_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_07807_00000 | RUNNING  | 172.17.0.4:15686 |     14 |          373.465 | 2265088 |  229.686 |              279.374 |              142.556 |            826.549 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_07807_00000:
  custom_metrics:
    time_step_max: 3975
    time_step_mean: 3392.6819964349374
    time_step_min: 3072
  date: 2020-10-12_16-57-14
  done: false
  episode_len_mean: 824.0545007032349
  episode_reward_max: 279.37373737373713
  episode_reward_mean: 230.68798746963307
  episode_reward_min: 142.55555555555537
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 8629eaf0f2b44862b9e6aec4798c2701
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8936072091261545
        entropy_coeff: 0.009999999999999998
        kl: 0.008960986121868094
        model: {}
        policy_loss: -0.01388007173469911
        total_loss: 9.011537790298462
        vf_explained_var: 0.9766192436218262
        vf_loss: 9.032561937967936
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.803333333333335
    gpu_util_percent0: 0.30166666666666664
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15686
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14997185346118497
    mean_env_wait_ms: 1.1851966669222174
    mean_inference_ms: 4.617874439122503
    mean_raw_obs_processing_ms: 0.39124517816664695
  time_since_restore: 399.68290519714355
  time_this_iter_s: 26.21755361557007
  time_total_s: 399.68290519714355
  timers:
    learn_throughput: 8341.826
    learn_time_ms: 19395.275
    sample_throughput: 23305.419
    sample_time_ms: 6942.248
    update_time_ms: 28.582
  timestamp: 1602521834
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 07807_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_07807_00000 | RUNNING  | 172.17.0.4:15686 |     15 |          399.683 | 2426880 |  230.688 |              279.374 |              142.556 |            824.055 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_07807_00000:
  custom_metrics:
    time_step_max: 3975
    time_step_mean: 3384.103562005277
    time_step_min: 3026
  date: 2020-10-12_16-57-41
  done: false
  episode_len_mean: 820.7730380983393
  episode_reward_max: 286.34343434343424
  episode_reward_mean: 232.08591285699725
  episode_reward_min: 142.55555555555537
  episodes_this_iter: 227
  episodes_total: 3071
  experiment_id: 8629eaf0f2b44862b9e6aec4798c2701
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8437182505925497
        entropy_coeff: 0.009999999999999998
        kl: 0.007974121913624307
        model: {}
        policy_loss: -0.012678359790394703
        total_loss: 12.515917936960856
        vf_explained_var: 0.9767115116119385
        vf_loss: 12.535438934961954
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.277419354838713
    gpu_util_percent0: 0.38451612903225807
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.767741935483871
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15686
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14974383821157997
    mean_env_wait_ms: 1.1875712566631642
    mean_inference_ms: 4.599562168541507
    mean_raw_obs_processing_ms: 0.39042115821667633
  time_since_restore: 425.8913788795471
  time_this_iter_s: 26.208473682403564
  time_total_s: 425.8913788795471
  timers:
    learn_throughput: 8344.598
    learn_time_ms: 19388.832
    sample_throughput: 23428.535
    sample_time_ms: 6905.767
    update_time_ms: 28.603
  timestamp: 1602521861
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 07807_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_07807_00000 | RUNNING  | 172.17.0.4:15686 |     16 |          425.891 | 2588672 |  232.086 |              286.343 |              142.556 |            820.773 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_07807_00000:
  custom_metrics:
    time_step_max: 3975
    time_step_mean: 3374.5227203415675
    time_step_min: 3026
  date: 2020-10-12_16-58-07
  done: false
  episode_len_mean: 817.6531042796865
  episode_reward_max: 286.34343434343424
  episode_reward_mean: 233.54629477414292
  episode_reward_min: 142.55555555555537
  episodes_this_iter: 247
  episodes_total: 3318
  experiment_id: 8629eaf0f2b44862b9e6aec4798c2701
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8292519450187683
        entropy_coeff: 0.009999999999999998
        kl: 0.008397612875948349
        model: {}
        policy_loss: -0.013120929666911252
        total_loss: 9.006597757339478
        vf_explained_var: 0.9819083213806152
        vf_loss: 9.026331583658854
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.125806451612902
    gpu_util_percent0: 0.29967741935483866
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15686
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14952770398447046
    mean_env_wait_ms: 1.1898982764992527
    mean_inference_ms: 4.5812394226867
    mean_raw_obs_processing_ms: 0.389634257219813
  time_since_restore: 452.49880266189575
  time_this_iter_s: 26.607423782348633
  time_total_s: 452.49880266189575
  timers:
    learn_throughput: 8335.193
    learn_time_ms: 19410.707
    sample_throughput: 23461.84
    sample_time_ms: 6895.964
    update_time_ms: 30.803
  timestamp: 1602521887
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 07807_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_07807_00000 | RUNNING  | 172.17.0.4:15686 |     17 |          452.499 | 2750464 |  233.546 |              286.343 |              142.556 |            817.653 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_07807_00000:
  custom_metrics:
    time_step_max: 3975
    time_step_mean: 3369.4515565900497
    time_step_min: 3026
  date: 2020-10-12_16-58-34
  done: false
  episode_len_mean: 815.9079401611048
  episode_reward_max: 286.34343434343424
  episode_reward_mean: 234.3875114784206
  episode_reward_min: 142.55555555555537
  episodes_this_iter: 158
  episodes_total: 3476
  experiment_id: 8629eaf0f2b44862b9e6aec4798c2701
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8419846345980962
        entropy_coeff: 0.009999999999999998
        kl: 0.00922968975889186
        model: {}
        policy_loss: -0.014930436367042907
        total_loss: 8.153529047966003
        vf_explained_var: 0.978463888168335
        vf_loss: 8.175033330917358
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.343333333333337
    gpu_util_percent0: 0.3456666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15686
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14940063494355954
    mean_env_wait_ms: 1.1912424240024564
    mean_inference_ms: 4.570742264330862
    mean_raw_obs_processing_ms: 0.38916823402092265
  time_since_restore: 478.6278052330017
  time_this_iter_s: 26.129002571105957
  time_total_s: 478.6278052330017
  timers:
    learn_throughput: 8329.971
    learn_time_ms: 19422.877
    sample_throughput: 23539.545
    sample_time_ms: 6873.2
    update_time_ms: 29.869
  timestamp: 1602521914
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 07807_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_07807_00000 | RUNNING  | 172.17.0.4:15686 |     18 |          478.628 | 2912256 |  234.388 |              286.343 |              142.556 |            815.908 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_07807_00000:
  custom_metrics:
    time_step_max: 3975
    time_step_mean: 3362.9655931736856
    time_step_min: 3026
  date: 2020-10-12_16-59-00
  done: false
  episode_len_mean: 813.7723311546841
  episode_reward_max: 286.34343434343424
  episode_reward_mean: 235.43900607381005
  episode_reward_min: 142.55555555555537
  episodes_this_iter: 196
  episodes_total: 3672
  experiment_id: 8629eaf0f2b44862b9e6aec4798c2701
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7971992095311483
        entropy_coeff: 0.009999999999999998
        kl: 0.009217347096030911
        model: {}
        policy_loss: -0.014890128484694287
        total_loss: 9.942100365956625
        vf_explained_var: 0.9790628552436829
        vf_loss: 9.96311902999878
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.7
    gpu_util_percent0: 0.3587096774193549
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774193548387097
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15686
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14924904518376825
    mean_env_wait_ms: 1.1928475201127233
    mean_inference_ms: 4.558677164508598
    mean_raw_obs_processing_ms: 0.38862022354222586
  time_since_restore: 505.0090398788452
  time_this_iter_s: 26.381234645843506
  time_total_s: 505.0090398788452
  timers:
    learn_throughput: 8336.967
    learn_time_ms: 19406.579
    sample_throughput: 23577.243
    sample_time_ms: 6862.21
    update_time_ms: 28.825
  timestamp: 1602521940
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 07807_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_07807_00000 | RUNNING  | 172.17.0.4:15686 |     19 |          505.009 | 3074048 |  235.439 |              286.343 |              142.556 |            813.772 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_07807_00000:
  custom_metrics:
    time_step_max: 3975
    time_step_mean: 3353.8230631552033
    time_step_min: 3026
  date: 2020-10-12_16-59-27
  done: false
  episode_len_mean: 810.7762025316456
  episode_reward_max: 286.34343434343424
  episode_reward_mean: 236.84120956399443
  episode_reward_min: 142.55555555555537
  episodes_this_iter: 278
  episodes_total: 3950
  experiment_id: 8629eaf0f2b44862b9e6aec4798c2701
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7776136149962743
        entropy_coeff: 0.009999999999999998
        kl: 0.007232995082934697
        model: {}
        policy_loss: -0.012186882959213108
        total_loss: 9.500701506932577
        vf_explained_var: 0.9819806218147278
        vf_loss: 9.519217491149902
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.609677419354835
    gpu_util_percent0: 0.3048387096774194
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7741935483870965
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15686
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1490644298217139
    mean_env_wait_ms: 1.1949989683236775
    mean_inference_ms: 4.543022164200832
    mean_raw_obs_processing_ms: 0.3879298920208774
  time_since_restore: 531.4766523838043
  time_this_iter_s: 26.467612504959106
  time_total_s: 531.4766523838043
  timers:
    learn_throughput: 8337.451
    learn_time_ms: 19405.452
    sample_throughput: 23536.665
    sample_time_ms: 6874.041
    update_time_ms: 29.309
  timestamp: 1602521967
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 07807_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_07807_00000 | RUNNING  | 172.17.0.4:15686 |     20 |          531.477 | 3235840 |  236.841 |              286.343 |              142.556 |            810.776 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_07807_00000:
  custom_metrics:
    time_step_max: 3975
    time_step_mean: 3349.2415826984516
    time_step_min: 3026
  date: 2020-10-12_16-59-53
  done: false
  episode_len_mean: 809.0993184031158
  episode_reward_max: 286.34343434343424
  episode_reward_mean: 237.5678744602796
  episode_reward_min: 142.55555555555537
  episodes_this_iter: 158
  episodes_total: 4108
  experiment_id: 8629eaf0f2b44862b9e6aec4798c2701
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8009628107150396
        entropy_coeff: 0.009999999999999998
        kl: 0.008123979593316713
        model: {}
        policy_loss: -0.012853600734767193
        total_loss: 7.859641909599304
        vf_explained_var: 0.9788579344749451
        vf_loss: 7.8788801829020185
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.476666666666663
    gpu_util_percent0: 0.32499999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15686
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14896614714718737
    mean_env_wait_ms: 1.1961153810740695
    mean_inference_ms: 4.534906850198911
    mean_raw_obs_processing_ms: 0.38756664768406535
  time_since_restore: 557.8363585472107
  time_this_iter_s: 26.359706163406372
  time_total_s: 557.8363585472107
  timers:
    learn_throughput: 8339.671
    learn_time_ms: 19400.285
    sample_throughput: 23487.319
    sample_time_ms: 6888.483
    update_time_ms: 28.904
  timestamp: 1602521993
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 07807_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_07807_00000 | RUNNING  | 172.17.0.4:15686 |     21 |          557.836 | 3397632 |  237.568 |              286.343 |              142.556 |            809.099 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_07807_00000:
  custom_metrics:
    time_step_max: 3975
    time_step_mean: 3343.3110642287857
    time_step_min: 3007
  date: 2020-10-12_17-00-20
  done: false
  episode_len_mean: 807.1379790940766
  episode_reward_max: 289.22222222222257
  episode_reward_mean: 238.48755851194886
  episode_reward_min: 142.55555555555537
  episodes_this_iter: 197
  episodes_total: 4305
  experiment_id: 8629eaf0f2b44862b9e6aec4798c2701
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7586390972137451
        entropy_coeff: 0.009999999999999998
        kl: 0.008810345704356829
        model: {}
        policy_loss: -0.014654385119987031
        total_loss: 10.276155630747477
        vf_explained_var: 0.9781619906425476
        vf_loss: 10.296634356180826
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.94516129032258
    gpu_util_percent0: 0.4045161290322581
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770967741935483
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15686
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1488439244247358
    mean_env_wait_ms: 1.19747651667191
    mean_inference_ms: 4.52544853221125
    mean_raw_obs_processing_ms: 0.3871403123563631
  time_since_restore: 584.2654433250427
  time_this_iter_s: 26.42908477783203
  time_total_s: 584.2654433250427
  timers:
    learn_throughput: 8344.21
    learn_time_ms: 19389.732
    sample_throughput: 23469.39
    sample_time_ms: 6893.745
    update_time_ms: 31.129
  timestamp: 1602522020
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 07807_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_07807_00000 | RUNNING  | 172.17.0.4:15686 |     22 |          584.265 | 3559424 |  238.488 |              289.222 |              142.556 |            807.138 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_07807_00000:
  custom_metrics:
    time_step_max: 3975
    time_step_mean: 3335.469293418446
    time_step_min: 3007
  date: 2020-10-12_17-00-46
  done: true
  episode_len_mean: 804.7784810126582
  episode_reward_max: 290.43434343434376
  episode_reward_mean: 239.60990525067356
  episode_reward_min: 142.55555555555537
  episodes_this_iter: 277
  episodes_total: 4582
  experiment_id: 8629eaf0f2b44862b9e6aec4798c2701
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7443148444096247
        entropy_coeff: 0.009999999999999998
        kl: 0.007100946192319195
        model: {}
        policy_loss: -0.0110812839314652
        total_loss: 10.199726422627768
        vf_explained_var: 0.9805071949958801
        vf_loss: 10.216830571492514
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.964516129032262
    gpu_util_percent0: 0.32967741935483874
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15686
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1486994420270807
    mean_env_wait_ms: 1.1992617078571612
    mean_inference_ms: 4.5131264161683635
    mean_raw_obs_processing_ms: 0.3865926732753508
  time_since_restore: 610.8025562763214
  time_this_iter_s: 26.537112951278687
  time_total_s: 610.8025562763214
  timers:
    learn_throughput: 8346.151
    learn_time_ms: 19385.223
    sample_throughput: 23448.23
    sample_time_ms: 6899.966
    update_time_ms: 32.961
  timestamp: 1602522046
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 07807_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_07807_00000 | TERMINATED |       |     23 |          610.803 | 3721216 |   239.61 |              290.434 |              142.556 |            804.778 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_07807_00000 | TERMINATED |       |     23 |          610.803 | 3721216 |   239.61 |              290.434 |              142.556 |            804.778 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


