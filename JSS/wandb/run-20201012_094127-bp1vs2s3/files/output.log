2020-10-12 09:41:31,654	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_1cd33_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=15409)[0m 2020-10-12 09:41:34,369	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=15387)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15387)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15363)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15363)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15408)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15408)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15397)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15397)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15369)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15369)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15427)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15427)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15413)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15413)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15380)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15380)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15368)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15368)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15394)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15394)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15392)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15392)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15418)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15418)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15402)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15402)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15389)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15389)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15411)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15411)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15388)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15388)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15371)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15371)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15365)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15365)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15382)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15382)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15422)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15422)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15294)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15294)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15305)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15305)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15311)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15311)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15293)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15293)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15359)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15359)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15299)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15299)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15354)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15354)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15303)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15303)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15375)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15375)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15370)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15370)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15289)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15289)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15398)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15398)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15297)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15297)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15404)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15404)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15306)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15306)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15313)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15313)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15361)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15361)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15399)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15399)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15291)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15291)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15314)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15314)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15288)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15288)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15405)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15405)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15304)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15304)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15321)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15321)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15319)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15319)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15290)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15290)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15308)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15308)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15296)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15296)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15357)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15357)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15309)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15309)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15360)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15360)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15302)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15302)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15366)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15366)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15395)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15395)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15298)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15298)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15300)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15300)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15356)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15356)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15358)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15358)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15307)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15307)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15396)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15396)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15362)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15362)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15355)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15355)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15324)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15324)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15367)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15367)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15373)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15373)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15350)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15350)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15352)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15352)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15374)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15374)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15353)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15353)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15322)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15322)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15372)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15372)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15385)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15385)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15316)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15316)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15416)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15416)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15292)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15292)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15328)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15328)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15390)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15390)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15364)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15364)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15287)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15287)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_1cd33_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_09-42-04
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 9a18e29456c8418ea74db1acd1907ed2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1827652951081593
        entropy_coeff: 0.0001
        kl: 0.007272620219737291
        model: {}
        policy_loss: -0.007613244587749553
        total_loss: 514.7338180541992
        vf_explained_var: 0.4917435944080353
        vf_loss: 514.7400767008463
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.096551724137928
    gpu_util_percent0: 0.28034482758620693
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5482758620689663
    vram_util_percent0: 0.08518055665509329
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16719988298548635
    mean_env_wait_ms: 1.1723686552739652
    mean_inference_ms: 5.654562095978923
    mean_raw_obs_processing_ms: 0.44828229128633545
  time_since_restore: 24.73012089729309
  time_this_iter_s: 24.73012089729309
  time_total_s: 24.73012089729309
  timers:
    learn_throughput: 10320.222
    learn_time_ms: 15677.182
    sample_throughput: 18007.396
    sample_time_ms: 8984.753
    update_time_ms: 29.302
  timestamp: 1602495724
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 1cd33_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |      1 |          24.7301 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1cd33_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3628.777777777778
    time_step_min: 3352
  date: 2020-10-12_09-42-27
  done: false
  episode_len_mean: 891.1075949367089
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.1851425648892
  episode_reward_min: 138.29292929292922
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 9a18e29456c8418ea74db1acd1907ed2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1526374816894531
        entropy_coeff: 0.0001
        kl: 0.00941026327200234
        model: {}
        policy_loss: -0.006966680482340355
        total_loss: 150.38987477620444
        vf_explained_var: 0.788153886795044
        vf_loss: 150.39507675170898
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.85555555555556
    gpu_util_percent0: 0.2437037037037037
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7518518518518515
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16348414029564448
    mean_env_wait_ms: 1.167435498228299
    mean_inference_ms: 5.453774285819036
    mean_raw_obs_processing_ms: 0.4380923883127803
  time_since_restore: 48.18699240684509
  time_this_iter_s: 23.456871509552002
  time_total_s: 48.18699240684509
  timers:
    learn_throughput: 10361.762
    learn_time_ms: 15614.332
    sample_throughput: 19268.285
    sample_time_ms: 8396.803
    update_time_ms: 37.785
  timestamp: 1602495747
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 1cd33_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |      2 |           48.187 | 323584 |  216.185 |              258.596 |              138.293 |            891.108 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1cd33_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3620.919282511211
    time_step_min: 3352
  date: 2020-10-12_09-42-50
  done: false
  episode_len_mean: 886.5253164556962
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 217.62197928653603
  episode_reward_min: 138.29292929292922
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 9a18e29456c8418ea74db1acd1907ed2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1465057929356892
        entropy_coeff: 0.0001
        kl: 0.007596938055939972
        model: {}
        policy_loss: -0.00962961143522989
        total_loss: 67.56635856628418
        vf_explained_var: 0.8835484385490417
        vf_loss: 67.57458432515462
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.669230769230772
    gpu_util_percent0: 0.22730769230769232
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765384615384615
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1609748364818216
    mean_env_wait_ms: 1.1668825514250778
    mean_inference_ms: 5.285935702802652
    mean_raw_obs_processing_ms: 0.4299000724180522
  time_since_restore: 70.7890784740448
  time_this_iter_s: 22.602086067199707
  time_total_s: 70.7890784740448
  timers:
    learn_throughput: 10389.349
    learn_time_ms: 15572.872
    sample_throughput: 20365.656
    sample_time_ms: 7944.355
    update_time_ms: 33.242
  timestamp: 1602495770
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 1cd33_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |      3 |          70.7891 | 485376 |  217.622 |              258.596 |              138.293 |            886.525 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1cd33_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3612.041390728477
    time_step_min: 3305
  date: 2020-10-12_09-43-13
  done: false
  episode_len_mean: 883.496835443038
  episode_reward_max: 265.26262626262604
  episode_reward_mean: 218.3276914716786
  episode_reward_min: 132.98989898989885
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 9a18e29456c8418ea74db1acd1907ed2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1241056124369304
        entropy_coeff: 0.0001
        kl: 0.011608533406009277
        model: {}
        policy_loss: -0.00946155054649959
        total_loss: 60.05288569132487
        vf_explained_var: 0.8973535895347595
        vf_loss: 60.060139656066895
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.76923076923077
    gpu_util_percent0: 0.25730769230769224
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.757692307692307
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15918644024100886
    mean_env_wait_ms: 1.1671787041913788
    mean_inference_ms: 5.161566920499106
    mean_raw_obs_processing_ms: 0.42358548790394485
  time_since_restore: 93.4354133605957
  time_this_iter_s: 22.646334886550903
  time_total_s: 93.4354133605957
  timers:
    learn_throughput: 10400.027
    learn_time_ms: 15556.883
    sample_throughput: 20944.531
    sample_time_ms: 7724.785
    update_time_ms: 30.506
  timestamp: 1602495793
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 1cd33_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |      4 |          93.4354 | 647168 |  218.328 |              265.263 |               132.99 |            883.497 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1cd33_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3606.551181102362
    time_step_min: 3305
  date: 2020-10-12_09-43-36
  done: false
  episode_len_mean: 881.6873417721519
  episode_reward_max: 265.26262626262604
  episode_reward_mean: 219.2177470911646
  episode_reward_min: 132.98989898989885
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 9a18e29456c8418ea74db1acd1907ed2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.096491704384486
        entropy_coeff: 0.0001
        kl: 0.008717880196248492
        model: {}
        policy_loss: -0.010342208658888316
        total_loss: 41.938445409139
        vf_explained_var: 0.9299905896186829
        vf_loss: 41.94715404510498
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.08846153846154
    gpu_util_percent0: 0.22923076923076927
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.761538461538461
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15783860786460846
    mean_env_wait_ms: 1.1679732276895893
    mean_inference_ms: 5.06718229484942
    mean_raw_obs_processing_ms: 0.4187261494125702
  time_since_restore: 116.06715679168701
  time_this_iter_s: 22.63174343109131
  time_total_s: 116.06715679168701
  timers:
    learn_throughput: 10387.849
    learn_time_ms: 15575.121
    sample_throughput: 21399.851
    sample_time_ms: 7560.427
    update_time_ms: 29.432
  timestamp: 1602495816
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 1cd33_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |      5 |          116.067 | 808960 |  219.218 |              265.263 |               132.99 |            881.687 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1cd33_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3598.375851996105
    time_step_min: 3232
  date: 2020-10-12_09-43-58
  done: false
  episode_len_mean: 875.7440758293839
  episode_reward_max: 276.32323232323233
  episode_reward_mean: 220.861649672076
  episode_reward_min: 127.9898989898988
  episodes_this_iter: 265
  episodes_total: 1055
  experiment_id: 9a18e29456c8418ea74db1acd1907ed2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0718888938426971
        entropy_coeff: 0.0001
        kl: 0.00855911266990006
        model: {}
        policy_loss: -0.008412331051658839
        total_loss: 43.087538401285805
        vf_explained_var: 0.950161874294281
        vf_loss: 43.09434572855631
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.08148148148148
    gpu_util_percent0: 0.25222222222222224
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7592592592592586
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15625250824378256
    mean_env_wait_ms: 1.1707091032801356
    mean_inference_ms: 4.955649532650974
    mean_raw_obs_processing_ms: 0.412994775757945
  time_since_restore: 138.94322419166565
  time_this_iter_s: 22.876067399978638
  time_total_s: 138.94322419166565
  timers:
    learn_throughput: 10357.435
    learn_time_ms: 15620.856
    sample_throughput: 21690.516
    sample_time_ms: 7459.112
    update_time_ms: 28.271
  timestamp: 1602495838
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 1cd33_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |      6 |          138.943 | 970752 |  220.862 |              276.323 |               127.99 |            875.744 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1cd33_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3588.668284789644
    time_step_min: 3232
  date: 2020-10-12_09-44-21
  done: false
  episode_len_mean: 871.2341772151899
  episode_reward_max: 276.32323232323233
  episode_reward_mean: 222.59301080424478
  episode_reward_min: 127.9898989898988
  episodes_this_iter: 209
  episodes_total: 1264
  experiment_id: 9a18e29456c8418ea74db1acd1907ed2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0818674564361572
        entropy_coeff: 0.0001
        kl: 0.00971197453327477
        model: {}
        policy_loss: -0.010616305696506364
        total_loss: 23.823532422383625
        vf_explained_var: 0.9594845771789551
        vf_loss: 23.83231512705485
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.46923076923077
    gpu_util_percent0: 0.22192307692307695
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769230769230769
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15537245096946856
    mean_env_wait_ms: 1.1723962844204818
    mean_inference_ms: 4.892394952236287
    mean_raw_obs_processing_ms: 0.40986308281523554
  time_since_restore: 161.52490735054016
  time_this_iter_s: 22.58168315887451
  time_total_s: 161.52490735054016
  timers:
    learn_throughput: 10365.723
    learn_time_ms: 15608.367
    sample_throughput: 21891.193
    sample_time_ms: 7390.735
    update_time_ms: 26.819
  timestamp: 1602495861
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 1cd33_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |      7 |          161.525 | 1132544 |  222.593 |              276.323 |               127.99 |            871.234 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1cd33_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3577.01649928264
    time_step_min: 3214
  date: 2020-10-12_09-44-44
  done: false
  episode_len_mean: 867.4001406469761
  episode_reward_max: 279.05050505050457
  episode_reward_mean: 224.2522056003067
  episode_reward_min: 127.9898989898988
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 9a18e29456c8418ea74db1acd1907ed2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0567615330219269
        entropy_coeff: 0.0001
        kl: 0.00996107313161095
        model: {}
        policy_loss: -0.011470459081465378
        total_loss: 18.90604877471924
        vf_explained_var: 0.9650539755821228
        vf_loss: 18.915632883707683
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.846153846153843
    gpu_util_percent0: 0.3761538461538461
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7769230769230764
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15482257370550753
    mean_env_wait_ms: 1.1737521015533703
    mean_inference_ms: 4.853095587210327
    mean_raw_obs_processing_ms: 0.40788148532503454
  time_since_restore: 184.23433375358582
  time_this_iter_s: 22.709426403045654
  time_total_s: 184.23433375358582
  timers:
    learn_throughput: 10360.714
    learn_time_ms: 15615.912
    sample_throughput: 22056.978
    sample_time_ms: 7335.184
    update_time_ms: 28.436
  timestamp: 1602495884
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 1cd33_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |      8 |          184.234 | 1294336 |  224.252 |              279.051 |               127.99 |              867.4 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1cd33_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3568.581829896907
    time_step_min: 3214
  date: 2020-10-12_09-45-07
  done: false
  episode_len_mean: 864.1550632911392
  episode_reward_max: 279.05050505050457
  episode_reward_mean: 225.24555683416426
  episode_reward_min: 127.9898989898988
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 9a18e29456c8418ea74db1acd1907ed2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0333571831385295
        entropy_coeff: 0.0001
        kl: 0.009536566135163108
        model: {}
        policy_loss: -0.01221390765082712
        total_loss: 19.71573845545451
        vf_explained_var: 0.9644169211387634
        vf_loss: 19.726147810618084
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.365384615384617
    gpu_util_percent0: 0.2776923076923077
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7730769230769234
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15434498849927897
    mean_env_wait_ms: 1.1750500902693974
    mean_inference_ms: 4.818796335363184
    mean_raw_obs_processing_ms: 0.40609763167483137
  time_since_restore: 207.12374019622803
  time_this_iter_s: 22.889406442642212
  time_total_s: 207.12374019622803
  timers:
    learn_throughput: 10337.867
    learn_time_ms: 15650.424
    sample_throughput: 22213.334
    sample_time_ms: 7283.553
    update_time_ms: 27.78
  timestamp: 1602495907
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 1cd33_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |      9 |          207.124 | 1456128 |  225.246 |              279.051 |               127.99 |            864.155 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1cd33_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3555.7805714285714
    time_step_min: 3191
  date: 2020-10-12_09-45-30
  done: false
  episode_len_mean: 858.9904386951631
  episode_reward_max: 282.5353535353537
  episode_reward_mean: 227.2556725863811
  episode_reward_min: 127.9898989898988
  episodes_this_iter: 198
  episodes_total: 1778
  experiment_id: 9a18e29456c8418ea74db1acd1907ed2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9826192061106364
        entropy_coeff: 0.0001
        kl: 0.008173057382615903
        model: {}
        policy_loss: -0.010862024593128202
        total_loss: 19.867599328358967
        vf_explained_var: 0.9715912342071533
        vf_loss: 19.876925468444824
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.685185185185187
    gpu_util_percent0: 0.3214814814814815
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15384385545962956
    mean_env_wait_ms: 1.1770206810921942
    mean_inference_ms: 4.782075729559632
    mean_raw_obs_processing_ms: 0.40416715160041744
  time_since_restore: 230.0156054496765
  time_this_iter_s: 22.891865253448486
  time_total_s: 230.0156054496765
  timers:
    learn_throughput: 10329.164
    learn_time_ms: 15663.61
    sample_throughput: 22295.036
    sample_time_ms: 7256.862
    update_time_ms: 28.799
  timestamp: 1602495930
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 1cd33_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     10 |          230.016 | 1617920 |  227.256 |              282.535 |               127.99 |             858.99 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1cd33_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3537.7013820335637
    time_step_min: 3178
  date: 2020-10-12_09-45-53
  done: false
  episode_len_mean: 852.246835443038
  episode_reward_max: 284.959595959596
  episode_reward_mean: 229.88133034335556
  episode_reward_min: 127.9898989898988
  episodes_this_iter: 276
  episodes_total: 2054
  experiment_id: 9a18e29456c8418ea74db1acd1907ed2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.980069100856781
        entropy_coeff: 0.0001
        kl: 0.008664651308208704
        model: {}
        policy_loss: -0.010285136828315444
        total_loss: 15.883270581563314
        vf_explained_var: 0.974926233291626
        vf_loss: 15.891921043395996
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.892307692307693
    gpu_util_percent0: 0.19692307692307692
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7615384615384615
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15324781903347287
    mean_env_wait_ms: 1.179404216594314
    mean_inference_ms: 4.739375283582631
    mean_raw_obs_processing_ms: 0.40196203413522014
  time_since_restore: 252.85740852355957
  time_this_iter_s: 22.841803073883057
  time_total_s: 252.85740852355957
  timers:
    learn_throughput: 10319.178
    learn_time_ms: 15678.768
    sample_throughput: 22948.39
    sample_time_ms: 7050.255
    update_time_ms: 30.064
  timestamp: 1602495953
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 1cd33_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     11 |          252.857 | 1779712 |  229.881 |               284.96 |               127.99 |            852.247 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1cd33_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3528.0755494505493
    time_step_min: 3178
  date: 2020-10-12_09-46-16
  done: false
  episode_len_mean: 848.6116636528029
  episode_reward_max: 284.959595959596
  episode_reward_mean: 231.47762434471284
  episode_reward_min: 127.9898989898988
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 9a18e29456c8418ea74db1acd1907ed2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9662584463755289
        entropy_coeff: 0.0001
        kl: 0.008741923840716481
        model: {}
        policy_loss: -0.011554634586597482
        total_loss: 12.84577759106954
        vf_explained_var: 0.9738784432411194
        vf_loss: 12.855680465698242
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.318518518518523
    gpu_util_percent0: 0.36111111111111116
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7740740740740737
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15296314168382433
    mean_env_wait_ms: 1.1806899230590775
    mean_inference_ms: 4.7187640040286425
    mean_raw_obs_processing_ms: 0.40088628297665907
  time_since_restore: 275.5384020805359
  time_this_iter_s: 22.68099355697632
  time_total_s: 275.5384020805359
  timers:
    learn_throughput: 10326.886
    learn_time_ms: 15667.066
    sample_throughput: 23205.705
    sample_time_ms: 6972.079
    update_time_ms: 27.402
  timestamp: 1602495976
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 1cd33_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     12 |          275.538 | 1941504 |  231.478 |               284.96 |               127.99 |            848.612 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1cd33_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3518.4350982066608
    time_step_min: 3174
  date: 2020-10-12_09-46-38
  done: false
  episode_len_mean: 845.4839662447257
  episode_reward_max: 285.111111111111
  episode_reward_mean: 233.07224140135523
  episode_reward_min: 127.9898989898988
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: 9a18e29456c8418ea74db1acd1907ed2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9387023200591406
        entropy_coeff: 0.0001
        kl: 0.008621097154294452
        model: {}
        policy_loss: -0.00967277765206139
        total_loss: 12.80953542391459
        vf_explained_var: 0.9729047417640686
        vf_loss: 12.817577521006266
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.83846153846154
    gpu_util_percent0: 0.3273076923076923
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.780769230769231
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15270777695146592
    mean_env_wait_ms: 1.181911912016204
    mean_inference_ms: 4.6999831064919215
    mean_raw_obs_processing_ms: 0.3998856494641744
  time_since_restore: 298.22470450401306
  time_this_iter_s: 22.686302423477173
  time_total_s: 298.22470450401306
  timers:
    learn_throughput: 10318.743
    learn_time_ms: 15679.429
    sample_throughput: 23225.474
    sample_time_ms: 6966.144
    update_time_ms: 28.708
  timestamp: 1602495998
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 1cd33_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     13 |          298.225 | 2103296 |  233.072 |              285.111 |               127.99 |            845.484 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1cd33_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3502.25966641395
    time_step_min: 3174
  date: 2020-10-12_09-47-01
  done: false
  episode_len_mean: 839.7460615153789
  episode_reward_max: 289.20202020202015
  episode_reward_mean: 235.52689687573402
  episode_reward_min: 127.9898989898988
  episodes_this_iter: 296
  episodes_total: 2666
  experiment_id: 9a18e29456c8418ea74db1acd1907ed2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9018679658571879
        entropy_coeff: 0.0001
        kl: 0.007377620747623344
        model: {}
        policy_loss: -0.008896974109423658
        total_loss: 17.63732163111369
        vf_explained_var: 0.9755610823631287
        vf_loss: 17.644832770029705
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.02307692307692
    gpu_util_percent0: 0.34461538461538466
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.753846153846154
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15229449529375025
    mean_env_wait_ms: 1.1842967672709355
    mean_inference_ms: 4.669254228442918
    mean_raw_obs_processing_ms: 0.39828135014453186
  time_since_restore: 320.7379891872406
  time_this_iter_s: 22.51328468322754
  time_total_s: 320.7379891872406
  timers:
    learn_throughput: 10319.958
    learn_time_ms: 15677.584
    sample_throughput: 23270.505
    sample_time_ms: 6952.664
    update_time_ms: 29.962
  timestamp: 1602496021
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 1cd33_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     14 |          320.738 | 2265088 |  235.527 |              289.202 |               127.99 |            839.746 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1cd33_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3493.146661931818
    time_step_min: 3111
  date: 2020-10-12_09-47-24
  done: false
  episode_len_mean: 836.4669479606189
  episode_reward_max: 294.6565656565655
  episode_reward_mean: 236.9221540297489
  episode_reward_min: 127.9898989898988
  episodes_this_iter: 178
  episodes_total: 2844
  experiment_id: 9a18e29456c8418ea74db1acd1907ed2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8971291532119116
        entropy_coeff: 0.0001
        kl: 0.007792771017799775
        model: {}
        policy_loss: -0.01206710331219559
        total_loss: 11.028913895289103
        vf_explained_var: 0.97767573595047
        vf_loss: 11.039512236913046
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.25925925925926
    gpu_util_percent0: 0.29851851851851846
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.781481481481481
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1520777230668347
    mean_env_wait_ms: 1.1856136436879912
    mean_inference_ms: 4.653484916351531
    mean_raw_obs_processing_ms: 0.39745939006799236
  time_since_restore: 343.63194274902344
  time_this_iter_s: 22.893953561782837
  time_total_s: 343.63194274902344
  timers:
    learn_throughput: 10323.846
    learn_time_ms: 15671.679
    sample_throughput: 23177.696
    sample_time_ms: 6980.504
    update_time_ms: 31.229
  timestamp: 1602496044
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 1cd33_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     15 |          343.632 | 2426880 |  236.922 |              294.657 |               127.99 |            836.467 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1cd33_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3485.8947545393407
    time_step_min: 3111
  date: 2020-10-12_09-47-47
  done: false
  episode_len_mean: 833.9077281812125
  episode_reward_max: 294.6565656565655
  episode_reward_mean: 238.04062274981655
  episode_reward_min: 127.9898989898988
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: 9a18e29456c8418ea74db1acd1907ed2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8899312863747278
        entropy_coeff: 0.0001
        kl: 0.008488959011932215
        model: {}
        policy_loss: -0.010237862666447958
        total_loss: 10.270389080047607
        vf_explained_var: 0.9769566655158997
        vf_loss: 10.27901848157247
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.696153846153848
    gpu_util_percent0: 0.28807692307692306
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769230769230769
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15189931799754364
    mean_env_wait_ms: 1.1867475833569647
    mean_inference_ms: 4.6404368159209435
    mean_raw_obs_processing_ms: 0.39677152911987984
  time_since_restore: 366.3158349990845
  time_this_iter_s: 22.683892250061035
  time_total_s: 366.3158349990845
  timers:
    learn_throughput: 10344.118
    learn_time_ms: 15640.966
    sample_throughput: 23143.103
    sample_time_ms: 6990.938
    update_time_ms: 31.546
  timestamp: 1602496067
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 1cd33_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     16 |          366.316 | 2588672 |  238.041 |              294.657 |               127.99 |            833.908 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1cd33_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3475.301276065982
    time_step_min: 3111
  date: 2020-10-12_09-48-10
  done: false
  episode_len_mean: 829.9645171243443
  episode_reward_max: 294.6565656565655
  episode_reward_mean: 239.72439919092182
  episode_reward_min: 127.9898989898988
  episodes_this_iter: 239
  episodes_total: 3241
  experiment_id: 9a18e29456c8418ea74db1acd1907ed2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8366131633520126
        entropy_coeff: 0.0001
        kl: 0.00847634948634853
        model: {}
        policy_loss: -0.011216631411419561
        total_loss: 12.429183880488077
        vf_explained_var: 0.9796220660209656
        vf_loss: 12.438788970311483
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.007407407407406
    gpu_util_percent0: 0.32185185185185183
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7592592592592586
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15165047693134606
    mean_env_wait_ms: 1.188484666843735
    mean_inference_ms: 4.622587604140873
    mean_raw_obs_processing_ms: 0.3958343784656538
  time_since_restore: 389.0548298358917
  time_this_iter_s: 22.73899483680725
  time_total_s: 389.0548298358917
  timers:
    learn_throughput: 10335.169
    learn_time_ms: 15654.509
    sample_throughput: 23147.303
    sample_time_ms: 6989.67
    update_time_ms: 33.686
  timestamp: 1602496090
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 1cd33_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     17 |          389.055 | 2750464 |  239.724 |              294.657 |               127.99 |            829.965 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1cd33_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3465.885150812065
    time_step_min: 3111
  date: 2020-10-12_09-48-33
  done: false
  episode_len_mean: 826.8173187571922
  episode_reward_max: 294.6565656565655
  episode_reward_mean: 241.0610884448628
  episode_reward_min: 127.9898989898988
  episodes_this_iter: 235
  episodes_total: 3476
  experiment_id: 9a18e29456c8418ea74db1acd1907ed2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8381501287221909
        entropy_coeff: 0.0001
        kl: 0.007169540428246061
        model: {}
        policy_loss: -0.010084045759867877
        total_loss: 10.701085885365805
        vf_explained_var: 0.981029748916626
        vf_loss: 10.709820111592611
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.207407407407405
    gpu_util_percent0: 0.2914814814814814
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7518518518518515
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1514377008951951
    mean_env_wait_ms: 1.1900698919360744
    mean_inference_ms: 4.606857549778642
    mean_raw_obs_processing_ms: 0.39502227879043644
  time_since_restore: 411.75859451293945
  time_this_iter_s: 22.70376467704773
  time_total_s: 411.75859451293945
  timers:
    learn_throughput: 10343.501
    learn_time_ms: 15641.899
    sample_throughput: 23136.695
    sample_time_ms: 6992.874
    update_time_ms: 33.346
  timestamp: 1602496113
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 1cd33_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     18 |          411.759 | 2912256 |  241.061 |              294.657 |               127.99 |            826.817 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1cd33_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3459.446755407654
    time_step_min: 3111
  date: 2020-10-12_09-48-56
  done: false
  episode_len_mean: 824.8090258668134
  episode_reward_max: 294.6565656565655
  episode_reward_mean: 242.09656832496674
  episode_reward_min: 127.9898989898988
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: 9a18e29456c8418ea74db1acd1907ed2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8284766972064972
        entropy_coeff: 0.0001
        kl: 0.008137651098271212
        model: {}
        policy_loss: -0.013230978317248324
        total_loss: 7.7549606164296465
        vf_explained_var: 0.9815869927406311
        vf_loss: 7.766646901766459
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.088461538461537
    gpu_util_percent0: 0.38923076923076927
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7807692307692307
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15130529253096925
    mean_env_wait_ms: 1.1910543649427872
    mean_inference_ms: 4.597200023030387
    mean_raw_obs_processing_ms: 0.3945180585983885
  time_since_restore: 434.47132658958435
  time_this_iter_s: 22.712732076644897
  time_total_s: 434.47132658958435
  timers:
    learn_throughput: 10371.676
    learn_time_ms: 15599.408
    sample_throughput: 23056.514
    sample_time_ms: 7017.193
    update_time_ms: 34.782
  timestamp: 1602496136
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 1cd33_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     19 |          434.471 | 3074048 |  242.097 |              294.657 |               127.99 |            824.809 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1cd33_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3451.6334472784642
    time_step_min: 3111
  date: 2020-10-12_09-49-18
  done: false
  episode_len_mean: 822.4053771861132
  episode_reward_max: 294.6565656565655
  episode_reward_mean: 243.31756879681694
  episode_reward_min: 127.9898989898988
  episodes_this_iter: 197
  episodes_total: 3831
  experiment_id: 9a18e29456c8418ea74db1acd1907ed2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7869208405415217
        entropy_coeff: 0.0001
        kl: 0.007604961205894749
        model: {}
        policy_loss: -0.010133413588240122
        total_loss: 9.840572754542032
        vf_explained_var: 0.981395423412323
        vf_loss: 9.8492640654246
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.67777777777778
    gpu_util_percent0: 0.2885185185185185
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7629629629629626
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15114941311387214
    mean_env_wait_ms: 1.1922685341408457
    mean_inference_ms: 4.586011574112173
    mean_raw_obs_processing_ms: 0.3939255104230208
  time_since_restore: 457.08566451072693
  time_this_iter_s: 22.614337921142578
  time_total_s: 457.08566451072693
  timers:
    learn_throughput: 10385.875
    learn_time_ms: 15578.081
    sample_throughput: 23103.616
    sample_time_ms: 7002.886
    update_time_ms: 41.171
  timestamp: 1602496158
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 1cd33_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     20 |          457.086 | 3235840 |  243.318 |              294.657 |               127.99 |            822.405 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1cd33_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3440.7480392156863
    time_step_min: 3104
  date: 2020-10-12_09-49-41
  done: false
  episode_len_mean: 819.3386075949367
  episode_reward_max: 295.7171717171717
  episode_reward_mean: 244.9092876181483
  episode_reward_min: 127.9898989898988
  episodes_this_iter: 277
  episodes_total: 4108
  experiment_id: 9a18e29456c8418ea74db1acd1907ed2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7745808561642965
        entropy_coeff: 0.0001
        kl: 0.0073812031575168175
        model: {}
        policy_loss: -0.009667965777528783
        total_loss: 11.363312005996704
        vf_explained_var: 0.9802958369255066
        vf_loss: 11.371581236521402
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.17777777777778
    gpu_util_percent0: 0.38370370370370377
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7629629629629626
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15095964670663803
    mean_env_wait_ms: 1.1939108660744921
    mean_inference_ms: 4.571771883008823
    mean_raw_obs_processing_ms: 0.3931828897760445
  time_since_restore: 480.1051948070526
  time_this_iter_s: 23.019530296325684
  time_total_s: 480.1051948070526
  timers:
    learn_throughput: 10396.548
    learn_time_ms: 15562.088
    sample_throughput: 22995.32
    sample_time_ms: 7035.867
    update_time_ms: 40.243
  timestamp: 1602496181
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 1cd33_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     21 |          480.105 | 3397632 |  244.909 |              295.717 |               127.99 |            819.339 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1cd33_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3435.5653610193485
    time_step_min: 3104
  date: 2020-10-12_09-50-04
  done: false
  episode_len_mean: 817.9139709329583
  episode_reward_max: 295.7171717171717
  episode_reward_mean: 245.59034082029856
  episode_reward_min: 127.9898989898988
  episodes_this_iter: 158
  episodes_total: 4266
  experiment_id: 9a18e29456c8418ea74db1acd1907ed2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7785022258758545
        entropy_coeff: 0.0001
        kl: 0.006874656615157922
        model: {}
        policy_loss: -0.008841376831696834
        total_loss: 9.293458461761475
        vf_explained_var: 0.979640781879425
        vf_loss: 9.301002740859985
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.51538461538462
    gpu_util_percent0: 0.2784615384615384
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7807692307692307
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1508585653708034
    mean_env_wait_ms: 1.1947677392219636
    mean_inference_ms: 4.56432513516632
    mean_raw_obs_processing_ms: 0.392795038315332
  time_since_restore: 502.90625405311584
  time_this_iter_s: 22.801059246063232
  time_total_s: 502.90625405311584
  timers:
    learn_throughput: 10376.632
    learn_time_ms: 15591.957
    sample_throughput: 23016.648
    sample_time_ms: 7029.347
    update_time_ms: 42.418
  timestamp: 1602496204
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 1cd33_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     22 |          502.906 | 3559424 |   245.59 |              295.717 |               127.99 |            817.914 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1cd33_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3430.725170068027
    time_step_min: 3104
  date: 2020-10-12_09-50-27
  done: false
  episode_len_mean: 816.4898602974313
  episode_reward_max: 296.3232323232323
  episode_reward_mean: 246.36010396893676
  episode_reward_min: 127.9898989898988
  episodes_this_iter: 172
  episodes_total: 4438
  experiment_id: 9a18e29456c8418ea74db1acd1907ed2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7434713492790858
        entropy_coeff: 0.0001
        kl: 0.00805954351865997
        model: {}
        policy_loss: -0.010885087378179984
        total_loss: 9.99376400311788
        vf_explained_var: 0.9799308776855469
        vf_loss: 10.003111282984415
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.17037037037037
    gpu_util_percent0: 0.4003703703703703
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666666
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15074949517692104
    mean_env_wait_ms: 1.1956699611848014
    mean_inference_ms: 4.556674012505479
    mean_raw_obs_processing_ms: 0.39239146014138515
  time_since_restore: 525.576878786087
  time_this_iter_s: 22.67062473297119
  time_total_s: 525.576878786087
  timers:
    learn_throughput: 10379.495
    learn_time_ms: 15587.656
    sample_throughput: 23008.521
    sample_time_ms: 7031.83
    update_time_ms: 41.74
  timestamp: 1602496227
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 1cd33_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     23 |          525.577 | 3721216 |   246.36 |              296.323 |               127.99 |             816.49 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1cd33_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3422.3333333333335
    time_step_min: 3104
  date: 2020-10-12_09-50-50
  done: false
  episode_len_mean: 814.1986070071761
  episode_reward_max: 296.3232323232323
  episode_reward_mean: 247.63816510397345
  episode_reward_min: 127.9898989898988
  episodes_this_iter: 300
  episodes_total: 4738
  experiment_id: 9a18e29456c8418ea74db1acd1907ed2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7324710537989935
        entropy_coeff: 0.0001
        kl: 0.006941189252150555
        model: {}
        policy_loss: -0.009583616231490547
        total_loss: 11.07440447807312
        vf_explained_var: 0.9827136397361755
        vf_loss: 11.082672993342081
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.58846153846154
    gpu_util_percent0: 0.3426923076923077
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765384615384615
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15058465836623514
    mean_env_wait_ms: 1.197189451212345
    mean_inference_ms: 4.544309060807315
    mean_raw_obs_processing_ms: 0.3917546261686602
  time_since_restore: 548.3126289844513
  time_this_iter_s: 22.735750198364258
  time_total_s: 548.3126289844513
  timers:
    learn_throughput: 10372.901
    learn_time_ms: 15597.566
    sample_throughput: 22967.39
    sample_time_ms: 7044.423
    update_time_ms: 40.949
  timestamp: 1602496250
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: 1cd33_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     24 |          548.313 | 3883008 |  247.638 |              296.323 |               127.99 |            814.199 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1cd33_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3418.177823408624
    time_step_min: 3098
  date: 2020-10-12_09-51-13
  done: false
  episode_len_mean: 812.9987750102082
  episode_reward_max: 296.6262626262622
  episode_reward_mean: 248.23236035322594
  episode_reward_min: 127.9898989898988
  episodes_this_iter: 160
  episodes_total: 4898
  experiment_id: 9a18e29456c8418ea74db1acd1907ed2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7477995902299881
        entropy_coeff: 0.0001
        kl: 0.006272289475115637
        model: {}
        policy_loss: -0.00882955159371098
        total_loss: 8.031121015548706
        vf_explained_var: 0.9821956157684326
        vf_loss: 8.038770953814188
    num_steps_sampled: 4044800
    num_steps_trained: 4044800
  iterations_since_restore: 25
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.055555555555557
    gpu_util_percent0: 0.2803703703703704
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7777777777777777
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1505027184591084
    mean_env_wait_ms: 1.197937655418847
    mean_inference_ms: 4.538297250322579
    mean_raw_obs_processing_ms: 0.3914461154179944
  time_since_restore: 571.0859563350677
  time_this_iter_s: 22.773327350616455
  time_total_s: 571.0859563350677
  timers:
    learn_throughput: 10375.664
    learn_time_ms: 15593.412
    sample_throughput: 23009.262
    sample_time_ms: 7031.603
    update_time_ms: 47.508
  timestamp: 1602496273
  timesteps_since_restore: 0
  timesteps_total: 4044800
  training_iteration: 25
  trial_id: 1cd33_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     25 |          571.086 | 4044800 |  248.232 |              296.626 |               127.99 |            812.999 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1cd33_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3414.383714001986
    time_step_min: 3098
  date: 2020-10-12_09-51-36
  done: false
  episode_len_mean: 811.8483112778985
  episode_reward_max: 296.6262626262622
  episode_reward_mean: 248.7943687317576
  episode_reward_min: 127.9898989898988
  episodes_this_iter: 165
  episodes_total: 5063
  experiment_id: 9a18e29456c8418ea74db1acd1907ed2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7201022605101267
        entropy_coeff: 0.0001
        kl: 0.007100002995381753
        model: {}
        policy_loss: -0.008267411200601297
        total_loss: 9.178823947906494
        vf_explained_var: 0.9805447459220886
        vf_loss: 9.18574333190918
    num_steps_sampled: 4206592
    num_steps_trained: 4206592
  iterations_since_restore: 26
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.266666666666673
    gpu_util_percent0: 0.33222222222222225
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7888888888888888
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15041981078311617
    mean_env_wait_ms: 1.1986901366963516
    mean_inference_ms: 4.532393263010814
    mean_raw_obs_processing_ms: 0.39113516813357185
  time_since_restore: 594.1627798080444
  time_this_iter_s: 23.076823472976685
  time_total_s: 594.1627798080444
  timers:
    learn_throughput: 10366.6
    learn_time_ms: 15607.046
    sample_throughput: 22955.404
    sample_time_ms: 7048.101
    update_time_ms: 54.407
  timestamp: 1602496296
  timesteps_since_restore: 0
  timesteps_total: 4206592
  training_iteration: 26
  trial_id: 1cd33_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     26 |          594.163 | 4206592 |  248.794 |              296.626 |               127.99 |            811.848 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1cd33_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3407.7780693533273
    time_step_min: 3098
  date: 2020-10-12_09-51-59
  done: true
  episode_len_mean: 809.7493939958978
  episode_reward_max: 296.6262626262622
  episode_reward_mean: 249.79949221847411
  episode_reward_min: 127.9898989898988
  episodes_this_iter: 300
  episodes_total: 5363
  experiment_id: 9a18e29456c8418ea74db1acd1907ed2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.692356526851654
        entropy_coeff: 0.0001
        kl: 0.006600421271286905
        model: {}
        policy_loss: -0.008063790268958352
        total_loss: 10.868266741434732
        vf_explained_var: 0.9833347797393799
        vf_loss: 10.87507971127828
    num_steps_sampled: 4368384
    num_steps_trained: 4368384
  iterations_since_restore: 27
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.450000000000006
    gpu_util_percent0: 0.2542307692307692
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765384615384615
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1502850982950706
    mean_env_wait_ms: 1.200029817732723
    mean_inference_ms: 4.522258614740064
    mean_raw_obs_processing_ms: 0.3906255556499739
  time_since_restore: 616.9574811458588
  time_this_iter_s: 22.79470133781433
  time_total_s: 616.9574811458588
  timers:
    learn_throughput: 10375.141
    learn_time_ms: 15594.197
    sample_throughput: 22896.593
    sample_time_ms: 7066.204
    update_time_ms: 54.302
  timestamp: 1602496319
  timesteps_since_restore: 0
  timesteps_total: 4368384
  training_iteration: 27
  trial_id: 1cd33_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1cd33_00000 | TERMINATED |       |     27 |          616.957 | 4368384 |  249.799 |              296.626 |               127.99 |            809.749 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1cd33_00000 | TERMINATED |       |     27 |          616.957 | 4368384 |  249.799 |              296.626 |               127.99 |            809.749 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


