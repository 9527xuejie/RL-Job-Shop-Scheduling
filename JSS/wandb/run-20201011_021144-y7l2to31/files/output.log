2020-10-11 02:11:46,879	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_1e41d_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=59409)[0m 2020-10-11 02:11:49,765	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=59362)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59362)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59342)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59342)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59366)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59366)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59369)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59369)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59345)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59345)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59358)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59358)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59368)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59368)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59322)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59322)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59262)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59262)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59320)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59320)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59335)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59335)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59379)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59379)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59378)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59378)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59351)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59351)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59294)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59294)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59341)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59341)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59343)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59343)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59398)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59398)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59329)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59329)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59260)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59260)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59272)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59272)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59336)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59336)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59270)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59270)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59261)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59261)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59330)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59330)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59289)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59289)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59318)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59318)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59339)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59339)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59324)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59324)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59288)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59288)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59337)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59337)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59344)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59344)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59282)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59282)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59327)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59327)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59285)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59285)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59346)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59346)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59295)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59295)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59258)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59258)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59273)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59273)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59347)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59347)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59275)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59275)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59274)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59274)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59395)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59395)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59333)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59333)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59372)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59372)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59259)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59259)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59334)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59334)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59284)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59284)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59266)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59266)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59340)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59340)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59268)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59268)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59355)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59355)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59265)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59265)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59331)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59331)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59370)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59370)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59387)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59387)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59267)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59267)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59389)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59389)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59279)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59279)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59352)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59352)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59291)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59291)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59256)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59256)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59297)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59297)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59386)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59386)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59325)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59325)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59380)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59380)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59364)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59364)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59332)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59332)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59277)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59277)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59363)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59363)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59326)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59326)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59257)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59257)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59263)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59263)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59323)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59323)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59338)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59338)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59328)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59328)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59298)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59298)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59350)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59350)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=59271)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=59271)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_1e41d_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_02-12-31
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: dd9313936f0140fa97db37e9aa7ded48
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1804874454225813
        entropy_coeff: 0.0
        kl: 0.008518951945006847
        model: {}
        policy_loss: -0.005339759817746069
        total_loss: 16.359916073935374
        vf_explained_var: 0.5462602972984314
        vf_loss: 16.36355229786464
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.854545454545452
    gpu_util_percent0: 0.3293181818181818
    gpu_util_percent1: 0.00022727272727272727
    gpu_util_percent2: 0.00022727272727272727
    ram_util_percent: 6.295454545454543
    vram_util_percent0: 0.1927084886251826
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 59409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16910317430675822
    mean_env_wait_ms: 1.1851558261316624
    mean_inference_ms: 5.68151983371227
    mean_raw_obs_processing_ms: 0.4474062888701046
  time_since_restore: 36.48057818412781
  time_this_iter_s: 36.48057818412781
  time_total_s: 36.48057818412781
  timers:
    learn_throughput: 5908.108
    learn_time_ms: 27384.738
    sample_throughput: 17938.217
    sample_time_ms: 9019.403
    update_time_ms: 42.088
  timestamp: 1602382351
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 1e41d_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1e41d_00000 | RUNNING  | 172.17.0.4:59409 |      1 |          36.4806 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1e41d_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3601.2673611111113
    time_step_min: 3288
  date: 2020-10-11_02-13-06
  done: false
  episode_len_mean: 879.9651898734177
  episode_reward_max: 267.8383838383835
  episode_reward_mean: 218.87501598261068
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: dd9313936f0140fa97db37e9aa7ded48
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1454810074397497
        entropy_coeff: 0.0
        kl: 0.011828737266893898
        model: {}
        policy_loss: -0.008730221710201087
        total_loss: 11.074564797537667
        vf_explained_var: 0.8130790591239929
        vf_loss: 11.080929006849017
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.988095238095234
    gpu_util_percent0: 0.3471428571428571
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4785714285714295
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 59409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16460964839430217
    mean_env_wait_ms: 1.1877326275238076
    mean_inference_ms: 5.422491113317723
    mean_raw_obs_processing_ms: 0.4354050306279813
  time_since_restore: 71.49877786636353
  time_this_iter_s: 35.01819968223572
  time_total_s: 71.49877786636353
  timers:
    learn_throughput: 5912.097
    learn_time_ms: 27366.262
    sample_throughput: 19469.398
    sample_time_ms: 8310.067
    update_time_ms: 30.938
  timestamp: 1602382386
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 1e41d_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1e41d_00000 | RUNNING  | 172.17.0.4:59409 |      2 |          71.4988 | 323584 |  218.875 |              267.838 |              145.717 |            879.965 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1e41d_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3595.7219730941706
    time_step_min: 3288
  date: 2020-10-11_02-13-41
  done: false
  episode_len_mean: 869.3122362869199
  episode_reward_max: 267.8383838383835
  episode_reward_mean: 220.80092059838876
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: dd9313936f0140fa97db37e9aa7ded48
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1211748719215393
        entropy_coeff: 0.0
        kl: 0.01131928519212774
        model: {}
        policy_loss: -0.008102217356541328
        total_loss: 12.420944963182722
        vf_explained_var: 0.8788701295852661
        vf_loss: 12.426783289228167
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.799999999999997
    gpu_util_percent0: 0.3242857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.492857142857144
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 59409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1619800977836972
    mean_env_wait_ms: 1.1916064694614763
    mean_inference_ms: 5.256055375616367
    mean_raw_obs_processing_ms: 0.4285067029751915
  time_since_restore: 106.25566959381104
  time_this_iter_s: 34.75689172744751
  time_total_s: 106.25566959381104
  timers:
    learn_throughput: 5915.407
    learn_time_ms: 27350.948
    sample_throughput: 20250.201
    sample_time_ms: 7989.649
    update_time_ms: 33.9
  timestamp: 1602382421
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 1e41d_00000
  
== Status ==
Memory usage on this node: 48.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1e41d_00000 | RUNNING  | 172.17.0.4:59409 |      3 |          106.256 | 485376 |  220.801 |              267.838 |              145.717 |            869.312 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1e41d_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3594.6241721854303
    time_step_min: 3288
  date: 2020-10-11_02-14-16
  done: false
  episode_len_mean: 860.2199367088608
  episode_reward_max: 271.92929292929244
  episode_reward_mean: 221.12065272982974
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: dd9313936f0140fa97db37e9aa7ded48
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.084406043801989
        entropy_coeff: 0.0
        kl: 0.008551391772925854
        model: {}
        policy_loss: -0.00659045767549417
        total_loss: 14.753157683781215
        vf_explained_var: 0.9117667078971863
        vf_loss: 14.758037907736641
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.273809523809526
    gpu_util_percent0: 0.33309523809523817
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.485714285714285
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 59409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1601179609626633
    mean_env_wait_ms: 1.1959236051944624
    mean_inference_ms: 5.137509620821981
    mean_raw_obs_processing_ms: 0.42342441974919276
  time_since_restore: 140.92278718948364
  time_this_iter_s: 34.66711759567261
  time_total_s: 140.92278718948364
  timers:
    learn_throughput: 5919.458
    learn_time_ms: 27332.233
    sample_throughput: 20687.865
    sample_time_ms: 7820.623
    update_time_ms: 32.228
  timestamp: 1602382456
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 1e41d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1e41d_00000 | RUNNING  | 172.17.0.4:59409 |      4 |          140.923 | 647168 |  221.121 |              271.929 |              145.717 |             860.22 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1e41d_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3589.8830601092895
    time_step_min: 3278
  date: 2020-10-11_02-14-51
  done: false
  episode_len_mean: 844.1590668080594
  episode_reward_max: 271.92929292929244
  episode_reward_mean: 222.6338464175154
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 311
  episodes_total: 943
  experiment_id: dd9313936f0140fa97db37e9aa7ded48
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.0539347699710302
        entropy_coeff: 0.0
        kl: 0.007881184141816837
        model: {}
        policy_loss: -0.007583644541487696
        total_loss: 19.97237750462123
        vf_explained_var: 0.9465331435203552
        vf_loss: 19.978384562901088
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.32439024390244
    gpu_util_percent0: 0.3351219512195122
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.490243902439025
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 59409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15782986086948456
    mean_env_wait_ms: 1.205206871386191
    mean_inference_ms: 4.987697080256673
    mean_raw_obs_processing_ms: 0.4170757853923332
  time_since_restore: 175.53704977035522
  time_this_iter_s: 34.61426258087158
  time_total_s: 175.53704977035522
  timers:
    learn_throughput: 5922.093
    learn_time_ms: 27320.073
    sample_throughput: 20992.71
    sample_time_ms: 7707.056
    update_time_ms: 33.539
  timestamp: 1602382491
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 1e41d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1e41d_00000 | RUNNING  | 172.17.0.4:59409 |      5 |          175.537 | 808960 |  222.634 |              271.929 |              145.717 |            844.159 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1e41d_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3582.5983302411873
    time_step_min: 3278
  date: 2020-10-11_02-15-25
  done: false
  episode_len_mean: 837.1084990958409
  episode_reward_max: 271.92929292929244
  episode_reward_mean: 223.5407510913839
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 163
  episodes_total: 1106
  experiment_id: dd9313936f0140fa97db37e9aa7ded48
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.0255346127918787
        entropy_coeff: 0.0
        kl: 0.00939968807090606
        model: {}
        policy_loss: -0.006213014330049711
        total_loss: 13.275995186397008
        vf_explained_var: 0.9535728096961975
        vf_loss: 13.28032854625157
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.33095238095238
    gpu_util_percent0: 0.39142857142857135
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.490476190476191
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 59409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15701010666941048
    mean_env_wait_ms: 1.2090106209367186
    mean_inference_ms: 4.934897960383863
    mean_raw_obs_processing_ms: 0.41469789296250714
  time_since_restore: 210.14910364151
  time_this_iter_s: 34.612053871154785
  time_total_s: 210.14910364151
  timers:
    learn_throughput: 5919.302
    learn_time_ms: 27332.955
    sample_throughput: 21255.222
    sample_time_ms: 7611.871
    update_time_ms: 32.299
  timestamp: 1602382525
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 1e41d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1e41d_00000 | RUNNING  | 172.17.0.4:59409 |      6 |          210.149 | 970752 |  223.541 |              271.929 |              145.717 |            837.108 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1e41d_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3576.5339805825242
    time_step_min: 3278
  date: 2020-10-11_02-16-00
  done: false
  episode_len_mean: 831.1898734177215
  episode_reward_max: 274.0505050505048
  episode_reward_mean: 224.41514831862924
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: dd9313936f0140fa97db37e9aa7ded48
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.9936733543872833
        entropy_coeff: 0.0
        kl: 0.009245377433087145
        model: {}
        policy_loss: -0.005528809752182237
        total_loss: 11.211450985499791
        vf_explained_var: 0.966867983341217
        vf_loss: 11.215130465371269
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.252380952380953
    gpu_util_percent0: 0.3721428571428572
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497619047619047
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 59409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15637202071269776
    mean_env_wait_ms: 1.2123557175460469
    mean_inference_ms: 4.8905777671176205
    mean_raw_obs_processing_ms: 0.4126551622918904
  time_since_restore: 245.15400767326355
  time_this_iter_s: 35.00490403175354
  time_total_s: 245.15400767326355
  timers:
    learn_throughput: 5907.549
    learn_time_ms: 27387.331
    sample_throughput: 21429.522
    sample_time_ms: 7549.958
    update_time_ms: 35.461
  timestamp: 1602382560
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 1e41d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1e41d_00000 | RUNNING  | 172.17.0.4:59409 |      7 |          245.154 | 1132544 |  224.415 |              274.051 |              145.717 |             831.19 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1e41d_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3574.3988764044943
    time_step_min: 3278
  date: 2020-10-11_02-16-35
  done: false
  episode_len_mean: 825.2995867768595
  episode_reward_max: 274.0505050505048
  episode_reward_mean: 224.75934969530002
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 188
  episodes_total: 1452
  experiment_id: dd9313936f0140fa97db37e9aa7ded48
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.9250889250210353
        entropy_coeff: 0.0
        kl: 0.008538675427969013
        model: {}
        policy_loss: -0.006471810470559701
        total_loss: 11.115035057067871
        vf_explained_var: 0.9800344109535217
        vf_loss: 11.119798864637103
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.76585365853659
    gpu_util_percent0: 0.32146341463414635
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.495121951219511
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 59409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15573039418633805
    mean_env_wait_ms: 1.2165819780532747
    mean_inference_ms: 4.846215730349667
    mean_raw_obs_processing_ms: 0.4104858223277838
  time_since_restore: 279.5318386554718
  time_this_iter_s: 34.37783098220825
  time_total_s: 279.5318386554718
  timers:
    learn_throughput: 5909.422
    learn_time_ms: 27378.65
    sample_throughput: 21635.355
    sample_time_ms: 7478.13
    update_time_ms: 35.205
  timestamp: 1602382595
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 1e41d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1e41d_00000 | RUNNING  | 172.17.0.4:59409 |      8 |          279.532 | 1294336 |  224.759 |              274.051 |              145.717 |              825.3 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1e41d_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3572.2461988304094
    time_step_min: 3278
  date: 2020-10-11_02-17-10
  done: false
  episode_len_mean: 818.2428078250863
  episode_reward_max: 274.0505050505048
  episode_reward_mean: 225.26280061838168
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 286
  episodes_total: 1738
  experiment_id: dd9313936f0140fa97db37e9aa7ded48
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.8926172511918204
        entropy_coeff: 0.0
        kl: 0.00742379276614104
        model: {}
        policy_loss: -0.004778007136857403
        total_loss: 9.954356602260045
        vf_explained_var: 0.982390820980072
        vf_loss: 9.957649980272565
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.81219512195122
    gpu_util_percent0: 0.35975609756097565
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.487804878048781
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 59409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15495209563821333
    mean_env_wait_ms: 1.2220358440451362
    mean_inference_ms: 4.7921950969481655
    mean_raw_obs_processing_ms: 0.4079850474867648
  time_since_restore: 314.11517238616943
  time_this_iter_s: 34.58333373069763
  time_total_s: 314.11517238616943
  timers:
    learn_throughput: 5910.698
    learn_time_ms: 27372.74
    sample_throughput: 21730.778
    sample_time_ms: 7445.292
    update_time_ms: 33.647
  timestamp: 1602382630
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 1e41d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1e41d_00000 | RUNNING  | 172.17.0.4:59409 |      9 |          314.115 | 1456128 |  225.263 |              274.051 |              145.717 |            818.243 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1e41d_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3571.436295503212
    time_step_min: 3278
  date: 2020-10-11_02-17-44
  done: false
  episode_len_mean: 814.998417721519
  episode_reward_max: 274.0505050505048
  episode_reward_mean: 225.47951029280142
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 1896
  experiment_id: dd9313936f0140fa97db37e9aa7ded48
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.8462866885321481
        entropy_coeff: 0.0
        kl: 0.007726780305217419
        model: {}
        policy_loss: -0.005671839649689251
        total_loss: 5.94110301562718
        vf_explained_var: 0.9884353876113892
        vf_loss: 5.945229530334473
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.658536585365855
    gpu_util_percent0: 0.40560975609756095
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.485365853658536
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 59409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15459683582585348
    mean_env_wait_ms: 1.2245818345368595
    mean_inference_ms: 4.767616451498846
    mean_raw_obs_processing_ms: 0.40682560687143987
  time_since_restore: 348.49624490737915
  time_this_iter_s: 34.38107252120972
  time_total_s: 348.49624490737915
  timers:
    learn_throughput: 5912.725
    learn_time_ms: 27363.356
    sample_throughput: 21861.553
    sample_time_ms: 7400.755
    update_time_ms: 35.148
  timestamp: 1602382664
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 1e41d_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1e41d_00000 | RUNNING  | 172.17.0.4:59409 |     10 |          348.496 | 1617920 |   225.48 |              274.051 |              145.717 |            814.998 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1e41d_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3569.786522380718
    time_step_min: 3276
  date: 2020-10-11_02-18-19
  done: false
  episode_len_mean: 811.7433284813197
  episode_reward_max: 274.0505050505048
  episode_reward_mean: 225.88838898445883
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 165
  episodes_total: 2061
  experiment_id: dd9313936f0140fa97db37e9aa7ded48
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.7988821864128113
        entropy_coeff: 0.0
        kl: 0.0061836774194879195
        model: {}
        policy_loss: -0.004184865806174847
        total_loss: 5.445086683545794
        vf_explained_var: 0.9914622902870178
        vf_loss: 5.448034933635166
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.45952380952381
    gpu_util_percent0: 0.3026190476190476
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4976190476190485
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 59409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15425888484961767
    mean_env_wait_ms: 1.227246539348935
    mean_inference_ms: 4.744252885752279
    mean_raw_obs_processing_ms: 0.405692853635352
  time_since_restore: 383.14280247688293
  time_this_iter_s: 34.646557569503784
  time_total_s: 383.14280247688293
  timers:
    learn_throughput: 5912.668
    learn_time_ms: 27363.622
    sample_throughput: 22425.248
    sample_time_ms: 7214.725
    update_time_ms: 35.022
  timestamp: 1602382699
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 1e41d_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1e41d_00000 | RUNNING  | 172.17.0.4:59409 |     11 |          383.143 | 1779712 |  225.888 |              274.051 |              145.717 |            811.743 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1e41d_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3563.723313407344
    time_step_min: 3276
  date: 2020-10-11_02-18-53
  done: false
  episode_len_mean: 806.9839662447257
  episode_reward_max: 274.0505050505048
  episode_reward_mean: 226.97583429229
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 309
  episodes_total: 2370
  experiment_id: dd9313936f0140fa97db37e9aa7ded48
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.7581991893904549
        entropy_coeff: 0.0
        kl: 0.006100377367277231
        model: {}
        policy_loss: -0.0057352106190852025
        total_loss: 6.068000316619873
        vf_explained_var: 0.9917846322059631
        vf_loss: 6.072515419551304
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.658536585365855
    gpu_util_percent0: 0.3931707317073171
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.475609756097561
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 59409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1537330504139994
    mean_env_wait_ms: 1.2318715805742297
    mean_inference_ms: 4.707754498406163
    mean_raw_obs_processing_ms: 0.40401792790920515
  time_since_restore: 417.72119426727295
  time_this_iter_s: 34.578391790390015
  time_total_s: 417.72119426727295
  timers:
    learn_throughput: 5914.655
    learn_time_ms: 27354.428
    sample_throughput: 22542.117
    sample_time_ms: 7177.321
    update_time_ms: 36.012
  timestamp: 1602382733
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 1e41d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1e41d_00000 | RUNNING  | 172.17.0.4:59409 |     12 |          417.721 | 1941504 |  226.976 |              274.051 |              145.717 |            806.984 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1e41d_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3559.4628
    time_step_min: 3276
  date: 2020-10-11_02-19-28
  done: false
  episode_len_mean: 804.8666930379746
  episode_reward_max: 274.0505050505048
  episode_reward_mean: 227.49759461705668
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 2528
  experiment_id: dd9313936f0140fa97db37e9aa7ded48
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.7126995239939008
        entropy_coeff: 0.0
        kl: 0.006177249763693128
        model: {}
        policy_loss: -0.005256150558125228
        total_loss: 3.6800253561564853
        vf_explained_var: 0.9933714866638184
        vf_loss: 3.684046064104353
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.34285714285714
    gpu_util_percent0: 0.3011904761904762
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.495238095238094
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 59409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15350655834140967
    mean_env_wait_ms: 1.2339055838959225
    mean_inference_ms: 4.691690573401652
    mean_raw_obs_processing_ms: 0.403272902196068
  time_since_restore: 452.383104801178
  time_this_iter_s: 34.66191053390503
  time_total_s: 452.383104801178
  timers:
    learn_throughput: 5914.001
    learn_time_ms: 27357.454
    sample_throughput: 22583.778
    sample_time_ms: 7164.08
    update_time_ms: 35.794
  timestamp: 1602382768
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 1e41d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1e41d_00000 | RUNNING  | 172.17.0.4:59409 |     13 |          452.383 | 2103296 |  227.498 |              274.051 |              145.717 |            804.867 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1e41d_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3555.434423149192
    time_step_min: 3264
  date: 2020-10-11_02-20-03
  done: false
  episode_len_mean: 802.9438452956489
  episode_reward_max: 274.0505050505048
  episode_reward_mean: 227.8680219825627
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 161
  episodes_total: 2689
  experiment_id: dd9313936f0140fa97db37e9aa7ded48
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.6822567965303149
        entropy_coeff: 0.0
        kl: 0.006382221389295799
        model: {}
        policy_loss: -0.003601989517587104
        total_loss: 3.7515718936920166
        vf_explained_var: 0.9939621090888977
        vf_loss: 3.753897479602269
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.488095238095234
    gpu_util_percent0: 0.3545238095238095
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 59409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15329357078417075
    mean_env_wait_ms: 1.2359742295983034
    mean_inference_ms: 4.676526660690614
    mean_raw_obs_processing_ms: 0.40255462659273045
  time_since_restore: 487.17724227905273
  time_this_iter_s: 34.794137477874756
  time_total_s: 487.17724227905273
  timers:
    learn_throughput: 5909.953
    learn_time_ms: 27376.189
    sample_throughput: 22608.798
    sample_time_ms: 7156.152
    update_time_ms: 36.847
  timestamp: 1602382803
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 1e41d_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1e41d_00000 | RUNNING  | 172.17.0.4:59409 |     14 |          487.177 | 2265088 |  227.868 |              274.051 |              145.717 |            802.944 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1e41d_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3548.4993275050438
    time_step_min: 3264
  date: 2020-10-11_02-20-38
  done: false
  episode_len_mean: 799.6922051965356
  episode_reward_max: 274.0505050505048
  episode_reward_mean: 228.76135438327316
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 313
  episodes_total: 3002
  experiment_id: dd9313936f0140fa97db37e9aa7ded48
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.6472731615815844
        entropy_coeff: 0.0
        kl: 0.0049553116716976675
        model: {}
        policy_loss: -0.0033206440462631042
        total_loss: 4.366232633590698
        vf_explained_var: 0.9941932559013367
        vf_loss: 4.3685622215271
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.16904761904762
    gpu_util_percent0: 0.3928571428571428
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.485714285714285
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 59409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1529323784699551
    mean_env_wait_ms: 1.2397455085265396
    mean_inference_ms: 4.650837958576405
    mean_raw_obs_processing_ms: 0.4013772270669052
  time_since_restore: 522.1379849910736
  time_this_iter_s: 34.960742712020874
  time_total_s: 522.1379849910736
  timers:
    learn_throughput: 5904.815
    learn_time_ms: 27400.011
    sample_throughput: 22602.519
    sample_time_ms: 7158.14
    update_time_ms: 36.961
  timestamp: 1602382838
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 1e41d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1e41d_00000 | RUNNING  | 172.17.0.4:59409 |     15 |          522.138 | 2426880 |  228.761 |              274.051 |              145.717 |            799.692 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1e41d_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3544.2956577266923
    time_step_min: 3264
  date: 2020-10-11_02-21-13
  done: false
  episode_len_mean: 798.337341772152
  episode_reward_max: 274.0505050505048
  episode_reward_mean: 229.35646017133365
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 3160
  experiment_id: dd9313936f0140fa97db37e9aa7ded48
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.6069066226482391
        entropy_coeff: 0.0
        kl: 0.008399375913930791
        model: {}
        policy_loss: -0.004928099739897464
        total_loss: 2.9113876479012624
        vf_explained_var: 0.9945334196090698
        vf_loss: 2.91547577721732
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.51707317073171
    gpu_util_percent0: 0.28365853658536583
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.512195121951219
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 59409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15277052267949337
    mean_env_wait_ms: 1.241413106032163
    mean_inference_ms: 4.639397521121545
    mean_raw_obs_processing_ms: 0.4008415735358378
  time_since_restore: 556.8464319705963
  time_this_iter_s: 34.708446979522705
  time_total_s: 556.8464319705963
  timers:
    learn_throughput: 5904.563
    learn_time_ms: 27401.182
    sample_throughput: 22587.495
    sample_time_ms: 7162.902
    update_time_ms: 38.084
  timestamp: 1602382873
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 1e41d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1e41d_00000 | RUNNING  | 172.17.0.4:59409 |     16 |          556.846 | 2588672 |  229.356 |              274.051 |              145.717 |            798.337 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1e41d_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3540.7630619684082
    time_step_min: 3264
  date: 2020-10-11_02-21-48
  done: false
  episode_len_mean: 797.0168674698796
  episode_reward_max: 274.0505050505048
  episode_reward_mean: 229.85586284532073
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 160
  episodes_total: 3320
  experiment_id: dd9313936f0140fa97db37e9aa7ded48
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.5859954399721963
        entropy_coeff: 0.0
        kl: 0.007355468713545373
        model: {}
        policy_loss: -0.004528576433325985
        total_loss: 2.741821323122297
        vf_explained_var: 0.9949012398719788
        vf_loss: 2.7456144264766147
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.24285714285714
    gpu_util_percent0: 0.39547619047619037
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.490476190476191
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 59409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15261859776190853
    mean_env_wait_ms: 1.2430625826627617
    mean_inference_ms: 4.628567993788783
    mean_raw_obs_processing_ms: 0.4003127006862807
  time_since_restore: 591.4457004070282
  time_this_iter_s: 34.599268436431885
  time_total_s: 591.4457004070282
  timers:
    learn_throughput: 5918.913
    learn_time_ms: 27334.747
    sample_throughput: 22517.697
    sample_time_ms: 7185.104
    update_time_ms: 35.16
  timestamp: 1602382908
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 1e41d_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1e41d_00000 | RUNNING  | 172.17.0.4:59409 |     17 |          591.446 | 2750464 |  229.856 |              274.051 |              145.717 |            797.017 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1e41d_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3532.9251247920133
    time_step_min: 3253
  date: 2020-10-11_02-22-23
  done: true
  episode_len_mean: 794.4928453494772
  episode_reward_max: 278.44444444444434
  episode_reward_mean: 231.12793871572086
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 314
  episodes_total: 3634
  experiment_id: dd9313936f0140fa97db37e9aa7ded48
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.5356663720948356
        entropy_coeff: 0.0
        kl: 0.006530061796573656
        model: {}
        policy_loss: -0.004436114578441318
        total_loss: 3.474828464644296
        vf_explained_var: 0.9948549270629883
        vf_loss: 3.478611537388393
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.29523809523809
    gpu_util_percent0: 0.36857142857142855
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488095238095238
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 59409
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1523538134506669
    mean_env_wait_ms: 1.2461048200464013
    mean_inference_ms: 4.609576823455986
    mean_raw_obs_processing_ms: 0.399421479688226
  time_since_restore: 626.2923498153687
  time_this_iter_s: 34.846649408340454
  time_total_s: 626.2923498153687
  timers:
    learn_throughput: 5921.42
    learn_time_ms: 27323.176
    sample_throughput: 22361.303
    sample_time_ms: 7235.356
    update_time_ms: 36.025
  timestamp: 1602382943
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 1e41d_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1e41d_00000 | TERMINATED |       |     18 |          626.292 | 2912256 |  231.128 |              278.444 |              145.717 |            794.493 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1e41d_00000 | TERMINATED |       |     18 |          626.292 | 2912256 |  231.128 |              278.444 |              145.717 |            794.493 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


