2020-10-10 17:17:29,240	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_7a69a_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=67892)[0m 2020-10-10 17:17:32,068	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=67875)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67875)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67885)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67885)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67883)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67883)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67806)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67806)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67870)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67870)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67771)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67771)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67802)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67802)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67895)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67895)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67907)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67907)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67838)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67838)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67863)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67863)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67903)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67903)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67891)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67891)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67904)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67904)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67852)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67852)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67864)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67864)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67849)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67849)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67776)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67776)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67854)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67854)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67881)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67881)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67846)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67846)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67874)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67874)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67896)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67896)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67834)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67834)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67777)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67777)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67865)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67865)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67790)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67790)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67868)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67868)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67770)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67770)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67853)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67853)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67855)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67855)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67859)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67859)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67788)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67788)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67873)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67873)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67812)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67812)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67878)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67878)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67836)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67836)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67840)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67840)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67862)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67862)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67827)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67827)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67888)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67888)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67782)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67782)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67804)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67804)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67848)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67848)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67843)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67843)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67779)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67779)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67850)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67850)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67773)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67773)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67901)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67901)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67772)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67772)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67841)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67841)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67786)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67786)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67799)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67799)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67844)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67844)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67833)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67833)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67794)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67794)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67784)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67784)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67774)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67774)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67887)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67887)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67783)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67783)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67858)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67858)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67793)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67793)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67809)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67809)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67796)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67796)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67778)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67778)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67839)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67839)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67857)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67857)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67800)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67800)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67842)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67842)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67814)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67814)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67785)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67785)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67787)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67787)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67830)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67830)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67856)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67856)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67781)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67781)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67851)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67851)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67860)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67860)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67847)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67847)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67807)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67807)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_7a69a_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-10_17-18-18
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 4660db18edec4133bea4146aef7b53ae
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1834652764456612
        entropy_coeff: 0.0
        kl: 0.00541871616483799
        model: {}
        policy_loss: -0.011508596551720984
        total_loss: 9.18058545248849
        vf_explained_var: 0.7775402665138245
        vf_loss: 9.191010407039098
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.553061224489795
    gpu_util_percent0: 0.3283673469387755
    gpu_util_percent1: 0.00020408163265306123
    gpu_util_percent2: 0.00020408163265306123
    ram_util_percent: 6.30204081632653
    vram_util_percent0: 0.1934090133265507
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 67892
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17333291864350975
    mean_env_wait_ms: 1.2005660930655921
    mean_inference_ms: 5.864667335974285
    mean_raw_obs_processing_ms: 0.4685189805674162
  time_since_restore: 40.61631178855896
  time_this_iter_s: 40.61631178855896
  time_total_s: 40.61631178855896
  timers:
    learn_throughput: 5164.891
    learn_time_ms: 31325.347
    sample_throughput: 17577.82
    sample_time_ms: 9204.327
    update_time_ms: 48.64
  timestamp: 1602350298
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 7a69a_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7a69a_00000 | RUNNING  | 172.17.0.4:67892 |      1 |          40.6163 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7a69a_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3592.90625
    time_step_min: 3244
  date: 2020-10-10_17-18-57
  done: false
  episode_len_mean: 882.373417721519
  episode_reward_max: 274.5050505050506
  episode_reward_mean: 220.25351617440202
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 4660db18edec4133bea4146aef7b53ae
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.15360689163208
        entropy_coeff: 0.0
        kl: 0.006871118176994579
        model: {}
        policy_loss: -0.014443823643627443
        total_loss: 6.438741547720773
        vf_explained_var: 0.9124731421470642
        vf_loss: 6.451811007090977
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.545833333333334
    gpu_util_percent0: 0.39395833333333335
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.472916666666666
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 67892
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16919574546207883
    mean_env_wait_ms: 1.2000593978685323
    mean_inference_ms: 5.658476787816781
    mean_raw_obs_processing_ms: 0.4586162109336386
  time_since_restore: 79.69121432304382
  time_this_iter_s: 39.07490253448486
  time_total_s: 79.69121432304382
  timers:
    learn_throughput: 5203.188
    learn_time_ms: 31094.784
    sample_throughput: 18655.369
    sample_time_ms: 8672.678
    update_time_ms: 35.339
  timestamp: 1602350337
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 7a69a_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7a69a_00000 | RUNNING  | 172.17.0.4:67892 |      2 |          79.6912 | 323584 |  220.254 |              274.505 |              145.717 |            882.373 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7a69a_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3598.744394618834
    time_step_min: 3244
  date: 2020-10-10_17-19-36
  done: false
  episode_len_mean: 874.9071729957806
  episode_reward_max: 274.5050505050506
  episode_reward_mean: 218.8631888505304
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 4660db18edec4133bea4146aef7b53ae
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1381249938692366
        entropy_coeff: 0.0
        kl: 0.007408512889274529
        model: {}
        policy_loss: -0.014615834777941927
        total_loss: 6.914931195122855
        vf_explained_var: 0.9512295126914978
        vf_loss: 6.928065197808402
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.852173913043476
    gpu_util_percent0: 0.3376086956521739
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4913043478260875
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 67892
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16621410643302909
    mean_env_wait_ms: 1.2002416903739128
    mean_inference_ms: 5.483020062091544
    mean_raw_obs_processing_ms: 0.45006939351836966
  time_since_restore: 118.03564405441284
  time_this_iter_s: 38.34442973136902
  time_total_s: 118.03564405441284
  timers:
    learn_throughput: 5222.799
    learn_time_ms: 30978.025
    sample_throughput: 19533.185
    sample_time_ms: 8282.93
    update_time_ms: 35.633
  timestamp: 1602350376
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 7a69a_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7a69a_00000 | RUNNING  | 172.17.0.4:67892 |      3 |          118.036 | 485376 |  218.863 |              274.505 |              145.717 |            874.907 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7a69a_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3603.917218543046
    time_step_min: 3244
  date: 2020-10-10_17-20-14
  done: false
  episode_len_mean: 868.1091772151899
  episode_reward_max: 274.5050505050506
  episode_reward_mean: 218.6220911648125
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 4660db18edec4133bea4146aef7b53ae
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1138069799968175
        entropy_coeff: 0.0
        kl: 0.0071294796320476705
        model: {}
        policy_loss: -0.017482716091243283
        total_loss: 6.95372063773019
        vf_explained_var: 0.9671352505683899
        vf_loss: 6.969777277537754
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.13617021276596
    gpu_util_percent0: 0.3840425531914894
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.482978723404255
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267445
    vram_util_percent2: 0.0009075233687267445
  pid: 67892
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1640963625279791
    mean_env_wait_ms: 1.2017222485393468
    mean_inference_ms: 5.34761571224861
    mean_raw_obs_processing_ms: 0.44316688300185325
  time_since_restore: 156.22893047332764
  time_this_iter_s: 38.193286418914795
  time_total_s: 156.22893047332764
  timers:
    learn_throughput: 5232.765
    learn_time_ms: 30919.028
    sample_throughput: 20081.124
    sample_time_ms: 8056.92
    update_time_ms: 32.429
  timestamp: 1602350414
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 7a69a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7a69a_00000 | RUNNING  | 172.17.0.4:67892 |      4 |          156.229 | 647168 |  218.622 |              274.505 |              145.717 |            868.109 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7a69a_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3613.498727735369
    time_step_min: 3244
  date: 2020-10-10_17-20-52
  done: false
  episode_len_mean: 861.5614250614251
  episode_reward_max: 274.5050505050506
  episode_reward_mean: 217.68314595587307
  episode_reward_min: 136.62626262626242
  episodes_this_iter: 182
  episodes_total: 814
  experiment_id: 4660db18edec4133bea4146aef7b53ae
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0770672304289681
        entropy_coeff: 0.0
        kl: 0.006634615561259645
        model: {}
        policy_loss: -0.01885532421978756
        total_loss: 8.41661787033081
        vf_explained_var: 0.9796894788742065
        vf_loss: 8.434146438326154
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.56521739130435
    gpu_util_percent0: 0.3073913043478261
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.478260869565218
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 67892
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16230202728662327
    mean_env_wait_ms: 1.204674960652707
    mean_inference_ms: 5.231724467421753
    mean_raw_obs_processing_ms: 0.43689677858881104
  time_since_restore: 194.5073220729828
  time_this_iter_s: 38.27839159965515
  time_total_s: 194.5073220729828
  timers:
    learn_throughput: 5236.341
    learn_time_ms: 30897.91
    sample_throughput: 20417.656
    sample_time_ms: 7924.122
    update_time_ms: 30.193
  timestamp: 1602350452
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 7a69a_00000
  
== Status ==
Memory usage on this node: 48.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7a69a_00000 | RUNNING  | 172.17.0.4:67892 |      5 |          194.507 | 808960 |  217.683 |              274.505 |              136.626 |            861.561 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7a69a_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.505565862709
    time_step_min: 3244
  date: 2020-10-10_17-21-31
  done: false
  episode_len_mean: 853.5877034358047
  episode_reward_max: 274.5050505050506
  episode_reward_mean: 217.76961294682798
  episode_reward_min: 136.62626262626242
  episodes_this_iter: 292
  episodes_total: 1106
  experiment_id: 4660db18edec4133bea4146aef7b53ae
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0835124594824654
        entropy_coeff: 0.0
        kl: 0.006567284298528518
        model: {}
        policy_loss: -0.01698065106588079
        total_loss: 7.095513650349209
        vf_explained_var: 0.9843395948410034
        vf_loss: 7.111181054796491
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.114893617021277
    gpu_util_percent0: 0.3840425531914893
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.482978723404255
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267445
    vram_util_percent2: 0.0009075233687267445
  pid: 67892
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1602946726342206
    mean_env_wait_ms: 1.208211918977328
    mean_inference_ms: 5.102053059461474
    mean_raw_obs_processing_ms: 0.4304488410011143
  time_since_restore: 232.88878798484802
  time_this_iter_s: 38.381465911865234
  time_total_s: 232.88878798484802
  timers:
    learn_throughput: 5236.782
    learn_time_ms: 30895.308
    sample_throughput: 20641.049
    sample_time_ms: 7838.361
    update_time_ms: 31.688
  timestamp: 1602350491
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 7a69a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7a69a_00000 | RUNNING  | 172.17.0.4:67892 |      6 |          232.889 | 970752 |   217.77 |              274.505 |              136.626 |            853.588 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7a69a_00000:
  custom_metrics:
    time_step_max: 4260
    time_step_mean: 3614.215210355987
    time_step_min: 3244
  date: 2020-10-10_17-22-09
  done: false
  episode_len_mean: 849.9232594936709
  episode_reward_max: 274.5050505050506
  episode_reward_mean: 218.12307409538408
  episode_reward_min: 120.56565656565674
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 4660db18edec4133bea4146aef7b53ae
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0520960262843542
        entropy_coeff: 0.0
        kl: 0.006422822463459202
        model: {}
        policy_loss: -0.01923604855047805
        total_loss: 5.168047973087856
        vf_explained_var: 0.9877662658691406
        vf_loss: 5.185999495642526
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.319565217391304
    gpu_util_percent0: 0.357391304347826
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4934782608695665
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 67892
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1594846189498809
    mean_env_wait_ms: 1.2098057464519496
    mean_inference_ms: 5.050034721374836
    mean_raw_obs_processing_ms: 0.42775298848765575
  time_since_restore: 271.52806186676025
  time_this_iter_s: 38.63927388191223
  time_total_s: 271.52806186676025
  timers:
    learn_throughput: 5232.01
    learn_time_ms: 30923.489
    sample_throughput: 20787.785
    sample_time_ms: 7783.032
    update_time_ms: 33.495
  timestamp: 1602350529
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 7a69a_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7a69a_00000 | RUNNING  | 172.17.0.4:67892 |      7 |          271.528 | 1132544 |  218.123 |              274.505 |              120.566 |            849.923 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7a69a_00000:
  custom_metrics:
    time_step_max: 4260
    time_step_mean: 3610.6298421807746
    time_step_min: 3244
  date: 2020-10-10_17-22-48
  done: false
  episode_len_mean: 846.549929676512
  episode_reward_max: 274.5050505050506
  episode_reward_mean: 218.7679324894514
  episode_reward_min: 120.56565656565674
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 4660db18edec4133bea4146aef7b53ae
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0287750448499406
        entropy_coeff: 0.0
        kl: 0.006032101710193923
        model: {}
        policy_loss: -0.018329167272895575
        total_loss: 4.119046824319022
        vf_explained_var: 0.991246223449707
        vf_loss: 4.136169672012329
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.999999999999996
    gpu_util_percent0: 0.3295744680851063
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.500000000000001
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267445
    vram_util_percent2: 0.0009075233687267445
  pid: 67892
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15877881311178219
    mean_env_wait_ms: 1.211196987073958
    mean_inference_ms: 5.004733965066759
    mean_raw_obs_processing_ms: 0.425338654610588
  time_since_restore: 309.94476199150085
  time_this_iter_s: 38.4167001247406
  time_total_s: 309.94476199150085
  timers:
    learn_throughput: 5236.427
    learn_time_ms: 30897.401
    sample_throughput: 20839.755
    sample_time_ms: 7763.623
    update_time_ms: 32.053
  timestamp: 1602350568
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 7a69a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7a69a_00000 | RUNNING  | 172.17.0.4:67892 |      8 |          309.945 | 1294336 |  218.768 |              274.505 |              120.566 |             846.55 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7a69a_00000:
  custom_metrics:
    time_step_max: 4260
    time_step_mean: 3606.925667090216
    time_step_min: 3244
  date: 2020-10-10_17-23-26
  done: false
  episode_len_mean: 843.2072409488139
  episode_reward_max: 274.5050505050506
  episode_reward_mean: 219.25384935497286
  episode_reward_min: 120.56565656565674
  episodes_this_iter: 180
  episodes_total: 1602
  experiment_id: 4660db18edec4133bea4146aef7b53ae
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9883736201695034
        entropy_coeff: 0.0
        kl: 0.005869971854346139
        model: {}
        policy_loss: -0.018845038388722708
        total_loss: 4.898521866117205
        vf_explained_var: 0.9929127097129822
        vf_loss: 4.91619290624346
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.012765957446806
    gpu_util_percent0: 0.37702127659574464
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.482978723404255
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267445
    vram_util_percent2: 0.0009075233687267445
  pid: 67892
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15809784180901257
    mean_env_wait_ms: 1.212842313011715
    mean_inference_ms: 4.960719945445077
    mean_raw_obs_processing_ms: 0.4229692280446368
  time_since_restore: 348.50148344039917
  time_this_iter_s: 38.556721448898315
  time_total_s: 348.50148344039917
  timers:
    learn_throughput: 5234.114
    learn_time_ms: 30911.055
    sample_throughput: 20930.274
    sample_time_ms: 7730.047
    update_time_ms: 30.617
  timestamp: 1602350606
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 7a69a_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7a69a_00000 | RUNNING  | 172.17.0.4:67892 |      9 |          348.501 | 1456128 |  219.254 |              274.505 |              120.566 |            843.207 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7a69a_00000:
  custom_metrics:
    time_step_max: 4260
    time_step_mean: 3599.154175588865
    time_step_min: 3233
  date: 2020-10-10_17-24-05
  done: false
  episode_len_mean: 838.2051687763714
  episode_reward_max: 276.1717171717169
  episode_reward_mean: 220.4804692494565
  episode_reward_min: 120.56565656565674
  episodes_this_iter: 294
  episodes_total: 1896
  experiment_id: 4660db18edec4133bea4146aef7b53ae
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9814445929867881
        entropy_coeff: 0.0
        kl: 0.005562052330268281
        model: {}
        policy_loss: -0.016679512270327126
        total_loss: 4.952855484826224
        vf_explained_var: 0.992482602596283
        vf_loss: 4.968422549111502
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.567391304347826
    gpu_util_percent0: 0.32086956521739135
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486956521739131
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 67892
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1571483485646625
    mean_env_wait_ms: 1.2152683223354808
    mean_inference_ms: 4.901575060032663
    mean_raw_obs_processing_ms: 0.4197449568805629
  time_since_restore: 386.6436197757721
  time_this_iter_s: 38.142136335372925
  time_total_s: 386.6436197757721
  timers:
    learn_throughput: 5236.579
    learn_time_ms: 30896.508
    sample_throughput: 21051.877
    sample_time_ms: 7685.395
    update_time_ms: 31.33
  timestamp: 1602350645
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 7a69a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7a69a_00000 | RUNNING  | 172.17.0.4:67892 |     10 |          386.644 | 1617920 |   220.48 |              276.172 |              120.566 |            838.205 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7a69a_00000:
  custom_metrics:
    time_step_max: 4260
    time_step_mean: 3596.3617966436327
    time_step_min: 3233
  date: 2020-10-10_17-24-43
  done: false
  episode_len_mean: 835.8417721518987
  episode_reward_max: 276.1717171717169
  episode_reward_mean: 220.91029083434137
  episode_reward_min: 120.56565656565674
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 4660db18edec4133bea4146aef7b53ae
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9543016595499856
        entropy_coeff: 0.0
        kl: 0.005486230864854795
        model: {}
        policy_loss: -0.018654728940288936
        total_loss: 3.3617433650153026
        vf_explained_var: 0.9941434264183044
        vf_loss: 3.3793009178979054
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.993478260869562
    gpu_util_percent0: 0.3376086956521739
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.495652173913044
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 67892
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15673599421581136
    mean_env_wait_ms: 1.2164667485868965
    mean_inference_ms: 4.875348739966297
    mean_raw_obs_processing_ms: 0.4183266569150505
  time_since_restore: 424.7784559726715
  time_this_iter_s: 38.134836196899414
  time_total_s: 424.7784559726715
  timers:
    learn_throughput: 5247.234
    learn_time_ms: 30833.768
    sample_throughput: 21574.838
    sample_time_ms: 7499.106
    update_time_ms: 28.64
  timestamp: 1602350683
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 7a69a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7a69a_00000 | RUNNING  | 172.17.0.4:67892 |     11 |          424.778 | 1779712 |   220.91 |              276.172 |              120.566 |            835.842 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7a69a_00000:
  custom_metrics:
    time_step_max: 4260
    time_step_mean: 3592.5128205128203
    time_step_min: 3216
  date: 2020-10-10_17-25-21
  done: false
  episode_len_mean: 834.0257685352622
  episode_reward_max: 278.74747474747517
  episode_reward_mean: 221.4878303833999
  episode_reward_min: 120.56565656565674
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 4660db18edec4133bea4146aef7b53ae
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9380227029323578
        entropy_coeff: 0.0
        kl: 0.005270224064588547
        model: {}
        policy_loss: -0.017499756666698625
        total_loss: 3.2552560567855835
        vf_explained_var: 0.9941660761833191
        vf_loss: 3.271701693534851
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.93617021276596
    gpu_util_percent0: 0.3897872340425531
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267445
    vram_util_percent2: 0.0009075233687267445
  pid: 67892
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15636746080075048
    mean_env_wait_ms: 1.2175800193348048
    mean_inference_ms: 4.851552314120332
    mean_raw_obs_processing_ms: 0.4170006208317083
  time_since_restore: 463.02917218208313
  time_this_iter_s: 38.25071620941162
  time_total_s: 463.02917218208313
  timers:
    learn_throughput: 5249.758
    learn_time_ms: 30818.944
    sample_throughput: 21775.828
    sample_time_ms: 7429.89
    update_time_ms: 28.792
  timestamp: 1602350721
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 7a69a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7a69a_00000 | RUNNING  | 172.17.0.4:67892 |     12 |          463.029 | 1941504 |  221.488 |              278.747 |              120.566 |            834.026 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7a69a_00000:
  custom_metrics:
    time_step_max: 4260
    time_step_mean: 3587.780637254902
    time_step_min: 3216
  date: 2020-10-10_17-26-00
  done: false
  episode_len_mean: 831.3453150242326
  episode_reward_max: 278.74747474747517
  episode_reward_mean: 222.2356888758342
  episode_reward_min: 120.56565656565674
  episodes_this_iter: 264
  episodes_total: 2476
  experiment_id: 4660db18edec4133bea4146aef7b53ae
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9064277495656695
        entropy_coeff: 0.0
        kl: 0.0050880440311240295
        model: {}
        policy_loss: -0.014993477729149163
        total_loss: 4.119505984442575
        vf_explained_var: 0.995075523853302
        vf_loss: 4.133481860160828
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.33478260869565
    gpu_util_percent0: 0.3752173913043478
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.480434782608696
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 67892
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15583684647069385
    mean_env_wait_ms: 1.2194277983904633
    mean_inference_ms: 4.817416000103564
    mean_raw_obs_processing_ms: 0.415110173716741
  time_since_restore: 501.18010783195496
  time_this_iter_s: 38.150935649871826
  time_total_s: 501.18010783195496
  timers:
    learn_throughput: 5250.226
    learn_time_ms: 30816.195
    sample_throughput: 21819.93
    sample_time_ms: 7414.873
    update_time_ms: 27.301
  timestamp: 1602350760
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 7a69a_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7a69a_00000 | RUNNING  | 172.17.0.4:67892 |     13 |           501.18 | 2103296 |  222.236 |              278.747 |              120.566 |            831.345 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7a69a_00000:
  custom_metrics:
    time_step_max: 4260
    time_step_mean: 3583.361926260346
    time_step_min: 3216
  date: 2020-10-10_17-26-38
  done: false
  episode_len_mean: 829.7069992553984
  episode_reward_max: 278.74747474747517
  episode_reward_mean: 223.0246470663447
  episode_reward_min: 120.56565656565674
  episodes_this_iter: 210
  episodes_total: 2686
  experiment_id: 4660db18edec4133bea4146aef7b53ae
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8865364704813276
        entropy_coeff: 0.0
        kl: 0.0052775687737656495
        model: {}
        policy_loss: -0.01754127286507615
        total_loss: 2.800782118524824
        vf_explained_var: 0.9954832792282104
        vf_loss: 2.817267792565482
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.127659574468087
    gpu_util_percent0: 0.3285106382978724
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497872340425531
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267445
    vram_util_percent2: 0.0009075233687267445
  pid: 67892
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1554629376447641
    mean_env_wait_ms: 1.2206274575645624
    mean_inference_ms: 4.793212685726262
    mean_raw_obs_processing_ms: 0.41372654957057486
  time_since_restore: 539.7545161247253
  time_this_iter_s: 38.574408292770386
  time_total_s: 539.7545161247253
  timers:
    learn_throughput: 5242.904
    learn_time_ms: 30859.233
    sample_throughput: 21836.858
    sample_time_ms: 7409.124
    update_time_ms: 27.047
  timestamp: 1602350798
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 7a69a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7a69a_00000 | RUNNING  | 172.17.0.4:67892 |     14 |          539.755 | 2265088 |  223.025 |              278.747 |              120.566 |            829.707 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7a69a_00000:
  custom_metrics:
    time_step_max: 4260
    time_step_mean: 3580.4332386363635
    time_step_min: 3216
  date: 2020-10-10_17-27-17
  done: false
  episode_len_mean: 828.8361462728551
  episode_reward_max: 278.74747474747517
  episode_reward_mean: 223.3777436815411
  episode_reward_min: 120.56565656565674
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 4660db18edec4133bea4146aef7b53ae
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.873735078743526
        entropy_coeff: 0.0
        kl: 0.00509105170411723
        model: {}
        policy_loss: -0.015952216652554592
        total_loss: 2.530301707131522
        vf_explained_var: 0.9957433342933655
        vf_loss: 2.5452356168201993
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.48913043478261
    gpu_util_percent0: 0.3497826086956522
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497826086956523
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 67892
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15521280301474777
    mean_env_wait_ms: 1.2214966479460105
    mean_inference_ms: 4.77704483234056
    mean_raw_obs_processing_ms: 0.41282626257206023
  time_since_restore: 577.8970608711243
  time_this_iter_s: 38.142544746398926
  time_total_s: 577.8970608711243
  timers:
    learn_throughput: 5244.779
    learn_time_ms: 30848.201
    sample_throughput: 21847.126
    sample_time_ms: 7405.642
    update_time_ms: 27.15
  timestamp: 1602350837
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 7a69a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7a69a_00000 | RUNNING  | 172.17.0.4:67892 |     15 |          577.897 | 2426880 |  223.378 |              278.747 |              120.566 |            828.836 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7a69a_00000:
  custom_metrics:
    time_step_max: 4260
    time_step_mean: 3578.48
    time_step_min: 3216
  date: 2020-10-10_17-27-55
  done: true
  episode_len_mean: 827.8711288711289
  episode_reward_max: 278.74747474747517
  episode_reward_mean: 223.84071484071478
  episode_reward_min: 120.56565656565674
  episodes_this_iter: 159
  episodes_total: 3003
  experiment_id: 4660db18edec4133bea4146aef7b53ae
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8618249850613731
        entropy_coeff: 0.0
        kl: 0.005082745437643358
        model: {}
        policy_loss: -0.015743943995663097
        total_loss: 2.7845021656581332
        vf_explained_var: 0.9952844977378845
        vf_loss: 2.799229519707816
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.089361702127665
    gpu_util_percent0: 0.3891489361702127
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4914893617021265
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267445
    vram_util_percent2: 0.0009075233687267445
  pid: 67892
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15497958222011543
    mean_env_wait_ms: 1.2223186700311448
    mean_inference_ms: 4.762011760653845
    mean_raw_obs_processing_ms: 0.4119742754011872
  time_since_restore: 616.273416519165
  time_this_iter_s: 38.37635564804077
  time_total_s: 616.273416519165
  timers:
    learn_throughput: 5247.121
    learn_time_ms: 30834.431
    sample_throughput: 21832.707
    sample_time_ms: 7410.533
    update_time_ms: 27.157
  timestamp: 1602350875
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 7a69a_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7a69a_00000 | TERMINATED |       |     16 |          616.273 | 2588672 |  223.841 |              278.747 |              120.566 |            827.871 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7a69a_00000 | TERMINATED |       |     16 |          616.273 | 2588672 |  223.841 |              278.747 |              120.566 |            827.871 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


2020-10-10 17:27:55,817	WARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff10f667b001000000.
[2m[36m(pid=67807)[0m 2020-10-10 17:27:55,786	ERROR worker.py:372 -- SystemExit was raised from the worker
[2m[36m(pid=67807)[0m Traceback (most recent call last):
[2m[36m(pid=67807)[0m   File "python/ray/_raylet.pyx", line 553, in ray._raylet.task_execution_handler
[2m[36m(pid=67807)[0m   File "python/ray/_raylet.pyx", line 440, in ray._raylet.execute_task
[2m[36m(pid=67807)[0m   File "python/ray/_raylet.pyx", line 479, in ray._raylet.execute_task
[2m[36m(pid=67807)[0m   File "python/ray/_raylet.pyx", line 483, in ray._raylet.execute_task
[2m[36m(pid=67807)[0m   File "python/ray/_raylet.pyx", line 484, in ray._raylet.execute_task
[2m[36m(pid=67807)[0m   File "python/ray/_raylet.pyx", line 438, in ray._raylet.execute_task.function_executor
[2m[36m(pid=67807)[0m   File "/root/miniconda3/lib/python3.8/site-packages/ray/function_manager.py", line 553, in actor_method_executor
[2m[36m(pid=67807)[0m     return method(actor, *args, **kwargs)
[2m[36m(pid=67807)[0m   File "/root/miniconda3/lib/python3.8/site-packages/ray/actor.py", line 929, in __ray_terminate__
[2m[36m(pid=67807)[0m     ray.actor.exit_actor()
[2m[36m(pid=67807)[0m   File "/root/miniconda3/lib/python3.8/site-packages/ray/actor.py", line 991, in exit_actor
[2m[36m(pid=67807)[0m     ray.state.state.disconnect()
[2m[36m(pid=67807)[0m   File "/root/miniconda3/lib/python3.8/site-packages/ray/state.py", line 61, in disconnect
[2m[36m(pid=67807)[0m     self.global_state_accessor = None
[2m[36m(pid=67807)[0m   File "/root/miniconda3/lib/python3.8/site-packages/ray/worker.py", line 369, in sigterm_handler
[2m[36m(pid=67807)[0m     sys.exit(1)
[2m[36m(pid=67807)[0m SystemExit: 1
