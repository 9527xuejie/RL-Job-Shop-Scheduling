2020-10-08 22:55:50,389	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8270[39m[22m
== Status ==
Memory usage on this node: 57.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_6a054_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=54121)[0m 2020-10-08 22:55:53,418	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=54127)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54127)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54109)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54109)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54029)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54029)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54036)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54036)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54085)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54085)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54088)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54088)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54016)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54016)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53998)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53998)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54062)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54062)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53992)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53992)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54110)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54110)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54027)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54027)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54108)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54108)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54082)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54082)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54129)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54129)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54089)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54089)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54113)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54113)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54134)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54134)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54091)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54091)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54112)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54112)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54104)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54104)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54138)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54138)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54013)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54013)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54077)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54077)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54025)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54025)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54078)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54078)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54124)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54124)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54083)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54083)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54105)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54105)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54125)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54125)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54119)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54119)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54115)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54115)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53996)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53996)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54126)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54126)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54100)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54100)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54099)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54099)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54116)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54116)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54093)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54093)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53993)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53993)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53990)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53990)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54079)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54079)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53995)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53995)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54021)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54021)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54030)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54030)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54004)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54004)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53991)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53991)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54000)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54000)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54097)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54097)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54059)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54059)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54002)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54002)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54001)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54001)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54076)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54076)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54010)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54010)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54022)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54022)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54026)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54026)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54067)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54067)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54080)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54080)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53989)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53989)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54069)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54069)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54136)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54136)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53994)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53994)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54066)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54066)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54058)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54058)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54071)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54071)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54003)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54003)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54064)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54064)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53997)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53997)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54015)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54015)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54019)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54019)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54033)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54033)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54061)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54061)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54090)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54090)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54063)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54063)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54084)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54084)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54065)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54065)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53999)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53999)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54107)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54107)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54070)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54070)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54060)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54060)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_6a054_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3279.0
  date: 2020-10-08_22-56-24
  done: false
  episode_len_mean: 877.1708860759494
  episode_reward_max: 273.13131313131294
  episode_reward_mean: 224.28870988364636
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 8f467b14e9d542dfbb38b8db4539f1dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 1.0e-05
        entropy: 1.1648113965988158
        entropy_coeff: 0.0
        kl: 0.0022728978423401714
        model: {}
        policy_loss: -0.002197753207292408
        total_loss: 34.43254280090332
        vf_explained_var: 0.012283146381378174
        vf_loss: 34.43428688049316
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 40.306896551724144
    gpu_util_percent0: 0.34103448275862064
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.482758620689655
    vram_util_percent0: 0.2718330487101481
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17914654259771504
    mean_env_wait_ms: 1.6535337194317323
    mean_inference_ms: 6.114312622715714
    mean_raw_obs_processing_ms: 0.48870172644883403
  time_since_restore: 25.153890371322632
  time_this_iter_s: 25.153890371322632
  time_total_s: 25.153890371322632
  timers:
    learn_throughput: 10812.486
    learn_time_ms: 14963.441
    sample_throughput: 15990.138
    sample_time_ms: 10118.236
    update_time_ms: 30.655
  timestamp: 1602197784
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 6a054_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 72.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6a054_00000 | RUNNING  | 172.17.0.4:54121 |      1 |          25.1539 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6a054_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3266.0
  date: 2020-10-08_22-56-47
  done: false
  episode_len_mean: 870.9335443037975
  episode_reward_max: 273.13131313131294
  episode_reward_mean: 229.62156373865213
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 8f467b14e9d542dfbb38b8db4539f1dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 1.0e-05
        entropy: 1.141463303565979
        entropy_coeff: 0.0
        kl: 0.004696479625999927
        model: {}
        policy_loss: -0.003537985717412084
        total_loss: 22.73115978240967
        vf_explained_var: 0.23253922164440155
        vf_loss: 22.734227561950682
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.455555555555556
    gpu_util_percent0: 0.30666666666666664
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.733333333333334
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17346385548668003
    mean_env_wait_ms: 1.6497675977362882
    mean_inference_ms: 5.755654006660209
    mean_raw_obs_processing_ms: 0.47290623033374063
  time_since_restore: 48.3136088848114
  time_this_iter_s: 23.15971851348877
  time_total_s: 48.3136088848114
  timers:
    learn_throughput: 10904.928
    learn_time_ms: 14836.595
    sample_throughput: 17515.053
    sample_time_ms: 9237.311
    update_time_ms: 32.917
  timestamp: 1602197807
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 6a054_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6a054_00000 | RUNNING  | 172.17.0.4:54121 |      2 |          48.3136 | 323584 |  229.622 |              273.131 |              115.788 |            870.934 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6a054_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3234.0
  date: 2020-10-08_22-57-11
  done: false
  episode_len_mean: 863.8354430379746
  episode_reward_max: 275.6262626262625
  episode_reward_mean: 231.82881558197994
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 8f467b14e9d542dfbb38b8db4539f1dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 1.0e-05
        entropy: 1.1280611038208008
        entropy_coeff: 0.0
        kl: 0.007710202364251018
        model: {}
        policy_loss: -0.003906858712434768
        total_loss: 19.426103591918945
        vf_explained_var: 0.47659435868263245
        vf_loss: 19.42962474822998
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.15555555555555
    gpu_util_percent0: 0.27814814814814814
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.751851851851852
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16996869131272926
    mean_env_wait_ms: 1.6482694931743205
    mean_inference_ms: 5.5507899124132996
    mean_raw_obs_processing_ms: 0.4616002363224263
  time_since_restore: 71.55794930458069
  time_this_iter_s: 23.244340419769287
  time_total_s: 71.55794930458069
  timers:
    learn_throughput: 10926.797
    learn_time_ms: 14806.901
    sample_throughput: 18052.638
    sample_time_ms: 8962.236
    update_time_ms: 34.269
  timestamp: 1602197831
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 6a054_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6a054_00000 | RUNNING  | 172.17.0.4:54121 |      3 |          71.5579 | 485376 |  231.829 |              275.626 |              115.788 |            863.835 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6a054_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3234.0
  date: 2020-10-08_22-57-34
  done: false
  episode_len_mean: 856.493670886076
  episode_reward_max: 275.6262626262625
  episode_reward_mean: 232.24136939010336
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 8f467b14e9d542dfbb38b8db4539f1dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 1.0e-05
        entropy: 1.0987186670303344
        entropy_coeff: 0.0
        kl: 0.008328616060316563
        model: {}
        policy_loss: -0.004164357716217637
        total_loss: 17.521116065979005
        vf_explained_var: 0.6805382966995239
        vf_loss: 17.524863243103027
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.150000000000006
    gpu_util_percent0: 0.23461538461538461
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.757692307692308
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16761611344024185
    mean_env_wait_ms: 1.651177027118393
    mean_inference_ms: 5.405218356608056
    mean_raw_obs_processing_ms: 0.4539114571036245
  time_since_restore: 94.34990096092224
  time_this_iter_s: 22.791951656341553
  time_total_s: 94.34990096092224
  timers:
    learn_throughput: 10930.713
    learn_time_ms: 14801.596
    sample_throughput: 18591.171
    sample_time_ms: 8702.626
    update_time_ms: 33.963
  timestamp: 1602197854
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 6a054_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6a054_00000 | RUNNING  | 172.17.0.4:54121 |      4 |          94.3499 | 647168 |  232.241 |              275.626 |              115.788 |            856.494 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6a054_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3200.0
  date: 2020-10-08_22-57-57
  done: false
  episode_len_mean: 841.0400843881856
  episode_reward_max: 278.43434343434285
  episode_reward_mean: 234.33752077739405
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 316
  episodes_total: 948
  experiment_id: 8f467b14e9d542dfbb38b8db4539f1dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 1.0e-05
        entropy: 1.0705839157104493
        entropy_coeff: 0.0
        kl: 0.005878678616136312
        model: {}
        policy_loss: -0.003223293274641037
        total_loss: 18.541922187805177
        vf_explained_var: 0.8600037693977356
        vf_loss: 18.54485149383545
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.73703703703704
    gpu_util_percent0: 0.30925925925925923
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.74074074074074
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16462206914779068
    mean_env_wait_ms: 1.6612084862401661
    mean_inference_ms: 5.222749088847251
    mean_raw_obs_processing_ms: 0.44454315185926574
  time_since_restore: 117.46443963050842
  time_this_iter_s: 23.11453866958618
  time_total_s: 117.46443963050842
  timers:
    learn_throughput: 10951.59
    learn_time_ms: 14773.38
    sample_throughput: 18763.464
    sample_time_ms: 8622.715
    update_time_ms: 32.735
  timestamp: 1602197877
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 6a054_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6a054_00000 | RUNNING  | 172.17.0.4:54121 |      5 |          117.464 | 808960 |  234.338 |              278.434 |              115.788 |             841.04 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6a054_00000:WARNING:root:NaN or Inf found in input tensor.

  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3200.0
  date: 2020-10-08_22-58-20
  done: false
  episode_len_mean: 834.1473779385171
  episode_reward_max: 279.05050505050474
  episode_reward_mean: 235.08592251630213
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1106
  experiment_id: 8f467b14e9d542dfbb38b8db4539f1dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 1.0e-05
        entropy: 1.0623404502868652
        entropy_coeff: 0.0
        kl: 0.005542096681892872
        model: {}
        policy_loss: -0.0038662336533889174
        total_loss: 15.690526485443115
        vf_explained_var: 0.875198245048523
        vf_loss: 15.694114875793456
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.11923076923077
    gpu_util_percent0: 0.3342307692307692
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.76923076923077
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1636421932535757
    mean_env_wait_ms: 1.6655289735119498
    mean_inference_ms: 5.16050852160769
    mean_raw_obs_processing_ms: 0.44145435803456745
  time_since_restore: 140.22468376159668
  time_this_iter_s: 22.760244131088257
  time_total_s: 140.22468376159668
  timers:
    learn_throughput: 10969.354
    learn_time_ms: 14749.456
    sample_throughput: 18974.714
    sample_time_ms: 8526.716
    update_time_ms: 31.719
  timestamp: 1602197900
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 6a054_00000
  
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6a054_00000 | RUNNING  | 172.17.0.4:54121 |      6 |          140.225 | 970752 |  235.086 |              279.051 |              115.788 |            834.147 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6a054_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3193.0
  date: 2020-10-08_22-58-43
  done: false
  episode_len_mean: 828.5284810126582
  episode_reward_max: 282.70707070707124
  episode_reward_mean: 235.6024565272981
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 8f467b14e9d542dfbb38b8db4539f1dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 1.0e-05
        entropy: 1.0354247212409973
        entropy_coeff: 0.0
        kl: 0.004570994898676873
        model: {}
        policy_loss: -0.003509957739152014
        total_loss: 16.52836103439331
        vf_explained_var: 0.905647873878479
        vf_loss: 16.531642532348634
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.23461538461538
    gpu_util_percent0: 0.2611538461538462
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.753846153846155
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16282469907640307
    mean_env_wait_ms: 1.6698189070830225
    mean_inference_ms: 5.107367614760313
    mean_raw_obs_processing_ms: 0.4388860917906533
  time_since_restore: 163.05849599838257
  time_this_iter_s: 22.83381223678589
  time_total_s: 163.05849599838257
  timers:
    learn_throughput: 10969.884
    learn_time_ms: 14748.743
    sample_throughput: 19148.701
    sample_time_ms: 8449.241
    update_time_ms: 32.738
  timestamp: 1602197923
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 6a054_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6a054_00000 | RUNNING  | 172.17.0.4:54121 |      7 |          163.058 | 1132544 |  235.602 |              282.707 |              115.788 |            828.528 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6a054_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3154.0
  date: 2020-10-08_22-59-05
  done: false
  episode_len_mean: 821.4410393071286
  episode_reward_max: 286.77777777777754
  episode_reward_mean: 236.14073445985488
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 237
  episodes_total: 1501
  experiment_id: 8f467b14e9d542dfbb38b8db4539f1dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025
        cur_lr: 1.0e-05
        entropy: 0.9873153150081635
        entropy_coeff: 0.0
        kl: 0.0040563403628766535
        model: {}
        policy_loss: -0.002754798758542165
        total_loss: 19.042165565490723
        vf_explained_var: 0.9409818649291992
        vf_loss: 19.044818687438966
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.011538461538464
    gpu_util_percent0: 0.26884615384615385
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.746153846153847
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16181289750402897
    mean_env_wait_ms: 1.6767616332091015
    mean_inference_ms: 5.042288258474885
    mean_raw_obs_processing_ms: 0.4357560879748162
  time_since_restore: 185.8590669631958
  time_this_iter_s: 22.800570964813232
  time_total_s: 185.8590669631958
  timers:
    learn_throughput: 10979.424
    learn_time_ms: 14735.927
    sample_throughput: 19257.3
    sample_time_ms: 8401.593
    update_time_ms: 32.625
  timestamp: 1602197945
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 6a054_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6a054_00000 | RUNNING  | 172.17.0.4:54121 |      8 |          185.859 | 1294336 |  236.141 |              286.778 |              115.788 |            821.441 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6a054_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3154.0
  date: 2020-10-08_22-59-28
  done: false
  episode_len_mean: 815.758918296893
  episode_reward_max: 286.77777777777754
  episode_reward_mean: 236.49792516650965
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 237
  episodes_total: 1738
  experiment_id: 8f467b14e9d542dfbb38b8db4539f1dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0125
        cur_lr: 1.0e-05
        entropy: 0.9948332607746124
        entropy_coeff: 0.0
        kl: 0.004597921017557382
        model: {}
        policy_loss: -0.0033867573598399757
        total_loss: 16.775896644592287
        vf_explained_var: 0.9435850977897644
        vf_loss: 16.77922592163086
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.15
    gpu_util_percent0: 0.3030769230769231
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.746153846153847
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16106088720393538
    mean_env_wait_ms: 1.6825864725088768
    mean_inference_ms: 4.991266092788013
    mean_raw_obs_processing_ms: 0.4332675186074147
  time_since_restore: 208.68815922737122
  time_this_iter_s: 22.829092264175415
  time_total_s: 208.68815922737122
  timers:
    learn_throughput: 10982.244
    learn_time_ms: 14732.143
    sample_throughput: 19348.582
    sample_time_ms: 8361.956
    update_time_ms: 31.931
  timestamp: 1602197968
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 6a054_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6a054_00000 | RUNNING  | 172.17.0.4:54121 |      9 |          208.688 | 1456128 |  236.498 |              286.778 |              115.788 |            815.759 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6a054_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3154.0
  date: 2020-10-08_22-59-51
  done: false
  episode_len_mean: 812.542194092827
  episode_reward_max: 286.77777777777754
  episode_reward_mean: 236.68400247197707
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1896
  experiment_id: 8f467b14e9d542dfbb38b8db4539f1dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.00625
        cur_lr: 1.0e-05
        entropy: 0.9621005594730377
        entropy_coeff: 0.0
        kl: 0.004332464607432485
        model: {}
        policy_loss: -0.003909371211193502
        total_loss: 14.689541149139405
        vf_explained_var: 0.9541420936584473
        vf_loss: 14.693423461914062
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.08461538461539
    gpu_util_percent0: 0.2530769230769231
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.75769230769231
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16063681712076103
    mean_env_wait_ms: 1.6861400567458171
    mean_inference_ms: 4.962181852934355
    mean_raw_obs_processing_ms: 0.4318544042135594
  time_since_restore: 231.5172302722931
  time_this_iter_s: 22.829071044921875
  time_total_s: 231.5172302722931
  timers:
    learn_throughput: 10991.992
    learn_time_ms: 14719.078
    sample_throughput: 19398.112
    sample_time_ms: 8340.605
    update_time_ms: 30.773
  timestamp: 1602197991
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 6a054_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6a054_00000 | RUNNING  | 172.17.0.4:54121 |     10 |          231.517 | 1617920 |  236.684 |              286.778 |              115.788 |            812.542 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6a054_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3154.0
  date: 2020-10-08_23-00-14
  done: false
  episode_len_mean: 809.3718010622888
  episode_reward_max: 286.77777777777754
  episode_reward_mean: 236.91331470182257
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 175
  episodes_total: 2071
  experiment_id: 8f467b14e9d542dfbb38b8db4539f1dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.003125
        cur_lr: 1.0e-05
        entropy: 0.9148220241069793
        entropy_coeff: 0.0
        kl: 0.0035740533843636514
        model: {}
        policy_loss: -0.0032656193594448268
        total_loss: 14.430828666687011
        vf_explained_var: 0.9686474800109863
        vf_loss: 14.434083175659179
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.818518518518516
    gpu_util_percent0: 0.22444444444444442
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.755555555555555
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16020710555816167
    mean_env_wait_ms: 1.6899923448095384
    mean_inference_ms: 4.933064172323698
    mean_raw_obs_processing_ms: 0.4303738896889182
  time_since_restore: 254.65097332000732
  time_this_iter_s: 23.133743047714233
  time_total_s: 254.65097332000732
  timers:
    learn_throughput: 11012.012
    learn_time_ms: 14692.32
    sample_throughput: 19818.884
    sample_time_ms: 8163.527
    update_time_ms: 30.985
  timestamp: 1602198014
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 6a054_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6a054_00000 | RUNNING  | 172.17.0.4:54121 |     11 |          254.651 | 1779712 |  236.913 |              286.778 |              115.788 |            809.372 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6a054_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3154.0
  date: 2020-10-08_23-00-37
  done: false
  episode_len_mean: 804.8590717299578
  episode_reward_max: 286.77777777777754
  episode_reward_mean: 237.28975408089323
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 299
  episodes_total: 2370
  experiment_id: 8f467b14e9d542dfbb38b8db4539f1dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0015625
        cur_lr: 1.0e-05
        entropy: 0.8988907992839813
        entropy_coeff: 0.0
        kl: 0.0037852192763239145
        model: {}
        policy_loss: -0.003238326116115786
        total_loss: 15.205560302734375
        vf_explained_var: 0.9693174362182617
        vf_loss: 15.208792400360107
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.0923076923077
    gpu_util_percent0: 0.2546153846153846
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.746153846153847
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15963507740144453
    mean_env_wait_ms: 1.6959065816909802
    mean_inference_ms: 4.8916171257653
    mean_raw_obs_processing_ms: 0.4283352057910521
  time_since_restore: 277.44833731651306
  time_this_iter_s: 22.797363996505737
  time_total_s: 277.44833731651306
  timers:
    learn_throughput: 11027.016
    learn_time_ms: 14672.328
    sample_throughput: 19854.255
    sample_time_ms: 8148.984
    update_time_ms: 29.513
  timestamp: 1602198037
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 6a054_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6a054_00000 | RUNNING  | 172.17.0.4:54121 |     12 |          277.448 | 1941504 |   237.29 |              286.778 |              115.788 |            804.859 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6a054_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3154.0
  date: 2020-10-08_23-01-01
  done: false
  episode_len_mean: 802.7337816455696
  episode_reward_max: 286.77777777777754
  episode_reward_mean: 237.51194700166212
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2528
  experiment_id: 8f467b14e9d542dfbb38b8db4539f1dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.00078125
        cur_lr: 1.0e-05
        entropy: 0.8602386295795441
        entropy_coeff: 0.0
        kl: 0.0033153876196593047
        model: {}
        policy_loss: -0.002950664085801691
        total_loss: 11.22075719833374
        vf_explained_var: 0.973965048789978
        vf_loss: 11.223705387115478
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.04074074074074
    gpu_util_percent0: 0.28777777777777774
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.759259259259261
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15936731018791875
    mean_env_wait_ms: 1.6987219669803233
    mean_inference_ms: 4.8727018334569365
    mean_raw_obs_processing_ms: 0.42737235885466407
  time_since_restore: 300.81031799316406
  time_this_iter_s: 23.361980676651
  time_total_s: 300.81031799316406
  timers:
    learn_throughput: 11009.398
    learn_time_ms: 14695.808
    sample_throughput: 19891.636
    sample_time_ms: 8133.67
    update_time_ms: 30.836
  timestamp: 1602198061
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 6a054_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6a054_00000 | RUNNING  | 172.17.0.4:54121 |     13 |           300.81 | 2103296 |  237.512 |              286.778 |              115.788 |            802.734 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6a054_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3154.0
  date: 2020-10-08_23-01-24
  done: false
  episode_len_mean: 800.695361781076
  episode_reward_max: 286.77777777777754
  episode_reward_mean: 237.748951481419
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 167
  episodes_total: 2695
  experiment_id: 8f467b14e9d542dfbb38b8db4539f1dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.000390625
        cur_lr: 1.0e-05
        entropy: 0.825560337305069
        entropy_coeff: 0.0
        kl: 0.0033393387449905275
        model: {}
        policy_loss: -0.0027418327517807484
        total_loss: 9.88377113342285
        vf_explained_var: 0.9820414781570435
        vf_loss: 9.886511611938477
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.896153846153844
    gpu_util_percent0: 0.3523076923076923
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.757692307692308
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1591146053476099
    mean_env_wait_ms: 1.7017734034055434
    mean_inference_ms: 4.8545680222852186
    mean_raw_obs_processing_ms: 0.4264490343896055
  time_since_restore: 323.63870310783386
  time_this_iter_s: 22.8283851146698
  time_total_s: 323.63870310783386
  timers:
    learn_throughput: 11018.374
    learn_time_ms: 14683.836
    sample_throughput: 19856.61
    sample_time_ms: 8148.017
    update_time_ms: 30.999
  timestamp: 1602198084
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 6a054_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6a054_00000 | RUNNING  | 172.17.0.4:54121 |     14 |          323.639 | 2265088 |  237.749 |              286.778 |              115.788 |            800.695 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6a054_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3154.0
  date: 2020-10-08_23-01-47
  done: false
  episode_len_mean: 797.4040639573618
  episode_reward_max: 286.77777777777754
  episode_reward_mean: 238.07683766377966
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 307
  episodes_total: 3002
  experiment_id: 8f467b14e9d542dfbb38b8db4539f1dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0001953125
        cur_lr: 1.0e-05
        entropy: 0.8043903887271882
        entropy_coeff: 0.0
        kl: 0.0032967134611681104
        model: {}
        policy_loss: -0.0026359956013038755
        total_loss: 12.596563339233398
        vf_explained_var: 0.9788484573364258
        vf_loss: 12.59919843673706
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.146153846153844
    gpu_util_percent0: 0.3080769230769231
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.746153846153847
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15869759455088753
    mean_env_wait_ms: 1.706750924697766
    mean_inference_ms: 4.824752663252629
    mean_raw_obs_processing_ms: 0.42491104019420534
  time_since_restore: 346.6275894641876
  time_this_iter_s: 22.98888635635376
  time_total_s: 346.6275894641876
  timers:
    learn_throughput: 10999.684
    learn_time_ms: 14708.786
    sample_throughput: 19932.1
    sample_time_ms: 8117.158
    update_time_ms: 30.448
  timestamp: 1602198107
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 6a054_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6a054_00000 | RUNNING  | 172.17.0.4:54121 |     15 |          346.628 | 2426880 |  238.077 |              286.778 |              115.788 |            797.404 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6a054_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3154.0
  date: 2020-10-08_23-02-10
  done: false
  episode_len_mean: 795.8955696202531
  episode_reward_max: 286.77777777777754
  episode_reward_mean: 238.29301240250606
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 3160
  experiment_id: 8f467b14e9d542dfbb38b8db4539f1dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 9.765625e-05
        cur_lr: 1.0e-05
        entropy: 0.7785100400447845
        entropy_coeff: 0.0
        kl: 0.003010418242774904
        model: {}
        policy_loss: -0.0024716993561014534
        total_loss: 8.327378940582275
        vf_explained_var: 0.9821082949638367
        vf_loss: 8.329850482940675
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.05384615384615
    gpu_util_percent0: 0.31192307692307697
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.761538461538462
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15850783110369898
    mean_env_wait_ms: 1.709081136726841
    mean_inference_ms: 4.811370440590917
    mean_raw_obs_processing_ms: 0.4242301826221224
  time_since_restore: 369.64703702926636
  time_this_iter_s: 23.019447565078735
  time_total_s: 369.64703702926636
  timers:
    learn_throughput: 10994.187
    learn_time_ms: 14716.141
    sample_throughput: 19889.862
    sample_time_ms: 8134.395
    update_time_ms: 31.253
  timestamp: 1602198130
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 6a054_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6a054_00000 | RUNNING  | 172.17.0.4:54121 |     16 |          369.647 | 2588672 |  238.293 |              286.778 |              115.788 |            795.896 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6a054_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3154.0
  date: 2020-10-08_23-02-33
  done: false
  episode_len_mean: 794.3343328335832
  episode_reward_max: 286.77777777777754
  episode_reward_mean: 238.40270470825192
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 175
  episodes_total: 3335
  experiment_id: 8f467b14e9d542dfbb38b8db4539f1dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 4.8828125e-05
        cur_lr: 1.0e-05
        entropy: 0.7525176405906677
        entropy_coeff: 0.0
        kl: 0.0029826701385900376
        model: {}
        policy_loss: -0.002314317354466766
        total_loss: 7.59319748878479
        vf_explained_var: 0.9869136810302734
        vf_loss: 7.59551157951355
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.92307692307692
    gpu_util_percent0: 0.29423076923076924
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.757692307692308
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1583150607956069
    mean_env_wait_ms: 1.7117405102444516
    mean_inference_ms: 4.79785828743347
    mean_raw_obs_processing_ms: 0.42355592059848307
  time_since_restore: 392.54659056663513
  time_this_iter_s: 22.899553537368774
  time_total_s: 392.54659056663513
  timers:
    learn_throughput: 11003.435
    learn_time_ms: 14703.771
    sample_throughput: 19840.121
    sample_time_ms: 8154.789
    update_time_ms: 30.014
  timestamp: 1602198153
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 6a054_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6a054_00000 | RUNNING  | 172.17.0.4:54121 |     17 |          392.547 | 2750464 |  238.403 |              286.778 |              115.788 |            794.334 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6a054_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3154.0
  date: 2020-10-08_23-02-56
  done: false
  episode_len_mean: 791.9716565767749
  episode_reward_max: 286.77777777777754
  episode_reward_mean: 238.509734104946
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 299
  episodes_total: 3634
  experiment_id: 8f467b14e9d542dfbb38b8db4539f1dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 2.44140625e-05
        cur_lr: 1.0e-05
        entropy: 0.7295843839645386
        entropy_coeff: 0.0
        kl: 0.0028185041155666113
        model: {}
        policy_loss: -0.0023871829442214222
        total_loss: 10.098224258422851
        vf_explained_var: 0.9830418825149536
        vf_loss: 10.100611305236816
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.8962962962963
    gpu_util_percent0: 0.2848148148148148
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.74814814814815
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1580129596470305
    mean_env_wait_ms: 1.715830718497983
    mean_inference_ms: 4.776473014450544
    mean_raw_obs_processing_ms: 0.42246524066559327
  time_since_restore: 415.4631555080414
  time_this_iter_s: 22.91656494140625
  time_total_s: 415.4631555080414
  timers:
    learn_throughput: 10996.124
    learn_time_ms: 14713.548
    sample_throughput: 19837.307
    sample_time_ms: 8155.946
    update_time_ms: 29.447
  timestamp: 1602198176
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 6a054_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6a054_00000 | RUNNING  | 172.17.0.4:54121 |     18 |          415.463 | 2912256 |   238.51 |              286.778 |              115.788 |            791.972 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6a054_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3154.0
  date: 2020-10-08_23-03-19
  done: false
  episode_len_mean: 790.8056434599156
  episode_reward_max: 286.77777777777754
  episode_reward_mean: 238.56425808720113
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 3792
  experiment_id: 8f467b14e9d542dfbb38b8db4539f1dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 1.220703125e-05
        cur_lr: 1.0e-05
        entropy: 0.6998473823070526
        entropy_coeff: 0.0
        kl: 0.002630642498843372
        model: {}
        policy_loss: -0.0023243708303198217
        total_loss: 6.923893547058105
        vf_explained_var: 0.985211968421936
        vf_loss: 6.926217842102051
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.40769230769231
    gpu_util_percent0: 0.25153846153846154
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.761538461538462
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15786644204550024
    mean_env_wait_ms: 1.717828340120302
    mean_inference_ms: 4.766390279757361
    mean_raw_obs_processing_ms: 0.4219569961761242
  time_since_restore: 438.4320902824402
  time_this_iter_s: 22.968934774398804
  time_total_s: 438.4320902824402
  timers:
    learn_throughput: 10997.607
    learn_time_ms: 14711.564
    sample_throughput: 19799.691
    sample_time_ms: 8171.441
    update_time_ms: 28.853
  timestamp: 1602198199
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 6a054_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6a054_00000 | RUNNING  | 172.17.0.4:54121 |     19 |          438.432 | 3074048 |  238.564 |              286.778 |              115.788 |            790.806 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6a054_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3154.0
  date: 2020-10-08_23-03-42
  done: false
  episode_len_mean: 789.464859437751
  episode_reward_max: 286.77777777777754
  episode_reward_mean: 238.53637529917646
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 192
  episodes_total: 3984
  experiment_id: 8f467b14e9d542dfbb38b8db4539f1dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 6.103515625e-06
        cur_lr: 1.0e-05
        entropy: 0.6909353852272033
        entropy_coeff: 0.0
        kl: 0.002786552393808961
        model: {}
        policy_loss: -0.0022236188873648644
        total_loss: 6.577482509613037
        vf_explained_var: 0.9890497922897339
        vf_loss: 6.579706144332886
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.84814814814815
    gpu_util_percent0: 0.3118518518518518
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.755555555555556
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1576939825146875
    mean_env_wait_ms: 1.7202154716847182
    mean_inference_ms: 4.7548893736228175
    mean_raw_obs_processing_ms: 0.42138131535953793
  time_since_restore: 461.2145085334778
  time_this_iter_s: 22.782418251037598
  time_total_s: 461.2145085334778
  timers:
    learn_throughput: 10994.42
    learn_time_ms: 14715.828
    sample_throughput: 19824.18
    sample_time_ms: 8161.346
    update_time_ms: 28.994
  timestamp: 1602198222
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 6a054_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6a054_00000 | RUNNING  | 172.17.0.4:54121 |     20 |          461.215 | 3235840 |  238.536 |              286.778 |              115.788 |            789.465 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6a054_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3154.0
  date: 2020-10-08_23-04-05
  done: false
  episode_len_mean: 787.6889357712142
  episode_reward_max: 286.77777777777754
  episode_reward_mean: 238.60690827638786
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 282
  episodes_total: 4266
  experiment_id: 8f467b14e9d542dfbb38b8db4539f1dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 3.0517578125e-06
        cur_lr: 1.0e-05
        entropy: 0.6663406372070313
        entropy_coeff: 0.0
        kl: 0.002715998142957687
        model: {}
        policy_loss: -0.0022297472110949456
        total_loss: 8.286970233917236
        vf_explained_var: 0.9852756261825562
        vf_loss: 8.289199924468994
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.43846153846153
    gpu_util_percent0: 0.23038461538461538
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.753846153846155
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15746269162829796
    mean_env_wait_ms: 1.7235395286411022
    mean_inference_ms: 4.739603257961487
    mean_raw_obs_processing_ms: 0.42060881895176455
  time_since_restore: 484.13749408721924
  time_this_iter_s: 22.922985553741455
  time_total_s: 484.13749408721924
  timers:
    learn_throughput: 11002.506
    learn_time_ms: 14705.013
    sample_throughput: 19849.776
    sample_time_ms: 8150.823
    update_time_ms: 27.649
  timestamp: 1602198245
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 6a054_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6a054_00000 | RUNNING  | 172.17.0.4:54121 |     21 |          484.137 | 3397632 |  238.607 |              286.778 |              115.788 |            787.689 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6a054_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3154.0
  date: 2020-10-08_23-04-28
  done: false
  episode_len_mean: 786.7330470162749
  episode_reward_max: 286.77777777777754
  episode_reward_mean: 238.4758594078214
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 4424
  experiment_id: 8f467b14e9d542dfbb38b8db4539f1dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 1.52587890625e-06
        cur_lr: 1.0e-05
        entropy: 0.6475628197193146
        entropy_coeff: 0.0
        kl: 0.0024256462231278418
        model: {}
        policy_loss: -0.0021905378438532353
        total_loss: 5.6774801254272464
        vf_explained_var: 0.9873422384262085
        vf_loss: 5.679670572280884
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.315384615384616
    gpu_util_percent0: 0.3230769230769231
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.761538461538462
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15734483015524012
    mean_env_wait_ms: 1.725284216729348
    mean_inference_ms: 4.731750240358693
    mean_raw_obs_processing_ms: 0.42021046506597204
  time_since_restore: 506.946248292923
  time_this_iter_s: 22.808754205703735
  time_total_s: 506.946248292923
  timers:
    learn_throughput: 10988.895
    learn_time_ms: 14723.227
    sample_throughput: 19898.148
    sample_time_ms: 8131.008
    update_time_ms: 28.959
  timestamp: 1602198268
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 6a054_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6a054_00000 | RUNNING  | 172.17.0.4:54121 |     22 |          506.946 | 3559424 |  238.476 |              286.778 |              115.788 |            786.733 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6a054_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3154.0
  date: 2020-10-08_23-04-51
  done: false
  episode_len_mean: 785.3918166238218
  episode_reward_max: 286.77777777777754
  episode_reward_mean: 238.61322306180918
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 244
  episodes_total: 4668
  experiment_id: 8f467b14e9d542dfbb38b8db4539f1dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 7.62939453125e-07
        cur_lr: 1.0e-05
        entropy: 0.6451138138771058
        entropy_coeff: 0.0
        kl: 0.002594156586565077
        model: {}
        policy_loss: -0.0022726220078766344
        total_loss: 6.3089683055877686
        vf_explained_var: 0.9898545145988464
        vf_loss: 6.311240863800049
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.58461538461538
    gpu_util_percent0: 0.28692307692307695
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.757692307692308
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1571777348581981
    mean_env_wait_ms: 1.7279952472558344
    mean_inference_ms: 4.7207069110368085
    mean_raw_obs_processing_ms: 0.4196505354305137
  time_since_restore: 529.9962582588196
  time_this_iter_s: 23.050009965896606
  time_total_s: 529.9962582588196
  timers:
    learn_throughput: 11023.996
    learn_time_ms: 14676.347
    sample_throughput: 19853.422
    sample_time_ms: 8149.326
    update_time_ms: 25.94
  timestamp: 1602198291
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 6a054_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6a054_00000 | RUNNING  | 172.17.0.4:54121 |     23 |          529.996 | 3721216 |  238.613 |              286.778 |              115.788 |            785.392 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6a054_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3154.0
  date: 2020-10-08_23-05-15
  done: false
  episode_len_mean: 784.2411188240098
  episode_reward_max: 286.77777777777754
  episode_reward_mean: 238.67967341854643
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 230
  episodes_total: 4898
  experiment_id: 8f467b14e9d542dfbb38b8db4539f1dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 3.814697265625e-07
        cur_lr: 1.0e-05
        entropy: 0.610208147764206
        entropy_coeff: 0.0
        kl: 0.0023356436286121607
        model: {}
        policy_loss: -0.0021327507798559963
        total_loss: 6.352502727508545
        vf_explained_var: 0.9875691533088684
        vf_loss: 6.354635572433471
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.05769230769231
    gpu_util_percent0: 0.23461538461538461
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.753846153846155
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15701936150099097
    mean_env_wait_ms: 1.730257340724802
    mean_inference_ms: 4.710711922523823
    mean_raw_obs_processing_ms: 0.419128859339616
  time_since_restore: 552.9503643512726
  time_this_iter_s: 22.954106092453003
  time_total_s: 552.9503643512726
  timers:
    learn_throughput: 11024.598
    learn_time_ms: 14675.547
    sample_throughput: 19820.798
    sample_time_ms: 8162.739
    update_time_ms: 24.838
  timestamp: 1602198315
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: 6a054_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6a054_00000 | RUNNING  | 172.17.0.4:54121 |     24 |           552.95 | 3883008 |   238.68 |              286.778 |              115.788 |            784.241 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6a054_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3154.0
  date: 2020-10-08_23-05-38
  done: false
  episode_len_mean: 783.46875
  episode_reward_max: 286.77777777777754
  episode_reward_mean: 238.71623273878023
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 5056
  experiment_id: 8f467b14e9d542dfbb38b8db4539f1dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 1.9073486328125e-07
        cur_lr: 1.0e-05
        entropy: 0.5977782666683197
        entropy_coeff: 0.0
        kl: 0.002501734928227961
        model: {}
        policy_loss: -0.0023524786411144305
        total_loss: 4.734297132492065
        vf_explained_var: 0.9889183044433594
        vf_loss: 4.736649703979492
    num_steps_sampled: 4044800
    num_steps_trained: 4044800
  iterations_since_restore: 25
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.925925925925924
    gpu_util_percent0: 0.29962962962962963
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.75925925925926
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1569211571440175
    mean_env_wait_ms: 1.7317687738796774
    mean_inference_ms: 4.704412867923855
    mean_raw_obs_processing_ms: 0.4188022087350006
  time_since_restore: 576.0533661842346
  time_this_iter_s: 23.103001832962036
  time_total_s: 576.0533661842346
  timers:
    learn_throughput: 11043.471
    learn_time_ms: 14650.466
    sample_throughput: 19734.93
    sample_time_ms: 8198.255
    update_time_ms: 24.568
  timestamp: 1602198338
  timesteps_since_restore: 0
  timesteps_total: 4044800
  training_iteration: 25
  trial_id: 6a054_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6a054_00000 | RUNNING  | 172.17.0.4:54121 |     25 |          576.053 | 4044800 |  238.716 |              286.778 |              115.788 |            783.469 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6a054_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3154.0
  date: 2020-10-08_23-06-01
  done: false
  episode_len_mean: 782.1940857196331
  episode_reward_max: 286.77777777777754
  episode_reward_mean: 238.78563285862558
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 287
  episodes_total: 5343
  experiment_id: 8f467b14e9d542dfbb38b8db4539f1dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 9.5367431640625e-08
        cur_lr: 1.0e-05
        entropy: 0.5934074699878693
        entropy_coeff: 0.0
        kl: 0.0022022858960554005
        model: {}
        policy_loss: -0.0018734702956862749
        total_loss: 5.857509613037109
        vf_explained_var: 0.990534782409668
        vf_loss: 5.859383058547974
    num_steps_sampled: 4206592
    num_steps_trained: 4206592
  iterations_since_restore: 26
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.21153846153846
    gpu_util_percent0: 0.3119230769230769
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.75769230769231
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15675869365316658
    mean_env_wait_ms: 1.7345411029848097
    mean_inference_ms: 4.6938483486024865
    mean_raw_obs_processing_ms: 0.41827048050898125
  time_since_restore: 599.2767276763916
  time_this_iter_s: 23.223361492156982
  time_total_s: 599.2767276763916
  timers:
    learn_throughput: 11030.318
    learn_time_ms: 14667.936
    sample_throughput: 19730.511
    sample_time_ms: 8200.092
    update_time_ms: 24.17
  timestamp: 1602198361
  timesteps_since_restore: 0
  timesteps_total: 4206592
  training_iteration: 26
  trial_id: 6a054_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6a054_00000 | RUNNING  | 172.17.0.4:54121 |     26 |          599.277 | 4206592 |  238.786 |              286.778 |              115.788 |            782.194 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6a054_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3154.0
  date: 2020-10-08_23-06-25
  done: true
  episode_len_mean: 781.4144665461121
  episode_reward_max: 286.77777777777754
  episode_reward_mean: 238.86818821122623
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 187
  episodes_total: 5530
  experiment_id: 8f467b14e9d542dfbb38b8db4539f1dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 4.76837158203125e-08
        cur_lr: 1.0e-05
        entropy: 0.5576469779014588
        entropy_coeff: 0.0
        kl: 0.0021356522105634213
        model: {}
        policy_loss: -0.002097145572770387
        total_loss: 4.487537097930908
        vf_explained_var: 0.9902731776237488
        vf_loss: 4.489634323120117
    num_steps_sampled: 4368384
    num_steps_trained: 4368384
  iterations_since_restore: 27
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.97777777777778
    gpu_util_percent0: 0.2822222222222222
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.77037037037037
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15665257688297723
    mean_env_wait_ms: 1.7361327817288779
    mean_inference_ms: 4.6872951847530455
    mean_raw_obs_processing_ms: 0.41792779587390816
  time_since_restore: 622.3750748634338
  time_this_iter_s: 23.098347187042236
  time_total_s: 622.3750748634338
  timers:
    learn_throughput: 11019.488
    learn_time_ms: 14682.352
    sample_throughput: 19719.179
    sample_time_ms: 8204.804
    update_time_ms: 23.795
  timestamp: 1602198385
  timesteps_since_restore: 0
  timesteps_total: 4368384
  training_iteration: 27
  trial_id: 6a054_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6a054_00000 | TERMINATED |       |     27 |          622.375 | 4368384 |  238.868 |              286.778 |              115.788 |            781.414 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6a054_00000 | TERMINATED |       |     27 |          622.375 | 4368384 |  238.868 |              286.778 |              115.788 |            781.414 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


