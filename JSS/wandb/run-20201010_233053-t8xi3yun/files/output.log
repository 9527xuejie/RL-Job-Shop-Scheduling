2020-10-10 23:30:55,446	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_a58bd_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=67152)[0m 2020-10-10 23:30:58,266	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=67104)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67104)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67161)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67161)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67112)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67112)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67101)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67101)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67144)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67144)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67127)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67127)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67120)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67120)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67118)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67118)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67102)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67102)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67108)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67108)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67148)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67148)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67121)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67121)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67136)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67136)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67098)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67098)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67123)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67123)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67107)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67107)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67099)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67099)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67129)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67129)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67106)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67106)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67029)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67029)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67041)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67041)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67043)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67043)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67140)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67140)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67059)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67059)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67122)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67122)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67053)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67053)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67026)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67026)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67116)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67116)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67117)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67117)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67111)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67111)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67038)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67038)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67068)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67068)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67039)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67039)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67035)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67035)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67147)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67147)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67040)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67040)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67049)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67049)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67085)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67085)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67030)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67030)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67051)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67051)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67066)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67066)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67119)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67119)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67055)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67055)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67093)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67093)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67036)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67036)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67034)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67034)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67028)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67028)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67109)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67109)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67042)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67042)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67142)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67142)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67088)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67088)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67094)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67094)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67114)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67114)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67089)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67089)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67139)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67139)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67150)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67150)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67063)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67063)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67070)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67070)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67103)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67103)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67092)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67092)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67105)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67105)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67057)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67057)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67096)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67096)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67060)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67060)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67125)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67125)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67169)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67169)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67091)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67091)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67027)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67027)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67031)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67031)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67045)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67045)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67174)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67174)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67156)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67156)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67047)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67047)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67064)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67064)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67113)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67113)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67032)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67032)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67137)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67137)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67134)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67134)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=67087)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=67087)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_a58bd_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-10_23-31-39
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: c34a132612f048e39dd21a8e26e1a6af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1800774676459176
        entropy_coeff: 0.00010000000000000002
        kl: 0.008974136452057533
        model: {}
        policy_loss: -0.012535192438268236
        total_loss: 9.353281259536743
        vf_explained_var: 0.7688503861427307
        vf_loss: 9.364139488765172
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.66511627906977
    gpu_util_percent0: 0.38441860465116284
    gpu_util_percent1: 0.00023255813953488373
    gpu_util_percent2: 0.00023255813953488373
    ram_util_percent: 6.29767441860465
    vram_util_percent0: 0.19243061011235096
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 67152
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16683881464619885
    mean_env_wait_ms: 1.1772966929592075
    mean_inference_ms: 5.4151761513427665
    mean_raw_obs_processing_ms: 0.43924965877597744
  time_since_restore: 35.613706827163696
  time_this_iter_s: 35.613706827163696
  time_total_s: 35.613706827163696
  timers:
    learn_throughput: 6076.825
    learn_time_ms: 26624.429
    sample_throughput: 18156.346
    sample_time_ms: 8911.044
    update_time_ms: 48.522
  timestamp: 1602372699
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: a58bd_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a58bd_00000 | RUNNING  | 172.17.0.4:67152 |      1 |          35.6137 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a58bd_00000:
  custom_metrics:
    time_step_max: 4306
    time_step_mean: 3622.2291666666665
    time_step_min: 3366
  date: 2020-10-10_23-32-14
  done: false
  episode_len_mean: 882.9240506329114
  episode_reward_max: 263.44444444444395
  episode_reward_mean: 217.3670566423729
  episode_reward_min: 113.59595959595949
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: c34a132612f048e39dd21a8e26e1a6af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1455609713281905
        entropy_coeff: 0.00010000000000000002
        kl: 0.010994878198419298
        model: {}
        policy_loss: -0.016170730695843565
        total_loss: 7.924509423119681
        vf_explained_var: 0.9014290571212769
        vf_loss: 7.93859566961016
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.623809523809523
    gpu_util_percent0: 0.3507142857142857
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.471428571428571
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 67152
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16337565560758738
    mean_env_wait_ms: 1.1807717333221324
    mean_inference_ms: 5.2618276477751955
    mean_raw_obs_processing_ms: 0.43079558466000945
  time_since_restore: 70.09587240219116
  time_this_iter_s: 34.482165575027466
  time_total_s: 70.09587240219116
  timers:
    learn_throughput: 6090.03
    learn_time_ms: 26566.7
    sample_throughput: 19275.432
    sample_time_ms: 8393.69
    update_time_ms: 47.471
  timestamp: 1602372734
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: a58bd_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a58bd_00000 | RUNNING  | 172.17.0.4:67152 |      2 |          70.0959 | 323584 |  217.367 |              263.444 |              113.596 |            882.924 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a58bd_00000:
  custom_metrics:
    time_step_max: 4306
    time_step_mean: 3630.4618834080716
    time_step_min: 3343
  date: 2020-10-10_23-32-48
  done: false
  episode_len_mean: 876.282700421941
  episode_reward_max: 263.7474747474749
  episode_reward_mean: 217.40749264799874
  episode_reward_min: 113.59595959595949
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: c34a132612f048e39dd21a8e26e1a6af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1312096629823958
        entropy_coeff: 0.00010000000000000002
        kl: 0.010075017211160489
        model: {}
        policy_loss: -0.01707063611995961
        total_loss: 7.438368592943464
        vf_explained_var: 0.9473341703414917
        vf_loss: 7.453537293842861
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.62439024390244
    gpu_util_percent0: 0.416829268292683
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.490243902439025
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 67152
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16098106207125898
    mean_env_wait_ms: 1.1837163412402405
    mean_inference_ms: 5.130382878522962
    mean_raw_obs_processing_ms: 0.4247059148232385
  time_since_restore: 104.29743647575378
  time_this_iter_s: 34.20156407356262
  time_total_s: 104.29743647575378
  timers:
    learn_throughput: 6077.967
    learn_time_ms: 26619.426
    sample_throughput: 20084.236
    sample_time_ms: 8055.671
    update_time_ms: 45.817
  timestamp: 1602372768
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: a58bd_00000
  
== Status ==
Memory usage on this node: 48.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a58bd_00000 | RUNNING  | 172.17.0.4:67152 |      3 |          104.297 | 485376 |  217.407 |              263.747 |              113.596 |            876.283 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a58bd_00000:
  custom_metrics:
    time_step_max: 4306
    time_step_mean: 3625.57119205298
    time_step_min: 3343
  date: 2020-10-10_23-33-21
  done: false
  episode_len_mean: 869.4003164556962
  episode_reward_max: 263.7474747474749
  episode_reward_mean: 218.4902346247281
  episode_reward_min: 113.59595959595949
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: c34a132612f048e39dd21a8e26e1a6af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1006435922213964
        entropy_coeff: 0.00010000000000000002
        kl: 0.009914366861007043
        model: {}
        policy_loss: -0.017496433491552516
        total_loss: 6.803455999919346
        vf_explained_var: 0.9666232466697693
        vf_loss: 6.819079535348075
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.979999999999997
    gpu_util_percent0: 0.3765
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.49
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 67152
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15931791849301793
    mean_env_wait_ms: 1.186879827792476
    mean_inference_ms: 5.0313331395244765
    mean_raw_obs_processing_ms: 0.42004904412276134
  time_since_restore: 137.87102842330933
  time_this_iter_s: 33.57359194755554
  time_total_s: 137.87102842330933
  timers:
    learn_throughput: 6091.283
    learn_time_ms: 26561.234
    sample_throughput: 20690.723
    sample_time_ms: 7819.543
    update_time_ms: 41.198
  timestamp: 1602372801
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: a58bd_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a58bd_00000 | RUNNING  | 172.17.0.4:67152 |      4 |          137.871 | 647168 |   218.49 |              263.747 |              113.596 |              869.4 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a58bd_00000:
  custom_metrics:
    time_step_max: 4306
    time_step_mean: 3618.5304347826086
    time_step_min: 3338
  date: 2020-10-10_23-33-55
  done: false
  episode_len_mean: 860.7827130852341
  episode_reward_max: 263.7474747474749
  episode_reward_mean: 219.7851625498683
  episode_reward_min: 113.59595959595949
  episodes_this_iter: 201
  episodes_total: 833
  experiment_id: c34a132612f048e39dd21a8e26e1a6af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0521672197750636
        entropy_coeff: 0.00010000000000000002
        kl: 0.009515491048140185
        model: {}
        policy_loss: -0.018104477901943028
        total_loss: 8.333245175225395
        vf_explained_var: 0.978638231754303
        vf_loss: 8.349551575524467
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.755000000000003
    gpu_util_percent0: 0.37575000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.472499999999999
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 67152
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15781010788453081
    mean_env_wait_ms: 1.1921241930863
    mean_inference_ms: 4.93980374229282
    mean_raw_obs_processing_ms: 0.4153228080412081
  time_since_restore: 171.497211933136
  time_this_iter_s: 33.62618350982666
  time_total_s: 171.497211933136
  timers:
    learn_throughput: 6099.756
    learn_time_ms: 26524.341
    sample_throughput: 21043.506
    sample_time_ms: 7688.453
    update_time_ms: 40.233
  timestamp: 1602372835
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: a58bd_00000
  
== Status ==
Memory usage on this node: 48.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a58bd_00000 | RUNNING  | 172.17.0.4:67152 |      5 |          171.497 | 808960 |  219.785 |              263.747 |              113.596 |            860.783 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a58bd_00000:
  custom_metrics:
    time_step_max: 4306
    time_step_mean: 3608.208719851577
    time_step_min: 3263
  date: 2020-10-10_23-34-29
  done: false
  episode_len_mean: 850.9493670886076
  episode_reward_max: 271.6262626262628
  episode_reward_mean: 220.21015763420817
  episode_reward_min: 113.59595959595949
  episodes_this_iter: 273
  episodes_total: 1106
  experiment_id: c34a132612f048e39dd21a8e26e1a6af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.056253663131169
        entropy_coeff: 0.00010000000000000002
        kl: 0.009298879852784532
        model: {}
        policy_loss: -0.015670059331958846
        total_loss: 7.307290656226022
        vf_explained_var: 0.9822210669517517
        vf_loss: 7.3212067399706156
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.75121951219512
    gpu_util_percent0: 0.3482926829268293
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.485365853658536
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 67152
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15650311541704504
    mean_env_wait_ms: 1.1977800218225694
    mean_inference_ms: 4.856795729447399
    mean_raw_obs_processing_ms: 0.4114632213035228
  time_since_restore: 205.23573851585388
  time_this_iter_s: 33.738526582717896
  time_total_s: 205.23573851585388
  timers:
    learn_throughput: 6102.567
    learn_time_ms: 26512.121
    sample_throughput: 21269.535
    sample_time_ms: 7606.748
    update_time_ms: 39.585
  timestamp: 1602372869
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: a58bd_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a58bd_00000 | RUNNING  | 172.17.0.4:67152 |      6 |          205.236 | 970752 |   220.21 |              271.626 |              113.596 |            850.949 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a58bd_00000:
  custom_metrics:
    time_step_max: 4306
    time_step_mean: 3603.435275080906
    time_step_min: 3263
  date: 2020-10-10_23-35-03
  done: false
  episode_len_mean: 846.5498417721519
  episode_reward_max: 271.6262626262628
  episode_reward_mean: 220.9377317478582
  episode_reward_min: 113.59595959595949
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: c34a132612f048e39dd21a8e26e1a6af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.015541706766401
        entropy_coeff: 0.00010000000000000002
        kl: 0.009091055486351252
        model: {}
        policy_loss: -0.01913653877064852
        total_loss: 4.48865328516279
        vf_explained_var: 0.988744854927063
        vf_loss: 4.50607316834586
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.6375
    gpu_util_percent0: 0.36774999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4925
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 67152
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15591121729483995
    mean_env_wait_ms: 1.2004490060527298
    mean_inference_ms: 4.820219391421771
    mean_raw_obs_processing_ms: 0.4096719548644275
  time_since_restore: 239.17530059814453
  time_this_iter_s: 33.93956208229065
  time_total_s: 239.17530059814453
  timers:
    learn_throughput: 6101.45
    learn_time_ms: 26516.975
    sample_throughput: 21384.27
    sample_time_ms: 7565.935
    update_time_ms: 37.152
  timestamp: 1602372903
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: a58bd_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a58bd_00000 | RUNNING  | 172.17.0.4:67152 |      7 |          239.175 | 1132544 |  220.938 |              271.626 |              113.596 |             846.55 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a58bd_00000:
  custom_metrics:
    time_step_max: 4306
    time_step_mean: 3597.654232424677
    time_step_min: 3263
  date: 2020-10-10_23-35-37
  done: false
  episode_len_mean: 842.6068917018284
  episode_reward_max: 278.14141414141443
  episode_reward_mean: 221.70106124536494
  episode_reward_min: 113.59595959595949
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: c34a132612f048e39dd21a8e26e1a6af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9774923580033439
        entropy_coeff: 0.00010000000000000002
        kl: 0.009738831514758723
        model: {}
        policy_loss: -0.017437248619639183
        total_loss: 4.061158861432757
        vf_explained_var: 0.9904336333274841
        vf_loss: 4.076746072087969
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.20731707317073
    gpu_util_percent0: 0.33999999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.504878048780489
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 67152
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1554036805161584
    mean_env_wait_ms: 1.2030172727220159
    mean_inference_ms: 4.788765412845906
    mean_raw_obs_processing_ms: 0.4081167871916112
  time_since_restore: 273.0606474876404
  time_this_iter_s: 33.88534688949585
  time_total_s: 273.0606474876404
  timers:
    learn_throughput: 6101.168
    learn_time_ms: 26518.201
    sample_throughput: 21494.52
    sample_time_ms: 7527.128
    update_time_ms: 37.571
  timestamp: 1602372937
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: a58bd_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a58bd_00000 | RUNNING  | 172.17.0.4:67152 |      8 |          273.061 | 1294336 |  221.701 |              278.141 |              113.596 |            842.607 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a58bd_00000:
  custom_metrics:
    time_step_max: 4306
    time_step_mean: 3591.089179548157
    time_step_min: 3263
  date: 2020-10-10_23-36-11
  done: false
  episode_len_mean: 835.0163742690058
  episode_reward_max: 278.14141414141443
  episode_reward_mean: 222.75252525252515
  episode_reward_min: 113.59595959595949
  episodes_this_iter: 288
  episodes_total: 1710
  experiment_id: c34a132612f048e39dd21a8e26e1a6af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9384779419217791
        entropy_coeff: 0.00010000000000000002
        kl: 0.008118975907564163
        model: {}
        policy_loss: -0.016743591537566056
        total_loss: 5.7687895979200094
        vf_explained_var: 0.9918931722640991
        vf_loss: 5.78400308745248
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.60975609756098
    gpu_util_percent0: 0.3665853658536586
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.475609756097561
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 67152
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15467019369943563
    mean_env_wait_ms: 1.2078838525678037
    mean_inference_ms: 4.742573220924069
    mean_raw_obs_processing_ms: 0.4058726320869268
  time_since_restore: 307.1014075279236
  time_this_iter_s: 34.0407600402832
  time_total_s: 307.1014075279236
  timers:
    learn_throughput: 6097.56
    learn_time_ms: 26533.892
    sample_throughput: 21596.444
    sample_time_ms: 7491.604
    update_time_ms: 38.498
  timestamp: 1602372971
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: a58bd_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a58bd_00000 | RUNNING  | 172.17.0.4:67152 |      9 |          307.101 | 1456128 |  222.753 |              278.141 |              113.596 |            835.016 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a58bd_00000:
  custom_metrics:
    time_step_max: 4306
    time_step_mean: 3585.036402569593
    time_step_min: 3263
  date: 2020-10-10_23-36-45
  done: false
  episode_len_mean: 831.0701476793249
  episode_reward_max: 278.14141414141443
  episode_reward_mean: 223.47529088351865
  episode_reward_min: 113.59595959595949
  episodes_this_iter: 186
  episodes_total: 1896
  experiment_id: c34a132612f048e39dd21a8e26e1a6af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9015402027538845
        entropy_coeff: 0.00010000000000000002
        kl: 0.008653785700776748
        model: {}
        policy_loss: -0.018763800717091987
        total_loss: 3.5422303336007253
        vf_explained_var: 0.9931491613388062
        vf_loss: 3.5593535048621043
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.8625
    gpu_util_percent0: 0.354
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4975
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 67152
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1542849740981397
    mean_env_wait_ms: 1.2104177204566022
    mean_inference_ms: 4.718733797850951
    mean_raw_obs_processing_ms: 0.40471425827794066
  time_since_restore: 340.72515082359314
  time_this_iter_s: 33.623743295669556
  time_total_s: 340.72515082359314
  timers:
    learn_throughput: 6098.828
    learn_time_ms: 26528.374
    sample_throughput: 21723.984
    sample_time_ms: 7447.621
    update_time_ms: 38.729
  timestamp: 1602373005
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: a58bd_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a58bd_00000 | RUNNING  | 172.17.0.4:67152 |     10 |          340.725 | 1617920 |  223.475 |              278.141 |              113.596 |             831.07 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a58bd_00000:
  custom_metrics:
    time_step_max: 4306
    time_step_mean: 3580.9955577492597
    time_step_min: 3263
  date: 2020-10-10_23-37-19
  done: false
  episode_len_mean: 828.3286270691334
  episode_reward_max: 278.14141414141443
  episode_reward_mean: 224.00226215416083
  episode_reward_min: 113.59595959595949
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: c34a132612f048e39dd21a8e26e1a6af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8796590226037162
        entropy_coeff: 0.00010000000000000002
        kl: 0.008924131015581744
        model: {}
        policy_loss: -0.0195518767577596
        total_loss: 2.8431226185389926
        vf_explained_var: 0.9944176077842712
        vf_loss: 2.8609775645392284
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.8
    gpu_util_percent0: 0.36524999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5025
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 67152
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15399510051481582
    mean_env_wait_ms: 1.2124995858091956
    mean_inference_ms: 4.700519761123117
    mean_raw_obs_processing_ms: 0.4037826444296771
  time_since_restore: 374.32729983329773
  time_this_iter_s: 33.60214900970459
  time_total_s: 374.32729983329773
  timers:
    learn_throughput: 6104.385
    learn_time_ms: 26504.228
    sample_throughput: 22263.182
    sample_time_ms: 7267.245
    update_time_ms: 37.235
  timestamp: 1602373039
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: a58bd_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a58bd_00000 | RUNNING  | 172.17.0.4:67152 |     11 |          374.327 | 1779712 |  224.002 |              278.141 |              113.596 |            828.329 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a58bd_00000:
  custom_metrics:
    time_step_max: 4306
    time_step_mean: 3578.2238465052537
    time_step_min: 3258
  date: 2020-10-10_23-37-53
  done: false
  episode_len_mean: 826.2228236355435
  episode_reward_max: 278.14141414141443
  episode_reward_mean: 224.39208048003712
  episode_reward_min: 113.59595959595949
  episodes_this_iter: 163
  episodes_total: 2217
  experiment_id: c34a132612f048e39dd21a8e26e1a6af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8491792593683515
        entropy_coeff: 0.00010000000000000002
        kl: 0.007976285248462642
        model: {}
        policy_loss: -0.01608753442165575
        total_loss: 3.382563982691084
        vf_explained_var: 0.9946712851524353
        vf_loss: 3.3971411841256276
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.760975609756095
    gpu_util_percent0: 0.3546341463414634
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.49268292682927
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 67152
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15372602041919273
    mean_env_wait_ms: 1.2145735455028812
    mean_inference_ms: 4.683328783603096
    mean_raw_obs_processing_ms: 0.4028952257842757
  time_since_restore: 408.1843020915985
  time_this_iter_s: 33.85700225830078
  time_total_s: 408.1843020915985
  timers:
    learn_throughput: 6103.319
    learn_time_ms: 26508.856
    sample_throughput: 22471.369
    sample_time_ms: 7199.917
    update_time_ms: 37.357
  timestamp: 1602373073
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: a58bd_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a58bd_00000 | RUNNING  | 172.17.0.4:67152 |     12 |          408.184 | 1941504 |  224.392 |              278.141 |              113.596 |            826.223 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a58bd_00000:
  custom_metrics:
    time_step_max: 4306
    time_step_mean: 3570.6028
    time_step_min: 3258
  date: 2020-10-10_23-38-26
  done: false
  episode_len_mean: 822.842167721519
  episode_reward_max: 278.14141414141443
  episode_reward_mean: 225.54443964966114
  episode_reward_min: 113.59595959595949
  episodes_this_iter: 311
  episodes_total: 2528
  experiment_id: c34a132612f048e39dd21a8e26e1a6af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8138272421700614
        entropy_coeff: 0.00010000000000000002
        kl: 0.006960445516077536
        model: {}
        policy_loss: -0.013669906599846269
        total_loss: 3.5770836898258755
        vf_explained_var: 0.9951993823051453
        vf_loss: 3.589442951338632
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.3375
    gpu_util_percent0: 0.37374999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.477500000000001
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 67152
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15330051714839577
    mean_env_wait_ms: 1.218171044751991
    mean_inference_ms: 4.655551917475644
    mean_raw_obs_processing_ms: 0.4015260112699021
  time_since_restore: 441.9169497489929
  time_this_iter_s: 33.73264765739441
  time_total_s: 441.9169497489929
  timers:
    learn_throughput: 6110.0
    learn_time_ms: 26479.867
    sample_throughput: 22521.791
    sample_time_ms: 7183.798
    update_time_ms: 35.223
  timestamp: 1602373106
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: a58bd_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a58bd_00000 | RUNNING  | 172.17.0.4:67152 |     13 |          441.917 | 2103296 |  225.544 |              278.141 |              113.596 |            822.842 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a58bd_00000:
  custom_metrics:
    time_step_max: 4306
    time_step_mean: 3566.594431903687
    time_step_min: 3258
  date: 2020-10-10_23-39-00
  done: false
  episode_len_mean: 821.1954579300075
  episode_reward_max: 278.14141414141443
  episode_reward_mean: 226.15919432598506
  episode_reward_min: 113.59595959595949
  episodes_this_iter: 158
  episodes_total: 2686
  experiment_id: c34a132612f048e39dd21a8e26e1a6af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.7873089866978782
        entropy_coeff: 0.00010000000000000002
        kl: 0.007817941684541958
        model: {}
        policy_loss: -0.01798194270148607
        total_loss: 2.3146224532808577
        vf_explained_var: 0.9956455230712891
        vf_loss: 2.331119571413313
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.609756097560975
    gpu_util_percent0: 0.3875609756097561
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.490243902439025
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 67152
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15311717678672818
    mean_env_wait_ms: 1.2197809210428423
    mean_inference_ms: 4.643337034443957
    mean_raw_obs_processing_ms: 0.4009194944486611
  time_since_restore: 475.6549332141876
  time_this_iter_s: 33.7379834651947
  time_total_s: 475.6549332141876
  timers:
    learn_throughput: 6105.075
    learn_time_ms: 26501.23
    sample_throughput: 22544.922
    sample_time_ms: 7176.428
    update_time_ms: 36.847
  timestamp: 1602373140
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: a58bd_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a58bd_00000 | RUNNING  | 172.17.0.4:67152 |     14 |          475.655 | 2265088 |  226.159 |              278.141 |              113.596 |            821.195 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a58bd_00000:
  custom_metrics:
    time_step_max: 4306
    time_step_mean: 3562.6548295454545
    time_step_min: 3258
  date: 2020-10-10_23-39-34
  done: false
  episode_len_mean: 819.7805907172996
  episode_reward_max: 278.14141414141443
  episode_reward_mean: 226.86845245706004
  episode_reward_min: 113.59595959595949
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: c34a132612f048e39dd21a8e26e1a6af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.7732321109090533
        entropy_coeff: 0.00010000000000000002
        kl: 0.007333279221451708
        model: {}
        policy_loss: -0.017772257128464326
        total_loss: 2.133357507841928
        vf_explained_var: 0.9957687258720398
        vf_loss: 2.1497404405048917
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.205
    gpu_util_percent0: 0.3395
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5025
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 67152
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.152949013129624
    mean_env_wait_ms: 1.221319598996701
    mean_inference_ms: 4.632011838406506
    mean_raw_obs_processing_ms: 0.40033412814874175
  time_since_restore: 509.3378372192383
  time_this_iter_s: 33.68290400505066
  time_total_s: 509.3378372192383
  timers:
    learn_throughput: 6105.803
    learn_time_ms: 26498.072
    sample_throughput: 22528.86
    sample_time_ms: 7181.544
    update_time_ms: 37.76
  timestamp: 1602373174
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: a58bd_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a58bd_00000 | RUNNING  | 172.17.0.4:67152 |     15 |          509.338 | 2426880 |  226.868 |              278.141 |              113.596 |            819.781 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a58bd_00000:
  custom_metrics:
    time_step_max: 4306
    time_step_mean: 3555.169689119171
    time_step_min: 3258
  date: 2020-10-10_23-40-08
  done: false
  episode_len_mean: 817.721758664955
  episode_reward_max: 278.14141414141443
  episode_reward_mean: 227.86678077307093
  episode_reward_min: 113.59595959595949
  episodes_this_iter: 272
  episodes_total: 3116
  experiment_id: c34a132612f048e39dd21a8e26e1a6af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.7466375742639814
        entropy_coeff: 0.00010000000000000002
        kl: 0.0072607041137026885
        model: {}
        policy_loss: -0.01422150940301695
        total_loss: 2.8245921645845686
        vf_explained_var: 0.9960805177688599
        vf_loss: 2.837436250277928
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.690243902439022
    gpu_util_percent0: 0.32682926829268294
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.485365853658536
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 67152
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15268985724639875
    mean_env_wait_ms: 1.2238476312736137
    mean_inference_ms: 4.614047668540391
    mean_raw_obs_processing_ms: 0.3994059020111786
  time_since_restore: 543.079784154892
  time_this_iter_s: 33.74194693565369
  time_total_s: 543.079784154892
  timers:
    learn_throughput: 6107.253
    learn_time_ms: 26491.779
    sample_throughput: 22524.107
    sample_time_ms: 7183.059
    update_time_ms: 42.499
  timestamp: 1602373208
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: a58bd_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a58bd_00000 | RUNNING  | 172.17.0.4:67152 |     16 |           543.08 | 2588672 |  227.867 |              278.141 |              113.596 |            817.722 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a58bd_00000:
  custom_metrics:
    time_step_max: 4306
    time_step_mean: 3551.105775075988
    time_step_min: 3233
  date: 2020-10-10_23-40-42
  done: false
  episode_len_mean: 816.466847498493
  episode_reward_max: 278.14141414141443
  episode_reward_mean: 228.57513653716188
  episode_reward_min: 113.59595959595949
  episodes_this_iter: 202
  episodes_total: 3318
  experiment_id: c34a132612f048e39dd21a8e26e1a6af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.7092543457235608
        entropy_coeff: 0.00010000000000000002
        kl: 0.006785347325993436
        model: {}
        policy_loss: -0.014969801679918808
        total_loss: 2.138042790549142
        vf_explained_var: 0.9960756301879883
        vf_loss: 2.151726407664163
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.2675
    gpu_util_percent0: 0.41025
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4975
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 67152
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1525195171895558
    mean_env_wait_ms: 1.225517663226703
    mean_inference_ms: 4.602937395256092
    mean_raw_obs_processing_ms: 0.3988818920776555
  time_since_restore: 576.9431412220001
  time_this_iter_s: 33.863357067108154
  time_total_s: 576.9431412220001
  timers:
    learn_throughput: 6107.821
    learn_time_ms: 26489.315
    sample_throughput: 22545.01
    sample_time_ms: 7176.4
    update_time_ms: 43.21
  timestamp: 1602373242
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: a58bd_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a58bd_00000 | RUNNING  | 172.17.0.4:67152 |     17 |          576.943 | 2750464 |  228.575 |              278.141 |              113.596 |            816.467 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a58bd_00000:
  custom_metrics:
    time_step_max: 4306
    time_step_mean: 3547.356438515081
    time_step_min: 3233
  date: 2020-10-10_23-41-16
  done: true
  episode_len_mean: 815.6582278481013
  episode_reward_max: 278.14141414141443
  episode_reward_mean: 229.1365060268973
  episode_reward_min: 113.59595959595949
  episodes_this_iter: 158
  episodes_total: 3476
  experiment_id: c34a132612f048e39dd21a8e26e1a6af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.7116708670343671
        entropy_coeff: 0.00010000000000000002
        kl: 0.007901468247707401
        model: {}
        policy_loss: -0.01638922231671001
        total_loss: 1.9197264313697815
        vf_explained_var: 0.9959777593612671
        vf_loss: 1.9346065095492773
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.82439024390244
    gpu_util_percent0: 0.3436585365853658
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.495121951219514
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 67152
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15239408337119345
    mean_env_wait_ms: 1.2267332359685699
    mean_inference_ms: 4.594566628085028
    mean_raw_obs_processing_ms: 0.39846246007976527
  time_since_restore: 610.7571783065796
  time_this_iter_s: 33.81403708457947
  time_total_s: 610.7571783065796
  timers:
    learn_throughput: 6107.4
    learn_time_ms: 26491.142
    sample_throughput: 22567.239
    sample_time_ms: 7169.331
    update_time_ms: 41.664
  timestamp: 1602373276
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: a58bd_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a58bd_00000 | TERMINATED |       |     18 |          610.757 | 2912256 |  229.137 |              278.141 |              113.596 |            815.658 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a58bd_00000 | TERMINATED |       |     18 |          610.757 | 2912256 |  229.137 |              278.141 |              113.596 |            815.658 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


