2020-10-11 21:43:15,932	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_c5c88_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=69834)[0m 2020-10-11 21:43:18,730	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=69843)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69843)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69806)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69806)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69777)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69777)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69842)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69842)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69840)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69840)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69776)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69776)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69831)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69831)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69836)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69836)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69802)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69802)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69838)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69838)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69711)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69711)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69825)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69825)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69810)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69810)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69773)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69773)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69719)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69719)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69823)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69823)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69827)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69827)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69809)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69809)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69801)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69801)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69789)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69789)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69722)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69722)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69787)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69787)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69713)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69713)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69726)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69726)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69774)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69774)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69792)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69792)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69812)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69812)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69788)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69788)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69837)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69837)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69795)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69795)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69796)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69796)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69770)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69770)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69729)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69729)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69737)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69737)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69813)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69813)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69815)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69815)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69733)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69733)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69740)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69740)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69741)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69741)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69718)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69718)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69720)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69720)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69742)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69742)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69710)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69710)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69716)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69716)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69791)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69791)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69731)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69731)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69790)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69790)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69793)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69793)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69727)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69727)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69714)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69714)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69779)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69779)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69709)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69709)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69828)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69828)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69783)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69783)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69724)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69724)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69786)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69786)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69725)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69725)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69728)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69728)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69712)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69712)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69814)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69814)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69735)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69735)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69748)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69748)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69775)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69775)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69785)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69785)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69821)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69821)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69749)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69749)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69781)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69781)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69799)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69799)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69794)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69794)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69822)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69822)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69745)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69745)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69800)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69800)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69784)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69784)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69717)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69717)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69715)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69715)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69730)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69730)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69772)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69772)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69807)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69807)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69778)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69778)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_c5c88_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_21-44-00
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 500cec2adad9483c8e460de7b4e14bf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.1844651301701863
        entropy_coeff: 0.0005000000000000001
        kl: 0.0044430313088620705
        model: {}
        policy_loss: -0.012179883121765064
        total_loss: 500.4128672281901
        vf_explained_var: 0.5819632411003113
        vf_loss: 500.42430623372394
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.969047619047622
    gpu_util_percent0: 0.30523809523809525
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5880952380952373
    vram_util_percent0: 0.08979915350856645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69834
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1743452561494192
    mean_env_wait_ms: 1.1876022466063023
    mean_inference_ms: 6.224559802779374
    mean_raw_obs_processing_ms: 0.4718945754387748
  time_since_restore: 36.09882164001465
  time_this_iter_s: 36.09882164001465
  time_total_s: 36.09882164001465
  timers:
    learn_throughput: 6146.461
    learn_time_ms: 26322.791
    sample_throughput: 16692.2
    sample_time_ms: 9692.671
    update_time_ms: 42.907
  timestamp: 1602452640
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: c5c88_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c5c88_00000 | RUNNING  | 172.17.0.4:69834 |      1 |          36.0988 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c5c88_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3621.590277777778
    time_step_min: 3354
  date: 2020-10-11_21-44-34
  done: false
  episode_len_mean: 889.4303797468355
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 217.1249200869452
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 500cec2adad9483c8e460de7b4e14bf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.1531025966008503
        entropy_coeff: 0.0005000000000000001
        kl: 0.007714953972026706
        model: {}
        policy_loss: -0.01635422941762954
        total_loss: 117.71188036600749
        vf_explained_var: 0.8277090191841125
        vf_loss: 117.72765223185222
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.5
    gpu_util_percent0: 0.3645
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7625
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69834
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1695640728355739
    mean_env_wait_ms: 1.1801280875955324
    mean_inference_ms: 5.928672357686778
    mean_raw_obs_processing_ms: 0.45966296873844215
  time_since_restore: 69.99370074272156
  time_this_iter_s: 33.89487910270691
  time_total_s: 69.99370074272156
  timers:
    learn_throughput: 6202.495
    learn_time_ms: 26084.985
    sample_throughput: 18316.389
    sample_time_ms: 8833.182
    update_time_ms: 33.554
  timestamp: 1602452674
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: c5c88_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c5c88_00000 | RUNNING  | 172.17.0.4:69834 |      2 |          69.9937 | 323584 |  217.125 |              258.596 |              145.717 |             889.43 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c5c88_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3614.4775784753365
    time_step_min: 3302
  date: 2020-10-11_21-45-07
  done: false
  episode_len_mean: 890.7257383966245
  episode_reward_max: 265.7171717171719
  episode_reward_mean: 218.3344840813193
  episode_reward_min: 140.41414141414108
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 500cec2adad9483c8e460de7b4e14bf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.1406760215759277
        entropy_coeff: 0.0005000000000000001
        kl: 0.0086228356231004
        model: {}
        policy_loss: -0.015899320094225306
        total_loss: 46.499051094055176
        vf_explained_var: 0.9181849956512451
        vf_loss: 46.51422945658366
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.923076923076927
    gpu_util_percent0: 0.3392307692307692
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7769230769230786
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69834
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16635078340245024
    mean_env_wait_ms: 1.175306389366152
    mean_inference_ms: 5.709399435484217
    mean_raw_obs_processing_ms: 0.45021174077110526
  time_since_restore: 103.63569378852844
  time_this_iter_s: 33.641993045806885
  time_total_s: 103.63569378852844
  timers:
    learn_throughput: 6194.602
    learn_time_ms: 26118.223
    sample_throughput: 19390.512
    sample_time_ms: 8343.875
    update_time_ms: 36.694
  timestamp: 1602452707
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: c5c88_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c5c88_00000 | RUNNING  | 172.17.0.4:69834 |      3 |          103.636 | 485376 |  218.334 |              265.717 |              140.414 |            890.726 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c5c88_00000:
  custom_metrics:
    time_step_max: 4218
    time_step_mean: 3607.407284768212
    time_step_min: 3302
  date: 2020-10-11_21-45-40
  done: false
  episode_len_mean: 890.1012658227849
  episode_reward_max: 265.8686868686864
  episode_reward_mean: 219.31541682649254
  episode_reward_min: 126.92929292929276
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 500cec2adad9483c8e460de7b4e14bf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.1265246272087097
        entropy_coeff: 0.0005000000000000001
        kl: 0.008462440688163042
        model: {}
        policy_loss: -0.019030045446318884
        total_loss: 26.90568955739339
        vf_explained_var: 0.951666533946991
        vf_loss: 26.9240140914917
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.010256410256407
    gpu_util_percent0: 0.3628205128205128
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7820512820512837
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69834
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16399883025854467
    mean_env_wait_ms: 1.1722547848077913
    mean_inference_ms: 5.541637706114139
    mean_raw_obs_processing_ms: 0.44231734286917357
  time_since_restore: 136.7021508216858
  time_this_iter_s: 33.06645703315735
  time_total_s: 136.7021508216858
  timers:
    learn_throughput: 6208.46
    learn_time_ms: 26059.923
    sample_throughput: 20140.468
    sample_time_ms: 8033.18
    update_time_ms: 35.971
  timestamp: 1602452740
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: c5c88_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c5c88_00000 | RUNNING  | 172.17.0.4:69834 |      4 |          136.702 | 647168 |  219.315 |              265.869 |              126.929 |            890.101 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c5c88_00000:
  custom_metrics:
    time_step_max: 4218
    time_step_mean: 3599.8595800524936
    time_step_min: 3302
  date: 2020-10-11_21-46-14
  done: false
  episode_len_mean: 887.9658227848101
  episode_reward_max: 265.8686868686864
  episode_reward_mean: 221.01157141030535
  episode_reward_min: 126.92929292929276
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 500cec2adad9483c8e460de7b4e14bf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.1021929879983265
        entropy_coeff: 0.0005000000000000001
        kl: 0.009454707615077496
        model: {}
        policy_loss: -0.01852187712211162
        total_loss: 21.74484173456828
        vf_explained_var: 0.9581985473632812
        vf_loss: 21.762495676676433
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.094871794871796
    gpu_util_percent0: 0.31179487179487175
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.771794871794873
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69834
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16216895996206301
    mean_env_wait_ms: 1.1704444236551272
    mean_inference_ms: 5.410998009731065
    mean_raw_obs_processing_ms: 0.4359159871451541
  time_since_restore: 170.01364064216614
  time_this_iter_s: 33.31148982048035
  time_total_s: 170.01364064216614
  timers:
    learn_throughput: 6202.309
    learn_time_ms: 26085.771
    sample_throughput: 20652.301
    sample_time_ms: 7834.091
    update_time_ms: 36.009
  timestamp: 1602452774
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: c5c88_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c5c88_00000 | RUNNING  | 172.17.0.4:69834 |      5 |          170.014 | 808960 |  221.012 |              265.869 |              126.929 |            887.966 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c5c88_00000:
  custom_metrics:
    time_step_max: 4218
    time_step_mean: 3588.039014373717
    time_step_min: 3287
  date: 2020-10-11_21-46-47
  done: false
  episode_len_mean: 882.5409181636727
  episode_reward_max: 283.59595959595924
  episode_reward_mean: 222.92517994314377
  episode_reward_min: 126.92929292929276
  episodes_this_iter: 212
  episodes_total: 1002
  experiment_id: 500cec2adad9483c8e460de7b4e14bf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.070347140232722
        entropy_coeff: 0.0005000000000000001
        kl: 0.008666444647436341
        model: {}
        policy_loss: -0.01832717432989739
        total_loss: 26.041357676188152
        vf_explained_var: 0.9653134346008301
        vf_loss: 26.058919111887615
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.83076923076923
    gpu_util_percent0: 0.3051282051282051
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.771794871794873
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69834
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16033077718165095
    mean_env_wait_ms: 1.170482974067725
    mean_inference_ms: 5.2796691685712025
    mean_raw_obs_processing_ms: 0.4293990935067226
  time_since_restore: 203.17402362823486
  time_this_iter_s: 33.160382986068726
  time_total_s: 203.17402362823486
  timers:
    learn_throughput: 6198.457
    learn_time_ms: 26101.981
    sample_throughput: 21073.806
    sample_time_ms: 7677.398
    update_time_ms: 35.748
  timestamp: 1602452807
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: c5c88_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c5c88_00000 | RUNNING  | 172.17.0.4:69834 |      6 |          203.174 | 970752 |  222.925 |              283.596 |              126.929 |            882.541 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c5c88_00000:
  custom_metrics:
    time_step_max: 4218
    time_step_mean: 3569.6674757281553
    time_step_min: 3207
  date: 2020-10-11_21-47-20
  done: false
  episode_len_mean: 876.0435126582279
  episode_reward_max: 283.59595959595924
  episode_reward_mean: 225.56385852192798
  episode_reward_min: 124.65656565656555
  episodes_this_iter: 262
  episodes_total: 1264
  experiment_id: 500cec2adad9483c8e460de7b4e14bf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.0884329974651337
        entropy_coeff: 0.0005000000000000001
        kl: 0.007705493868949513
        model: {}
        policy_loss: -0.01605685978817443
        total_loss: 20.35645357767741
        vf_explained_var: 0.9663594365119934
        vf_loss: 20.371898969014484
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.53333333333333
    gpu_util_percent0: 0.2935897435897436
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.779487179487181
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69834
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15863015974032038
    mean_env_wait_ms: 1.1707564865663762
    mean_inference_ms: 5.159930077891861
    mean_raw_obs_processing_ms: 0.4233208804774411
  time_since_restore: 236.3120641708374
  time_this_iter_s: 33.13804054260254
  time_total_s: 236.3120641708374
  timers:
    learn_throughput: 6198.323
    learn_time_ms: 26102.545
    sample_throughput: 21366.206
    sample_time_ms: 7572.332
    update_time_ms: 36.161
  timestamp: 1602452840
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: c5c88_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c5c88_00000 | RUNNING  | 172.17.0.4:69834 |      7 |          236.312 | 1132544 |  225.564 |              283.596 |              124.657 |            876.044 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c5c88_00000:
  custom_metrics:
    time_step_max: 4218
    time_step_mean: 3561.0200860832138
    time_step_min: 3207
  date: 2020-10-11_21-47-54
  done: false
  episode_len_mean: 871.9880450070324
  episode_reward_max: 283.59595959595924
  episode_reward_mean: 226.68369347483258
  episode_reward_min: 124.65656565656555
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 500cec2adad9483c8e460de7b4e14bf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.0663296182950337
        entropy_coeff: 0.0005000000000000001
        kl: 0.007993325009010732
        model: {}
        policy_loss: -0.016870515818785254
        total_loss: 18.95603322982788
        vf_explained_var: 0.9652079939842224
        vf_loss: 18.972237586975098
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.894871794871793
    gpu_util_percent0: 0.32282051282051283
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7897435897435914
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69834
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15782614249839408
    mean_env_wait_ms: 1.1712779203595212
    mean_inference_ms: 5.103302799905964
    mean_raw_obs_processing_ms: 0.42047265495489966
  time_since_restore: 269.5199325084686
  time_this_iter_s: 33.207868337631226
  time_total_s: 269.5199325084686
  timers:
    learn_throughput: 6198.558
    learn_time_ms: 26101.556
    sample_throughput: 21557.077
    sample_time_ms: 7505.285
    update_time_ms: 34.556
  timestamp: 1602452874
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: c5c88_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c5c88_00000 | RUNNING  | 172.17.0.4:69834 |      8 |           269.52 | 1294336 |  226.684 |              283.596 |              124.657 |            871.988 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c5c88_00000:
  custom_metrics:
    time_step_max: 4218
    time_step_mean: 3553.5612113402062
    time_step_min: 3207
  date: 2020-10-11_21-48-27
  done: false
  episode_len_mean: 868.6436708860759
  episode_reward_max: 283.59595959595924
  episode_reward_mean: 227.8897839151002
  episode_reward_min: 124.65656565656555
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 500cec2adad9483c8e460de7b4e14bf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.0481368104616802
        entropy_coeff: 0.0005000000000000001
        kl: 0.007944589092706641
        model: {}
        policy_loss: -0.01694945936712126
        total_loss: 16.303564071655273
        vf_explained_var: 0.9678131937980652
        vf_loss: 16.319845994313557
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.250000000000004
    gpu_util_percent0: 0.30736842105263157
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.778947368421054
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69834
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15712155427833038
    mean_env_wait_ms: 1.1718470467882602
    mean_inference_ms: 5.05363310953136
    mean_raw_obs_processing_ms: 0.41791079153045396
  time_since_restore: 302.45601987838745
  time_this_iter_s: 32.93608736991882
  time_total_s: 302.45601987838745
  timers:
    learn_throughput: 6203.87
    learn_time_ms: 26079.206
    sample_throughput: 21737.896
    sample_time_ms: 7442.855
    update_time_ms: 34.99
  timestamp: 1602452907
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: c5c88_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c5c88_00000 | RUNNING  | 172.17.0.4:69834 |      9 |          302.456 | 1456128 |   227.89 |              283.596 |              124.657 |            868.644 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c5c88_00000:
  custom_metrics:
    time_step_max: 4405
    time_step_mean: 3548.158878504673
    time_step_min: 3207
  date: 2020-10-11_21-48-59
  done: false
  episode_len_mean: 865.466091954023
  episode_reward_max: 283.59595959595924
  episode_reward_mean: 228.72161267850908
  episode_reward_min: 98.5959595959593
  episodes_this_iter: 160
  episodes_total: 1740
  experiment_id: 500cec2adad9483c8e460de7b4e14bf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.0159983734289806
        entropy_coeff: 0.0005000000000000001
        kl: 0.007835847907699645
        model: {}
        policy_loss: -0.016908873706900824
        total_loss: 21.36884530385335
        vf_explained_var: 0.9641661047935486
        vf_loss: 21.38508685429891
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.78974358974359
    gpu_util_percent0: 0.34846153846153843
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7769230769230786
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69834
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1564948025695987
    mean_env_wait_ms: 1.172530675287108
    mean_inference_ms: 5.009352279180749
    mean_raw_obs_processing_ms: 0.41560262109644125
  time_since_restore: 335.3128111362457
  time_this_iter_s: 32.856791257858276
  time_total_s: 335.3128111362457
  timers:
    learn_throughput: 6209.669
    learn_time_ms: 26054.85
    sample_throughput: 21884.011
    sample_time_ms: 7393.16
    update_time_ms: 33.466
  timestamp: 1602452939
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: c5c88_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c5c88_00000 | RUNNING  | 172.17.0.4:69834 |     10 |          335.313 | 1617920 |  228.722 |              283.596 |               98.596 |            865.466 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c5c88_00000:
  custom_metrics:
    time_step_max: 4405
    time_step_mean: 3533.9269383697815
    time_step_min: 3187
  date: 2020-10-11_21-49-32
  done: false
  episode_len_mean: 860.6583333333333
  episode_reward_max: 283.59595959595924
  episode_reward_mean: 230.56112596553757
  episode_reward_min: 98.5959595959593
  episodes_this_iter: 300
  episodes_total: 2040
  experiment_id: 500cec2adad9483c8e460de7b4e14bf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9981327603260676
        entropy_coeff: 0.0005000000000000001
        kl: 0.007394914049655199
        model: {}
        policy_loss: -0.012757446616888046
        total_loss: 25.785602887471516
        vf_explained_var: 0.9669091701507568
        vf_loss: 25.79775110880534
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.257894736842104
    gpu_util_percent0: 0.296578947368421
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.778947368421054
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69834
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15551892156546968
    mean_env_wait_ms: 1.173995427351584
    mean_inference_ms: 4.940677775923174
    mean_raw_obs_processing_ms: 0.4120980792030251
  time_since_restore: 367.9651622772217
  time_this_iter_s: 32.65235114097595
  time_total_s: 367.9651622772217
  timers:
    learn_throughput: 6225.675
    learn_time_ms: 25987.865
    sample_throughput: 22734.741
    sample_time_ms: 7116.509
    update_time_ms: 31.157
  timestamp: 1602452972
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: c5c88_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c5c88_00000 | RUNNING  | 172.17.0.4:69834 |     11 |          367.965 | 1779712 |  230.561 |              283.596 |               98.596 |            860.658 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c5c88_00000:
  custom_metrics:
    time_step_max: 4405
    time_step_mean: 3526.944597069597
    time_step_min: 3187
  date: 2020-10-11_21-50-05
  done: false
  episode_len_mean: 857.7961121157324
  episode_reward_max: 283.59595959595924
  episode_reward_mean: 231.80935485049392
  episode_reward_min: 98.5959595959593
  episodes_this_iter: 172
  episodes_total: 2212
  experiment_id: 500cec2adad9483c8e460de7b4e14bf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.989641492565473
        entropy_coeff: 0.0005000000000000001
        kl: 0.007394452889760335
        model: {}
        policy_loss: -0.016756904173462317
        total_loss: 15.457003275553385
        vf_explained_var: 0.9710670113563538
        vf_loss: 15.473145564397177
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.056410256410256
    gpu_util_percent0: 0.3156410256410256
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7820512820512837
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69834
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15505424730794148
    mean_env_wait_ms: 1.1748121548950812
    mean_inference_ms: 4.907579391956036
    mean_raw_obs_processing_ms: 0.410404372216827
  time_since_restore: 400.99655199050903
  time_this_iter_s: 33.03138971328735
  time_total_s: 400.99655199050903
  timers:
    learn_throughput: 6227.194
    learn_time_ms: 25981.525
    sample_throughput: 22997.868
    sample_time_ms: 7035.087
    update_time_ms: 32.323
  timestamp: 1602453005
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: c5c88_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c5c88_00000 | RUNNING  | 172.17.0.4:69834 |     12 |          400.997 | 1941504 |  231.809 |              283.596 |               98.596 |            857.796 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c5c88_00000:
  custom_metrics:
    time_step_max: 4405
    time_step_mean: 3520.0781383432964
    time_step_min: 3187
  date: 2020-10-11_21-50-39
  done: false
  episode_len_mean: 855.7177215189873
  episode_reward_max: 283.59595959595924
  episode_reward_mean: 232.81709500063914
  episode_reward_min: 98.5959595959593
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: 500cec2adad9483c8e460de7b4e14bf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9710322717825571
        entropy_coeff: 0.0005000000000000001
        kl: 0.007759747328236699
        model: {}
        policy_loss: -0.018782921484671533
        total_loss: 12.314237912495932
        vf_explained_var: 0.9753606915473938
        vf_loss: 12.33234190940857
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.794871794871796
    gpu_util_percent0: 0.3071794871794872
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7769230769230786
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69834
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1546657470715114
    mean_env_wait_ms: 1.175515310523175
    mean_inference_ms: 4.88016437187829
    mean_raw_obs_processing_ms: 0.40897746859900086
  time_since_restore: 434.10307240486145
  time_this_iter_s: 33.10652041435242
  time_total_s: 434.10307240486145
  timers:
    learn_throughput: 6225.791
    learn_time_ms: 25987.379
    sample_throughput: 23194.152
    sample_time_ms: 6975.551
    update_time_ms: 31.994
  timestamp: 1602453039
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: c5c88_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c5c88_00000 | RUNNING  | 172.17.0.4:69834 |     13 |          434.103 | 2103296 |  232.817 |              283.596 |               98.596 |            855.718 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c5c88_00000:
  custom_metrics:
    time_step_max: 4405
    time_step_mean: 3515.3532
    time_step_min: 3187
  date: 2020-10-11_21-51-11
  done: false
  episode_len_mean: 853.929588607595
  episode_reward_max: 283.59595959595924
  episode_reward_mean: 233.54980980692991
  episode_reward_min: 98.5959595959593
  episodes_this_iter: 158
  episodes_total: 2528
  experiment_id: 500cec2adad9483c8e460de7b4e14bf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9411386003096899
        entropy_coeff: 0.0005000000000000001
        kl: 0.0078789460627983
        model: {}
        policy_loss: -0.01864502253010869
        total_loss: 13.57163961728414
        vf_explained_var: 0.9755325317382812
        vf_loss: 13.589573542277018
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.173684210526314
    gpu_util_percent0: 0.355
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.781578947368422
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69834
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15431003454755926
    mean_env_wait_ms: 1.176162795245097
    mean_inference_ms: 4.8550593789235545
    mean_raw_obs_processing_ms: 0.4076453530945982
  time_since_restore: 466.9717061519623
  time_this_iter_s: 32.86863374710083
  time_total_s: 466.9717061519623
  timers:
    learn_throughput: 6229.655
    learn_time_ms: 25971.261
    sample_throughput: 23210.133
    sample_time_ms: 6970.748
    update_time_ms: 32.492
  timestamp: 1602453071
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: c5c88_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c5c88_00000 | RUNNING  | 172.17.0.4:69834 |     14 |          466.972 | 2265088 |   233.55 |              283.596 |               98.596 |             853.93 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c5c88_00000:
  custom_metrics:
    time_step_max: 4405
    time_step_mean: 3504.7522506301766
    time_step_min: 3160
  date: 2020-10-11_21-51-44
  done: false
  episode_len_mean: 850.696256684492
  episode_reward_max: 287.2323232323231
  episode_reward_mean: 235.23291740938785
  episode_reward_min: 98.5959595959593
  episodes_this_iter: 277
  episodes_total: 2805
  experiment_id: 500cec2adad9483c8e460de7b4e14bf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9185725053151449
        entropy_coeff: 0.0005000000000000001
        kl: 0.0076120824087411165
        model: {}
        policy_loss: -0.017464759526774287
        total_loss: 14.2229696114858
        vf_explained_var: 0.9805099368095398
        vf_loss: 14.23975165685018
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.769230769230774
    gpu_util_percent0: 0.4584615384615384
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7692307692307705
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69834
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15376058434644774
    mean_env_wait_ms: 1.1773457118726802
    mean_inference_ms: 4.816514767695161
    mean_raw_obs_processing_ms: 0.4056190806162467
  time_since_restore: 499.7606568336487
  time_this_iter_s: 32.7889506816864
  time_total_s: 499.7606568336487
  timers:
    learn_throughput: 6238.622
    learn_time_ms: 25933.933
    sample_throughput: 23263.341
    sample_time_ms: 6954.805
    update_time_ms: 32.404
  timestamp: 1602453104
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: c5c88_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c5c88_00000 | RUNNING  | 172.17.0.4:69834 |     15 |          499.761 | 2426880 |  235.233 |              287.232 |               98.596 |            850.696 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c5c88_00000:
  custom_metrics:
    time_step_max: 4405
    time_step_mean: 3497.5252185608606
    time_step_min: 3160
  date: 2020-10-11_21-52-17
  done: false
  episode_len_mean: 848.7338441039307
  episode_reward_max: 287.2323232323231
  episode_reward_mean: 236.2599411839917
  episode_reward_min: 98.5959595959593
  episodes_this_iter: 197
  episodes_total: 3002
  experiment_id: 500cec2adad9483c8e460de7b4e14bf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9119441409905752
        entropy_coeff: 0.0005000000000000001
        kl: 0.007370872733493646
        model: {}
        policy_loss: -0.0162467596528586
        total_loss: 10.526597817738852
        vf_explained_var: 0.9817022681236267
        vf_loss: 10.542195002237955
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.915789473684207
    gpu_util_percent0: 0.3307894736842105
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7868421052631587
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69834
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15341554352797318
    mean_env_wait_ms: 1.1780449814046599
    mean_inference_ms: 4.792070184253365
    mean_raw_obs_processing_ms: 0.4043349151226029
  time_since_restore: 532.5686991214752
  time_this_iter_s: 32.80804228782654
  time_total_s: 532.5686991214752
  timers:
    learn_throughput: 6243.287
    learn_time_ms: 25914.552
    sample_throughput: 23315.225
    sample_time_ms: 6939.328
    update_time_ms: 31.243
  timestamp: 1602453137
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: c5c88_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c5c88_00000 | RUNNING  | 172.17.0.4:69834 |     16 |          532.569 | 2588672 |   236.26 |              287.232 |               98.596 |            848.734 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c5c88_00000:
  custom_metrics:
    time_step_max: 4405
    time_step_mean: 3493.01245210728
    time_step_min: 3160
  date: 2020-10-11_21-52-50
  done: false
  episode_len_mean: 847.2835443037975
  episode_reward_max: 287.2323232323231
  episode_reward_mean: 237.03396304820345
  episode_reward_min: 98.5959595959593
  episodes_this_iter: 158
  episodes_total: 3160
  experiment_id: 500cec2adad9483c8e460de7b4e14bf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9039774686098099
        entropy_coeff: 0.0005000000000000001
        kl: 0.007751676603220403
        model: {}
        policy_loss: -0.017733167061426986
        total_loss: 8.846900860468546
        vf_explained_var: 0.9826404452323914
        vf_loss: 8.86392347017924
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.076315789473682
    gpu_util_percent0: 0.3257894736842105
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.789473684210528
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69834
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1531620137736619
    mean_env_wait_ms: 1.1785841209251577
    mean_inference_ms: 4.774247900945405
    mean_raw_obs_processing_ms: 0.4033865956572879
  time_since_restore: 565.163741350174
  time_this_iter_s: 32.59504222869873
  time_total_s: 565.163741350174
  timers:
    learn_throughput: 6253.167
    learn_time_ms: 25873.609
    sample_throughput: 23359.206
    sample_time_ms: 6926.263
    update_time_ms: 30.261
  timestamp: 1602453170
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: c5c88_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c5c88_00000 | RUNNING  | 172.17.0.4:69834 |     17 |          565.164 | 2750464 |  237.034 |              287.232 |               98.596 |            847.284 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c5c88_00000:
  custom_metrics:
    time_step_max: 4405
    time_step_mean: 3487.5860394537176
    time_step_min: 3160
  date: 2020-10-11_21-53-23
  done: false
  episode_len_mean: 845.663557026783
  episode_reward_max: 287.2323232323231
  episode_reward_mean: 237.8492812567443
  episode_reward_min: 98.5959595959593
  episodes_this_iter: 163
  episodes_total: 3323
  experiment_id: 500cec2adad9483c8e460de7b4e14bf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.88096850613753
        entropy_coeff: 0.0005000000000000001
        kl: 0.007509191132461031
        model: {}
        policy_loss: -0.018452690972480923
        total_loss: 10.750850041707357
        vf_explained_var: 0.9801997542381287
        vf_loss: 10.768616676330566
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.86410256410256
    gpu_util_percent0: 0.374871794871795
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.784615384615386
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69834
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15291839392049458
    mean_env_wait_ms: 1.1791418013902448
    mean_inference_ms: 4.757088438367938
    mean_raw_obs_processing_ms: 0.4024674768160958
  time_since_restore: 597.8947439193726
  time_this_iter_s: 32.73100256919861
  time_total_s: 597.8947439193726
  timers:
    learn_throughput: 6261.294
    learn_time_ms: 25840.026
    sample_throughput: 23418.145
    sample_time_ms: 6908.831
    update_time_ms: 33.003
  timestamp: 1602453203
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: c5c88_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c5c88_00000 | RUNNING  | 172.17.0.4:69834 |     18 |          597.895 | 2912256 |  237.849 |              287.232 |               98.596 |            845.664 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c5c88_00000:
  custom_metrics:
    time_step_max: 4405
    time_step_mean: 3478.559227107253
    time_step_min: 3160
  date: 2020-10-11_21-53-56
  done: true
  episode_len_mean: 843.0483467629897
  episode_reward_max: 288.2929292929295
  episode_reward_mean: 239.21401848437125
  episode_reward_min: 98.5959595959593
  episodes_this_iter: 276
  episodes_total: 3599
  experiment_id: 500cec2adad9483c8e460de7b4e14bf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.8589139133691788
        entropy_coeff: 0.0005000000000000001
        kl: 0.0070207819032172365
        model: {}
        policy_loss: -0.01479576098305794
        total_loss: 11.604901870091757
        vf_explained_var: 0.9836686253547668
        vf_loss: 11.61907434463501
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.028947368421058
    gpu_util_percent0: 0.45210526315789484
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7736842105263166
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69834
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15254311972486093
    mean_env_wait_ms: 1.180065663435994
    mean_inference_ms: 4.730862830685344
    mean_raw_obs_processing_ms: 0.40107899941550457
  time_since_restore: 630.5852525234222
  time_this_iter_s: 32.69050860404968
  time_total_s: 630.5852525234222
  timers:
    learn_throughput: 6264.007
    learn_time_ms: 25828.836
    sample_throughput: 23466.988
    sample_time_ms: 6894.451
    update_time_ms: 33.306
  timestamp: 1602453236
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: c5c88_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c5c88_00000 | TERMINATED |       |     19 |          630.585 | 3074048 |  239.214 |              288.293 |               98.596 |            843.048 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c5c88_00000 | TERMINATED |       |     19 |          630.585 | 3074048 |  239.214 |              288.293 |               98.596 |            843.048 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


