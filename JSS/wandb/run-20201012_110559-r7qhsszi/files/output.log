2020-10-12 11:06:03,732	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_ec062_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=79312)[0m 2020-10-12 11:06:06,528	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=79366)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79366)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79361)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79361)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79245)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79245)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79352)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79352)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79266)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79266)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79294)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79294)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79292)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79292)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79272)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79272)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79331)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79331)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79316)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79316)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79262)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79262)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79318)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79318)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79280)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79280)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79328)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79328)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79335)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79335)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79349)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79349)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79355)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79355)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79348)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79348)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79354)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79354)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79347)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79347)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79330)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79330)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79250)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79250)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79252)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79252)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79341)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79341)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79247)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79247)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79317)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79317)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79242)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79242)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79297)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79297)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79309)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79309)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79346)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79346)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79358)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79358)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79323)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79323)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79350)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79350)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79360)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79360)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79322)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79322)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79337)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79337)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79364)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79364)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79293)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79293)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79256)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79256)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79290)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79290)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79260)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79260)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79311)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79311)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79238)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79238)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79332)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79332)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79278)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79278)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79371)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79371)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79357)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79357)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79344)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79344)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79314)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79314)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79243)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79243)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79305)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79305)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79271)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79271)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79342)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79342)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79244)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79244)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79333)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79333)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79251)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79251)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79246)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79246)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79254)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79254)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79324)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79324)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79258)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79258)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79275)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79275)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79255)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79255)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79249)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79249)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79313)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79313)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79338)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79338)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79301)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79301)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79240)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79240)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79241)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79241)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79321)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79321)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79257)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79257)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79261)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79261)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79259)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79259)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79326)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79326)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79307)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79307)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79276)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79276)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79239)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79239)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79320)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79320)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79325)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79325)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79298)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79298)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_ec062_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_11-06-43
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: f6da3cea93a14f28a7d05abdc377fac8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1810798048973083
        entropy_coeff: 0.0005000000000000001
        kl: 0.008566662125910321
        model: {}
        policy_loss: -0.012310020567383617
        total_loss: 502.2355448404948
        vf_explained_var: 0.5664147734642029
        vf_loss: 502.24672444661456
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.134210526315787
    gpu_util_percent0: 0.29500000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.581578947368421
    vram_util_percent0: 0.08828606445599078
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79312
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1733017321095197
    mean_env_wait_ms: 1.1909320156454266
    mean_inference_ms: 6.057532432087412
    mean_raw_obs_processing_ms: 0.4641718362429585
  time_since_restore: 32.15226674079895
  time_this_iter_s: 32.15226674079895
  time_total_s: 32.15226674079895
  timers:
    learn_throughput: 7127.091
    learn_time_ms: 22700.986
    sample_throughput: 17372.094
    sample_time_ms: 9313.328
    update_time_ms: 103.972
  timestamp: 1602500803
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: ec062_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |      1 |          32.1523 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ec062_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3623.7708333333335
    time_step_min: 3280
  date: 2020-10-12_11-07-14
  done: false
  episode_len_mean: 890.2120253164557
  episode_reward_max: 271.77777777777766
  episode_reward_mean: 216.57352001022863
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: f6da3cea93a14f28a7d05abdc377fac8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1473211546738942
        entropy_coeff: 0.0005000000000000001
        kl: 0.011223212660600742
        model: {}
        policy_loss: -0.013796255535756549
        total_loss: 126.24822680155437
        vf_explained_var: 0.813798725605011
        vf_loss: 126.26034990946452
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.137142857142855
    gpu_util_percent0: 0.3471428571428571
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765714285714286
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79312
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16806359585411593
    mean_env_wait_ms: 1.1841379708651558
    mean_inference_ms: 5.750448117607469
    mean_raw_obs_processing_ms: 0.4512361015597604
  time_since_restore: 62.52883005142212
  time_this_iter_s: 30.37656331062317
  time_total_s: 62.52883005142212
  timers:
    learn_throughput: 7138.833
    learn_time_ms: 22663.647
    sample_throughput: 19058.946
    sample_time_ms: 8489.032
    update_time_ms: 70.943
  timestamp: 1602500834
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: ec062_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |      2 |          62.5288 | 323584 |  216.574 |              271.778 |              145.717 |            890.212 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ec062_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3623.7892376681616
    time_step_min: 3280
  date: 2020-10-12_11-07-44
  done: false
  episode_len_mean: 886.9367088607595
  episode_reward_max: 271.77777777777766
  episode_reward_mean: 217.08176703746304
  episode_reward_min: 140.7171717171715
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: f6da3cea93a14f28a7d05abdc377fac8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1341195205847423
        entropy_coeff: 0.0005000000000000001
        kl: 0.0113501554975907
        model: {}
        policy_loss: -0.015694307706629235
        total_loss: 56.475844065348305
        vf_explained_var: 0.9051428437232971
        vf_loss: 56.4898354212443
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.238888888888894
    gpu_util_percent0: 0.40555555555555556
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7777777777777786
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79312
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16478888845848663
    mean_env_wait_ms: 1.1803292261417089
    mean_inference_ms: 5.533704102533503
    mean_raw_obs_processing_ms: 0.44188504180828364
  time_since_restore: 92.7837405204773
  time_this_iter_s: 30.254910469055176
  time_total_s: 92.7837405204773
  timers:
    learn_throughput: 7114.123
    learn_time_ms: 22742.368
    sample_throughput: 20022.711
    sample_time_ms: 8080.424
    update_time_ms: 61.025
  timestamp: 1602500864
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: ec062_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |      3 |          92.7837 | 485376 |  217.082 |              271.778 |              140.717 |            886.937 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ec062_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3621.864238410596
    time_step_min: 3259
  date: 2020-10-12_11-08-14
  done: false
  episode_len_mean: 884.7626582278481
  episode_reward_max: 272.23232323232315
  episode_reward_mean: 217.0697800792735
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: f6da3cea93a14f28a7d05abdc377fac8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1208285590012868
        entropy_coeff: 0.0005000000000000001
        kl: 0.011465752497315407
        model: {}
        policy_loss: -0.01761480169564796
        total_loss: 38.10077794392904
        vf_explained_var: 0.9357242584228516
        vf_loss: 38.11666043599447
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.21764705882353
    gpu_util_percent0: 0.2861764705882353
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7794117647058822
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79312
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1624482993263691
    mean_env_wait_ms: 1.1785222685194872
    mean_inference_ms: 5.378206156901586
    mean_raw_obs_processing_ms: 0.4347376840177948
  time_since_restore: 122.39383602142334
  time_this_iter_s: 29.610095500946045
  time_total_s: 122.39383602142334
  timers:
    learn_throughput: 7128.507
    learn_time_ms: 22696.477
    sample_throughput: 20739.428
    sample_time_ms: 7801.179
    update_time_ms: 55.395
  timestamp: 1602500894
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: ec062_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |      4 |          122.394 | 647168 |   217.07 |              272.232 |              138.899 |            884.763 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ec062_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3614.723097112861
    time_step_min: 3259
  date: 2020-10-12_11-08-44
  done: false
  episode_len_mean: 880.6405063291139
  episode_reward_max: 272.23232323232315
  episode_reward_mean: 218.68169032093064
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: f6da3cea93a14f28a7d05abdc377fac8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0919292469819386
        entropy_coeff: 0.0005000000000000001
        kl: 0.011500499909743667
        model: {}
        policy_loss: -0.016317931944892432
        total_loss: 29.171505610148113
        vf_explained_var: 0.9493789076805115
        vf_loss: 29.186068852742512
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.137142857142855
    gpu_util_percent0: 0.3737142857142857
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7714285714285714
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79312
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1607412947237584
    mean_env_wait_ms: 1.1779883561216367
    mean_inference_ms: 5.261237598311126
    mean_raw_obs_processing_ms: 0.4290507164599673
  time_since_restore: 152.33566164970398
  time_this_iter_s: 29.94182562828064
  time_total_s: 152.33566164970398
  timers:
    learn_throughput: 7132.281
    learn_time_ms: 22684.467
    sample_throughput: 21058.444
    sample_time_ms: 7682.999
    update_time_ms: 52.788
  timestamp: 1602500924
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: ec062_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |      5 |          152.336 | 808960 |  218.682 |              272.232 |              138.899 |            880.641 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ec062_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3587.817334575955
    time_step_min: 3253
  date: 2020-10-12_11-09-13
  done: false
  episode_len_mean: 869.0708446866485
  episode_reward_max: 281.77777777777794
  episode_reward_mean: 222.88462279470437
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 311
  episodes_total: 1101
  experiment_id: f6da3cea93a14f28a7d05abdc377fac8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0718796054522197
        entropy_coeff: 0.0005000000000000001
        kl: 0.01130249296935896
        model: {}
        policy_loss: -0.017208602143606793
        total_loss: 30.61871035893758
        vf_explained_var: 0.9621255397796631
        vf_loss: 30.63419500986735
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.258823529411767
    gpu_util_percent0: 0.29911764705882354
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7735294117647062
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79312
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15842836598029506
    mean_env_wait_ms: 1.1800898851125674
    mean_inference_ms: 5.103987253229784
    mean_raw_obs_processing_ms: 0.4214483470163353
  time_since_restore: 181.6211371421814
  time_this_iter_s: 29.285475492477417
  time_total_s: 181.6211371421814
  timers:
    learn_throughput: 7149.157
    learn_time_ms: 22630.921
    sample_throughput: 21459.038
    sample_time_ms: 7539.574
    update_time_ms: 50.889
  timestamp: 1602500953
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: ec062_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |      6 |          181.621 | 970752 |  222.885 |              281.778 |              138.899 |            869.071 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ec062_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3574.628640776699
    time_step_min: 3194
  date: 2020-10-12_11-09-43
  done: false
  episode_len_mean: 863.879746835443
  episode_reward_max: 282.08080808080786
  episode_reward_mean: 224.91116864851026
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 163
  episodes_total: 1264
  experiment_id: f6da3cea93a14f28a7d05abdc377fac8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.060988982518514
        entropy_coeff: 0.0005000000000000001
        kl: 0.011702353289971748
        model: {}
        policy_loss: -0.019268650217175793
        total_loss: 18.453628063201904
        vf_explained_var: 0.9659398198127747
        vf_loss: 18.471086502075195
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.845714285714287
    gpu_util_percent0: 0.2934285714285715
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.791428571428572
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79312
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1575680302218401
    mean_env_wait_ms: 1.1812803730465038
    mean_inference_ms: 5.044244172096538
    mean_raw_obs_processing_ms: 0.41852570780371284
  time_since_restore: 211.47951650619507
  time_this_iter_s: 29.858379364013672
  time_total_s: 211.47951650619507
  timers:
    learn_throughput: 7132.476
    learn_time_ms: 22683.848
    sample_throughput: 21778.119
    sample_time_ms: 7429.108
    update_time_ms: 49.21
  timestamp: 1602500983
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: ec062_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |      7 |           211.48 | 1132544 |  224.911 |              282.081 |              138.899 |             863.88 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ec062_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3559.687230989957
    time_step_min: 3194
  date: 2020-10-12_11-10-13
  done: false
  episode_len_mean: 858.7841068917019
  episode_reward_max: 282.08080808080786
  episode_reward_mean: 227.159442526531
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: f6da3cea93a14f28a7d05abdc377fac8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0327277580897014
        entropy_coeff: 0.0005000000000000001
        kl: 0.011306605534628034
        model: {}
        policy_loss: -0.0188012203531495
        total_loss: 15.273218075434366
        vf_explained_var: 0.9682538509368896
        vf_loss: 15.290274302164713
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.538235294117644
    gpu_util_percent0: 0.43441176470588233
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7794117647058822
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79312
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15685768288033522
    mean_env_wait_ms: 1.1824192503621984
    mean_inference_ms: 4.994578322802786
    mean_raw_obs_processing_ms: 0.41600770103500656
  time_since_restore: 241.07298350334167
  time_this_iter_s: 29.593466997146606
  time_total_s: 241.07298350334167
  timers:
    learn_throughput: 7137.946
    learn_time_ms: 22666.464
    sample_throughput: 21955.807
    sample_time_ms: 7368.984
    update_time_ms: 47.752
  timestamp: 1602501013
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: ec062_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |      8 |          241.073 | 1294336 |  227.159 |              282.081 |              138.899 |            858.784 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ec062_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3548.699742268041
    time_step_min: 3194
  date: 2020-10-12_11-10-42
  done: false
  episode_len_mean: 854.1525316455696
  episode_reward_max: 292.5353535353532
  episode_reward_mean: 228.90723692622413
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: f6da3cea93a14f28a7d05abdc377fac8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0014687329530716
        entropy_coeff: 0.0005000000000000001
        kl: 0.01150376326404512
        model: {}
        policy_loss: -0.016004978213459253
        total_loss: 19.093974113464355
        vf_explained_var: 0.9633541107177734
        vf_loss: 19.108178933461506
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.191176470588236
    gpu_util_percent0: 0.33617647058823524
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7764705882352945
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79312
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1562354407759429
    mean_env_wait_ms: 1.1837066205442477
    mean_inference_ms: 4.9512944069986835
    mean_raw_obs_processing_ms: 0.41377123150621203
  time_since_restore: 270.64611411094666
  time_this_iter_s: 29.57313060760498
  time_total_s: 270.64611411094666
  timers:
    learn_throughput: 7142.357
    learn_time_ms: 22652.468
    sample_throughput: 22095.038
    sample_time_ms: 7322.549
    update_time_ms: 45.674
  timestamp: 1602501042
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: ec062_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |      9 |          270.646 | 1456128 |  228.907 |              292.535 |              138.899 |            854.153 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ec062_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3527.288317256163
    time_step_min: 3194
  date: 2020-10-12_11-11-12
  done: false
  episode_len_mean: 845.3901795142556
  episode_reward_max: 292.5353535353532
  episode_reward_mean: 232.04648917901278
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 314
  episodes_total: 1894
  experiment_id: f6da3cea93a14f28a7d05abdc377fac8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9655029277006785
        entropy_coeff: 0.0005000000000000001
        kl: 0.010109123696262637
        model: {}
        policy_loss: -0.016467383014969528
        total_loss: 19.649176279703777
        vf_explained_var: 0.9746022820472717
        vf_loss: 19.664104143778484
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.870588235294118
    gpu_util_percent0: 0.3364705882352941
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7735294117647062
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79312
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1552292831014224
    mean_env_wait_ms: 1.186625595007512
    mean_inference_ms: 4.881686367267097
    mean_raw_obs_processing_ms: 0.41029242161785917
  time_since_restore: 300.233526468277
  time_this_iter_s: 29.587412357330322
  time_total_s: 300.233526468277
  timers:
    learn_throughput: 7143.766
    learn_time_ms: 22647.998
    sample_throughput: 22227.275
    sample_time_ms: 7278.985
    update_time_ms: 45.004
  timestamp: 1602501072
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: ec062_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |     10 |          300.234 | 1617920 |  232.046 |              292.535 |              138.899 |             845.39 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ec062_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3518.6243830207304
    time_step_min: 3194
  date: 2020-10-12_11-11-42
  done: false
  episode_len_mean: 841.65141187926
  episode_reward_max: 292.5353535353532
  episode_reward_mean: 233.41700353092745
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 160
  episodes_total: 2054
  experiment_id: f6da3cea93a14f28a7d05abdc377fac8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9469701697429022
        entropy_coeff: 0.0005000000000000001
        kl: 0.010086450492963195
        model: {}
        policy_loss: -0.018124834440338116
        total_loss: 12.415512720743815
        vf_explained_var: 0.9763712286949158
        vf_loss: 12.432093620300293
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.873529411764707
    gpu_util_percent0: 0.31470588235294117
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7882352941176474
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79312
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1548127093773671
    mean_env_wait_ms: 1.1880107176796835
    mean_inference_ms: 4.852438405198466
    mean_raw_obs_processing_ms: 0.4088344939810243
  time_since_restore: 329.7829658985138
  time_this_iter_s: 29.549439430236816
  time_total_s: 329.7829658985138
  timers:
    learn_throughput: 7150.465
    learn_time_ms: 22626.781
    sample_throughput: 22968.45
    sample_time_ms: 7044.097
    update_time_ms: 38.831
  timestamp: 1602501102
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: ec062_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |     11 |          329.783 | 1779712 |  233.417 |              292.535 |              138.899 |            841.651 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ec062_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3509.8141025641025
    time_step_min: 3194
  date: 2020-10-12_11-12-11
  done: false
  episode_len_mean: 838.3146473779385
  episode_reward_max: 292.5353535353532
  episode_reward_mean: 234.829383345206
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: f6da3cea93a14f28a7d05abdc377fac8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9210369984308878
        entropy_coeff: 0.0005000000000000001
        kl: 0.010504102567210793
        model: {}
        policy_loss: -0.016645007805588346
        total_loss: 10.698445002237955
        vf_explained_var: 0.9771132469177246
        vf_loss: 10.713449398676554
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.38529411764706
    gpu_util_percent0: 0.38
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7882352941176474
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79312
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15444011041607467
    mean_env_wait_ms: 1.189267327205493
    mean_inference_ms: 4.826345559128167
    mean_raw_obs_processing_ms: 0.4074932954231811
  time_since_restore: 359.473717212677
  time_this_iter_s: 29.690751314163208
  time_total_s: 359.473717212677
  timers:
    learn_throughput: 7147.549
    learn_time_ms: 22636.012
    sample_throughput: 23224.099
    sample_time_ms: 6966.557
    update_time_ms: 37.882
  timestamp: 1602501131
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: ec062_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |     12 |          359.474 | 1941504 |  234.829 |              292.535 |              138.899 |            838.315 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ec062_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3496.74555968608
    time_step_min: 3194
  date: 2020-10-12_11-12-41
  done: false
  episode_len_mean: 833.5634953042058
  episode_reward_max: 292.5353535353532
  episode_reward_mean: 236.63003658471183
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 237
  episodes_total: 2449
  experiment_id: f6da3cea93a14f28a7d05abdc377fac8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.874845951795578
        entropy_coeff: 0.0005000000000000001
        kl: 0.009460883758341273
        model: {}
        policy_loss: -0.01588716957970367
        total_loss: 14.987916946411133
        vf_explained_var: 0.9778693318367004
        vf_loss: 15.002349376678467
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.13823529411765
    gpu_util_percent0: 0.37235294117647066
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7764705882352945
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79312
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1539508848252292
    mean_env_wait_ms: 1.1912813547915042
    mean_inference_ms: 4.791974394857117
    mean_raw_obs_processing_ms: 0.40572168105096845
  time_since_restore: 388.83686232566833
  time_this_iter_s: 29.363145112991333
  time_total_s: 388.83686232566833
  timers:
    learn_throughput: 7162.416
    learn_time_ms: 22589.025
    sample_throughput: 23368.563
    sample_time_ms: 6923.49
    update_time_ms: 37.6
  timestamp: 1602501161
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: ec062_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |     13 |          388.837 | 2103296 |   236.63 |              292.535 |              138.899 |            833.563 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ec062_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3485.0489089541006
    time_step_min: 3159
  date: 2020-10-12_11-13-10
  done: false
  episode_len_mean: 829.1816827997021
  episode_reward_max: 292.5353535353532
  episode_reward_mean: 238.27470911648115
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 237
  episodes_total: 2686
  experiment_id: f6da3cea93a14f28a7d05abdc377fac8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8784356613953909
        entropy_coeff: 0.0005000000000000001
        kl: 0.008936016277099649
        model: {}
        policy_loss: -0.0144694714108482
        total_loss: 12.34289781252543
        vf_explained_var: 0.9786873459815979
        vf_loss: 12.356019179026285
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.84705882352941
    gpu_util_percent0: 0.4517647058823529
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7735294117647062
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79312
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1535247550740816
    mean_env_wait_ms: 1.1931720837126862
    mean_inference_ms: 4.7620908972039935
    mean_raw_obs_processing_ms: 0.4042169402130369
  time_since_restore: 417.9772484302521
  time_this_iter_s: 29.14038610458374
  time_total_s: 417.9772484302521
  timers:
    learn_throughput: 7171.687
    learn_time_ms: 22559.824
    sample_throughput: 23430.636
    sample_time_ms: 6905.148
    update_time_ms: 37.671
  timestamp: 1602501190
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: ec062_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |     14 |          417.977 | 2265088 |  238.275 |              292.535 |              138.899 |            829.182 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ec062_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3478.615411931818
    time_step_min: 3159
  date: 2020-10-12_11-13-40
  done: false
  episode_len_mean: 826.7542194092827
  episode_reward_max: 292.5353535353532
  episode_reward_mean: 239.19818437539945
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: f6da3cea93a14f28a7d05abdc377fac8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8649471998214722
        entropy_coeff: 0.0005000000000000001
        kl: 0.01006123865954578
        model: {}
        policy_loss: -0.017844289424829185
        total_loss: 9.70694867769877
        vf_explained_var: 0.9796954989433289
        vf_loss: 9.723213116327921
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.876470588235296
    gpu_util_percent0: 0.3244117647058823
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7794117647058822
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79312
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15327356539218503
    mean_env_wait_ms: 1.194326233850043
    mean_inference_ms: 4.744338916417169
    mean_raw_obs_processing_ms: 0.40329630038774883
  time_since_restore: 447.3988480567932
  time_this_iter_s: 29.421599626541138
  time_total_s: 447.3988480567932
  timers:
    learn_throughput: 7176.041
    learn_time_ms: 22546.137
    sample_throughput: 23560.775
    sample_time_ms: 6867.007
    update_time_ms: 37.136
  timestamp: 1602501220
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: ec062_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |     15 |          447.399 | 2426880 |  239.198 |              292.535 |              138.899 |            826.754 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ec062_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3472.0551311856525
    time_step_min: 3159
  date: 2020-10-12_11-14-09
  done: false
  episode_len_mean: 823.651201052978
  episode_reward_max: 292.5353535353532
  episode_reward_mean: 240.11829050624695
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 195
  episodes_total: 3039
  experiment_id: f6da3cea93a14f28a7d05abdc377fac8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8254145234823227
        entropy_coeff: 0.0005000000000000001
        kl: 0.009458012490843734
        model: {}
        policy_loss: -0.01512273036253949
        total_loss: 13.99141558011373
        vf_explained_var: 0.9766866564750671
        vf_loss: 14.005059798558554
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.51176470588235
    gpu_util_percent0: 0.33176470588235296
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7735294117647054
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79312
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15298767215998352
    mean_env_wait_ms: 1.1957940587841065
    mean_inference_ms: 4.724218103088548
    mean_raw_obs_processing_ms: 0.40222561069745294
  time_since_restore: 476.6713652610779
  time_this_iter_s: 29.272517204284668
  time_total_s: 476.6713652610779
  timers:
    learn_throughput: 7180.725
    learn_time_ms: 22531.431
    sample_throughput: 23533.661
    sample_time_ms: 6874.918
    update_time_ms: 35.121
  timestamp: 1602501249
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: ec062_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |     16 |          476.671 | 2588672 |  240.118 |              292.535 |              138.899 |            823.651 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ec062_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3463.277591973244
    time_step_min: 3122
  date: 2020-10-12_11-14-38
  done: false
  episode_len_mean: 820.0826047633403
  episode_reward_max: 292.989898989899
  episode_reward_mean: 241.4787671712603
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 278
  episodes_total: 3317
  experiment_id: f6da3cea93a14f28a7d05abdc377fac8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8151738196611404
        entropy_coeff: 0.0005000000000000001
        kl: 0.009590728984524807
        model: {}
        policy_loss: -0.01601108305233841
        total_loss: 10.88164758682251
        vf_explained_var: 0.9833198189735413
        vf_loss: 10.896148045857748
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.66969696969697
    gpu_util_percent0: 0.33909090909090905
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.772727272727273
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79312
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15263561454670363
    mean_env_wait_ms: 1.1977706296572646
    mean_inference_ms: 4.698803894164137
    mean_raw_obs_processing_ms: 0.400909170294569
  time_since_restore: 505.8517713546753
  time_this_iter_s: 29.180406093597412
  time_total_s: 505.8517713546753
  timers:
    learn_throughput: 7203.419
    learn_time_ms: 22460.446
    sample_throughput: 23518.9
    sample_time_ms: 6879.233
    update_time_ms: 33.392
  timestamp: 1602501278
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: ec062_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |     17 |          505.852 | 2750464 |  241.479 |               292.99 |              138.899 |            820.083 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ec062_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3459.457366589327
    time_step_min: 3122
  date: 2020-10-12_11-15-08
  done: false
  episode_len_mean: 818.1067318757192
  episode_reward_max: 292.989898989899
  episode_reward_mean: 242.01891178761136
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 159
  episodes_total: 3476
  experiment_id: f6da3cea93a14f28a7d05abdc377fac8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7972376495599747
        entropy_coeff: 0.0005000000000000001
        kl: 0.009708141054337224
        model: {}
        policy_loss: -0.017444406868889928
        total_loss: 9.293004115422567
        vf_explained_var: 0.9813184142112732
        vf_loss: 9.308905283610025
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.91176470588235
    gpu_util_percent0: 0.35205882352941176
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7764705882352945
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79312
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15244909410231441
    mean_env_wait_ms: 1.1988208182932776
    mean_inference_ms: 4.685620595286818
    mean_raw_obs_processing_ms: 0.40022293191948377
  time_since_restore: 535.3326375484467
  time_this_iter_s: 29.480866193771362
  time_total_s: 535.3326375484467
  timers:
    learn_throughput: 7203.658
    learn_time_ms: 22459.702
    sample_throughput: 23554.42
    sample_time_ms: 6868.859
    update_time_ms: 33.715
  timestamp: 1602501308
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: ec062_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |     18 |          535.333 | 2912256 |  242.019 |               292.99 |              138.899 |            818.107 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ec062_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3455.4910146530274
    time_step_min: 3122
  date: 2020-10-12_11-15-38
  done: false
  episode_len_mean: 816.3349794238683
  episode_reward_max: 292.989898989899
  episode_reward_mean: 242.54158872677382
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 169
  episodes_total: 3645
  experiment_id: f6da3cea93a14f28a7d05abdc377fac8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7739134132862091
        entropy_coeff: 0.0005000000000000001
        kl: 0.009328874681765834
        model: {}
        policy_loss: -0.01628954194408531
        total_loss: 9.141257365544638
        vf_explained_var: 0.9834416508674622
        vf_loss: 9.156067848205566
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.514285714285716
    gpu_util_percent0: 0.3065714285714286
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7857142857142856
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79312
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15226120163607904
    mean_env_wait_ms: 1.1999160371375377
    mean_inference_ms: 4.672479068198147
    mean_raw_obs_processing_ms: 0.39952560571722434
  time_since_restore: 564.7683990001678
  time_this_iter_s: 29.43576145172119
  time_total_s: 564.7683990001678
  timers:
    learn_throughput: 7206.845
    learn_time_ms: 22449.767
    sample_throughput: 23595.931
    sample_time_ms: 6856.776
    update_time_ms: 33.005
  timestamp: 1602501338
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: ec062_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |     19 |          564.768 | 3074048 |  242.542 |               292.99 |              138.899 |            816.335 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ec062_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3450.714504596527
    time_step_min: 3122
  date: 2020-10-12_11-16-07
  done: false
  episode_len_mean: 813.685598377282
  episode_reward_max: 292.989898989899
  episode_reward_mean: 243.27625647960326
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 299
  episodes_total: 3944
  experiment_id: f6da3cea93a14f28a7d05abdc377fac8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7598459174235662
        entropy_coeff: 0.0005000000000000001
        kl: 0.008437203515010575
        model: {}
        policy_loss: -0.014525203267112374
        total_loss: 12.6011643409729
        vf_explained_var: 0.9831928610801697
        vf_loss: 12.614381790161133
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.912121212121217
    gpu_util_percent0: 0.2693939393939394
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.778787878787879
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79312
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15196848488671325
    mean_env_wait_ms: 1.2018070298209165
    mean_inference_ms: 4.651604684034456
    mean_raw_obs_processing_ms: 0.3984450119874049
  time_since_restore: 593.9878306388855
  time_this_iter_s: 29.21943163871765
  time_total_s: 593.9878306388855
  timers:
    learn_throughput: 7217.754
    learn_time_ms: 22415.837
    sample_throughput: 23604.007
    sample_time_ms: 6854.429
    update_time_ms: 31.065
  timestamp: 1602501367
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: ec062_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |     20 |          593.988 | 3235840 |  243.276 |               292.99 |              138.899 |            813.686 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ec062_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3447.600490196078
    time_step_min: 3122
  date: 2020-10-12_11-16-36
  done: true
  episode_len_mean: 812.2758033106135
  episode_reward_max: 292.989898989899
  episode_reward_mean: 243.7780875945432
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 164
  episodes_total: 4108
  experiment_id: f6da3cea93a14f28a7d05abdc377fac8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7564162909984589
        entropy_coeff: 0.0005000000000000001
        kl: 0.009951598476618528
        model: {}
        policy_loss: -0.017080792342312634
        total_loss: 7.360955437024434
        vf_explained_var: 0.9852108955383301
        vf_loss: 7.376423915227254
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.944117647058825
    gpu_util_percent0: 0.3264705882352941
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7882352941176474
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79312
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15181886518479826
    mean_env_wait_ms: 1.2027377553939933
    mean_inference_ms: 4.641133432730056
    mean_raw_obs_processing_ms: 0.3979022439175898
  time_since_restore: 623.2816741466522
  time_this_iter_s: 29.293843507766724
  time_total_s: 623.2816741466522
  timers:
    learn_throughput: 7220.531
    learn_time_ms: 22407.215
    sample_throughput: 23662.482
    sample_time_ms: 6837.491
    update_time_ms: 30.226
  timestamp: 1602501396
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: ec062_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ec062_00000 | TERMINATED |       |     21 |          623.282 | 3397632 |  243.778 |               292.99 |              138.899 |            812.276 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ec062_00000 | TERMINATED |       |     21 |          623.282 | 3397632 |  243.778 |               292.99 |              138.899 |            812.276 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


