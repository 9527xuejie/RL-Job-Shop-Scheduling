2020-10-12 13:55:37,054	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_9bcae_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=19343)[0m 2020-10-12 13:55:39,841	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=19232)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19232)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19231)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19231)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19227)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19227)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19240)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19240)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19323)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19323)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19233)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19233)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19244)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19244)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19312)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19312)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19238)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19238)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19300)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19300)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19226)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19226)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19340)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19340)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19229)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19229)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19252)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19252)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19321)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19321)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19298)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19298)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19304)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19304)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19358)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19358)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19337)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19337)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19339)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19339)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19356)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19356)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19352)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19352)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19329)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19329)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19263)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19263)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19291)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19291)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19253)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19253)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19288)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19288)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19225)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19225)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19255)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19255)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19241)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19241)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19344)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19344)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19275)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19275)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19293)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19293)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19308)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19308)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19332)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19332)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19327)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19327)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19333)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19333)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19302)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19302)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19318)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19318)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19303)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19303)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19309)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19309)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19311)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19311)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19335)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19335)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19320)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19320)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19256)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19256)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19284)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19284)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19243)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19243)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19234)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19234)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19287)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19287)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19239)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19239)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19228)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19228)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19242)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19242)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19350)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19350)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19235)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19235)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19325)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19325)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19341)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19341)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19306)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19306)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19247)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19247)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19248)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19248)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19347)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19347)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19317)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19317)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19305)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19305)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19251)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19251)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19257)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19257)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19295)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19295)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19307)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19307)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19260)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19260)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19278)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19278)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19230)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19230)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19310)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19310)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19258)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19258)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19279)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19279)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19264)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19264)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19334)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19334)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19314)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19314)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19315)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19315)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19313)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19313)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19285)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19285)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19281)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19281)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_9bcae_00000:
  custom_metrics:
    time_step_max: 3996
    time_step_mean: 3522.9508196721313
    time_step_min: 3235
  date: 2020-10-12_13-56-14
  done: false
  episode_len_mean: 892.2341772151899
  episode_reward_max: 254.5757575757571
  episode_reward_mean: 208.69735327963153
  episode_reward_min: 139.27272727272737
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 2bd6846c51c84a59b085a5d4a9f71128
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1783752640088399
        entropy_coeff: 0.0005000000000000001
        kl: 0.006224280456081033
        model: {}
        policy_loss: -0.008764721734526878
        total_loss: 425.68236541748047
        vf_explained_var: 0.5529740452766418
        vf_loss: 425.6904652913411
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.408823529411766
    gpu_util_percent0: 0.32411764705882357
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.561764705882353
    vram_util_percent0: 0.0862288503463045
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 19343
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1671851671341946
    mean_env_wait_ms: 1.1541409770733562
    mean_inference_ms: 6.026029006755437
    mean_raw_obs_processing_ms: 0.45174526262886916
  time_since_restore: 29.27948498725891
  time_this_iter_s: 29.27948498725891
  time_total_s: 29.27948498725891
  timers:
    learn_throughput: 8318.826
    learn_time_ms: 19448.899
    sample_throughput: 16592.887
    sample_time_ms: 9750.684
    update_time_ms: 49.317
  timestamp: 1602510974
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 9bcae_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9bcae_00000 | RUNNING  | 172.17.0.4:19343 |      1 |          29.2795 | 161792 |  208.697 |              254.576 |              139.273 |            892.234 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9bcae_00000:
  custom_metrics:
    time_step_max: 3996
    time_step_mean: 3540.239285714286
    time_step_min: 3225
  date: 2020-10-12_13-56-41
  done: false
  episode_len_mean: 892.8132911392405
  episode_reward_max: 256.090909090909
  episode_reward_mean: 207.67510548523182
  episode_reward_min: 136.9999999999997
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 2bd6846c51c84a59b085a5d4a9f71128
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1473518113295238
        entropy_coeff: 0.0005000000000000001
        kl: 0.009707549742112557
        model: {}
        policy_loss: -0.012061994328784445
        total_loss: 117.24793815612793
        vf_explained_var: 0.807797908782959
        vf_loss: 117.25863265991211
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.77741935483871
    gpu_util_percent0: 0.3412903225806451
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7516129032258054
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 19343
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16329458556986232
    mean_env_wait_ms: 1.1510671834867001
    mean_inference_ms: 5.735139462783482
    mean_raw_obs_processing_ms: 0.43921917723874115
  time_since_restore: 56.441887617111206
  time_this_iter_s: 27.162402629852295
  time_total_s: 56.441887617111206
  timers:
    learn_throughput: 8379.203
    learn_time_ms: 19308.757
    sample_throughput: 18332.349
    sample_time_ms: 8825.492
    update_time_ms: 46.658
  timestamp: 1602511001
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 9bcae_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9bcae_00000 | RUNNING  | 172.17.0.4:19343 |      2 |          56.4419 | 323584 |  207.675 |              256.091 |                  137 |            892.813 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9bcae_00000:
  custom_metrics:
    time_step_max: 4048
    time_step_mean: 3538.7100456621006
    time_step_min: 3185
  date: 2020-10-12_13-57-08
  done: false
  episode_len_mean: 889.0295358649789
  episode_reward_max: 262.1515151515147
  episode_reward_mean: 207.29695691088077
  episode_reward_min: 131.39393939393904
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 2bd6846c51c84a59b085a5d4a9f71128
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1407590508460999
        entropy_coeff: 0.0005000000000000001
        kl: 0.009017363268261155
        model: {}
        policy_loss: -0.012204123423240768
        total_loss: 51.48660437266032
        vf_explained_var: 0.9018257260322571
        vf_loss: 51.49757480621338
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.10322580645162
    gpu_util_percent0: 0.39645161290322584
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770967741935483
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 19343
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16070270384101376
    mean_env_wait_ms: 1.15143339350832
    mean_inference_ms: 5.520486442638844
    mean_raw_obs_processing_ms: 0.43030316194803825
  time_since_restore: 82.93800497055054
  time_this_iter_s: 26.49611735343933
  time_total_s: 82.93800497055054
  timers:
    learn_throughput: 8399.283
    learn_time_ms: 19262.597
    sample_throughput: 19510.155
    sample_time_ms: 8292.707
    update_time_ms: 48.175
  timestamp: 1602511028
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 9bcae_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9bcae_00000 | RUNNING  | 172.17.0.4:19343 |      3 |           82.938 | 485376 |  207.297 |              262.152 |              131.394 |             889.03 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9bcae_00000:
  custom_metrics:
    time_step_max: 4048
    time_step_mean: 3530.6124161073826
    time_step_min: 3185
  date: 2020-10-12_13-57-34
  done: false
  episode_len_mean: 887.4145569620254
  episode_reward_max: 262.1515151515147
  episode_reward_mean: 208.2610280015341
  episode_reward_min: 131.39393939393904
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 2bd6846c51c84a59b085a5d4a9f71128
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1180773675441742
        entropy_coeff: 0.0005000000000000001
        kl: 0.013175127329304814
        model: {}
        policy_loss: -0.01547485678747762
        total_loss: 37.00454457600912
        vf_explained_var: 0.9259020686149597
        vf_loss: 37.01794242858887
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.753333333333334
    gpu_util_percent0: 0.3516666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7733333333333325
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 19343
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15890623127360562
    mean_env_wait_ms: 1.1520820940992922
    mean_inference_ms: 5.364542087923223
    mean_raw_obs_processing_ms: 0.4237716763317906
  time_since_restore: 109.2086501121521
  time_this_iter_s: 26.270645141601562
  time_total_s: 109.2086501121521
  timers:
    learn_throughput: 8407.363
    learn_time_ms: 19244.083
    sample_throughput: 20304.78
    sample_time_ms: 7968.173
    update_time_ms: 46.535
  timestamp: 1602511054
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 9bcae_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9bcae_00000 | RUNNING  | 172.17.0.4:19343 |      4 |          109.209 | 647168 |  208.261 |              262.152 |              131.394 |            887.415 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9bcae_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3528.20424403183
    time_step_min: 3185
  date: 2020-10-12_13-58-00
  done: false
  episode_len_mean: 884.5341772151899
  episode_reward_max: 262.1515151515147
  episode_reward_mean: 209.26486382815474
  episode_reward_min: 118.96969696969654
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 2bd6846c51c84a59b085a5d4a9f71128
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.08646959066391
        entropy_coeff: 0.0005000000000000001
        kl: 0.010437002948795756
        model: {}
        policy_loss: -0.015410024585435167
        total_loss: 38.18381309509277
        vf_explained_var: 0.9267735481262207
        vf_loss: 38.197678883870445
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.310000000000002
    gpu_util_percent0: 0.32266666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.77
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 19343
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15755175547294684
    mean_env_wait_ms: 1.1533938493699414
    mean_inference_ms: 5.246164527055292
    mean_raw_obs_processing_ms: 0.4186448586413122
  time_since_restore: 135.37551617622375
  time_this_iter_s: 26.166866064071655
  time_total_s: 135.37551617622375
  timers:
    learn_throughput: 8424.674
    learn_time_ms: 19204.541
    sample_throughput: 20786.8
    sample_time_ms: 7783.401
    update_time_ms: 42.412
  timestamp: 1602511080
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 9bcae_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9bcae_00000 | RUNNING  | 172.17.0.4:19343 |      5 |          135.376 | 808960 |  209.265 |              262.152 |               118.97 |            884.534 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9bcae_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3512.6745562130177
    time_step_min: 3175
  date: 2020-10-12_13-58-26
  done: false
  episode_len_mean: 877.032380952381
  episode_reward_max: 263.6666666666664
  episode_reward_mean: 211.53015873015858
  episode_reward_min: 118.96969696969654
  episodes_this_iter: 260
  episodes_total: 1050
  experiment_id: 2bd6846c51c84a59b085a5d4a9f71128
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.052406370639801
        entropy_coeff: 0.0005000000000000001
        kl: 0.009752811941628655
        model: {}
        policy_loss: -0.011150413787011834
        total_loss: 35.76066780090332
        vf_explained_var: 0.952979326248169
        vf_loss: 35.77039337158203
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.15333333333334
    gpu_util_percent0: 0.38966666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7633333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 19343
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15593436081327272
    mean_env_wait_ms: 1.1567118220892716
    mean_inference_ms: 5.106559044644324
    mean_raw_obs_processing_ms: 0.41269046183175306
  time_since_restore: 161.40690326690674
  time_this_iter_s: 26.031387090682983
  time_total_s: 161.40690326690674
  timers:
    learn_throughput: 8439.968
    learn_time_ms: 19169.741
    sample_throughput: 21165.303
    sample_time_ms: 7644.209
    update_time_ms: 41.814
  timestamp: 1602511106
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 9bcae_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9bcae_00000 | RUNNING  | 172.17.0.4:19343 |      6 |          161.407 | 970752 |   211.53 |              263.667 |               118.97 |            877.032 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9bcae_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3506.5651465798046
    time_step_min: 3175
  date: 2020-10-12_13-58-53
  done: false
  episode_len_mean: 872.2776898734177
  episode_reward_max: 263.6666666666664
  episode_reward_mean: 213.06180475642483
  episode_reward_min: 118.96969696969654
  episodes_this_iter: 214
  episodes_total: 1264
  experiment_id: 2bd6846c51c84a59b085a5d4a9f71128
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0661503672599792
        entropy_coeff: 0.0005000000000000001
        kl: 0.010846636025235057
        model: {}
        policy_loss: -0.0128801137082822
        total_loss: 20.732417424519856
        vf_explained_var: 0.9618821144104004
        vf_loss: 20.743661244710285
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.583870967741934
    gpu_util_percent0: 0.34774193548387095
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.76774193548387
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 19343
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15498853412642533
    mean_env_wait_ms: 1.1588040685375882
    mean_inference_ms: 5.024969722080633
    mean_raw_obs_processing_ms: 0.40926644363148074
  time_since_restore: 187.6260199546814
  time_this_iter_s: 26.219116687774658
  time_total_s: 187.6260199546814
  timers:
    learn_throughput: 8427.561
    learn_time_ms: 19197.963
    sample_throughput: 21525.363
    sample_time_ms: 7516.342
    update_time_ms: 43.391
  timestamp: 1602511133
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 9bcae_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9bcae_00000 | RUNNING  | 172.17.0.4:19343 |      7 |          187.626 | 1132544 |  213.062 |              263.667 |               118.97 |            872.278 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9bcae_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3496.2886002886003
    time_step_min: 3175
  date: 2020-10-12_13-59-19
  done: false
  episode_len_mean: 869.824894514768
  episode_reward_max: 265.93939393939445
  episode_reward_mean: 214.3814090269785
  episode_reward_min: 118.96969696969654
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 2bd6846c51c84a59b085a5d4a9f71128
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0312921504179637
        entropy_coeff: 0.0005000000000000001
        kl: 0.011058010005702576
        model: {}
        policy_loss: -0.010687086828208217
        total_loss: 18.0527499516805
        vf_explained_var: 0.9657447934150696
        vf_loss: 18.0617413520813
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.153333333333332
    gpu_util_percent0: 0.4160000000000001
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7799999999999994
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 19343
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15440829477458004
    mean_env_wait_ms: 1.1601439452390188
    mean_inference_ms: 4.974985289625392
    mean_raw_obs_processing_ms: 0.4071542157550645
  time_since_restore: 213.45776677131653
  time_this_iter_s: 25.831746816635132
  time_total_s: 213.45776677131653
  timers:
    learn_throughput: 8437.622
    learn_time_ms: 19175.071
    sample_throughput: 21809.263
    sample_time_ms: 7418.499
    update_time_ms: 40.859
  timestamp: 1602511159
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 9bcae_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9bcae_00000 | RUNNING  | 172.17.0.4:19343 |      8 |          213.458 | 1294336 |  214.381 |              265.939 |               118.97 |            869.825 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9bcae_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3489.6599740932643
    time_step_min: 3175
  date: 2020-10-12_13-59-45
  done: false
  episode_len_mean: 867.2094936708861
  episode_reward_max: 265.93939393939445
  episode_reward_mean: 215.606156501726
  episode_reward_min: 118.96969696969654
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 2bd6846c51c84a59b085a5d4a9f71128
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0136480331420898
        entropy_coeff: 0.0005000000000000001
        kl: 0.010413666799043616
        model: {}
        policy_loss: -0.01282383079524152
        total_loss: 16.17000691095988
        vf_explained_var: 0.968193531036377
        vf_loss: 16.181254784266155
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.20666666666667
    gpu_util_percent0: 0.3273333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7766666666666664
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 19343
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1539021368120852
    mean_env_wait_ms: 1.161281883461447
    mean_inference_ms: 4.931434734798462
    mean_raw_obs_processing_ms: 0.4052712239425404
  time_since_restore: 239.67405343055725
  time_this_iter_s: 26.216286659240723
  time_total_s: 239.67405343055725
  timers:
    learn_throughput: 8435.545
    learn_time_ms: 19179.792
    sample_throughput: 21972.555
    sample_time_ms: 7363.368
    update_time_ms: 38.708
  timestamp: 1602511185
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 9bcae_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9bcae_00000 | RUNNING  | 172.17.0.4:19343 |      9 |          239.674 | 1456128 |  215.606 |              265.939 |               118.97 |            867.209 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9bcae_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3481.9289906103286
    time_step_min: 3175
  date: 2020-10-12_14-00-11
  done: false
  episode_len_mean: 864.8528735632184
  episode_reward_max: 265.93939393939445
  episode_reward_mean: 216.99312086381045
  episode_reward_min: 118.96969696969654
  episodes_this_iter: 160
  episodes_total: 1740
  experiment_id: 2bd6846c51c84a59b085a5d4a9f71128
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9605605701605479
        entropy_coeff: 0.0005000000000000001
        kl: 0.010173246885339418
        model: {}
        policy_loss: -0.011618643999099731
        total_loss: 16.00428303082784
        vf_explained_var: 0.9715494513511658
        vf_loss: 16.014346996943157
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.86666666666667
    gpu_util_percent0: 0.28300000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769999999999999
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 19343
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1534522066686958
    mean_env_wait_ms: 1.1623194108979273
    mean_inference_ms: 4.8926743718379235
    mean_raw_obs_processing_ms: 0.403555705782233
  time_since_restore: 265.66258811950684
  time_this_iter_s: 25.988534688949585
  time_total_s: 265.66258811950684
  timers:
    learn_throughput: 8436.023
    learn_time_ms: 19178.705
    sample_throughput: 22164.671
    sample_time_ms: 7299.544
    update_time_ms: 38.888
  timestamp: 1602511211
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 9bcae_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9bcae_00000 | RUNNING  | 172.17.0.4:19343 |     10 |          265.663 | 1617920 |  216.993 |              265.939 |               118.97 |            864.853 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9bcae_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3465.284577114428
    time_step_min: 3111
  date: 2020-10-12_14-00-37
  done: false
  episode_len_mean: 859.1627565982404
  episode_reward_max: 273.3636363636368
  episode_reward_mean: 219.60382416540767
  episode_reward_min: 118.96969696969654
  episodes_this_iter: 306
  episodes_total: 2046
  experiment_id: 2bd6846c51c84a59b085a5d4a9f71128
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9559945712486903
        entropy_coeff: 0.0005000000000000001
        kl: 0.008927065646275878
        model: {}
        policy_loss: -0.012010416258514548
        total_loss: 20.703050136566162
        vf_explained_var: 0.9714192748069763
        vf_loss: 20.71375338236491
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.076666666666668
    gpu_util_percent0: 0.3486666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666657
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 19343
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15273004529801903
    mean_env_wait_ms: 1.164461241052488
    mean_inference_ms: 4.831198375790457
    mean_raw_obs_processing_ms: 0.400931809783862
  time_since_restore: 291.72839760780334
  time_this_iter_s: 26.06580948829651
  time_total_s: 291.72839760780334
  timers:
    learn_throughput: 8445.504
    learn_time_ms: 19157.175
    sample_throughput: 23119.488
    sample_time_ms: 6998.079
    update_time_ms: 38.069
  timestamp: 1602511237
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 9bcae_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9bcae_00000 | RUNNING  | 172.17.0.4:19343 |     11 |          291.728 | 1779712 |  219.604 |              273.364 |               118.97 |            859.163 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9bcae_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3457.0661764705883
    time_step_min: 3111
  date: 2020-10-12_14-01-03
  done: false
  episode_len_mean: 856.1532549728752
  episode_reward_max: 273.3636363636368
  episode_reward_mean: 220.87576031563367
  episode_reward_min: 118.96969696969654
  episodes_this_iter: 166
  episodes_total: 2212
  experiment_id: 2bd6846c51c84a59b085a5d4a9f71128
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.934467742840449
        entropy_coeff: 0.0005000000000000001
        kl: 0.009529634456460675
        model: {}
        policy_loss: -0.013765764228689173
        total_loss: 13.12931776046753
        vf_explained_var: 0.974297821521759
        vf_loss: 13.141644477844238
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.39666666666667
    gpu_util_percent0: 0.3293333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 19343
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15240467183129497
    mean_env_wait_ms: 1.1655237937418597
    mean_inference_ms: 4.803697849136825
    mean_raw_obs_processing_ms: 0.3997344102975058
  time_since_restore: 317.92287158966064
  time_this_iter_s: 26.1944739818573
  time_total_s: 317.92287158966064
  timers:
    learn_throughput: 8435.761
    learn_time_ms: 19179.301
    sample_throughput: 23514.951
    sample_time_ms: 6880.389
    update_time_ms: 36.184
  timestamp: 1602511263
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 9bcae_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9bcae_00000 | RUNNING  | 172.17.0.4:19343 |     12 |          317.923 | 1941504 |  220.876 |              273.364 |               118.97 |            856.153 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9bcae_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3450.1088260497
    time_step_min: 3111
  date: 2020-10-12_14-01-30
  done: false
  episode_len_mean: 853.1438818565401
  episode_reward_max: 273.3636363636368
  episode_reward_mean: 221.8906789413118
  episode_reward_min: 118.96969696969654
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: 2bd6846c51c84a59b085a5d4a9f71128
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9140155613422394
        entropy_coeff: 0.0005000000000000001
        kl: 0.009746001567691565
        model: {}
        policy_loss: -0.014765678759431466
        total_loss: 11.469939947128296
        vf_explained_var: 0.9766791462898254
        vf_loss: 11.48321302731832
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.577419354838714
    gpu_util_percent0: 0.33161290322580644
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 19343
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15212241058682066
    mean_env_wait_ms: 1.1665341377311491
    mean_inference_ms: 4.7797814678848844
    mean_raw_obs_processing_ms: 0.39867881581899534
  time_since_restore: 344.37844347953796
  time_this_iter_s: 26.45557188987732
  time_total_s: 344.37844347953796
  timers:
    learn_throughput: 8428.034
    learn_time_ms: 19196.886
    sample_throughput: 23593.709
    sample_time_ms: 6857.421
    update_time_ms: 35.249
  timestamp: 1602511290
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 9bcae_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9bcae_00000 | RUNNING  | 172.17.0.4:19343 |     13 |          344.378 | 2103296 |  221.891 |              273.364 |               118.97 |            853.144 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9bcae_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3443.9309381237526
    time_step_min: 3108
  date: 2020-10-12_14-01-56
  done: false
  episode_len_mean: 850.3415977961432
  episode_reward_max: 273.81818181818164
  episode_reward_mean: 222.9115356636017
  episode_reward_min: 118.96969696969654
  episodes_this_iter: 171
  episodes_total: 2541
  experiment_id: 2bd6846c51c84a59b085a5d4a9f71128
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.876707727710406
        entropy_coeff: 0.0005000000000000001
        kl: 0.008321557504435381
        model: {}
        policy_loss: -0.01225017395336181
        total_loss: 14.675002813339233
        vf_explained_var: 0.9748527407646179
        vf_loss: 14.68602705001831
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.903333333333332
    gpu_util_percent0: 0.3413333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769999999999999
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 19343
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15184167152204006
    mean_env_wait_ms: 1.167634653939543
    mean_inference_ms: 4.756252603693443
    mean_raw_obs_processing_ms: 0.3976207001568892
  time_since_restore: 370.5900583267212
  time_this_iter_s: 26.211614847183228
  time_total_s: 370.5900583267212
  timers:
    learn_throughput: 8424.719
    learn_time_ms: 19204.439
    sample_throughput: 23642.093
    sample_time_ms: 6843.387
    update_time_ms: 35.001
  timestamp: 1602511316
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 9bcae_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9bcae_00000 | RUNNING  | 172.17.0.4:19343 |     14 |           370.59 | 2265088 |  222.912 |              273.818 |               118.97 |            850.342 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9bcae_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3430.536594073545
    time_step_min: 3108
  date: 2020-10-12_14-02-22
  done: false
  episode_len_mean: 846.4924215720832
  episode_reward_max: 275.48484848484856
  episode_reward_mean: 224.93817626387238
  episode_reward_min: 118.96969696969654
  episodes_this_iter: 296
  episodes_total: 2837
  experiment_id: 2bd6846c51c84a59b085a5d4a9f71128
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8600564996401469
        entropy_coeff: 0.0005000000000000001
        kl: 0.007423677326490481
        model: {}
        policy_loss: -0.012161423054446155
        total_loss: 13.714412291844686
        vf_explained_var: 0.9796054363250732
        vf_loss: 13.725518782933554
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.69666666666667
    gpu_util_percent0: 0.33
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 19343
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1514239561271678
    mean_env_wait_ms: 1.1693550306672926
    mean_inference_ms: 4.7207448986074105
    mean_raw_obs_processing_ms: 0.39607764234055415
  time_since_restore: 396.76795959472656
  time_this_iter_s: 26.17790126800537
  time_total_s: 396.76795959472656
  timers:
    learn_throughput: 8418.966
    learn_time_ms: 19217.563
    sample_throughput: 23690.003
    sample_time_ms: 6829.547
    update_time_ms: 36.314
  timestamp: 1602511342
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 9bcae_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9bcae_00000 | RUNNING  | 172.17.0.4:19343 |     15 |          396.768 | 2426880 |  224.938 |              275.485 |               118.97 |            846.492 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9bcae_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3422.936614969656
    time_step_min: 3108
  date: 2020-10-12_14-02-49
  done: false
  episode_len_mean: 844.6219187208528
  episode_reward_max: 280.18181818181864
  episode_reward_mean: 226.11866836250573
  episode_reward_min: 118.96969696969654
  episodes_this_iter: 165
  episodes_total: 3002
  experiment_id: 2bd6846c51c84a59b085a5d4a9f71128
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8541879653930664
        entropy_coeff: 0.0005000000000000001
        kl: 0.008496153013159832
        model: {}
        policy_loss: -0.012434076789456109
        total_loss: 9.61726689338684
        vf_explained_var: 0.9800946712493896
        vf_loss: 9.628429174423218
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.253333333333337
    gpu_util_percent0: 0.2750000000000001
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7799999999999994
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 19343
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15122018477721175
    mean_env_wait_ms: 1.1702386758326981
    mean_inference_ms: 4.703527006168454
    mean_raw_obs_processing_ms: 0.3953259579093535
  time_since_restore: 422.98321509361267
  time_this_iter_s: 26.21525549888611
  time_total_s: 422.98321509361267
  timers:
    learn_throughput: 8405.178
    learn_time_ms: 19249.086
    sample_throughput: 23741.004
    sample_time_ms: 6814.876
    update_time_ms: 36.222
  timestamp: 1602511369
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 9bcae_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9bcae_00000 | RUNNING  | 172.17.0.4:19343 |     16 |          422.983 | 2588672 |  226.119 |              280.182 |               118.97 |            844.622 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9bcae_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3417.0134443021766
    time_step_min: 3108
  date: 2020-10-12_14-03-15
  done: false
  episode_len_mean: 843.0037974683544
  episode_reward_max: 280.18181818181864
  episode_reward_mean: 227.04291331031834
  episode_reward_min: 118.96969696969654
  episodes_this_iter: 158
  episodes_total: 3160
  experiment_id: 2bd6846c51c84a59b085a5d4a9f71128
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.840729370713234
        entropy_coeff: 0.0005000000000000001
        kl: 0.009318466453502575
        model: {}
        policy_loss: -0.012025856789477984
        total_loss: 10.750532229741415
        vf_explained_var: 0.9772968888282776
        vf_loss: 10.761114438374838
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.406451612903222
    gpu_util_percent0: 0.36451612903225805
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 19343
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15103845225801893
    mean_env_wait_ms: 1.1710362143993032
    mean_inference_ms: 4.688155044284583
    mean_raw_obs_processing_ms: 0.39464972823629646
  time_since_restore: 449.0966012477875
  time_this_iter_s: 26.113386154174805
  time_total_s: 449.0966012477875
  timers:
    learn_throughput: 8414.786
    learn_time_ms: 19227.107
    sample_throughput: 23723.328
    sample_time_ms: 6819.954
    update_time_ms: 32.876
  timestamp: 1602511395
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 9bcae_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9bcae_00000 | RUNNING  | 172.17.0.4:19343 |     17 |          449.097 | 2750464 |  227.043 |              280.182 |               118.97 |            843.004 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9bcae_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3408.405089820359
    time_step_min: 3068
  date: 2020-10-12_14-03-41
  done: false
  episode_len_mean: 840.4600118483412
  episode_reward_max: 280.18181818181864
  episode_reward_mean: 228.28500646273156
  episode_reward_min: 118.96969696969654
  episodes_this_iter: 216
  episodes_total: 3376
  experiment_id: 2bd6846c51c84a59b085a5d4a9f71128
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.78706427415212
        entropy_coeff: 0.0005000000000000001
        kl: 0.008685613904769221
        model: {}
        policy_loss: -0.013051105823554584
        total_loss: 12.880223035812378
        vf_explained_var: 0.9789538979530334
        vf_loss: 12.8919305006663
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.773333333333333
    gpu_util_percent0: 0.26033333333333336
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 19343
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15080612014526668
    mean_env_wait_ms: 1.1721363805877938
    mean_inference_ms: 4.6688328585899
    mean_raw_obs_processing_ms: 0.39379637514493804
  time_since_restore: 475.23756098747253
  time_this_iter_s: 26.14095973968506
  time_total_s: 475.23756098747253
  timers:
    learn_throughput: 8405.297
    learn_time_ms: 19248.813
    sample_throughput: 23698.146
    sample_time_ms: 6827.201
    update_time_ms: 34.712
  timestamp: 1602511421
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 9bcae_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9bcae_00000 | RUNNING  | 172.17.0.4:19343 |     18 |          475.238 | 2912256 |  228.285 |              280.182 |               118.97 |             840.46 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9bcae_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3399.910431154381
    time_step_min: 3068
  date: 2020-10-12_14-04-08
  done: false
  episode_len_mean: 837.9944918755164
  episode_reward_max: 280.18181818181864
  episode_reward_mean: 229.57851163799936
  episode_reward_min: 118.96969696969654
  episodes_this_iter: 255
  episodes_total: 3631
  experiment_id: 2bd6846c51c84a59b085a5d4a9f71128
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7837072412172953
        entropy_coeff: 0.0005000000000000001
        kl: 0.007392142938139538
        model: {}
        policy_loss: -0.012837554425156364
        total_loss: 11.511511325836182
        vf_explained_var: 0.9807853102684021
        vf_loss: 11.523262023925781
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.10645161290323
    gpu_util_percent0: 0.3103225806451613
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322573
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 19343
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15056928291778854
    mean_env_wait_ms: 1.1733025312897936
    mean_inference_ms: 4.648505286749454
    mean_raw_obs_processing_ms: 0.3929252002952134
  time_since_restore: 501.59520149230957
  time_this_iter_s: 26.357640504837036
  time_total_s: 501.59520149230957
  timers:
    learn_throughput: 8408.202
    learn_time_ms: 19242.164
    sample_throughput: 23663.157
    sample_time_ms: 6837.296
    update_time_ms: 36.575
  timestamp: 1602511448
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 9bcae_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9bcae_00000 | RUNNING  | 172.17.0.4:19343 |     19 |          501.595 | 3074048 |  229.579 |              280.182 |               118.97 |            837.994 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9bcae_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3394.68077742279
    time_step_min: 3068
  date: 2020-10-12_14-04-34
  done: false
  episode_len_mean: 836.6561181434599
  episode_reward_max: 280.18181818181864
  episode_reward_mean: 230.34567990026846
  episode_reward_min: 118.96969696969654
  episodes_this_iter: 161
  episodes_total: 3792
  experiment_id: 2bd6846c51c84a59b085a5d4a9f71128
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7807947099208832
        entropy_coeff: 0.0005000000000000001
        kl: 0.007794124772772193
        model: {}
        policy_loss: -0.013530306411363805
        total_loss: 10.587139368057251
        vf_explained_var: 0.977923572063446
        vf_loss: 10.599501689275106
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.326666666666664
    gpu_util_percent0: 0.32266666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 19343
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15043172319694545
    mean_env_wait_ms: 1.1740101194544441
    mean_inference_ms: 4.6368255007766175
    mean_raw_obs_processing_ms: 0.39242387245708477
  time_since_restore: 527.9581639766693
  time_this_iter_s: 26.36296248435974
  time_total_s: 527.9581639766693
  timers:
    learn_throughput: 8404.762
    learn_time_ms: 19250.04
    sample_throughput: 23567.849
    sample_time_ms: 6864.945
    update_time_ms: 36.563
  timestamp: 1602511474
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 9bcae_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9bcae_00000 | RUNNING  | 172.17.0.4:19343 |     20 |          527.958 | 3235840 |  230.346 |              280.182 |               118.97 |            836.656 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9bcae_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3389.483146067416
    time_step_min: 3053
  date: 2020-10-12_14-05-01
  done: false
  episode_len_mean: 835.477479757085
  episode_reward_max: 282.45454545454567
  episode_reward_mean: 231.12595080358236
  episode_reward_min: 118.96969696969654
  episodes_this_iter: 160
  episodes_total: 3952
  experiment_id: 2bd6846c51c84a59b085a5d4a9f71128
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7537526140610377
        entropy_coeff: 0.0005000000000000001
        kl: 0.008836925340195497
        model: {}
        policy_loss: -0.015005943268382302
        total_loss: 8.847823143005371
        vf_explained_var: 0.9812431931495667
        vf_loss: 8.861438512802124
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.863333333333333
    gpu_util_percent0: 0.3396666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 19343
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15030133995446246
    mean_env_wait_ms: 1.17468750696913
    mean_inference_ms: 4.6258667187821185
    mean_raw_obs_processing_ms: 0.3919423753405193
  time_since_restore: 554.1195402145386
  time_this_iter_s: 26.161376237869263
  time_total_s: 554.1195402145386
  timers:
    learn_throughput: 8402.193
    learn_time_ms: 19255.926
    sample_throughput: 23562.139
    sample_time_ms: 6866.609
    update_time_ms: 36.513
  timestamp: 1602511501
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 9bcae_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9bcae_00000 | RUNNING  | 172.17.0.4:19343 |     21 |           554.12 | 3397632 |  231.126 |              282.455 |               118.97 |            835.477 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9bcae_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3382.6460687665303
    time_step_min: 3052
  date: 2020-10-12_14-05-27
  done: false
  episode_len_mean: 834.0402860548272
  episode_reward_max: 282.45454545454567
  episode_reward_mean: 232.1772311915339
  episode_reward_min: 118.96969696969654
  episodes_this_iter: 243
  episodes_total: 4195
  experiment_id: 2bd6846c51c84a59b085a5d4a9f71128
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7219241062800089
        entropy_coeff: 0.0005000000000000001
        kl: 0.008677327229330936
        model: {}
        policy_loss: -0.012592746847076342
        total_loss: 11.804911613464355
        vf_explained_var: 0.981519877910614
        vf_loss: 11.816129843393961
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.99677419354839
    gpu_util_percent0: 0.3258064516129032
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.761290322580645
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 19343
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15012036478211216
    mean_env_wait_ms: 1.1756333244878006
    mean_inference_ms: 4.610512974433915
    mean_raw_obs_processing_ms: 0.39125986063063894
  time_since_restore: 580.3980836868286
  time_this_iter_s: 26.27854347229004
  time_total_s: 580.3980836868286
  timers:
    learn_throughput: 8400.446
    learn_time_ms: 19259.931
    sample_throughput: 23550.472
    sample_time_ms: 6870.011
    update_time_ms: 36.218
  timestamp: 1602511527
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 9bcae_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9bcae_00000 | RUNNING  | 172.17.0.4:19343 |     22 |          580.398 | 3559424 |  232.177 |              282.455 |               118.97 |             834.04 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9bcae_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3376.109895120839
    time_step_min: 3052
  date: 2020-10-12_14-05-53
  done: true
  episode_len_mean: 832.9579375848033
  episode_reward_max: 283.06060606060595
  episode_reward_mean: 233.1677494072338
  episode_reward_min: 118.96969696969654
  episodes_this_iter: 227
  episodes_total: 4422
  experiment_id: 2bd6846c51c84a59b085a5d4a9f71128
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.721272220214208
        entropy_coeff: 0.0005000000000000001
        kl: 0.007052261809197565
        model: {}
        policy_loss: -0.011887276506361863
        total_loss: 10.31869888305664
        vf_explained_var: 0.9811952114105225
        vf_loss: 10.329536199569702
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.610000000000003
    gpu_util_percent0: 0.3403333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 19343
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14996995823591364
    mean_env_wait_ms: 1.1764556244160236
    mean_inference_ms: 4.597263151910942
    mean_raw_obs_processing_ms: 0.3907229182524231
  time_since_restore: 606.49396443367
  time_this_iter_s: 26.09588074684143
  time_total_s: 606.49396443367
  timers:
    learn_throughput: 8404.021
    learn_time_ms: 19251.738
    sample_throughput: 23649.138
    sample_time_ms: 6841.349
    update_time_ms: 36.517
  timestamp: 1602511553
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 9bcae_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9bcae_00000 | TERMINATED |       |     23 |          606.494 | 3721216 |  233.168 |              283.061 |               118.97 |            832.958 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9bcae_00000 | TERMINATED |       |     23 |          606.494 | 3721216 |  233.168 |              283.061 |               118.97 |            832.958 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


