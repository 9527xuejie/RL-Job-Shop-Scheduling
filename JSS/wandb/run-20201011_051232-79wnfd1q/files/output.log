2020-10-11 05:12:35,009	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_603a4_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=5110)[0m 2020-10-11 05:12:37,907	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=4991)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4991)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5040)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5040)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5070)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5070)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4986)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4986)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5093)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5093)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5052)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5052)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5031)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5031)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5074)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5074)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5092)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5092)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5065)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5065)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5043)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5043)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5107)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5107)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5078)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5078)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5016)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5016)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5114)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5114)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5089)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5089)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5120)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5120)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5051)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5051)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5063)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5063)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5059)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5059)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5085)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5085)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5091)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5091)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4982)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4982)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4993)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4993)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5033)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5033)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5035)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5035)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5096)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5096)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5020)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5020)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4980)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4980)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5000)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5000)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5012)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5012)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5083)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5083)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4998)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4998)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5010)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5010)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4978)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4978)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5062)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5062)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4996)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4996)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5046)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5046)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4992)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4992)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4989)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4989)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5047)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5047)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5082)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5082)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5037)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5037)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5058)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5058)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5068)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5068)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4983)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4983)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5067)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5067)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5003)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5003)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5060)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5060)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5061)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5061)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5014)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5014)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5116)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5116)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5103)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5103)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5044)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5044)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5019)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5019)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5064)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5064)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5056)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5056)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5049)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5049)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5018)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5018)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5069)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5069)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5072)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5072)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5004)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5004)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5008)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5008)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4987)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4987)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4994)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4994)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4981)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4981)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5006)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5006)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4985)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4985)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5066)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5066)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5075)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5075)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5054)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5054)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4995)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4995)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4984)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4984)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4979)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4979)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5088)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5088)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5057)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5057)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5111)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5111)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5038)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5038)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5081)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5081)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_603a4_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_05-13-17
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 41658d9b694d45209f4c9782cf45c5eb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1842407158442907
        entropy_coeff: 0.00010000000000000002
        kl: 0.00516631204767951
        model: {}
        policy_loss: -0.003630182007327676
        total_loss: 701.1909877232143
        vf_explained_var: 0.005364171229302883
        vf_loss: 701.1936819893973
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.5875
    gpu_util_percent0: 0.3015
    gpu_util_percent1: 0.00025
    gpu_util_percent2: 0.00025
    ram_util_percent: 6.284999999999999
    vram_util_percent0: 0.19141521810429646
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 5110
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17396145449924263
    mean_env_wait_ms: 1.1968672441162787
    mean_inference_ms: 6.290420138861671
    mean_raw_obs_processing_ms: 0.4662364042257961
  time_since_restore: 34.035202741622925
  time_this_iter_s: 34.035202741622925
  time_total_s: 34.035202741622925
  timers:
    learn_throughput: 6750.66
    learn_time_ms: 23966.841
    sample_throughput: 16195.593
    sample_time_ms: 9989.878
    update_time_ms: 27.443
  timestamp: 1602393197
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 603a4_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_603a4_00000 | RUNNING  | 172.17.0.4:5110 |      1 |          34.0352 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_603a4_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3608.4131944444443
    time_step_min: 3338
  date: 2020-10-11_05-13-49
  done: false
  episode_len_mean: 889.7151898734177
  episode_reward_max: 261.17171717171686
  episode_reward_mean: 218.81987597493904
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 41658d9b694d45209f4c9782cf45c5eb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.156774035521916
        entropy_coeff: 0.00010000000000000002
        kl: 0.00539517226362867
        model: {}
        policy_loss: -0.0028289739607966374
        total_loss: 349.3508082798549
        vf_explained_var: 0.4263021647930145
        vf_loss: 349.35266549246654
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.31081081081081
    gpu_util_percent0: 0.27540540540540537
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.475675675675675
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5110
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16864514565290373
    mean_env_wait_ms: 1.1918468385226644
    mean_inference_ms: 5.896118399049492
    mean_raw_obs_processing_ms: 0.45222544558017863
  time_since_restore: 65.67843985557556
  time_this_iter_s: 31.643237113952637
  time_total_s: 65.67843985557556
  timers:
    learn_throughput: 6772.654
    learn_time_ms: 23889.009
    sample_throughput: 18248.06
    sample_time_ms: 8866.258
    update_time_ms: 34.411
  timestamp: 1602393229
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 603a4_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_603a4_00000 | RUNNING  | 172.17.0.4:5110 |      2 |          65.6784 | 323584 |   218.82 |              261.172 |              145.717 |            889.715 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_603a4_00000:
  custom_metrics:
    time_step_max: 4147
    time_step_mean: 3615.95067264574
    time_step_min: 3338
  date: 2020-10-11_05-14-20
  done: false
  episode_len_mean: 886.7510548523206
  episode_reward_max: 261.17171717171686
  episode_reward_mean: 218.12031709500042
  episode_reward_min: 137.68686868686873
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 41658d9b694d45209f4c9782cf45c5eb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1543464745794023
        entropy_coeff: 0.00010000000000000002
        kl: 0.006310235875259552
        model: {}
        policy_loss: -0.003985156666853332
        total_loss: 178.8522186279297
        vf_explained_var: 0.7038881182670593
        vf_loss: 178.8550578526088
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.354054054054057
    gpu_util_percent0: 0.3240540540540541
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4837837837837835
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5110
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16547093878429128
    mean_env_wait_ms: 1.1899753608929617
    mean_inference_ms: 5.647213392306117
    mean_raw_obs_processing_ms: 0.44323911754333944
  time_since_restore: 97.19321703910828
  time_this_iter_s: 31.514777183532715
  time_total_s: 97.19321703910828
  timers:
    learn_throughput: 6756.238
    learn_time_ms: 23947.054
    sample_throughput: 19335.688
    sample_time_ms: 8367.533
    update_time_ms: 35.516
  timestamp: 1602393260
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 603a4_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_603a4_00000 | RUNNING  | 172.17.0.4:5110 |      3 |          97.1932 | 485376 |   218.12 |              261.172 |              137.687 |            886.751 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_603a4_00000:
  custom_metrics:
    time_step_max: 4368
    time_step_mean: 3613.566225165563
    time_step_min: 3338
  date: 2020-10-11_05-14-52
  done: false
  episode_len_mean: 883.0
  episode_reward_max: 265.86868686868644
  episode_reward_mean: 218.57102672292524
  episode_reward_min: 104.20202020202022
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 41658d9b694d45209f4c9782cf45c5eb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1482033474104745
        entropy_coeff: 0.00010000000000000002
        kl: 0.006251115085823196
        model: {}
        policy_loss: -0.004969394000779305
        total_loss: 112.03744179861886
        vf_explained_var: 0.8073918223381042
        vf_loss: 112.04127556937081
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.23333333333333
    gpu_util_percent0: 0.2836111111111111
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497222222222222
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5110
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1633007367155203
    mean_env_wait_ms: 1.1887208566403373
    mean_inference_ms: 5.474911906216273
    mean_raw_obs_processing_ms: 0.4365369966966704
  time_since_restore: 128.2409529685974
  time_this_iter_s: 31.047735929489136
  time_total_s: 128.2409529685974
  timers:
    learn_throughput: 6777.861
    learn_time_ms: 23870.657
    sample_throughput: 19950.274
    sample_time_ms: 8109.763
    update_time_ms: 30.96
  timestamp: 1602393292
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 603a4_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_603a4_00000 | RUNNING  | 172.17.0.4:5110 |      4 |          128.241 | 647168 |  218.571 |              265.869 |              104.202 |                883 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_603a4_00000:
  custom_metrics:
    time_step_max: 4368
    time_step_mean: 3608.1325459317586
    time_step_min: 3311
  date: 2020-10-11_05-15-23
  done: false
  episode_len_mean: 880.5949367088608
  episode_reward_max: 265.86868686868644
  episode_reward_mean: 220.09653496995253
  episode_reward_min: 104.20202020202022
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 41658d9b694d45209f4c9782cf45c5eb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.126569892678942
        entropy_coeff: 0.00010000000000000002
        kl: 0.005807555879333189
        model: {}
        policy_loss: -0.005011302376650357
        total_loss: 76.32984869820731
        vf_explained_var: 0.8564322590827942
        vf_loss: 76.33381162370954
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.783783783783782
    gpu_util_percent0: 0.3632432432432432
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.489189189189189
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5110
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1616712445342332
    mean_env_wait_ms: 1.1883386163069682
    mean_inference_ms: 5.3473771059952835
    mean_raw_obs_processing_ms: 0.43128105666089056
  time_since_restore: 159.48883867263794
  time_this_iter_s: 31.247885704040527
  time_total_s: 159.48883867263794
  timers:
    learn_throughput: 6772.707
    learn_time_ms: 23888.823
    sample_throughput: 20400.182
    sample_time_ms: 7930.91
    update_time_ms: 28.756
  timestamp: 1602393323
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 603a4_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_603a4_00000 | RUNNING  | 172.17.0.4:5110 |      5 |          159.489 | 808960 |  220.097 |              265.869 |              104.202 |            880.595 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_603a4_00000:
  custom_metrics:
    time_step_max: 4368
    time_step_mean: 3589.183191690274
    time_step_min: 3211
  date: 2020-10-11_05-15-54
  done: false
  episode_len_mean: 873.196872125115
  episode_reward_max: 279.5050505050501
  episode_reward_mean: 222.64714300316857
  episode_reward_min: 101.92929292929284
  episodes_this_iter: 297
  episodes_total: 1087
  experiment_id: 41658d9b694d45209f4c9782cf45c5eb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.118994074208396
        entropy_coeff: 0.00010000000000000002
        kl: 0.0047890183382800645
        model: {}
        policy_loss: -0.002593084645923227
        total_loss: 87.7653454371861
        vf_explained_var: 0.8952369689941406
        vf_loss: 87.767092023577
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.491666666666667
    gpu_util_percent0: 0.3002777777777778
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486111111111111
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5110
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1595940930463617
    mean_env_wait_ms: 1.1905049707263369
    mean_inference_ms: 5.184975894029734
    mean_raw_obs_processing_ms: 0.42460308784663353
  time_since_restore: 190.6499855518341
  time_this_iter_s: 31.161146879196167
  time_total_s: 190.6499855518341
  timers:
    learn_throughput: 6776.092
    learn_time_ms: 23876.888
    sample_throughput: 20692.65
    sample_time_ms: 7818.815
    update_time_ms: 30.515
  timestamp: 1602393354
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 603a4_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_603a4_00000 | RUNNING  | 172.17.0.4:5110 |      6 |           190.65 | 970752 |  222.647 |              279.505 |              101.929 |            873.197 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_603a4_00000:
  custom_metrics:
    time_step_max: 4368
    time_step_mean: 3578.9765372168285
    time_step_min: 3201
  date: 2020-10-11_05-16-26
  done: false
  episode_len_mean: 869.3441455696203
  episode_reward_max: 281.0202020202014
  episode_reward_mean: 224.23426511954975
  episode_reward_min: 101.92929292929284
  episodes_this_iter: 177
  episodes_total: 1264
  experiment_id: 41658d9b694d45209f4c9782cf45c5eb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.128586939402989
        entropy_coeff: 0.00010000000000000002
        kl: 0.010215562901326589
        model: {}
        policy_loss: -0.004169968297771577
        total_loss: 62.98684447152274
        vf_explained_var: 0.8781145215034485
        vf_loss: 62.990105220249724
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.532432432432433
    gpu_util_percent0: 0.23378378378378376
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.518918918918919
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5110
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15872244623019272
    mean_env_wait_ms: 1.1913248962390948
    mean_inference_ms: 5.116262113565598
    mean_raw_obs_processing_ms: 0.42177160009075937
  time_since_restore: 222.1841537952423
  time_this_iter_s: 31.534168243408203
  time_total_s: 222.1841537952423
  timers:
    learn_throughput: 6765.219
    learn_time_ms: 23915.266
    sample_throughput: 20898.074
    sample_time_ms: 7741.958
    update_time_ms: 33.157
  timestamp: 1602393386
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 603a4_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_603a4_00000 | RUNNING  | 172.17.0.4:5110 |      7 |          222.184 | 1132544 |  224.234 |               281.02 |              101.929 |            869.344 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_603a4_00000:
  custom_metrics:
    time_step_max: 4368
    time_step_mean: 3567.351506456241
    time_step_min: 3201
  date: 2020-10-11_05-16-57
  done: false
  episode_len_mean: 865.8199718706048
  episode_reward_max: 281.0202020202014
  episode_reward_mean: 226.06005199676068
  episode_reward_min: 101.92929292929284
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 41658d9b694d45209f4c9782cf45c5eb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.099193777356829
        entropy_coeff: 0.00010000000000000002
        kl: 0.010906780404703957
        model: {}
        policy_loss: -0.0068335542704777
        total_loss: 47.040901456560405
        vf_explained_var: 0.9012299180030823
        vf_loss: 47.046751839774
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.988888888888887
    gpu_util_percent0: 0.3302777777777777
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491666666666666
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5110
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15803730625177834
    mean_env_wait_ms: 1.1921636122819748
    mean_inference_ms: 5.0644047583537555
    mean_raw_obs_processing_ms: 0.41954256623470754
  time_since_restore: 253.23777508735657
  time_this_iter_s: 31.053621292114258
  time_total_s: 253.23777508735657
  timers:
    learn_throughput: 6773.094
    learn_time_ms: 23887.457
    sample_throughput: 21064.245
    sample_time_ms: 7680.883
    update_time_ms: 33.211
  timestamp: 1602393417
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 603a4_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_603a4_00000 | RUNNING  | 172.17.0.4:5110 |      8 |          253.238 | 1294336 |   226.06 |               281.02 |              101.929 |             865.82 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_603a4_00000:
  custom_metrics:
    time_step_max: 4368
    time_step_mean: 3558.3015463917527
    time_step_min: 3201
  date: 2020-10-11_05-17-28
  done: false
  episode_len_mean: 861.1120253164557
  episode_reward_max: 281.0202020202014
  episode_reward_mean: 227.18571793888236
  episode_reward_min: 101.92929292929284
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 41658d9b694d45209f4c9782cf45c5eb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0664239355495997
        entropy_coeff: 0.00010000000000000002
        kl: 0.008783216189060892
        model: {}
        policy_loss: -0.00419574389499238
        total_loss: 45.26836640494211
        vf_explained_var: 0.90814208984375
        vf_loss: 45.271789823259624
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.994594594594595
    gpu_util_percent0: 0.2832432432432433
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4972972972972975
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5110
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15743671087609357
    mean_env_wait_ms: 1.1932293642573994
    mean_inference_ms: 5.019384010376573
    mean_raw_obs_processing_ms: 0.41750927359215784
  time_since_restore: 284.6013078689575
  time_this_iter_s: 31.363532781600952
  time_total_s: 284.6013078689575
  timers:
    learn_throughput: 6772.907
    learn_time_ms: 23888.118
    sample_throughput: 21153.471
    sample_time_ms: 7648.485
    update_time_ms: 32.035
  timestamp: 1602393448
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 603a4_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_603a4_00000 | RUNNING  | 172.17.0.4:5110 |      9 |          284.601 | 1456128 |  227.186 |               281.02 |              101.929 |            861.112 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_603a4_00000:
  custom_metrics:
    time_step_max: 4368
    time_step_mean: 3544.035087719298
    time_step_min: 3201
  date: 2020-10-11_05-18-00
  done: false
  episode_len_mean: 852.7159827213823
  episode_reward_max: 282.38383838383845
  episode_reward_mean: 229.38266029626706
  episode_reward_min: 101.92929292929284
  episodes_this_iter: 272
  episodes_total: 1852
  experiment_id: 41658d9b694d45209f4c9782cf45c5eb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.028698308127267
        entropy_coeff: 0.00010000000000000002
        kl: 0.007697608055812972
        model: {}
        policy_loss: -0.0043692215944507295
        total_loss: 48.862800053187776
        vf_explained_var: 0.9341015219688416
        vf_loss: 48.86650167192732
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.527027027027028
    gpu_util_percent0: 0.43621621621621626
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.47027027027027
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5110
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15658201241390957
    mean_env_wait_ms: 1.1959128898190297
    mean_inference_ms: 4.955994855578889
    mean_raw_obs_processing_ms: 0.4145933005590136
  time_since_restore: 316.03824949264526
  time_this_iter_s: 31.436941623687744
  time_total_s: 316.03824949264526
  timers:
    learn_throughput: 6776.982
    learn_time_ms: 23873.755
    sample_throughput: 21186.149
    sample_time_ms: 7636.688
    update_time_ms: 38.851
  timestamp: 1602393480
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 603a4_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_603a4_00000 | RUNNING  | 172.17.0.4:5110 |     10 |          316.038 | 1617920 |  229.383 |              282.384 |              101.929 |            852.716 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_603a4_00000:
  custom_metrics:
    time_step_max: 4368
    time_step_mean: 3534.4407699901285
    time_step_min: 3179
  date: 2020-10-11_05-18-31
  done: false
  episode_len_mean: 847.2677702044791
  episode_reward_max: 284.3535353535349
  episode_reward_mean: 230.76253774355027
  episode_reward_min: 101.92929292929284
  episodes_this_iter: 202
  episodes_total: 2054
  experiment_id: 41658d9b694d45209f4c9782cf45c5eb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.038395004613059
        entropy_coeff: 0.00010000000000000002
        kl: 0.00922813160078866
        model: {}
        policy_loss: -0.005092022455106157
        total_loss: 35.313028880528044
        vf_explained_var: 0.9347212910652161
        vf_loss: 35.317301341465544
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.766666666666666
    gpu_util_percent0: 0.2672222222222222
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.508333333333334
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5110
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15607383703692132
    mean_env_wait_ms: 1.1977466889707071
    mean_inference_ms: 4.916769742871419
    mean_raw_obs_processing_ms: 0.41286572176222097
  time_since_restore: 347.21064829826355
  time_this_iter_s: 31.172398805618286
  time_total_s: 347.21064829826355
  timers:
    learn_throughput: 6780.028
    learn_time_ms: 23863.028
    sample_throughput: 21985.355
    sample_time_ms: 7359.081
    update_time_ms: 40.667
  timestamp: 1602393511
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 603a4_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_603a4_00000 | RUNNING  | 172.17.0.4:5110 |     11 |          347.211 | 1779712 |  230.763 |              284.354 |              101.929 |            847.268 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_603a4_00000:
  custom_metrics:
    time_step_max: 4368
    time_step_mean: 3526.4619963369964
    time_step_min: 3179
  date: 2020-10-11_05-19-02
  done: false
  episode_len_mean: 843.0904159132007
  episode_reward_max: 284.3535353535349
  episode_reward_mean: 231.88655086123427
  episode_reward_min: 101.92929292929284
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 41658d9b694d45209f4c9782cf45c5eb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0020559898444585
        entropy_coeff: 0.00010000000000000002
        kl: 0.007957880784358298
        model: {}
        policy_loss: -0.004234836307919717
        total_loss: 27.67995616367885
        vf_explained_var: 0.94200199842453
        vf_loss: 27.683495794023788
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.362857142857145
    gpu_util_percent0: 0.26714285714285707
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494285714285715
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5110
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15571335132118916
    mean_env_wait_ms: 1.199221934571143
    mean_inference_ms: 4.8898710592623855
    mean_raw_obs_processing_ms: 0.41164413050030846
  time_since_restore: 377.8788368701935
  time_this_iter_s: 30.66818857192993
  time_total_s: 377.8788368701935
  timers:
    learn_throughput: 6792.828
    learn_time_ms: 23818.063
    sample_throughput: 22140.518
    sample_time_ms: 7307.507
    update_time_ms: 38.793
  timestamp: 1602393542
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 603a4_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_603a4_00000 | RUNNING  | 172.17.0.4:5110 |     12 |          377.879 | 1941504 |  231.887 |              284.354 |              101.929 |             843.09 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_603a4_00000:
  custom_metrics:
    time_step_max: 4368
    time_step_mean: 3518.0467289719627
    time_step_min: 3179
  date: 2020-10-11_05-19-33
  done: false
  episode_len_mean: 838.879932829555
  episode_reward_max: 284.3535353535349
  episode_reward_mean: 233.1914103249114
  episode_reward_min: 101.92929292929284
  episodes_this_iter: 170
  episodes_total: 2382
  experiment_id: 41658d9b694d45209f4c9782cf45c5eb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.9508459184850965
        entropy_coeff: 0.00010000000000000002
        kl: 0.008727048058062792
        model: {}
        policy_loss: -0.005006230644149972
        total_loss: 27.4719877243042
        vf_explained_var: 0.9515079855918884
        vf_loss: 27.476215498788015
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.2
    gpu_util_percent0: 0.3008333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4944444444444445
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5110
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15535981343133357
    mean_env_wait_ms: 1.200898836815271
    mean_inference_ms: 4.863393456974855
    mean_raw_obs_processing_ms: 0.4104124089889358
  time_since_restore: 408.59159660339355
  time_this_iter_s: 30.712759733200073
  time_total_s: 408.59159660339355
  timers:
    learn_throughput: 6809.062
    learn_time_ms: 23761.277
    sample_throughput: 22212.654
    sample_time_ms: 7283.776
    update_time_ms: 37.357
  timestamp: 1602393573
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 603a4_00000
  
== Status ==
Memory usage on this node: 48.9/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_603a4_00000 | RUNNING  | 172.17.0.4:5110 |     13 |          408.592 | 2103296 |  233.191 |              284.354 |              101.929 |             838.88 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_603a4_00000:
  custom_metrics:
    time_step_max: 4368
    time_step_mean: 3504.282919488337
    time_step_min: 3173
  date: 2020-10-11_05-20-03
  done: false
  episode_len_mean: 832.1016381236038
  episode_reward_max: 285.2626262626261
  episode_reward_mean: 235.17051001451586
  episode_reward_min: 101.92929292929284
  episodes_this_iter: 304
  episodes_total: 2686
  experiment_id: 41658d9b694d45209f4c9782cf45c5eb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.9652171518121447
        entropy_coeff: 0.00010000000000000002
        kl: 0.007867441146767564
        model: {}
        policy_loss: -0.003027555624222649
        total_loss: 26.019750458853586
        vf_explained_var: 0.96122807264328
        vf_loss: 26.02208845955985
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.98611111111111
    gpu_util_percent0: 0.2941666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888889
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5110
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15482497976240397
    mean_env_wait_ms: 1.2039856953346348
    mean_inference_ms: 4.823094631075825
    mean_raw_obs_processing_ms: 0.40860741070001344
  time_since_restore: 439.18208956718445
  time_this_iter_s: 30.590492963790894
  time_total_s: 439.18208956718445
  timers:
    learn_throughput: 6817.106
    learn_time_ms: 23733.24
    sample_throughput: 22270.895
    sample_time_ms: 7264.728
    update_time_ms: 37.673
  timestamp: 1602393603
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 603a4_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_603a4_00000 | RUNNING  | 172.17.0.4:5110 |     14 |          439.182 | 2265088 |  235.171 |              285.263 |              101.929 |            832.102 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_603a4_00000:
  custom_metrics:
    time_step_max: 4368
    time_step_mean: 3496.795809659091
    time_step_min: 3160
  date: 2020-10-11_05-20-34
  done: false
  episode_len_mean: 828.9571026722925
  episode_reward_max: 287.23232323232287
  episode_reward_mean: 236.28210373779984
  episode_reward_min: 101.92929292929284
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 41658d9b694d45209f4c9782cf45c5eb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.9417285110269275
        entropy_coeff: 0.00010000000000000002
        kl: 0.008985472909573997
        model: {}
        policy_loss: -0.003089737512969545
        total_loss: 16.46417474746704
        vf_explained_var: 0.9651752710342407
        vf_loss: 16.466460364205496
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.880555555555556
    gpu_util_percent0: 0.3302777777777777
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491666666666666
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5110
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15457800281279055
    mean_env_wait_ms: 1.205431147762604
    mean_inference_ms: 4.804732431236653
    mean_raw_obs_processing_ms: 0.4077767049816446
  time_since_restore: 469.77456879615784
  time_this_iter_s: 30.59247922897339
  time_total_s: 469.77456879615784
  timers:
    learn_throughput: 6835.963
    learn_time_ms: 23667.77
    sample_throughput: 22283.005
    sample_time_ms: 7260.78
    update_time_ms: 38.925
  timestamp: 1602393634
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 603a4_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_603a4_00000 | RUNNING  | 172.17.0.4:5110 |     15 |          469.775 | 2426880 |  236.282 |              287.232 |              101.929 |            828.957 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_603a4_00000:
  custom_metrics:
    time_step_max: 4368
    time_step_mean: 3490.3821356615176
    time_step_min: 3160
  date: 2020-10-11_05-21-05
  done: false
  episode_len_mean: 826.0326014637392
  episode_reward_max: 287.5353535353535
  episode_reward_mean: 237.29724389604618
  episode_reward_min: 101.92929292929284
  episodes_this_iter: 162
  episodes_total: 3006
  experiment_id: 41658d9b694d45209f4c9782cf45c5eb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.9121482627732413
        entropy_coeff: 0.00010000000000000002
        kl: 0.006907256619472589
        model: {}
        policy_loss: -0.0033237007545332225
        total_loss: 17.234318324497767
        vf_explained_var: 0.9667437672615051
        vf_loss: 17.23704242706299
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.711428571428566
    gpu_util_percent0: 0.2988571428571428
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.502857142857143
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5110
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15434342595131703
    mean_env_wait_ms: 1.2068964300833032
    mean_inference_ms: 4.787198362686749
    mean_raw_obs_processing_ms: 0.406962293297353
  time_since_restore: 500.4949219226837
  time_this_iter_s: 30.72035312652588
  time_total_s: 500.4949219226837
  timers:
    learn_throughput: 6845.176
    learn_time_ms: 23635.915
    sample_throughput: 22319.328
    sample_time_ms: 7248.964
    update_time_ms: 37.086
  timestamp: 1602393665
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 603a4_00000
  
== Status ==
Memory usage on this node: 48.9/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_603a4_00000 | RUNNING  | 172.17.0.4:5110 |     16 |          500.495 | 2588672 |  237.297 |              287.535 |              101.929 |            826.033 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_603a4_00000:
  custom_metrics:
    time_step_max: 4368
    time_step_mean: 3478.770820668693
    time_step_min: 3160
  date: 2020-10-11_05-21-36
  done: false
  episode_len_mean: 821.2049427365884
  episode_reward_max: 287.5353535353535
  episode_reward_mean: 239.0809176758543
  episode_reward_min: 101.92929292929284
  episodes_this_iter: 312
  episodes_total: 3318
  experiment_id: 41658d9b694d45209f4c9782cf45c5eb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.8994097879954747
        entropy_coeff: 0.00010000000000000002
        kl: 0.007613718443151031
        model: {}
        policy_loss: -0.004890357510053686
        total_loss: 19.304526737758092
        vf_explained_var: 0.9721727967262268
        vf_loss: 19.30874592917306
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.72432432432432
    gpu_util_percent0: 0.28216216216216217
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.489189189189189
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5110
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1539394155122039
    mean_env_wait_ms: 1.2096293188109268
    mean_inference_ms: 4.757428041174457
    mean_raw_obs_processing_ms: 0.40559752520656595
  time_since_restore: 531.5022013187408
  time_this_iter_s: 31.00727939605713
  time_total_s: 531.5022013187408
  timers:
    learn_throughput: 6860.303
    learn_time_ms: 23583.796
    sample_throughput: 22317.728
    sample_time_ms: 7249.484
    update_time_ms: 35.249
  timestamp: 1602393696
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 603a4_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_603a4_00000 | RUNNING  | 172.17.0.4:5110 |     17 |          531.502 | 2750464 |  239.081 |              287.535 |              101.929 |            821.205 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_603a4_00000:
  custom_metrics:
    time_step_max: 4368
    time_step_mean: 3473.5110208816704
    time_step_min: 3160
  date: 2020-10-11_05-22-06
  done: false
  episode_len_mean: 819.1179516685846
  episode_reward_max: 287.5353535353535
  episode_reward_mean: 239.86474642861285
  episode_reward_min: 101.92929292929284
  episodes_this_iter: 158
  episodes_total: 3476
  experiment_id: 41658d9b694d45209f4c9782cf45c5eb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.8825668053967612
        entropy_coeff: 0.00010000000000000002
        kl: 0.009380628887031759
        model: {}
        policy_loss: -0.003946351774045199
        total_loss: 13.725978306361608
        vf_explained_var: 0.9710115790367126
        vf_loss: 13.729074478149414
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.611428571428576
    gpu_util_percent0: 0.28628571428571425
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.499999999999999
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5110
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1537571184673398
    mean_env_wait_ms: 1.2108858094476067
    mean_inference_ms: 4.743958332659167
    mean_raw_obs_processing_ms: 0.4049743779308125
  time_since_restore: 561.7916667461395
  time_this_iter_s: 30.28946542739868
  time_total_s: 561.7916667461395
  timers:
    learn_throughput: 6880.19
    learn_time_ms: 23515.631
    sample_throughput: 22339.273
    sample_time_ms: 7242.492
    update_time_ms: 33.74
  timestamp: 1602393726
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 603a4_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_603a4_00000 | RUNNING  | 172.17.0.4:5110 |     18 |          561.792 | 2912256 |  239.865 |              287.535 |              101.929 |            819.118 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_603a4_00000:
  custom_metrics:
    time_step_max: 4368
    time_step_mean: 3468.3169717138103
    time_step_min: 3160
  date: 2020-10-11_05-22-38
  done: false
  episode_len_mean: 817.2438084755091
  episode_reward_max: 287.5353535353535
  episode_reward_mean: 240.6229021085927
  episode_reward_min: 101.92929292929284
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: 41658d9b694d45209f4c9782cf45c5eb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.8429429743971143
        entropy_coeff: 0.00010000000000000002
        kl: 0.007443245866202882
        model: {}
        policy_loss: -0.0031074166929881486
        total_loss: 13.038210800715856
        vf_explained_var: 0.9729158282279968
        vf_loss: 13.04065820149013
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.697297297297297
    gpu_util_percent0: 0.3008108108108108
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.502702702702703
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5110
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1535870329877975
    mean_env_wait_ms: 1.212120020679383
    mean_inference_ms: 4.731313188995787
    mean_raw_obs_processing_ms: 0.4043762567655632
  time_since_restore: 592.7167747020721
  time_this_iter_s: 30.925107955932617
  time_total_s: 592.7167747020721
  timers:
    learn_throughput: 6889.163
    learn_time_ms: 23485.001
    sample_throughput: 22389.992
    sample_time_ms: 7226.085
    update_time_ms: 36.556
  timestamp: 1602393758
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 603a4_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_603a4_00000 | RUNNING  | 172.17.0.4:5110 |     19 |          592.717 | 3074048 |  240.623 |              287.535 |              101.929 |            817.244 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_603a4_00000:
  custom_metrics:
    time_step_max: 4368
    time_step_mean: 3458.761346251912
    time_step_min: 3136
  date: 2020-10-11_05-23-08
  done: true
  episode_len_mean: 813.6156962025317
  episode_reward_max: 291.3232323232327
  episode_reward_mean: 242.05932745173243
  episode_reward_min: 101.92929292929284
  episodes_this_iter: 316
  episodes_total: 3950
  experiment_id: 41658d9b694d45209f4c9782cf45c5eb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.8286702292306083
        entropy_coeff: 0.00010000000000000002
        kl: 0.0074459698516875505
        model: {}
        policy_loss: -0.0028437973368064767
        total_loss: 16.70643901824951
        vf_explained_var: 0.975891649723053
        vf_loss: 16.708621161324636
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.924999999999997
    gpu_util_percent0: 0.2747222222222222
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888889
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5110
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15327859194360416
    mean_env_wait_ms: 1.2145212835666037
    mean_inference_ms: 4.708430152834449
    mean_raw_obs_processing_ms: 0.4033228776821586
  time_since_restore: 623.5082082748413
  time_this_iter_s: 30.791433572769165
  time_total_s: 623.5082082748413
  timers:
    learn_throughput: 6896.918
    learn_time_ms: 23458.595
    sample_throughput: 22508.961
    sample_time_ms: 7187.893
    update_time_ms: 35.783
  timestamp: 1602393788
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 603a4_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_603a4_00000 | TERMINATED |       |     20 |          623.508 | 3235840 |  242.059 |              291.323 |              101.929 |            813.616 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_603a4_00000 | TERMINATED |       |     20 |          623.508 | 3235840 |  242.059 |              291.323 |              101.929 |            813.616 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


