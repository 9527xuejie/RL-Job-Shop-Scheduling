2020-10-12 15:11:53,561	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_43967_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=35494)[0m 2020-10-12 15:11:56,334	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=35485)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35485)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35512)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35512)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35526)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35526)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35492)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35492)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35528)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35528)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35546)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35546)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35499)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35499)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35520)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35520)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35469)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35469)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35489)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35489)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35508)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35508)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35491)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35491)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35466)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35466)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35431)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35431)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35416)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35416)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35503)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35503)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35493)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35493)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35473)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35473)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35486)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35486)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35475)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35475)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35443)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35443)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35488)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35488)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35418)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35418)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35422)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35422)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35405)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35405)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35481)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35481)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35537)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35537)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35427)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35427)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35429)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35429)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35496)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35496)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35507)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35507)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35538)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35538)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35540)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35540)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35424)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35424)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35519)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35519)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35498)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35498)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35428)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35428)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35525)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35525)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35411)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35411)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35460)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35460)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35510)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35510)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35523)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35523)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35409)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35409)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35406)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35406)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35534)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35534)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35453)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35453)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35430)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35430)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35420)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35420)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35425)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35425)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35442)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35442)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35458)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35458)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35408)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35408)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35414)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35414)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35531)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35531)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35463)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35463)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35482)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35482)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35407)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35407)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35483)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35483)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35433)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35433)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35423)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35423)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35487)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35487)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35497)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35497)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35419)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35419)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35505)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35505)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35410)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35410)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35440)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35440)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35415)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35415)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35501)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35501)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35484)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35484)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35513)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35513)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35413)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35413)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35476)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35476)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35412)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35412)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35478)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35478)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35438)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35438)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35533)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35533)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35472)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35472)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35462)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35462)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35426)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35426)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_43967_00000:
  custom_metrics:
    time_step_max: 3924
    time_step_mean: 3604.0258620689656
    time_step_min: 3359
  date: 2020-10-12_15-12-30
  done: false
  episode_len_mean: 901.8924050632911
  episode_reward_max: 263.14141414141426
  episode_reward_mean: 220.7612837233088
  episode_reward_min: 158.89898989898953
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 949329b4dde9497e8a93f245d8af3c76
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1608085731665294
        entropy_coeff: 0.0005000000000000001
        kl: 0.004805326461791992
        model: {}
        policy_loss: -0.009253671441304808
        total_loss: 406.1570561726888
        vf_explained_var: 0.5482549071311951
        vf_loss: 406.1659342447917
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.52941176470588
    gpu_util_percent0: 0.36588235294117644
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5647058823529414
    vram_util_percent0: 0.08636872262844136
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35494
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17155219758502785
    mean_env_wait_ms: 1.1704086970311325
    mean_inference_ms: 5.906946556772041
    mean_raw_obs_processing_ms: 0.4561081592151139
  time_since_restore: 28.932388067245483
  time_this_iter_s: 28.932388067245483
  time_total_s: 28.932388067245483
  timers:
    learn_throughput: 8242.3
    learn_time_ms: 19629.473
    sample_throughput: 17517.242
    sample_time_ms: 9236.157
    update_time_ms: 31.567
  timestamp: 1602515550
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: '43967_00000'
  
== Status ==
Memory usage on this node: 27.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43967_00000 | RUNNING  | 172.17.0.4:35494 |      1 |          28.9324 | 161792 |  220.761 |              263.141 |              158.899 |            901.892 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43967_00000:
  custom_metrics:
    time_step_max: 3980
    time_step_mean: 3600.970802919708
    time_step_min: 3333
  date: 2020-10-12_15-12-57
  done: false
  episode_len_mean: 899.1962025316456
  episode_reward_max: 273.2929292929292
  episode_reward_mean: 221.7322273366575
  episode_reward_min: 149.65656565656565
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 949329b4dde9497e8a93f245d8af3c76
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1335585514704387
        entropy_coeff: 0.0005000000000000001
        kl: 0.008734231581911445
        model: {}
        policy_loss: -0.010306129270854095
        total_loss: 93.4173018137614
        vf_explained_var: 0.8161735534667969
        vf_loss: 93.42730140686035
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.815624999999997
    gpu_util_percent0: 0.29218750000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7593750000000004
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35494
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1668717207318688
    mean_env_wait_ms: 1.166596165610076
    mean_inference_ms: 5.6304384197154
    mean_raw_obs_processing_ms: 0.4439844037196848
  time_since_restore: 56.09487700462341
  time_this_iter_s: 27.16248893737793
  time_total_s: 56.09487700462341
  timers:
    learn_throughput: 8284.588
    learn_time_ms: 19529.275
    sample_throughput: 19162.826
    sample_time_ms: 8443.014
    update_time_ms: 33.068
  timestamp: 1602515577
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: '43967_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43967_00000 | RUNNING  | 172.17.0.4:35494 |      2 |          56.0949 | 323584 |  221.732 |              273.293 |              149.657 |            899.196 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43967_00000:
  custom_metrics:
    time_step_max: 3980
    time_step_mean: 3595.8611111111113
    time_step_min: 3295
  date: 2020-10-12_15-13-24
  done: false
  episode_len_mean: 892.9345991561181
  episode_reward_max: 273.2929292929292
  episode_reward_mean: 222.41484464902166
  episode_reward_min: 149.65656565656565
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 949329b4dde9497e8a93f245d8af3c76
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1224475900332134
        entropy_coeff: 0.0005000000000000001
        kl: 0.009928210948904356
        model: {}
        policy_loss: -0.013527336258751651
        total_loss: 46.36474482218424
        vf_explained_var: 0.8946500420570374
        vf_loss: 46.37784067789713
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.46
    gpu_util_percent0: 0.26566666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.773333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35494
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16365702587652556
    mean_env_wait_ms: 1.1664763991604892
    mean_inference_ms: 5.419997670786168
    mean_raw_obs_processing_ms: 0.4344032504353477
  time_since_restore: 82.42610669136047
  time_this_iter_s: 26.33122968673706
  time_total_s: 82.42610669136047
  timers:
    learn_throughput: 8301.359
    learn_time_ms: 19489.82
    sample_throughput: 20456.54
    sample_time_ms: 7909.06
    update_time_ms: 29.651
  timestamp: 1602515604
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: '43967_00000'
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43967_00000 | RUNNING  | 172.17.0.4:35494 |      3 |          82.4261 | 485376 |  222.415 |              273.293 |              149.657 |            892.935 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43967_00000:
  custom_metrics:
    time_step_max: 3980
    time_step_mean: 3588.886440677966
    time_step_min: 3295
  date: 2020-10-12_15-13-50
  done: false
  episode_len_mean: 889.3892405063291
  episode_reward_max: 273.2929292929292
  episode_reward_mean: 223.09178813450944
  episode_reward_min: 149.65656565656565
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 949329b4dde9497e8a93f245d8af3c76
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1078311800956726
        entropy_coeff: 0.0005000000000000001
        kl: 0.008517272498769065
        model: {}
        policy_loss: -0.011693460956280433
        total_loss: 35.83105627695719
        vf_explained_var: 0.9196924567222595
        vf_loss: 35.84245204925537
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.612903225806452
    gpu_util_percent0: 0.23548387096774193
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7741935483870965
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35494
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16137815732506475
    mean_env_wait_ms: 1.1673043626280242
    mean_inference_ms: 5.268399230507405
    mean_raw_obs_processing_ms: 0.4272722226594859
  time_since_restore: 108.92601466178894
  time_this_iter_s: 26.499907970428467
  time_total_s: 108.92601466178894
  timers:
    learn_throughput: 8293.224
    learn_time_ms: 19508.938
    sample_throughput: 21160.284
    sample_time_ms: 7646.022
    update_time_ms: 28.71
  timestamp: 1602515630
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: '43967_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43967_00000 | RUNNING  | 172.17.0.4:35494 |      4 |          108.926 | 647168 |  223.092 |              273.293 |              149.657 |            889.389 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43967_00000:
  custom_metrics:
    time_step_max: 3980
    time_step_mean: 3577.756684491979
    time_step_min: 3290
  date: 2020-10-12_15-14-17
  done: false
  episode_len_mean: 881.9746835443038
  episode_reward_max: 273.2929292929292
  episode_reward_mean: 224.92679964198936
  episode_reward_min: 148.1414141414143
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 949329b4dde9497e8a93f245d8af3c76
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0736220180988312
        entropy_coeff: 0.0005000000000000001
        kl: 0.007788454958548148
        model: {}
        policy_loss: -0.013847309475143751
        total_loss: 26.951021671295166
        vf_explained_var: 0.9353466629981995
        vf_loss: 26.964626948038738
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.951612903225808
    gpu_util_percent0: 0.25967741935483873
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774193548387097
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35494
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15972523118573673
    mean_env_wait_ms: 1.1692508421786514
    mean_inference_ms: 5.1545660974173035
    mean_raw_obs_processing_ms: 0.42178515404817285
  time_since_restore: 135.522043466568
  time_this_iter_s: 26.596028804779053
  time_total_s: 135.522043466568
  timers:
    learn_throughput: 8287.858
    learn_time_ms: 19521.569
    sample_throughput: 21564.0
    sample_time_ms: 7502.875
    update_time_ms: 31.575
  timestamp: 1602515657
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: '43967_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43967_00000 | RUNNING  | 172.17.0.4:35494 |      5 |          135.522 | 808960 |  224.927 |              273.293 |              148.141 |            881.975 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43967_00000:
  custom_metrics:
    time_step_max: 3980
    time_step_mean: 3563.447592067989
    time_step_min: 3284
  date: 2020-10-12_15-14-44
  done: false
  episode_len_mean: 868.5930971843778
  episode_reward_max: 273.2929292929292
  episode_reward_mean: 227.7086120056146
  episode_reward_min: 148.1414141414143
  episodes_this_iter: 311
  episodes_total: 1101
  experiment_id: 949329b4dde9497e8a93f245d8af3c76
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0425472756226857
        entropy_coeff: 0.0005000000000000001
        kl: 0.008018907392397523
        model: {}
        policy_loss: -0.0111910367947227
        total_loss: 29.674411137898762
        vf_explained_var: 0.9557506442070007
        vf_loss: 29.685321807861328
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.48064516129033
    gpu_util_percent0: 0.3841935483870968
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35494
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1575204321083379
    mean_env_wait_ms: 1.17385401625619
    mean_inference_ms: 5.003146077115474
    mean_raw_obs_processing_ms: 0.4146553318357278
  time_since_restore: 162.071848154068
  time_this_iter_s: 26.5498046875
  time_total_s: 162.071848154068
  timers:
    learn_throughput: 8281.401
    learn_time_ms: 19536.791
    sample_throughput: 21883.405
    sample_time_ms: 7393.365
    update_time_ms: 33.271
  timestamp: 1602515684
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: '43967_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43967_00000 | RUNNING  | 172.17.0.4:35494 |      6 |          162.072 | 970752 |  227.709 |              273.293 |              148.141 |            868.593 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43967_00000:
  custom_metrics:
    time_step_max: 3980
    time_step_mean: 3552.6792144026185
    time_step_min: 3193
  date: 2020-10-12_15-15-10
  done: false
  episode_len_mean: 863.0371835443038
  episode_reward_max: 282.8383838383837
  episode_reward_mean: 229.1686964582533
  episode_reward_min: 148.1414141414143
  episodes_this_iter: 163
  episodes_total: 1264
  experiment_id: 949329b4dde9497e8a93f245d8af3c76
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.037640631198883
        entropy_coeff: 0.0005000000000000001
        kl: 0.007880023564212024
        model: {}
        policy_loss: -0.013542136293835938
        total_loss: 18.04273223876953
        vf_explained_var: 0.9574272632598877
        vf_loss: 18.056005160013836
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.883333333333336
    gpu_util_percent0: 0.269
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.783333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35494
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1566968449149529
    mean_env_wait_ms: 1.1759646452917794
    mean_inference_ms: 4.946616396574944
    mean_raw_obs_processing_ms: 0.4119915000102004
  time_since_restore: 188.2840895652771
  time_this_iter_s: 26.212241411209106
  time_total_s: 188.2840895652771
  timers:
    learn_throughput: 8292.122
    learn_time_ms: 19511.531
    sample_throughput: 22152.435
    sample_time_ms: 7303.576
    update_time_ms: 33.695
  timestamp: 1602515710
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: '43967_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43967_00000 | RUNNING  | 172.17.0.4:35494 |      7 |          188.284 | 1132544 |  229.169 |              282.838 |              148.141 |            863.037 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43967_00000:
  custom_metrics:
    time_step_max: 3980
    time_step_mean: 3546.1608695652176
    time_step_min: 3193
  date: 2020-10-12_15-15-36
  done: false
  episode_len_mean: 858.1448663853727
  episode_reward_max: 282.8383838383837
  episode_reward_mean: 230.0799982951881
  episode_reward_min: 148.1414141414143
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 949329b4dde9497e8a93f245d8af3c76
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0278969705104828
        entropy_coeff: 0.0005000000000000001
        kl: 0.007529285775187115
        model: {}
        policy_loss: -0.011286740329524036
        total_loss: 17.775658925374348
        vf_explained_var: 0.9589188098907471
        vf_loss: 17.78670644760132
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.374193548387098
    gpu_util_percent0: 0.28548387096774197
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.777419354838709
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35494
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15600515399938722
    mean_env_wait_ms: 1.178014646486596
    mean_inference_ms: 4.89915699258781
    mean_raw_obs_processing_ms: 0.40969934529144275
  time_since_restore: 214.61291408538818
  time_this_iter_s: 26.328824520111084
  time_total_s: 214.61291408538818
  timers:
    learn_throughput: 8296.21
    learn_time_ms: 19501.916
    sample_throughput: 22344.371
    sample_time_ms: 7240.839
    update_time_ms: 34.382
  timestamp: 1602515736
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: '43967_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43967_00000 | RUNNING  | 172.17.0.4:35494 |      8 |          214.613 | 1294336 |   230.08 |              282.838 |              148.141 |            858.145 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43967_00000:
  custom_metrics:
    time_step_max: 3980
    time_step_mean: 3541.243823146944
    time_step_min: 3193
  date: 2020-10-12_15-16-03
  done: false
  episode_len_mean: 853.8582278481013
  episode_reward_max: 282.8383838383837
  episode_reward_mean: 230.84768571793876
  episode_reward_min: 148.1414141414143
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 949329b4dde9497e8a93f245d8af3c76
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9909720321496328
        entropy_coeff: 0.0005000000000000001
        kl: 0.007027940048525731
        model: {}
        policy_loss: -0.012216423288919032
        total_loss: 17.90696128209432
        vf_explained_var: 0.9601621627807617
        vf_loss: 17.918970108032227
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.01333333333334
    gpu_util_percent0: 0.27466666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.773333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35494
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1553998696050613
    mean_env_wait_ms: 1.180010130883402
    mean_inference_ms: 4.857762840002158
    mean_raw_obs_processing_ms: 0.4076352199960522
  time_since_restore: 240.78037524223328
  time_this_iter_s: 26.167461156845093
  time_total_s: 240.78037524223328
  timers:
    learn_throughput: 8306.525
    learn_time_ms: 19477.7
    sample_throughput: 22497.25
    sample_time_ms: 7191.634
    update_time_ms: 34.046
  timestamp: 1602515763
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: '43967_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43967_00000 | RUNNING  | 172.17.0.4:35494 |      9 |           240.78 | 1456128 |  230.848 |              282.838 |              148.141 |            853.858 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43967_00000:
  custom_metrics:
    time_step_max: 3980
    time_step_mean: 3526.0804101457097
    time_step_min: 3193
  date: 2020-10-12_15-16-29
  done: false
  episode_len_mean: 845.9282321899736
  episode_reward_max: 284.2020202020208
  episode_reward_mean: 232.8910743317075
  episode_reward_min: 148.1414141414143
  episodes_this_iter: 315
  episodes_total: 1895
  experiment_id: 949329b4dde9497e8a93f245d8af3c76
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9543150613705317
        entropy_coeff: 0.0005000000000000001
        kl: 0.006918751479436954
        model: {}
        policy_loss: -0.0114073078148067
        total_loss: 22.750616709391277
        vf_explained_var: 0.9664721488952637
        vf_loss: 22.761809190114338
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.89677419354838
    gpu_util_percent0: 0.3041935483870968
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35494
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15441902047366424
    mean_env_wait_ms: 1.183886114104576
    mean_inference_ms: 4.791234715439032
    mean_raw_obs_processing_ms: 0.4043928241593902
  time_since_restore: 267.2437586784363
  time_this_iter_s: 26.463383436203003
  time_total_s: 267.2437586784363
  timers:
    learn_throughput: 8309.821
    learn_time_ms: 19469.973
    sample_throughput: 22560.77
    sample_time_ms: 7171.387
    update_time_ms: 32.636
  timestamp: 1602515789
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: '43967_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43967_00000 | RUNNING  | 172.17.0.4:35494 |     10 |          267.244 | 1617920 |  232.891 |              284.202 |              148.141 |            845.928 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43967_00000:
  custom_metrics:
    time_step_max: 3980
    time_step_mean: 3519.0531809145127
    time_step_min: 3193
  date: 2020-10-12_15-16-56
  done: false
  episode_len_mean: 842.6231742940604
  episode_reward_max: 284.2020202020208
  episode_reward_mean: 233.80722512368075
  episode_reward_min: 148.1414141414143
  episodes_this_iter: 159
  episodes_total: 2054
  experiment_id: 949329b4dde9497e8a93f245d8af3c76
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9550424267848333
        entropy_coeff: 0.0005000000000000001
        kl: 0.006833299140756329
        model: {}
        policy_loss: -0.010028554146022847
        total_loss: 14.67298936843872
        vf_explained_var: 0.9665574431419373
        vf_loss: 14.682812054951986
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.79032258064516
    gpu_util_percent0: 0.2948387096774193
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7838709677419353
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35494
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15401346673906746
    mean_env_wait_ms: 1.185611096660403
    mean_inference_ms: 4.763744931836722
    mean_raw_obs_processing_ms: 0.40304496295955256
  time_since_restore: 293.52497386932373
  time_this_iter_s: 26.28121519088745
  time_total_s: 293.52497386932373
  timers:
    learn_throughput: 8317.347
    learn_time_ms: 19452.357
    sample_throughput: 23370.844
    sample_time_ms: 6922.814
    update_time_ms: 31.854
  timestamp: 1602515816
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: '43967_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43967_00000 | RUNNING  | 172.17.0.4:35494 |     11 |          293.525 | 1779712 |  233.807 |              284.202 |              148.141 |            842.623 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43967_00000:
  custom_metrics:
    time_step_max: 3980
    time_step_mean: 3512.883410138249
    time_step_min: 3193
  date: 2020-10-12_15-17-22
  done: false
  episode_len_mean: 839.2165461121157
  episode_reward_max: 284.2020202020208
  episode_reward_mean: 234.68375892742978
  episode_reward_min: 148.1414141414143
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 949329b4dde9497e8a93f245d8af3c76
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9333042154709498
        entropy_coeff: 0.0005000000000000001
        kl: 0.006979815157440801
        model: {}
        policy_loss: -0.012605925294337794
        total_loss: 12.56671412785848
        vf_explained_var: 0.9697521328926086
        vf_loss: 12.57908852895101
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.2
    gpu_util_percent0: 0.3966666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7733333333333334
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35494
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1536473292905027
    mean_env_wait_ms: 1.1872645740285774
    mean_inference_ms: 4.739011102132329
    mean_raw_obs_processing_ms: 0.40179326595292186
  time_since_restore: 319.84925150871277
  time_this_iter_s: 26.324277639389038
  time_total_s: 319.84925150871277
  timers:
    learn_throughput: 8319.664
    learn_time_ms: 19446.94
    sample_throughput: 23640.657
    sample_time_ms: 6843.803
    update_time_ms: 32.102
  timestamp: 1602515842
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: '43967_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43967_00000 | RUNNING  | 172.17.0.4:35494 |     12 |          319.849 | 1941504 |  234.684 |              284.202 |              148.141 |            839.217 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43967_00000:
  custom_metrics:
    time_step_max: 3980
    time_step_mean: 3505.884792626728
    time_step_min: 3193
  date: 2020-10-12_15-17-49
  done: false
  episode_len_mean: 834.7291066282421
  episode_reward_max: 288.1414141414142
  episode_reward_mean: 235.89819146591478
  episode_reward_min: 148.1414141414143
  episodes_this_iter: 217
  episodes_total: 2429
  experiment_id: 949329b4dde9497e8a93f245d8af3c76
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8839850127696991
        entropy_coeff: 0.0005000000000000001
        kl: 0.006719793581093351
        model: {}
        policy_loss: -0.011859170898484686
        total_loss: 17.87238534291585
        vf_explained_var: 0.9688119888305664
        vf_loss: 17.884014129638672
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.703225806451613
    gpu_util_percent0: 0.2625806451612903
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322573
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35494
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1531961444158221
    mean_env_wait_ms: 1.1896250023174904
    mean_inference_ms: 4.708905744797614
    mean_raw_obs_processing_ms: 0.40025268398364167
  time_since_restore: 346.1721875667572
  time_this_iter_s: 26.322936058044434
  time_total_s: 346.1721875667572
  timers:
    learn_throughput: 8318.29
    learn_time_ms: 19450.151
    sample_throughput: 23654.391
    sample_time_ms: 6839.829
    update_time_ms: 32.148
  timestamp: 1602515869
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: '43967_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43967_00000 | RUNNING  | 172.17.0.4:35494 |     13 |          346.172 | 2103296 |  235.898 |              288.141 |              148.141 |            834.729 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43967_00000:
  custom_metrics:
    time_step_max: 3980
    time_step_mean: 3497.321482602118
    time_step_min: 3193
  date: 2020-10-12_15-18-15
  done: false
  episode_len_mean: 830.2896500372301
  episode_reward_max: 288.1414141414142
  episode_reward_mean: 237.30001429033445
  episode_reward_min: 148.1414141414143
  episodes_this_iter: 257
  episodes_total: 2686
  experiment_id: 949329b4dde9497e8a93f245d8af3c76
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8755106230576833
        entropy_coeff: 0.0005000000000000001
        kl: 0.006404241585793595
        model: {}
        policy_loss: -0.011880003226300081
        total_loss: 13.644367694854736
        vf_explained_var: 0.973446786403656
        vf_loss: 13.656045198440552
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.259999999999998
    gpu_util_percent0: 0.29999999999999993
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35494
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1527384526000428
    mean_env_wait_ms: 1.1920292117330695
    mean_inference_ms: 4.678030583249781
    mean_raw_obs_processing_ms: 0.3987125313646171
  time_since_restore: 372.4884617328644
  time_this_iter_s: 26.316274166107178
  time_total_s: 372.4884617328644
  timers:
    learn_throughput: 8320.705
    learn_time_ms: 19444.507
    sample_throughput: 23699.602
    sample_time_ms: 6826.781
    update_time_ms: 31.638
  timestamp: 1602515895
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: '43967_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43967_00000 | RUNNING  | 172.17.0.4:35494 |     14 |          372.488 | 2265088 |    237.3 |              288.141 |              148.141 |             830.29 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43967_00000:
  custom_metrics:
    time_step_max: 3980
    time_step_mean: 3490.0749464668093
    time_step_min: 3174
  date: 2020-10-12_15-18-41
  done: false
  episode_len_mean: 827.7123769338959
  episode_reward_max: 288.1414141414142
  episode_reward_mean: 238.29095810424926
  episode_reward_min: 148.1414141414143
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 949329b4dde9497e8a93f245d8af3c76
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8695435126622518
        entropy_coeff: 0.0005000000000000001
        kl: 0.006383650974991421
        model: {}
        policy_loss: -0.01124639364813144
        total_loss: 11.072142362594604
        vf_explained_var: 0.9715961813926697
        vf_loss: 11.08318535486857
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.000000000000004
    gpu_util_percent0: 0.37225806451612903
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7741935483870965
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35494
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1524883888859107
    mean_env_wait_ms: 1.193399213665772
    mean_inference_ms: 4.661235209851582
    mean_raw_obs_processing_ms: 0.3978550832096485
  time_since_restore: 398.88048672676086
  time_this_iter_s: 26.392024993896484
  time_total_s: 398.88048672676086
  timers:
    learn_throughput: 8322.312
    learn_time_ms: 19440.753
    sample_throughput: 23752.801
    sample_time_ms: 6811.491
    update_time_ms: 29.591
  timestamp: 1602515921
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: '43967_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43967_00000 | RUNNING  | 172.17.0.4:35494 |     15 |           398.88 | 2426880 |  238.291 |              288.141 |              148.141 |            827.712 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43967_00000:
  custom_metrics:
    time_step_max: 3980
    time_step_mean: 3484.8203572632287
    time_step_min: 3141
  date: 2020-10-12_15-19-08
  done: false
  episode_len_mean: 825.2964440013293
  episode_reward_max: 290.7171717171717
  episode_reward_mean: 239.07910611599544
  episode_reward_min: 148.1414141414143
  episodes_this_iter: 165
  episodes_total: 3009
  experiment_id: 949329b4dde9497e8a93f245d8af3c76
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8375518967707952
        entropy_coeff: 0.0005000000000000001
        kl: 0.007002773229032755
        model: {}
        policy_loss: -0.009874908602796495
        total_loss: 12.741058508555094
        vf_explained_var: 0.9726340174674988
        vf_loss: 12.750651995340982
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.17741935483871
    gpu_util_percent0: 0.24451612903225808
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7774193548387096
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35494
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15224939303670906
    mean_env_wait_ms: 1.1948451778737224
    mean_inference_ms: 4.64507567314594
    mean_raw_obs_processing_ms: 0.39702710384775763
  time_since_restore: 425.3490617275238
  time_this_iter_s: 26.46857500076294
  time_total_s: 425.3490617275238
  timers:
    learn_throughput: 8321.64
    learn_time_ms: 19442.321
    sample_throughput: 23783.703
    sample_time_ms: 6802.641
    update_time_ms: 27.805
  timestamp: 1602515948
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: '43967_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43967_00000 | RUNNING  | 172.17.0.4:35494 |     16 |          425.349 | 2588672 |  239.079 |              290.717 |              148.141 |            825.296 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43967_00000:
  custom_metrics:
    time_step_max: 3980
    time_step_mean: 3474.40231990232
    time_step_min: 3141
  date: 2020-10-12_15-19-34
  done: false
  episode_len_mean: 820.6868595539481
  episode_reward_max: 290.7171717171717
  episode_reward_mean: 240.6259795057263
  episode_reward_min: 148.1414141414143
  episodes_this_iter: 309
  episodes_total: 3318
  experiment_id: 949329b4dde9497e8a93f245d8af3c76
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8005305876334509
        entropy_coeff: 0.0005000000000000001
        kl: 0.005828887418222924
        model: {}
        policy_loss: -0.010037912928964943
        total_loss: 13.088919321695963
        vf_explained_var: 0.9782760739326477
        vf_loss: 13.098775068918863
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.090000000000007
    gpu_util_percent0: 0.388
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.773333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35494
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1518451116374494
    mean_env_wait_ms: 1.1973659775645324
    mean_inference_ms: 4.618083932001328
    mean_raw_obs_processing_ms: 0.3956393068581374
  time_since_restore: 451.57380175590515
  time_this_iter_s: 26.224740028381348
  time_total_s: 451.57380175590515
  timers:
    learn_throughput: 8320.785
    learn_time_ms: 19444.32
    sample_throughput: 23791.215
    sample_time_ms: 6800.493
    update_time_ms: 28.092
  timestamp: 1602515974
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: '43967_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43967_00000 | RUNNING  | 172.17.0.4:35494 |     17 |          451.574 | 2750464 |  240.626 |              290.717 |              148.141 |            820.687 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43967_00000:
  custom_metrics:
    time_step_max: 3980
    time_step_mean: 3469.9321490972625
    time_step_min: 3141
  date: 2020-10-12_15-20-01
  done: false
  episode_len_mean: 818.5382623705409
  episode_reward_max: 290.7171717171717
  episode_reward_mean: 241.24904394927412
  episode_reward_min: 148.1414141414143
  episodes_this_iter: 158
  episodes_total: 3476
  experiment_id: 949329b4dde9497e8a93f245d8af3c76
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8076162983973821
        entropy_coeff: 0.0005000000000000001
        kl: 0.005866569311668475
        model: {}
        policy_loss: -0.010886732585883388
        total_loss: 10.134718100229898
        vf_explained_var: 0.9754086136817932
        vf_loss: 10.145421981811523
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.080645161290327
    gpu_util_percent0: 0.34419354838709676
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774193548387097
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35494
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15166088531925812
    mean_env_wait_ms: 1.1985373007182534
    mean_inference_ms: 4.605814483310541
    mean_raw_obs_processing_ms: 0.3950044343818205
  time_since_restore: 477.68138813972473
  time_this_iter_s: 26.10758638381958
  time_total_s: 477.68138813972473
  timers:
    learn_throughput: 8329.201
    learn_time_ms: 19424.671
    sample_throughput: 23798.73
    sample_time_ms: 6798.346
    update_time_ms: 26.449
  timestamp: 1602516001
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: '43967_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43967_00000 | RUNNING  | 172.17.0.4:35494 |     18 |          477.681 | 2912256 |  241.249 |              290.717 |              148.141 |            818.538 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43967_00000:
  custom_metrics:
    time_step_max: 3980
    time_step_mean: 3465.5599443671767
    time_step_min: 3141
  date: 2020-10-12_15-20-27
  done: false
  episode_len_mean: 816.4492713775089
  episode_reward_max: 290.7171717171717
  episode_reward_mean: 241.9722437462333
  episode_reward_min: 148.1414141414143
  episodes_this_iter: 161
  episodes_total: 3637
  experiment_id: 949329b4dde9497e8a93f245d8af3c76
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7810584157705307
        entropy_coeff: 0.0005000000000000001
        kl: 0.005782775154026846
        model: {}
        policy_loss: -0.010712247264261046
        total_loss: 10.520259141921997
        vf_explained_var: 0.9756563305854797
        vf_loss: 10.530783812204996
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.176666666666666
    gpu_util_percent0: 0.30233333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7733333333333325
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35494
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15148720222350695
    mean_env_wait_ms: 1.1997484781595151
    mean_inference_ms: 4.594128330896139
    mean_raw_obs_processing_ms: 0.3943955582610793
  time_since_restore: 504.0242455005646
  time_this_iter_s: 26.342857360839844
  time_total_s: 504.0242455005646
  timers:
    learn_throughput: 8321.128
    learn_time_ms: 19443.518
    sample_throughput: 23804.966
    sample_time_ms: 6796.565
    update_time_ms: 26.009
  timestamp: 1602516027
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: '43967_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43967_00000 | RUNNING  | 172.17.0.4:35494 |     19 |          504.024 | 3074048 |  241.972 |              290.717 |              148.141 |            816.449 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43967_00000:
  custom_metrics:
    time_step_max: 3980
    time_step_mean: 3457.474923234391
    time_step_min: 3141
  date: 2020-10-12_15-20-53
  done: false
  episode_len_mean: 812.6521518987341
  episode_reward_max: 290.7171717171717
  episode_reward_mean: 243.1544175936581
  episode_reward_min: 148.1414141414143
  episodes_this_iter: 313
  episodes_total: 3950
  experiment_id: 949329b4dde9497e8a93f245d8af3c76
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7413140634695689
        entropy_coeff: 0.0005000000000000001
        kl: 0.005068241152912378
        model: {}
        policy_loss: -0.011031584620165328
        total_loss: 13.177871386210123
        vf_explained_var: 0.9785845279693604
        vf_loss: 13.188766797383627
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.241935483870968
    gpu_util_percent0: 0.2790322580645161
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35494
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15117461524036999
    mean_env_wait_ms: 1.2019664929172704
    mean_inference_ms: 4.573495836962765
    mean_raw_obs_processing_ms: 0.3933185955402415
  time_since_restore: 530.1690263748169
  time_this_iter_s: 26.14478087425232
  time_total_s: 530.1690263748169
  timers:
    learn_throughput: 8326.846
    learn_time_ms: 19430.166
    sample_throughput: 23878.506
    sample_time_ms: 6775.633
    update_time_ms: 27.821
  timestamp: 1602516053
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: '43967_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43967_00000 | RUNNING  | 172.17.0.4:35494 |     20 |          530.169 | 3235840 |  243.154 |              290.717 |              148.141 |            812.652 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43967_00000:
  custom_metrics:
    time_step_max: 3980
    time_step_mean: 3453.5418101328087
    time_step_min: 3099
  date: 2020-10-12_15-21-20
  done: false
  episode_len_mean: 811.0791139240506
  episode_reward_max: 297.08080808080797
  episode_reward_mean: 243.73076677190602
  episode_reward_min: 148.1414141414143
  episodes_this_iter: 158
  episodes_total: 4108
  experiment_id: 949329b4dde9497e8a93f245d8af3c76
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7540231595436732
        entropy_coeff: 0.0005000000000000001
        kl: 0.006251458660699427
        model: {}
        policy_loss: -0.010166963950420419
        total_loss: 9.666405280431112
        vf_explained_var: 0.9757277369499207
        vf_loss: 9.676324129104614
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.663333333333334
    gpu_util_percent0: 0.2963333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7799999999999994
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35494
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15103219092684
    mean_env_wait_ms: 1.2029809790731962
    mean_inference_ms: 4.56408960121424
    mean_raw_obs_processing_ms: 0.3928232250873983
  time_since_restore: 556.4016888141632
  time_this_iter_s: 26.232662439346313
  time_total_s: 556.4016888141632
  timers:
    learn_throughput: 8330.526
    learn_time_ms: 19421.582
    sample_throughput: 23872.634
    sample_time_ms: 6777.3
    update_time_ms: 28.613
  timestamp: 1602516080
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: '43967_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43967_00000 | RUNNING  | 172.17.0.4:35494 |     21 |          556.402 | 3397632 |  243.731 |              297.081 |              148.141 |            811.079 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43967_00000:
  custom_metrics:
    time_step_max: 3980
    time_step_mean: 3449.165326395459
    time_step_min: 3099
  date: 2020-10-12_15-21-46
  done: false
  episode_len_mean: 809.4182669789227
  episode_reward_max: 297.08080808080797
  episode_reward_mean: 244.39348993447354
  episode_reward_min: 148.1414141414143
  episodes_this_iter: 162
  episodes_total: 4270
  experiment_id: 949329b4dde9497e8a93f245d8af3c76
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7344886114199957
        entropy_coeff: 0.0005000000000000001
        kl: 0.00542777714629968
        model: {}
        policy_loss: -0.010750282885661969
        total_loss: 10.668164094289144
        vf_explained_var: 0.9743292331695557
        vf_loss: 10.678739309310913
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.838709677419363
    gpu_util_percent0: 0.2880645161290322
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35494
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15089532428676156
    mean_env_wait_ms: 1.2040201776630346
    mean_inference_ms: 4.555007782772498
    mean_raw_obs_processing_ms: 0.39234438372809793
  time_since_restore: 582.7169961929321
  time_this_iter_s: 26.31530737876892
  time_total_s: 582.7169961929321
  timers:
    learn_throughput: 8337.86
    learn_time_ms: 19404.5
    sample_throughput: 23819.55
    sample_time_ms: 6792.404
    update_time_ms: 28.521
  timestamp: 1602516106
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: '43967_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43967_00000 | RUNNING  | 172.17.0.4:35494 |     22 |          582.717 | 3559424 |  244.393 |              297.081 |              148.141 |            809.418 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43967_00000:
  custom_metrics:
    time_step_max: 3980
    time_step_mean: 3441.851321585903
    time_step_min: 3099
  date: 2020-10-12_15-22-12
  done: true
  episode_len_mean: 806.577258838935
  episode_reward_max: 297.08080808080797
  episode_reward_mean: 245.50656499521628
  episode_reward_min: 148.1414141414143
  episodes_this_iter: 312
  episodes_total: 4582
  experiment_id: 949329b4dde9497e8a93f245d8af3c76
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.6938638339440028
        entropy_coeff: 0.0005000000000000001
        kl: 0.005188658911113937
        model: {}
        policy_loss: -0.00690779621557643
        total_loss: 12.988922595977783
        vf_explained_var: 0.9786821007728577
        vf_loss: 12.995658238728842
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.51
    gpu_util_percent0: 0.2343333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769999999999999
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35494
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15064710291102656
    mean_env_wait_ms: 1.205915038770701
    mean_inference_ms: 4.538889996376111
    mean_raw_obs_processing_ms: 0.39148964505541745
  time_since_restore: 608.764997959137
  time_this_iter_s: 26.048001766204834
  time_total_s: 608.764997959137
  timers:
    learn_throughput: 8349.497
    learn_time_ms: 19377.455
    sample_throughput: 23824.534
    sample_time_ms: 6790.983
    update_time_ms: 28.061
  timestamp: 1602516132
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: '43967_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43967_00000 | TERMINATED |       |     23 |          608.765 | 3721216 |  245.507 |              297.081 |              148.141 |            806.577 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43967_00000 | TERMINATED |       |     23 |          608.765 | 3721216 |  245.507 |              297.081 |              148.141 |            806.577 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


