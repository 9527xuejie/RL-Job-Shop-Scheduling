2020-10-11 11:33:38,953	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_9c2e6_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=478)[0m 2020-10-11 11:33:41,717	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=447)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=447)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=381)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=381)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=380)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=380)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=377)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=377)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=440)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=440)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=463)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=463)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=451)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=451)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=392)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=392)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=481)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=481)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=453)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=453)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=499)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=499)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=477)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=477)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=455)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=455)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=470)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=470)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=413)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=413)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=480)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=480)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=496)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=496)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=458)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=458)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=484)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=484)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=471)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=471)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=449)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=449)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=382)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=382)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=387)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=387)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=485)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=485)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=410)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=410)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=483)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=483)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=438)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=438)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=389)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=389)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=391)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=391)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=385)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=385)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=482)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=482)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=373)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=373)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=513)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=513)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=487)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=487)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=376)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=376)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=414)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=414)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=434)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=434)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=408)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=408)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=435)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=435)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=461)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=461)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=454)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=454)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=386)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=386)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=452)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=452)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=388)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=388)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=473)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=473)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=379)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=379)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=400)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=400)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=378)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=378)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=397)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=397)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=457)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=457)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=395)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=395)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=502)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=502)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=444)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=444)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=394)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=394)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=448)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=448)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=393)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=393)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=439)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=439)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=450)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=450)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=472)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=472)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=486)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=486)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=492)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=492)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=456)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=456)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=445)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=445)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=459)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=459)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=375)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=375)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=462)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=462)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=372)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=372)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=433)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=433)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=443)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=443)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=441)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=441)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=446)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=446)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=467)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=467)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=507)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=507)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=490)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=490)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=405)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=405)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=404)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=404)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=384)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=384)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=374)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=374)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=498)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=498)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_9c2e6_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.267942583732
    time_step_min: 3363
  date: 2020-10-11_11-34-25
  done: false
  episode_len_mean: 889.379746835443
  episode_reward_max: 261.32323232323233
  episode_reward_mean: 217.15624600434705
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 237
  episodes_total: 237
  experiment_id: df1157d3fdda43dcb890a3196b2b9b86
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.1508206791347928
        entropy_coeff: 0.0001
        kl: 0.011506594562282165
        model: {}
        policy_loss: -0.024802520728877023
        total_loss: -0.02261628385167569
        vf_explained_var: 0.004114177543669939
        vf_loss: 0.0
    num_steps_sampled: 210783
    num_steps_trained: 210783
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.611111111111114
    gpu_util_percent0: 0.22022222222222218
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.57111111111111
    vram_util_percent0: 0.0693761160307569
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 478
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1636744937338249
    mean_env_wait_ms: 1.174430520550134
    mean_inference_ms: 5.3161623781693
    mean_raw_obs_processing_ms: 0.4152495414106662
  time_since_restore: 37.93847155570984
  time_this_iter_s: 37.93847155570984
  time_total_s: 37.93847155570984
  timers:
    learn_throughput: 8808.281
    learn_time_ms: 23930.096
    sample_throughput: 15134.176
    sample_time_ms: 13927.616
    update_time_ms: 46.272
  timestamp: 1602416065
  timesteps_since_restore: 0
  timesteps_total: 210783
  training_iteration: 1
  trial_id: 9c2e6_00000
  
== Status ==
Memory usage on this node: 27.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |      1 |          37.9385 | 210783 |  217.156 |              261.323 |              145.717 |             889.38 |
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c2e6_00000:
  custom_metrics:
    time_step_max: 4177
    time_step_mean: 3620.4843049327355
    time_step_min: 3285
  date: 2020-10-11_11-34-56
  done: false
  episode_len_mean: 894.6962025316456
  episode_reward_max: 268.29292929292905
  episode_reward_mean: 215.82137834036547
  episode_reward_min: 133.14141414141423
  episodes_this_iter: 237
  episodes_total: 474
  experiment_id: df1157d3fdda43dcb890a3196b2b9b86
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.1413822571436565
        entropy_coeff: 0.0001
        kl: 0.012332628015428782
        model: {}
        policy_loss: -0.02454338926408026
        total_loss: -0.0221910018266903
        vf_explained_var: 0.004096451681107283
        vf_loss: 0.0
    num_steps_sampled: 424086
    num_steps_trained: 424086
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.864864864864867
    gpu_util_percent0: 0.2378378378378378
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.851351351351352
    vram_util_percent0: 0.08374256512990523
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 478
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16101945000676418
    mean_env_wait_ms: 1.169159001890284
    mean_inference_ms: 5.163287186706875
    mean_raw_obs_processing_ms: 0.41340410230382457
  time_since_restore: 69.00788903236389
  time_this_iter_s: 31.069417476654053
  time_total_s: 69.00788903236389
  timers:
    learn_throughput: 8801.604
    learn_time_ms: 24091.404
    sample_throughput: 20553.76
    sample_time_ms: 10316.507
    update_time_ms: 44.454
  timestamp: 1602416096
  timesteps_since_restore: 0
  timesteps_total: 424086
  training_iteration: 2
  trial_id: 9c2e6_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |      2 |          69.0079 | 424086 |  215.821 |              268.293 |              133.141 |            894.696 |
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c2e6_00000:
  custom_metrics:
    time_step_max: 4177
    time_step_mean: 3628.0805270863834
    time_step_min: 3281
  date: 2020-10-11_11-35-32
  done: false
  episode_len_mean: 897.2475386779184
  episode_reward_max: 268.89898989898984
  episode_reward_mean: 215.26092145079465
  episode_reward_min: 133.14141414141423
  episodes_this_iter: 237
  episodes_total: 711
  experiment_id: df1157d3fdda43dcb890a3196b2b9b86
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.1282787322998047
        entropy_coeff: 0.0001
        kl: 0.011565119959414005
        model: {}
        policy_loss: -0.02850140682939026
        total_loss: -0.026301210487468377
        vf_explained_var: 0.004243327304720879
        vf_loss: 0.0
    num_steps_sampled: 637943
    num_steps_trained: 637943
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.75
    gpu_util_percent0: 0.35547619047619045
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.869047619047619
    vram_util_percent0: 0.0846999016070843
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 478
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15856108821083387
    mean_env_wait_ms: 1.163652462203573
    mean_inference_ms: 5.0243813341893615
    mean_raw_obs_processing_ms: 0.4064302444759944
  time_since_restore: 105.58087587356567
  time_this_iter_s: 36.57298684120178
  time_total_s: 105.58087587356567
  timers:
    learn_throughput: 8776.554
    learn_time_ms: 24229.062
    sample_throughput: 19555.7
    sample_time_ms: 10873.948
    update_time_ms: 36.401
  timestamp: 1602416132
  timesteps_since_restore: 0
  timesteps_total: 637943
  training_iteration: 3
  trial_id: 9c2e6_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |      3 |          105.581 | 637943 |  215.261 |              268.899 |              133.141 |            897.248 |
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c2e6_00000:
  custom_metrics:
    time_step_max: 4177
    time_step_mean: 3626.8021739130436
    time_step_min: 3281
  date: 2020-10-11_11-36-04
  done: false
  episode_len_mean: 898.785864978903
  episode_reward_max: 268.89898989898984
  episode_reward_mean: 215.9509973149211
  episode_reward_min: 133.14141414141423
  episodes_this_iter: 237
  episodes_total: 948
  experiment_id: df1157d3fdda43dcb890a3196b2b9b86
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.1202221711476643
        entropy_coeff: 0.0001
        kl: 0.012885241769254208
        model: {}
        policy_loss: -0.028739885789238744
        total_loss: -0.026274858611739345
        vf_explained_var: 0.004139645025134087
        vf_loss: 0.0
    num_steps_sampled: 852049
    num_steps_trained: 852049
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.299999999999997
    gpu_util_percent0: 0.4605263157894737
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8789473684210534
    vram_util_percent0: 0.08469990160708428
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 478
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15698071319986298
    mean_env_wait_ms: 1.1601976301052868
    mean_inference_ms: 4.9340688951794105
    mean_raw_obs_processing_ms: 0.40318035135376784
  time_since_restore: 137.01121926307678
  time_this_iter_s: 31.43034338951111
  time_total_s: 137.01121926307678
  timers:
    learn_throughput: 8757.236
    learn_time_ms: 24324.143
    sample_throughput: 21655.065
    sample_time_ms: 9836.602
    update_time_ms: 36.012
  timestamp: 1602416164
  timesteps_since_restore: 0
  timesteps_total: 852049
  training_iteration: 4
  trial_id: 9c2e6_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |      4 |          137.011 | 852049 |  215.951 |              268.899 |              133.141 |            898.786 |
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c2e6_00000:
  custom_metrics:
    time_step_max: 4177
    time_step_mean: 3627.2143474503023
    time_step_min: 3281
  date: 2020-10-11_11-36-40
  done: false
  episode_len_mean: 897.9054852320675
  episode_reward_max: 269.05050505050474
  episode_reward_mean: 216.19639432297637
  episode_reward_min: 133.14141414141423
  episodes_this_iter: 237
  episodes_total: 1185
  experiment_id: df1157d3fdda43dcb890a3196b2b9b86
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.1091025140550401
        entropy_coeff: 0.0001
        kl: 0.011930530218200551
        model: {}
        policy_loss: -0.03239480613006486
        total_loss: -0.030119610174248617
        vf_explained_var: 0.004592326004058123
        vf_loss: 0.0
    num_steps_sampled: 1064018
    num_steps_trained: 1064018
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.214285714285708
    gpu_util_percent0: 0.20214285714285715
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.885714285714286
    vram_util_percent0: 0.0846999016070843
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 478
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1557465530250387
    mean_env_wait_ms: 1.1574808450465757
    mean_inference_ms: 4.862228219797691
    mean_raw_obs_processing_ms: 0.39960825263491473
  time_since_restore: 173.09106850624084
  time_this_iter_s: 36.07984924316406
  time_total_s: 173.09106850624084
  timers:
    learn_throughput: 8741.753
    learn_time_ms: 24343.355
    sample_throughput: 20897.294
    sample_time_ms: 10183.309
    update_time_ms: 33.526
  timestamp: 1602416200
  timesteps_since_restore: 0
  timesteps_total: 1064018
  training_iteration: 5
  trial_id: 9c2e6_00000
  
== Status ==
Memory usage on this node: 28.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |      5 |          173.091 | 1064018 |  216.196 |              269.051 |              133.141 |            897.905 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c2e6_00000:
  custom_metrics:
    time_step_max: 4278
    time_step_mean: 3625.2769010043044
    time_step_min: 3281
  date: 2020-10-11_11-37-11
  done: false
  episode_len_mean: 896.626582278481
  episode_reward_max: 269.05050505050474
  episode_reward_mean: 216.61624685675295
  episode_reward_min: 117.83838383838362
  episodes_this_iter: 237
  episodes_total: 1422
  experiment_id: df1157d3fdda43dcb890a3196b2b9b86
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.1058683726522658
        entropy_coeff: 0.0001
        kl: 0.013779823668301105
        model: {}
        policy_loss: -0.03383349896305137
        total_loss: -0.031188121686379116
        vf_explained_var: 0.004375427961349487
        vf_loss: 0.0
    num_steps_sampled: 1275003
    num_steps_trained: 1275003
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.83888888888889
    gpu_util_percent0: 0.32833333333333337
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8916666666666675
    vram_util_percent0: 0.08469990160708428
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 478
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15480226438213127
    mean_env_wait_ms: 1.1556744661925493
    mean_inference_ms: 4.808124976113362
    mean_raw_obs_processing_ms: 0.3973575039580816
  time_since_restore: 203.9486174583435
  time_this_iter_s: 30.85754895210266
  time_total_s: 203.9486174583435
  timers:
    learn_throughput: 8743.977
    learn_time_ms: 24302.5
    sample_throughput: 22152.544
    sample_time_ms: 9592.6
    update_time_ms: 34.755
  timestamp: 1602416231
  timesteps_since_restore: 0
  timesteps_total: 1275003
  training_iteration: 6
  trial_id: 9c2e6_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |      6 |          203.949 | 1275003 |  216.616 |              269.051 |              117.838 |            896.627 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c2e6_00000:
  custom_metrics:
    time_step_max: 4278
    time_step_mean: 3622.4530962599633
    time_step_min: 3281
  date: 2020-10-11_11-37-47
  done: false
  episode_len_mean: 894.9029535864979
  episode_reward_max: 269.05050505050474
  episode_reward_mean: 217.01651232030957
  episode_reward_min: 117.83838383838362
  episodes_this_iter: 237
  episodes_total: 1659
  experiment_id: df1157d3fdda43dcb890a3196b2b9b86
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.0927574502097235
        entropy_coeff: 0.0001
        kl: 0.012546442604313294
        model: {}
        policy_loss: -0.035685616752339736
        total_loss: -0.033285604065491095
        vf_explained_var: 0.0044588083401322365
        vf_loss: 0.0
    num_steps_sampled: 1484644
    num_steps_trained: 1484644
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.633333333333333
    gpu_util_percent0: 0.28500000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.876190476190477
    vram_util_percent0: 0.0846999016070843
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 478
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1540133323616834
    mean_env_wait_ms: 1.1544321575145495
    mean_inference_ms: 4.763016603687438
    mean_raw_obs_processing_ms: 0.39503044627312545
  time_since_restore: 239.55271339416504
  time_this_iter_s: 35.60409593582153
  time_total_s: 239.55271339416504
  timers:
    learn_throughput: 8740.909
    learn_time_ms: 24264.294
    sample_throughput: 21534.624
    sample_time_ms: 9848.884
    update_time_ms: 35.412
  timestamp: 1602416267
  timesteps_since_restore: 0
  timesteps_total: 1484644
  training_iteration: 7
  trial_id: 9c2e6_00000
  
== Status ==
Memory usage on this node: 28.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |      7 |          239.553 | 1484644 |  217.017 |              269.051 |              117.838 |            894.903 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c2e6_00000:
  custom_metrics:
    time_step_max: 4278
    time_step_mean: 3621.7789079229124
    time_step_min: 3245
  date: 2020-10-11_11-38-17
  done: false
  episode_len_mean: 892.9240506329114
  episode_reward_max: 274.3535353535355
  episode_reward_mean: 217.11181434599132
  episode_reward_min: 117.83838383838362
  episodes_this_iter: 237
  episodes_total: 1896
  experiment_id: df1157d3fdda43dcb890a3196b2b9b86
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.0877870519955952
        entropy_coeff: 0.0001
        kl: 0.014053100616567664
        model: {}
        policy_loss: -0.036782152795543276
        total_loss: -0.03408031062119537
        vf_explained_var: 0.004147387109696865
        vf_loss: 0.0
    num_steps_sampled: 1692984
    num_steps_trained: 1692984
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.683333333333334
    gpu_util_percent0: 0.30944444444444447
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8916666666666675
    vram_util_percent0: 0.08469990160708428
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 478
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15337511452129216
    mean_env_wait_ms: 1.1536417821691023
    mean_inference_ms: 4.726508534969858
    mean_raw_obs_processing_ms: 0.39338917198844775
  time_since_restore: 270.2423267364502
  time_this_iter_s: 30.689613342285156
  time_total_s: 270.2423267364502
  timers:
    learn_throughput: 8734.946
    learn_time_ms: 24227.168
    sample_throughput: 22406.357
    sample_time_ms: 9444.775
    update_time_ms: 36.407
  timestamp: 1602416297
  timesteps_since_restore: 0
  timesteps_total: 1692984
  training_iteration: 8
  trial_id: 9c2e6_00000
  
== Status ==
Memory usage on this node: 28.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |      8 |          270.242 | 1692984 |  217.112 |              274.354 |              117.838 |            892.924 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c2e6_00000:
  custom_metrics:
    time_step_max: 4278
    time_step_mean: 3619.964370546318
    time_step_min: 3245
  date: 2020-10-11_11-38-53
  done: false
  episode_len_mean: 892.0590717299579
  episode_reward_max: 276.02020202020157
  episode_reward_mean: 217.23367287502285
  episode_reward_min: 117.83838383838362
  episodes_this_iter: 237
  episodes_total: 2133
  experiment_id: df1157d3fdda43dcb890a3196b2b9b86
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.0724814070595636
        entropy_coeff: 0.0001
        kl: 0.012386405995736519
        model: {}
        policy_loss: -0.03819261729303333
        total_loss: -0.03582258429378271
        vf_explained_var: 0.0043792459182441235
        vf_loss: 0.0
    num_steps_sampled: 1902762
    num_steps_trained: 1902762
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.034146341463412
    gpu_util_percent0: 0.23902439024390246
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.880487804878049
    vram_util_percent0: 0.0846999016070843
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 478
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1528267206439357
    mean_env_wait_ms: 1.153000049259824
    mean_inference_ms: 4.695004094684524
    mean_raw_obs_processing_ms: 0.39174524064795563
  time_since_restore: 305.92427682876587
  time_this_iter_s: 35.681950092315674
  time_total_s: 305.92427682876587
  timers:
    learn_throughput: 8726.411
    learn_time_ms: 24227.372
    sample_throughput: 21896.229
    sample_time_ms: 9655.452
    update_time_ms: 37.204
  timestamp: 1602416333
  timesteps_since_restore: 0
  timesteps_total: 1902762
  training_iteration: 9
  trial_id: 9c2e6_00000
  
== Status ==
Memory usage on this node: 28.9/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |      9 |          305.924 | 1902762 |  217.234 |               276.02 |              117.838 |            892.059 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c2e6_00000:
  custom_metrics:
    time_step_max: 4278
    time_step_mean: 3621.0990606319383
    time_step_min: 3245
  date: 2020-10-11_11-39-24
  done: false
  episode_len_mean: 891.0700421940928
  episode_reward_max: 276.02020202020157
  episode_reward_mean: 217.2751566295868
  episode_reward_min: 117.83838383838362
  episodes_this_iter: 237
  episodes_total: 2370
  experiment_id: df1157d3fdda43dcb890a3196b2b9b86
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.0645562211672466
        entropy_coeff: 0.0001
        kl: 0.013964535668492317
        model: {}
        policy_loss: -0.03785448128150569
        total_loss: -0.03516803009228574
        vf_explained_var: 0.004580974578857422
        vf_loss: 0.0
    num_steps_sampled: 2111836
    num_steps_trained: 2111836
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.80833333333333
    gpu_util_percent0: 0.3402777777777778
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8888888888888897
    vram_util_percent0: 0.08469990160708428
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 478
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15236541509539533
    mean_env_wait_ms: 1.1525677384010393
    mean_inference_ms: 4.668415033559
    mean_raw_obs_processing_ms: 0.39051778190252684
  time_since_restore: 336.3577198982239
  time_this_iter_s: 30.433443069458008
  time_total_s: 336.3577198982239
  timers:
    learn_throughput: 8737.509
    learn_time_ms: 24169.773
    sample_throughput: 22569.624
    sample_time_ms: 9356.984
    update_time_ms: 37.424
  timestamp: 1602416364
  timesteps_since_restore: 0
  timesteps_total: 2111836
  training_iteration: 10
  trial_id: 9c2e6_00000
  
== Status ==
Memory usage on this node: 28.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |     10 |          336.358 | 2111836 |  217.275 |               276.02 |              117.838 |             891.07 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c2e6_00000:
  custom_metrics:
    time_step_max: 4278
    time_step_mean: 3620.0957735556417
    time_step_min: 3245
  date: 2020-10-11_11-39-59
  done: false
  episode_len_mean: 889.4353663214423
  episode_reward_max: 276.02020202020157
  episode_reward_mean: 217.5044344480476
  episode_reward_min: 117.83838383838362
  episodes_this_iter: 237
  episodes_total: 2607
  experiment_id: df1157d3fdda43dcb890a3196b2b9b86
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.0534564057985942
        entropy_coeff: 0.0001
        kl: 0.012721320200297568
        model: {}
        policy_loss: -0.041706488778193794
        total_loss: -0.03926757205691603
        vf_explained_var: 0.0045647090300917625
        vf_loss: 0.0
    num_steps_sampled: 2318758
    num_steps_trained: 2318758
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.419512195121946
    gpu_util_percent0: 0.2424390243902439
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8756097560975613
    vram_util_percent0: 0.0846999016070843
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 478
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1519518673022639
    mean_env_wait_ms: 1.152256679175318
    mean_inference_ms: 4.645006252307939
    mean_raw_obs_processing_ms: 0.38928804389411903
  time_since_restore: 371.5491871833801
  time_this_iter_s: 35.19146728515625
  time_total_s: 371.5491871833801
  timers:
    learn_throughput: 8728.437
    learn_time_ms: 24150.659
    sample_throughput: 23167.734
    sample_time_ms: 9098.753
    update_time_ms: 37.269
  timestamp: 1602416399
  timesteps_since_restore: 0
  timesteps_total: 2318758
  training_iteration: 11
  trial_id: 9c2e6_00000
  
== Status ==
Memory usage on this node: 28.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |     11 |          371.549 | 2318758 |  217.504 |               276.02 |              117.838 |            889.435 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c2e6_00000:
  custom_metrics:
    time_step_max: 4278
    time_step_mean: 3619.186434659091
    time_step_min: 3245
  date: 2020-10-11_11-40-30
  done: false
  episode_len_mean: 887.9982419127989
  episode_reward_max: 276.02020202020157
  episode_reward_mean: 217.57792055576846
  episode_reward_min: 117.83838383838362
  episodes_this_iter: 237
  episodes_total: 2844
  experiment_id: df1157d3fdda43dcb890a3196b2b9b86
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.0404738320244684
        entropy_coeff: 0.0001
        kl: 0.014134101724872986
        model: {}
        policy_loss: -0.03792600789003902
        total_loss: -0.03520323522388935
        vf_explained_var: 0.0047518182545900345
        vf_loss: 0.0
    num_steps_sampled: 2525467
    num_steps_trained: 2525467
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.44054054054054
    gpu_util_percent0: 0.31675675675675674
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.88918918918919
    vram_util_percent0: 0.08469990160708428
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 478
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1515918898863825
    mean_env_wait_ms: 1.152054790422858
    mean_inference_ms: 4.624642872725377
    mean_raw_obs_processing_ms: 0.38831806674843455
  time_since_restore: 402.2105643749237
  time_this_iter_s: 30.66137719154358
  time_total_s: 402.2105643749237
  timers:
    learn_throughput: 8716.718
    learn_time_ms: 24107.479
    sample_throughput: 23087.081
    sample_time_ms: 9101.978
    update_time_ms: 36.772
  timestamp: 1602416430
  timesteps_since_restore: 0
  timesteps_total: 2525467
  training_iteration: 12
  trial_id: 9c2e6_00000
  
== Status ==
Memory usage on this node: 28.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |     12 |          402.211 | 2525467 |  217.578 |               276.02 |              117.838 |            887.998 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c2e6_00000:
  custom_metrics:
    time_step_max: 4278
    time_step_mean: 3617.957746478873
    time_step_min: 3240
  date: 2020-10-11_11-41-04
  done: false
  episode_len_mean: 886.2528399870172
  episode_reward_max: 276.02020202020157
  episode_reward_mean: 217.87575855930265
  episode_reward_min: 117.83838383838362
  episodes_this_iter: 237
  episodes_total: 3081
  experiment_id: df1157d3fdda43dcb890a3196b2b9b86
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.0285753292195938
        entropy_coeff: 0.0001
        kl: 0.011995552655528574
        model: {}
        policy_loss: -0.03939158841967583
        total_loss: -0.03709533503826927
        vf_explained_var: 0.004629951901733875
        vf_loss: 0.0
    num_steps_sampled: 2730545
    num_steps_trained: 2730545
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.517499999999995
    gpu_util_percent0: 0.15775
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8875
    vram_util_percent0: 0.0846999016070843
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 478
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15126712051208008
    mean_env_wait_ms: 1.1519746175500274
    mean_inference_ms: 4.606332420711713
    mean_raw_obs_processing_ms: 0.3873457283671401
  time_since_restore: 436.7092037200928
  time_this_iter_s: 34.49863934516907
  time_total_s: 436.7092037200928
  timers:
    learn_throughput: 8713.26
    learn_time_ms: 24016.292
    sample_throughput: 23298.0
    sample_time_ms: 8981.896
    update_time_ms: 39.203
  timestamp: 1602416464
  timesteps_since_restore: 0
  timesteps_total: 2730545
  training_iteration: 13
  trial_id: 9c2e6_00000
  
== Status ==
Memory usage on this node: 28.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |     13 |          436.709 | 2730545 |  217.876 |               276.02 |              117.838 |            886.253 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c2e6_00000:
  custom_metrics:
    time_step_max: 4278
    time_step_mean: 3615.473556231003
    time_step_min: 3240
  date: 2020-10-11_11-41-34
  done: false
  episode_len_mean: 884.6006630500301
  episode_reward_max: 276.02020202020157
  episode_reward_mean: 218.18630244579595
  episode_reward_min: 117.83838383838362
  episodes_this_iter: 237
  episodes_total: 3318
  experiment_id: df1157d3fdda43dcb890a3196b2b9b86
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.0195737656425028
        entropy_coeff: 0.0001
        kl: 0.014620853204499273
        model: {}
        policy_loss: -0.040181194815565556
        total_loss: -0.03735898172154146
        vf_explained_var: 0.0048517691902816296
        vf_loss: 0.0
    num_steps_sampled: 2935105
    num_steps_trained: 2935105
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.248571428571434
    gpu_util_percent0: 0.2117142857142857
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8885714285714292
    vram_util_percent0: 0.08469990160708428
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 478
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15097851241621377
    mean_env_wait_ms: 1.151986226839648
    mean_inference_ms: 4.59004149259784
    mean_raw_obs_processing_ms: 0.38655923185663227
  time_since_restore: 466.56523871421814
  time_this_iter_s: 29.856034994125366
  time_total_s: 466.56523871421814
  timers:
    learn_throughput: 8727.576
    learn_time_ms: 23867.521
    sample_throughput: 23216.942
    sample_time_ms: 8972.138
    update_time_ms: 39.799
  timestamp: 1602416494
  timesteps_since_restore: 0
  timesteps_total: 2935105
  training_iteration: 14
  trial_id: 9c2e6_00000
  
== Status ==
Memory usage on this node: 28.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |     14 |          466.565 | 2935105 |  218.186 |               276.02 |              117.838 |            884.601 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c2e6_00000:
  custom_metrics:
    time_step_max: 4294
    time_step_mean: 3615.3926850014177
    time_step_min: 3240
  date: 2020-10-11_11-42-09
  done: false
  episode_len_mean: 883.6264416315049
  episode_reward_max: 276.02020202020157
  episode_reward_mean: 218.1418403443718
  episode_reward_min: 115.41414141414138
  episodes_this_iter: 237
  episodes_total: 3555
  experiment_id: df1157d3fdda43dcb890a3196b2b9b86
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.0012975103325314
        entropy_coeff: 0.0001
        kl: 0.014535996855960952
        model: {}
        policy_loss: -0.03526349003530211
        total_loss: -0.032456420879397124
        vf_explained_var: 0.00504864938557148
        vf_loss: 0.0
    num_steps_sampled: 3141292
    num_steps_trained: 3141292
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.37317073170731
    gpu_util_percent0: 0.16682926829268294
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.890243902439025
    vram_util_percent0: 0.0846999016070843
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 478
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1507143981115296
    mean_env_wait_ms: 1.1520130121453596
    mean_inference_ms: 4.575249397096355
    mean_raw_obs_processing_ms: 0.385776842638709
  time_since_restore: 501.3796808719635
  time_this_iter_s: 34.81444215774536
  time_total_s: 501.3796808719635
  timers:
    learn_throughput: 8733.554
    learn_time_ms: 23784.979
    sample_throughput: 23270.813
    sample_time_ms: 8926.521
    update_time_ms: 40.872
  timestamp: 1602416529
  timesteps_since_restore: 0
  timesteps_total: 3141292
  training_iteration: 15
  trial_id: 9c2e6_00000
  
== Status ==
Memory usage on this node: 28.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |     15 |           501.38 | 3141292 |  218.142 |               276.02 |              115.414 |            883.626 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c2e6_00000:
  custom_metrics:
    time_step_max: 4294
    time_step_mean: 3615.337407013815
    time_step_min: 3240
  date: 2020-10-11_11-42-40
  done: false
  episode_len_mean: 882.57805907173
  episode_reward_max: 276.02020202020157
  episode_reward_mean: 218.2741097685716
  episode_reward_min: 115.41414141414138
  episodes_this_iter: 237
  episodes_total: 3792
  experiment_id: df1157d3fdda43dcb890a3196b2b9b86
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.9924393120933982
        entropy_coeff: 0.0001
        kl: 0.013116635984795936
        model: {}
        policy_loss: -0.036610624479020346
        total_loss: -0.03408654198488768
        vf_explained_var: 0.005047868471592665
        vf_loss: 0.0
    num_steps_sampled: 3346736
    num_steps_trained: 3346736
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.352777777777778
    gpu_util_percent0: 0.2844444444444444
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8972222222222226
    vram_util_percent0: 0.08469990160708428
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 478
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15047497998216566
    mean_env_wait_ms: 1.1520761809338669
    mean_inference_ms: 4.561845659716743
    mean_raw_obs_processing_ms: 0.3851282199475179
  time_since_restore: 531.4751350879669
  time_this_iter_s: 30.095454216003418
  time_total_s: 531.4751350879669
  timers:
    learn_throughput: 8734.893
    learn_time_ms: 23717.899
    sample_throughput: 23225.831
    sample_time_ms: 8919.952
    update_time_ms: 38.881
  timestamp: 1602416560
  timesteps_since_restore: 0
  timesteps_total: 3346736
  training_iteration: 16
  trial_id: 9c2e6_00000
  
== Status ==
Memory usage on this node: 28.9/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |     16 |          531.475 | 3346736 |  218.274 |               276.02 |              115.414 |            882.578 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c2e6_00000:
  custom_metrics:
    time_step_max: 4294
    time_step_mean: 3613.5941014746313
    time_step_min: 3240
  date: 2020-10-11_11-43-14
  done: false
  episode_len_mean: 881.4896996773393
  episode_reward_max: 276.02020202020157
  episode_reward_mean: 218.48013267447354
  episode_reward_min: 115.41414141414138
  episodes_this_iter: 237
  episodes_total: 4029
  experiment_id: df1157d3fdda43dcb890a3196b2b9b86
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.9786315595402437
        entropy_coeff: 0.0001
        kl: 0.012351499815635821
        model: {}
        policy_loss: -0.04146460597129429
        total_loss: -0.03909216941717793
        vf_explained_var: 0.005017775110900402
        vf_loss: 0.0
    num_steps_sampled: 3551522
    num_steps_trained: 3551522
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.402499999999996
    gpu_util_percent0: 0.28675
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.88
    vram_util_percent0: 0.0846999016070843
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 478
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15025081057749468
    mean_env_wait_ms: 1.1521409602354007
    mean_inference_ms: 4.549440483702669
    mean_raw_obs_processing_ms: 0.38447308950954834
  time_since_restore: 565.6918759346008
  time_this_iter_s: 34.21674084663391
  time_total_s: 565.6918759346008
  timers:
    learn_throughput: 8753.328
    learn_time_ms: 23612.482
    sample_throughput: 23253.61
    sample_time_ms: 8888.418
    update_time_ms: 36.842
  timestamp: 1602416594
  timesteps_since_restore: 0
  timesteps_total: 3551522
  training_iteration: 17
  trial_id: 9c2e6_00000
  
== Status ==
Memory usage on this node: 28.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |     17 |          565.692 | 3551522 |   218.48 |               276.02 |              115.414 |             881.49 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c2e6_00000:
  custom_metrics:
    time_step_max: 4294
    time_step_mean: 3612.9728645587543
    time_step_min: 3240
  date: 2020-10-11_11-43-44
  done: false
  episode_len_mean: 880.2920768870136
  episode_reward_max: 276.02020202020157
  episode_reward_mean: 218.76413217974383
  episode_reward_min: 115.41414141414138
  episodes_this_iter: 237
  episodes_total: 4266
  experiment_id: df1157d3fdda43dcb890a3196b2b9b86
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.9642671241479761
        entropy_coeff: 0.0001
        kl: 0.014467166462803589
        model: {}
        policy_loss: -0.041976395227453285
        total_loss: -0.03917938941980109
        vf_explained_var: 0.005014840513467789
        vf_loss: 0.0
    num_steps_sampled: 3755326
    num_steps_trained: 3755326
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.957142857142856
    gpu_util_percent0: 0.36085714285714293
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8885714285714292
    vram_util_percent0: 0.08469990160708428
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 478
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15004368629945075
    mean_env_wait_ms: 1.152218182465942
    mean_inference_ms: 4.53807491236111
    mean_raw_obs_processing_ms: 0.3839184638798795
  time_since_restore: 595.9380519390106
  time_this_iter_s: 30.24617600440979
  time_total_s: 595.9380519390106
  timers:
    learn_throughput: 8751.49
    learn_time_ms: 23565.61
    sample_throughput: 23196.739
    sample_time_ms: 8890.655
    update_time_ms: 36.326
  timestamp: 1602416624
  timesteps_since_restore: 0
  timesteps_total: 3755326
  training_iteration: 18
  trial_id: 9c2e6_00000
  
== Status ==
Memory usage on this node: 28.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |     18 |          595.938 | 3755326 |  218.764 |               276.02 |              115.414 |            880.292 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c2e6_00000:
  custom_metrics:
    time_step_max: 4294
    time_step_mean: 3611.5343016759775
    time_step_min: 3240
  date: 2020-10-11_11-44-18
  done: true
  episode_len_mean: 879.0453031312459
  episode_reward_max: 276.02020202020157
  episode_reward_mean: 218.88085384154653
  episode_reward_min: 115.41414141414138
  episodes_this_iter: 237
  episodes_total: 4503
  experiment_id: df1157d3fdda43dcb890a3196b2b9b86
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.9430958418285146
        entropy_coeff: 0.0001
        kl: 0.013297418954179567
        model: {}
        policy_loss: -0.04472087937242845
        total_loss: -0.04215570407755235
        vf_explained_var: 0.004909925628453493
        vf_loss: 0.0
    num_steps_sampled: 3958341
    num_steps_trained: 3958341
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.860000000000003
    gpu_util_percent0: 0.26749999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8775000000000004
    vram_util_percent0: 0.0846999016070843
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 478
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1498507029804729
    mean_env_wait_ms: 1.1523313063198106
    mean_inference_ms: 4.527459740401997
    mean_raw_obs_processing_ms: 0.38335573474692985
  time_since_restore: 629.5950663089752
  time_this_iter_s: 33.6570143699646
  time_total_s: 629.5950663089752
  timers:
    learn_throughput: 8771.996
    learn_time_ms: 23433.423
    sample_throughput: 23320.558
    sample_time_ms: 8814.45
    update_time_ms: 41.147
  timestamp: 1602416658
  timesteps_since_restore: 0
  timesteps_total: 3958341
  training_iteration: 19
  trial_id: 9c2e6_00000
  
== Status ==
Memory usage on this node: 28.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c2e6_00000 | TERMINATED |       |     19 |          629.595 | 3958341 |  218.881 |               276.02 |              115.414 |            879.045 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c2e6_00000 | TERMINATED |       |     19 |          629.595 | 3958341 |  218.881 |               276.02 |              115.414 |            879.045 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


