2020-10-11 18:19:57,867	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_5f249_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=23079)[0m 2020-10-11 18:20:00,613	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=23099)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23099)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23077)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23077)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23045)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23045)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23046)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23046)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23075)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23075)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23085)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23085)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23071)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23071)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23105)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23105)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23050)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23050)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23055)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23055)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23051)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23051)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23066)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23066)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22995)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22995)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23092)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23092)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23096)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23096)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23058)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23058)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23059)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23059)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23089)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23089)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23042)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23042)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23033)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23033)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23065)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23065)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22979)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22979)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23054)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23054)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23043)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23043)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23069)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23069)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22983)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22983)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23041)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23041)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23004)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23004)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22980)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22980)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22987)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22987)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22977)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22977)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23029)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23029)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22974)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22974)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23031)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23031)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22988)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22988)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22993)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22993)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22991)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22991)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22975)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22975)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23062)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23062)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23086)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23086)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22998)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22998)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22981)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22981)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23037)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23037)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22994)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22994)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22976)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22976)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23047)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23047)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22971)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22971)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23063)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23063)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23040)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23040)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23034)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23034)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23044)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23044)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23036)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23036)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22973)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22973)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23100)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23100)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22989)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22989)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23057)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23057)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22984)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22984)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23049)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23049)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22996)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22996)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23039)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23039)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22969)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22969)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23070)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23070)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22985)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22985)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22997)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22997)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23081)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23081)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22982)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22982)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23083)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23083)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22990)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22990)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23053)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23053)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23073)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23073)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22972)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22972)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23000)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23000)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22986)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22986)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22970)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22970)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23052)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23052)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23088)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23088)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23048)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23048)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23072)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23072)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23056)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23056)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_5f249_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_18-20-39
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: dfab02fd42b6486e9e451b6779345bcb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.1834523901343346
        entropy_coeff: 0.0001
        kl: 0.005613055982394144
        model: {}
        policy_loss: -0.014200786616129335
        total_loss: 497.9777069091797
        vf_explained_var: 0.591008722782135
        vf_loss: 497.9909019470215
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.68205128205128
    gpu_util_percent0: 0.31641025641025644
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5846153846153843
    vram_util_percent0: 0.07998629226900793
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16829094352380622
    mean_env_wait_ms: 1.1709666480323198
    mean_inference_ms: 6.057185826385488
    mean_raw_obs_processing_ms: 0.45487156838831916
  time_since_restore: 33.22992396354675
  time_this_iter_s: 33.22992396354675
  time_total_s: 33.22992396354675
  timers:
    learn_throughput: 6832.658
    learn_time_ms: 23679.219
    sample_throughput: 17066.274
    sample_time_ms: 9480.218
    update_time_ms: 37.528
  timestamp: 1602440439
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 5f249_00000
  
== Status ==
Memory usage on this node: 27.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5f249_00000 | RUNNING  | 172.17.0.4:23079 |      1 |          33.2299 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5f249_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3605.5173611111113
    time_step_min: 3312
  date: 2020-10-11_18-21-10
  done: false
  episode_len_mean: 887.0506329113924
  episode_reward_max: 264.2020202020202
  episode_reward_mean: 217.93763585219259
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: dfab02fd42b6486e9e451b6779345bcb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.1539186760783195
        entropy_coeff: 0.0001
        kl: 0.007508977287216112
        model: {}
        policy_loss: -0.01595580365665228
        total_loss: 112.63971519470215
        vf_explained_var: 0.8323094248771667
        vf_loss: 112.65428924560547
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.03055555555555
    gpu_util_percent0: 0.3413888888888889
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666668
    vram_util_percent0: 0.09224335847818958
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16340419572524195
    mean_env_wait_ms: 1.168670514565361
    mean_inference_ms: 5.698402812802527
    mean_raw_obs_processing_ms: 0.43948812600579534
  time_since_restore: 64.05748319625854
  time_this_iter_s: 30.827559232711792
  time_total_s: 64.05748319625854
  timers:
    learn_throughput: 6874.387
    learn_time_ms: 23535.481
    sample_throughput: 19204.012
    sample_time_ms: 8424.906
    update_time_ms: 27.172
  timestamp: 1602440470
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 5f249_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5f249_00000 | RUNNING  | 172.17.0.4:23079 |      2 |          64.0575 | 323584 |  217.938 |              264.202 |              145.717 |            887.051 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5f249_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3605.663677130045
    time_step_min: 3312
  date: 2020-10-11_18-21-40
  done: false
  episode_len_mean: 882.8122362869199
  episode_reward_max: 264.2020202020202
  episode_reward_mean: 219.80008950262092
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: dfab02fd42b6486e9e451b6779345bcb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.1443624794483185
        entropy_coeff: 0.0001
        kl: 0.007522903208155185
        model: {}
        policy_loss: -0.017458065299706504
        total_loss: 39.23629355430603
        vf_explained_var: 0.928857684135437
        vf_loss: 39.25236129760742
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.025000000000002
    gpu_util_percent0: 0.3233333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7777777777777786
    vram_util_percent0: 0.09224335847818958
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16040906067506153
    mean_env_wait_ms: 1.1685273327870966
    mean_inference_ms: 5.463974754654477
    mean_raw_obs_processing_ms: 0.4296793880539397
  time_since_restore: 94.53159713745117
  time_this_iter_s: 30.474113941192627
  time_total_s: 94.53159713745117
  timers:
    learn_throughput: 6875.884
    learn_time_ms: 23530.356
    sample_throughput: 20449.702
    sample_time_ms: 7911.705
    update_time_ms: 24.743
  timestamp: 1602440500
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 5f249_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5f249_00000 | RUNNING  | 172.17.0.4:23079 |      3 |          94.5316 | 485376 |    219.8 |              264.202 |              145.717 |            882.812 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5f249_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3601.099337748344
    time_step_min: 3279
  date: 2020-10-11_18-22-11
  done: false
  episode_len_mean: 878.3212025316456
  episode_reward_max: 269.6565656565656
  episode_reward_mean: 220.61048778928506
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: dfab02fd42b6486e9e451b6779345bcb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.1258741691708565
        entropy_coeff: 0.0001
        kl: 0.008721297432202846
        model: {}
        policy_loss: -0.01911571827076841
        total_loss: 27.730449438095093
        vf_explained_var: 0.9499508142471313
        vf_loss: 27.747933506965637
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.847222222222225
    gpu_util_percent0: 0.3538888888888889
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333337
    vram_util_percent0: 0.09224335847818958
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15837213932133212
    mean_env_wait_ms: 1.1690176579259752
    mean_inference_ms: 5.302599547322746
    mean_raw_obs_processing_ms: 0.4228130526369309
  time_since_restore: 125.35296392440796
  time_this_iter_s: 30.821366786956787
  time_total_s: 125.35296392440796
  timers:
    learn_throughput: 6867.495
    learn_time_ms: 23559.098
    sample_throughput: 20985.65
    sample_time_ms: 7709.649
    update_time_ms: 23.115
  timestamp: 1602440531
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 5f249_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5f249_00000 | RUNNING  | 172.17.0.4:23079 |      4 |          125.353 | 647168 |   220.61 |              269.657 |              145.717 |            878.321 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5f249_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3594.670603674541
    time_step_min: 3271
  date: 2020-10-11_18-22-42
  done: false
  episode_len_mean: 873.5493670886076
  episode_reward_max: 270.8686868686861
  episode_reward_mean: 221.87942718322446
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: dfab02fd42b6486e9e451b6779345bcb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.0943499356508255
        entropy_coeff: 0.0001
        kl: 0.007845118263503537
        model: {}
        policy_loss: -0.017542113695526496
        total_loss: 22.74095916748047
        vf_explained_var: 0.963560938835144
        vf_loss: 22.757041573524475
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.755555555555553
    gpu_util_percent0: 0.2827777777777778
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775000000000001
    vram_util_percent0: 0.09224335847818958
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15690875723487882
    mean_env_wait_ms: 1.170519371530343
    mean_inference_ms: 5.1841713372532965
    mean_raw_obs_processing_ms: 0.4176710689414744
  time_since_restore: 156.05204272270203
  time_this_iter_s: 30.699078798294067
  time_total_s: 156.05204272270203
  timers:
    learn_throughput: 6864.377
    learn_time_ms: 23569.802
    sample_throughput: 21368.222
    sample_time_ms: 7571.617
    update_time_ms: 22.184
  timestamp: 1602440562
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 5f249_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5f249_00000 | RUNNING  | 172.17.0.4:23079 |      5 |          156.052 | 808960 |  221.879 |              270.869 |              145.717 |            873.549 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5f249_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3575.130797773655
    time_step_min: 3212
  date: 2020-10-11_18-23-12
  done: false
  episode_len_mean: 861.7007233273056
  episode_reward_max: 279.3535353535355
  episode_reward_mean: 224.56025900962592
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 316
  episodes_total: 1106
  experiment_id: dfab02fd42b6486e9e451b6779345bcb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.0974950715899467
        entropy_coeff: 0.0001
        kl: 0.007565566513221711
        model: {}
        policy_loss: -0.01637603374547325
        total_loss: 27.140122056007385
        vf_explained_var: 0.9662643671035767
        vf_loss: 27.155094861984253
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.99722222222222
    gpu_util_percent0: 0.3897222222222222
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775000000000001
    vram_util_percent0: 0.09224335847818958
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15500824692656773
    mean_env_wait_ms: 1.1749577561250775
    mean_inference_ms: 5.027765390449786
    mean_raw_obs_processing_ms: 0.41119706680698276
  time_since_restore: 186.5811243057251
  time_this_iter_s: 30.52908158302307
  time_total_s: 186.5811243057251
  timers:
    learn_throughput: 6869.276
    learn_time_ms: 23552.992
    sample_throughput: 21646.304
    sample_time_ms: 7474.348
    update_time_ms: 21.817
  timestamp: 1602440592
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 5f249_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5f249_00000 | RUNNING  | 172.17.0.4:23079 |      6 |          186.581 | 970752 |   224.56 |              279.354 |              145.717 |            861.701 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5f249_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3566.9660194174758
    time_step_min: 3212
  date: 2020-10-11_18-23-43
  done: false
  episode_len_mean: 856.3583860759494
  episode_reward_max: 279.3535353535355
  episode_reward_mean: 225.96266462089233
  episode_reward_min: 104.20202020202
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: dfab02fd42b6486e9e451b6779345bcb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.0811996385455132
        entropy_coeff: 0.0001
        kl: 0.00764909153804183
        model: {}
        policy_loss: -0.01918093068525195
        total_loss: 16.52116107940674
        vf_explained_var: 0.9706059694290161
        vf_loss: 16.538920402526855
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.78611111111111
    gpu_util_percent0: 0.3033333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7861111111111123
    vram_util_percent0: 0.09224335847818958
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15432436104860356
    mean_env_wait_ms: 1.1768374199891016
    mean_inference_ms: 4.972416586251885
    mean_raw_obs_processing_ms: 0.408926191587385
  time_since_restore: 217.31747126579285
  time_this_iter_s: 30.73634696006775
  time_total_s: 217.31747126579285
  timers:
    learn_throughput: 6866.633
    learn_time_ms: 23562.057
    sample_throughput: 21824.29
    sample_time_ms: 7413.391
    update_time_ms: 21.717
  timestamp: 1602440623
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 5f249_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5f249_00000 | RUNNING  | 172.17.0.4:23079 |      7 |          217.317 | 1132544 |  225.963 |              279.354 |              104.202 |            856.358 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5f249_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3559.2604017216645
    time_step_min: 3212
  date: 2020-10-11_18-24-14
  done: false
  episode_len_mean: 852.3059071729958
  episode_reward_max: 279.3535353535355
  episode_reward_mean: 227.21165238886744
  episode_reward_min: 104.20202020202
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: dfab02fd42b6486e9e451b6779345bcb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.0563684403896332
        entropy_coeff: 0.0001
        kl: 0.008180528384400532
        model: {}
        policy_loss: -0.018238085496705025
        total_loss: 15.083132684230804
        vf_explained_var: 0.97185218334198
        vf_loss: 15.099840700626373
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.561111111111114
    gpu_util_percent0: 0.27
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333345
    vram_util_percent0: 0.09224335847818958
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1537381501770555
    mean_env_wait_ms: 1.1784899602649614
    mean_inference_ms: 4.925084633809137
    mean_raw_obs_processing_ms: 0.4069477269037535
  time_since_restore: 248.05071544647217
  time_this_iter_s: 30.73324418067932
  time_total_s: 248.05071544647217
  timers:
    learn_throughput: 6866.532
    learn_time_ms: 23562.402
    sample_throughput: 21951.738
    sample_time_ms: 7370.35
    update_time_ms: 24.363
  timestamp: 1602440654
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 5f249_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5f249_00000 | RUNNING  | 172.17.0.4:23079 |      8 |          248.051 | 1294336 |  227.212 |              279.354 |              104.202 |            852.306 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5f249_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3550.872913992298
    time_step_min: 3212
  date: 2020-10-11_18-24-45
  done: false
  episode_len_mean: 848.7099621689786
  episode_reward_max: 279.3535353535355
  episode_reward_mean: 228.3638146916834
  episode_reward_min: 104.20202020202
  episodes_this_iter: 164
  episodes_total: 1586
  experiment_id: dfab02fd42b6486e9e451b6779345bcb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.0195335522294044
        entropy_coeff: 0.0001
        kl: 0.008048057643463835
        model: {}
        policy_loss: -0.017898785314173438
        total_loss: 17.17383098602295
        vf_explained_var: 0.972780168056488
        vf_loss: 17.190222084522247
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.516666666666666
    gpu_util_percent0: 0.2702777777777778
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7805555555555563
    vram_util_percent0: 0.09224335847818958
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15321759825300377
    mean_env_wait_ms: 1.1801937019502822
    mean_inference_ms: 4.882246080435339
    mean_raw_obs_processing_ms: 0.4051023406856046
  time_since_restore: 278.8282849788666
  time_this_iter_s: 30.77756953239441
  time_total_s: 278.8282849788666
  timers:
    learn_throughput: 6864.495
    learn_time_ms: 23569.396
    sample_throughput: 22059.952
    sample_time_ms: 7334.195
    update_time_ms: 26.211
  timestamp: 1602440685
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 5f249_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5f249_00000 | RUNNING  | 172.17.0.4:23079 |      9 |          278.828 | 1456128 |  228.364 |              279.354 |              104.202 |             848.71 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5f249_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3533.0310825294746
    time_step_min: 3212
  date: 2020-10-11_18-25-15
  done: false
  episode_len_mean: 842.1642027455122
  episode_reward_max: 279.50505050505063
  episode_reward_mean: 230.69301249026688
  episode_reward_min: 104.20202020202
  episodes_this_iter: 308
  episodes_total: 1894
  experiment_id: dfab02fd42b6486e9e451b6779345bcb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.0144055038690567
        entropy_coeff: 0.0001
        kl: 0.007067149301292375
        model: {}
        policy_loss: -0.016223774378886446
        total_loss: 18.50676429271698
        vf_explained_var: 0.9753490090370178
        vf_loss: 18.521675944328308
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.048571428571428
    gpu_util_percent0: 0.29314285714285715
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7714285714285714
    vram_util_percent0: 0.09224335847818958
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15242860485895113
    mean_env_wait_ms: 1.1833609405123646
    mean_inference_ms: 4.818327918423421
    mean_raw_obs_processing_ms: 0.40240991644436414
  time_since_restore: 308.60192251205444
  time_this_iter_s: 29.773637533187866
  time_total_s: 308.60192251205444
  timers:
    learn_throughput: 6888.937
    learn_time_ms: 23485.771
    sample_throughput: 22172.088
    sample_time_ms: 7297.103
    update_time_ms: 25.982
  timestamp: 1602440715
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 5f249_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5f249_00000 | RUNNING  | 172.17.0.4:23079 |     10 |          308.602 | 1617920 |  230.693 |              279.505 |              104.202 |            842.164 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5f249_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3525.3632773938793
    time_step_min: 3206
  date: 2020-10-11_18-25-45
  done: false
  episode_len_mean: 839.0350535540409
  episode_reward_max: 280.26262626262627
  episode_reward_mean: 231.67907900819282
  episode_reward_min: 104.20202020202
  episodes_this_iter: 160
  episodes_total: 2054
  experiment_id: dfab02fd42b6486e9e451b6779345bcb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.9942892119288445
        entropy_coeff: 0.0001
        kl: 0.007306597748538479
        model: {}
        policy_loss: -0.01803169777849689
        total_loss: 12.080819547176361
        vf_explained_var: 0.9778757095336914
        vf_loss: 12.097489595413208
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.86111111111111
    gpu_util_percent0: 0.3927777777777777
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333337
    vram_util_percent0: 0.09224335847818958
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15209159951602721
    mean_env_wait_ms: 1.18485076640769
    mean_inference_ms: 4.7909420459183565
    mean_raw_obs_processing_ms: 0.40124692153161645
  time_since_restore: 339.21248388290405
  time_this_iter_s: 30.61056137084961
  time_total_s: 339.21248388290405
  timers:
    learn_throughput: 6894.193
    learn_time_ms: 23467.866
    sample_throughput: 22940.873
    sample_time_ms: 7052.565
    update_time_ms: 24.299
  timestamp: 1602440745
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 5f249_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5f249_00000 | RUNNING  | 172.17.0.4:23079 |     11 |          339.212 | 1779712 |  231.679 |              280.263 |              104.202 |            839.035 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5f249_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3518.7614468864467
    time_step_min: 3206
  date: 2020-10-11_18-26-17
  done: false
  episode_len_mean: 836.0646473779385
  episode_reward_max: 280.26262626262627
  episode_reward_mean: 232.7887920799312
  episode_reward_min: 104.20202020202
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: dfab02fd42b6486e9e451b6779345bcb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.967091541737318
        entropy_coeff: 0.0001
        kl: 0.007904929690994322
        model: {}
        policy_loss: -0.018363158735155594
        total_loss: 10.625218272209167
        vf_explained_var: 0.9782837629318237
        vf_loss: 10.642097473144531
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.363888888888894
    gpu_util_percent0: 0.4469444444444444
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7777777777777786
    vram_util_percent0: 0.09224335847818958
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15179255313133275
    mean_env_wait_ms: 1.1862082738476523
    mean_inference_ms: 4.7665990783895005
    mean_raw_obs_processing_ms: 0.4001776164989288
  time_since_restore: 370.27554750442505
  time_this_iter_s: 31.063063621520996
  time_total_s: 370.27554750442505
  timers:
    learn_throughput: 6883.293
    learn_time_ms: 23505.029
    sample_throughput: 22996.165
    sample_time_ms: 7035.608
    update_time_ms: 26.911
  timestamp: 1602440777
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 5f249_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5f249_00000 | RUNNING  | 172.17.0.4:23079 |     12 |          370.276 | 1941504 |  232.789 |              280.263 |              104.202 |            836.065 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5f249_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3507.093762739503
    time_step_min: 3191
  date: 2020-10-11_18-26-48
  done: false
  episode_len_mean: 831.1406690850464
  episode_reward_max: 282.5353535353536
  episode_reward_mean: 234.6693293271285
  episode_reward_min: 104.20202020202
  episodes_this_iter: 269
  episodes_total: 2481
  experiment_id: dfab02fd42b6486e9e451b6779345bcb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.9374842308461666
        entropy_coeff: 0.0001
        kl: 0.007325579586904496
        model: {}
        policy_loss: -0.016780944853962865
        total_loss: 16.830816864967346
        vf_explained_var: 0.9769120216369629
        vf_loss: 16.84622585773468
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.41388888888889
    gpu_util_percent0: 0.39861111111111114
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7722222222222226
    vram_util_percent0: 0.09224335847818958
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15135406461081807
    mean_env_wait_ms: 1.188651211659747
    mean_inference_ms: 4.73065593991135
    mean_raw_obs_processing_ms: 0.3986232537151043
  time_since_restore: 401.15090346336365
  time_this_iter_s: 30.8753559589386
  time_total_s: 401.15090346336365
  timers:
    learn_throughput: 6877.818
    learn_time_ms: 23523.741
    sample_throughput: 22934.009
    sample_time_ms: 7054.676
    update_time_ms: 28.567
  timestamp: 1602440808
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 5f249_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5f249_00000 | RUNNING  | 172.17.0.4:23079 |     13 |          401.151 | 2103296 |  234.669 |              282.535 |              104.202 |            831.141 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5f249_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3499.051166290444
    time_step_min: 3184
  date: 2020-10-11_18-27-18
  done: false
  episode_len_mean: 827.8127326880119
  episode_reward_max: 283.59595959595964
  episode_reward_mean: 235.8831840369442
  episode_reward_min: 104.20202020202
  episodes_this_iter: 205
  episodes_total: 2686
  experiment_id: dfab02fd42b6486e9e451b6779345bcb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.9310766756534576
        entropy_coeff: 0.0001
        kl: 0.006801744777476415
        model: {}
        policy_loss: -0.01683555421186611
        total_loss: 10.64886474609375
        vf_explained_var: 0.980786144733429
        vf_loss: 10.664433002471924
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.733333333333334
    gpu_util_percent0: 0.3188888888888889
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7861111111111123
    vram_util_percent0: 0.09224335847818958
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15106364933009103
    mean_env_wait_ms: 1.1902879828491024
    mean_inference_ms: 4.707258568197888
    mean_raw_obs_processing_ms: 0.397595783333547
  time_since_restore: 431.94489312171936
  time_this_iter_s: 30.793989658355713
  time_total_s: 431.94489312171936
  timers:
    learn_throughput: 6879.129
    learn_time_ms: 23519.256
    sample_throughput: 22935.18
    sample_time_ms: 7054.316
    update_time_ms: 28.473
  timestamp: 1602440838
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 5f249_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5f249_00000 | RUNNING  | 172.17.0.4:23079 |     14 |          431.945 | 2265088 |  235.883 |              283.596 |              104.202 |            827.813 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5f249_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3493.2389914772725
    time_step_min: 3184
  date: 2020-10-11_18-27-49
  done: false
  episode_len_mean: 825.6237693389592
  episode_reward_max: 290.41414141414134
  episode_reward_mean: 236.87362016792386
  episode_reward_min: 104.20202020202
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: dfab02fd42b6486e9e451b6779345bcb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.9135946072638035
        entropy_coeff: 0.0001
        kl: 0.006944256485439837
        model: {}
        policy_loss: -0.01781624907744117
        total_loss: 10.351810574531555
        vf_explained_var: 0.9789829254150391
        vf_loss: 10.368329346179962
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.714285714285715
    gpu_util_percent0: 0.4297142857142857
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7800000000000002
    vram_util_percent0: 0.09224335847818958
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15086427069224745
    mean_env_wait_ms: 1.1914622964396744
    mean_inference_ms: 4.6908840462352694
    mean_raw_obs_processing_ms: 0.3968706645607378
  time_since_restore: 462.4495804309845
  time_this_iter_s: 30.504687309265137
  time_total_s: 462.4495804309845
  timers:
    learn_throughput: 6877.964
    learn_time_ms: 23523.24
    sample_throughput: 23019.417
    sample_time_ms: 7028.501
    update_time_ms: 30.149
  timestamp: 1602440869
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 5f249_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5f249_00000 | RUNNING  | 172.17.0.4:23079 |     15 |           462.45 | 2426880 |  236.874 |              290.414 |              104.202 |            825.624 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5f249_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3484.192026578073
    time_step_min: 3184
  date: 2020-10-11_18-28-19
  done: false
  episode_len_mean: 822.8647136273864
  episode_reward_max: 290.41414141414134
  episode_reward_mean: 238.19762137504063
  episode_reward_min: 104.20202020202
  episodes_this_iter: 194
  episodes_total: 3038
  experiment_id: dfab02fd42b6486e9e451b6779345bcb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.8806382194161415
        entropy_coeff: 0.0001
        kl: 0.007801589817972854
        model: {}
        policy_loss: -0.017748524696798995
        total_loss: 10.544836223125458
        vf_explained_var: 0.982378363609314
        vf_loss: 10.561112463474274
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.674285714285716
    gpu_util_percent0: 0.2865714285714286
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7800000000000002
    vram_util_percent0: 0.09224335847818958
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15064166673226473
    mean_env_wait_ms: 1.1928764193534258
    mean_inference_ms: 4.672339260362204
    mean_raw_obs_processing_ms: 0.3960442259706729
  time_since_restore: 492.6983938217163
  time_this_iter_s: 30.24881339073181
  time_total_s: 492.6983938217163
  timers:
    learn_throughput: 6878.557
    learn_time_ms: 23521.212
    sample_throughput: 23107.066
    sample_time_ms: 7001.841
    update_time_ms: 29.941
  timestamp: 1602440899
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 5f249_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5f249_00000 | RUNNING  | 172.17.0.4:23079 |     16 |          492.698 | 2588672 |  238.198 |              290.414 |              104.202 |            822.865 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5f249_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3475.7217999391914
    time_step_min: 3168
  date: 2020-10-11_18-28-50
  done: false
  episode_len_mean: 819.488393126319
  episode_reward_max: 290.41414141414134
  episode_reward_mean: 239.61143542753425
  episode_reward_min: 104.20202020202
  episodes_this_iter: 279
  episodes_total: 3317
  experiment_id: dfab02fd42b6486e9e451b6779345bcb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.8803978376090527
        entropy_coeff: 0.0001
        kl: 0.006713388575008139
        model: {}
        policy_loss: -0.01683700781359221
        total_loss: 12.135042250156403
        vf_explained_var: 0.9818198680877686
        vf_loss: 12.150624394416809
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.794285714285717
    gpu_util_percent0: 0.414
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7714285714285714
    vram_util_percent0: 0.09224335847818958
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15035181745448986
    mean_env_wait_ms: 1.1948256644030373
    mean_inference_ms: 4.648824344122676
    mean_raw_obs_processing_ms: 0.39498204698502304
  time_since_restore: 523.0558061599731
  time_this_iter_s: 30.357412338256836
  time_total_s: 523.0558061599731
  timers:
    learn_throughput: 6881.586
    learn_time_ms: 23510.858
    sample_throughput: 23207.316
    sample_time_ms: 6971.595
    update_time_ms: 31.335
  timestamp: 1602440930
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 5f249_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5f249_00000 | RUNNING  | 172.17.0.4:23079 |     17 |          523.056 | 2750464 |  239.611 |              290.414 |              104.202 |            819.488 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5f249_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3469.786542923434
    time_step_min: 3157
  date: 2020-10-11_18-29-20
  done: false
  episode_len_mean: 817.8705408515535
  episode_reward_max: 290.41414141414134
  episode_reward_mean: 240.49238355941455
  episode_reward_min: 104.20202020202
  episodes_this_iter: 159
  episodes_total: 3476
  experiment_id: dfab02fd42b6486e9e451b6779345bcb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.8674679175019264
        entropy_coeff: 0.0001
        kl: 0.0066587814362719655
        model: {}
        policy_loss: -0.017646767490077764
        total_loss: 8.075953274965286
        vf_explained_var: 0.9828952550888062
        vf_loss: 8.092355072498322
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.608333333333334
    gpu_util_percent0: 0.3188888888888889
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7916666666666674
    vram_util_percent0: 0.09224335847818958
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15020329663393517
    mean_env_wait_ms: 1.1958335666759967
    mean_inference_ms: 4.636701825069091
    mean_raw_obs_processing_ms: 0.39443748651059596
  time_since_restore: 553.3393270969391
  time_this_iter_s: 30.283520936965942
  time_total_s: 553.3393270969391
  timers:
    learn_throughput: 6887.389
    learn_time_ms: 23491.049
    sample_throughput: 23287.994
    sample_time_ms: 6947.443
    update_time_ms: 29.953
  timestamp: 1602440960
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 5f249_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5f249_00000 | RUNNING  | 172.17.0.4:23079 |     18 |          553.339 | 2912256 |  240.492 |              290.414 |              104.202 |            817.871 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5f249_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3464.576486860304
    time_step_min: 3157
  date: 2020-10-11_18-29-51
  done: false
  episode_len_mean: 816.329398847104
  episode_reward_max: 290.41414141414134
  episode_reward_mean: 241.22383039841174
  episode_reward_min: 104.20202020202
  episodes_this_iter: 167
  episodes_total: 3643
  experiment_id: dfab02fd42b6486e9e451b6779345bcb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.8435412533581257
        entropy_coeff: 0.0001
        kl: 0.0070840438129380345
        model: {}
        policy_loss: -0.017348378110909835
        total_loss: 10.529172003269196
        vf_explained_var: 0.9804550409317017
        vf_loss: 10.545188009738922
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.768571428571423
    gpu_util_percent0: 0.4142857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7857142857142865
    vram_util_percent0: 0.09224335847818958
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1500553400473927
    mean_env_wait_ms: 1.1968401587951842
    mean_inference_ms: 4.624638444591439
    mean_raw_obs_processing_ms: 0.39387791950558915
  time_since_restore: 583.6999273300171
  time_this_iter_s: 30.360600233078003
  time_total_s: 583.6999273300171
  timers:
    learn_throughput: 6890.191
    learn_time_ms: 23481.496
    sample_throughput: 23388.593
    sample_time_ms: 6917.56
    update_time_ms: 27.994
  timestamp: 1602440991
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 5f249_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5f249_00000 | RUNNING  | 172.17.0.4:23079 |     19 |            583.7 | 3074048 |  241.224 |              290.414 |              104.202 |            816.329 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5f249_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3455.25
    time_step_min: 3141
  date: 2020-10-11_18-30-21
  done: true
  episode_len_mean: 813.7246707193516
  episode_reward_max: 290.41414141414134
  episode_reward_mean: 242.59249792760426
  episode_reward_min: 104.20202020202
  episodes_this_iter: 305
  episodes_total: 3948
  experiment_id: dfab02fd42b6486e9e451b6779345bcb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.8319440372288227
        entropy_coeff: 0.0001
        kl: 0.006855020736111328
        model: {}
        policy_loss: -0.01724567578639835
        total_loss: 10.262589454650879
        vf_explained_var: 0.9852497577667236
        vf_loss: 10.27854734659195
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.945714285714285
    gpu_util_percent0: 0.43628571428571433
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774285714285714
    vram_util_percent0: 0.09224335847818958
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14981407214315978
    mean_env_wait_ms: 1.198621716911785
    mean_inference_ms: 4.604987710609354
    mean_raw_obs_processing_ms: 0.39299337326282574
  time_since_restore: 614.111894607544
  time_this_iter_s: 30.411967277526855
  time_total_s: 614.111894607544
  timers:
    learn_throughput: 6867.333
    learn_time_ms: 23559.656
    sample_throughput: 23439.508
    sample_time_ms: 6902.534
    update_time_ms: 27.623
  timestamp: 1602441021
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 5f249_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5f249_00000 | TERMINATED |       |     20 |          614.112 | 3235840 |  242.592 |              290.414 |              104.202 |            813.725 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5f249_00000 | TERMINATED |       |     20 |          614.112 | 3235840 |  242.592 |              290.414 |              104.202 |            813.725 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


