2020-10-12 13:34:22,578	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_a4253_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=51491)[0m 2020-10-12 13:34:25,388	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=51454)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51454)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51488)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51488)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51469)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51469)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51515)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51515)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51476)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51476)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51477)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51477)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51494)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51494)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51513)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51513)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51483)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51483)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51493)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51493)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51480)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51480)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51460)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51460)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51508)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51508)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51461)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51461)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51448)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51448)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51471)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51471)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51393)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51393)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51462)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51462)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51416)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51416)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51440)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51440)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51383)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51383)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51382)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51382)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51458)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51458)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51391)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51391)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51403)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51403)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51459)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51459)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51376)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51376)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51497)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51497)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51505)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51505)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51503)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51503)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51396)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51396)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51394)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51394)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51478)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51478)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51496)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51496)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51386)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51386)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51411)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51411)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51481)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51481)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51490)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51490)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51415)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51415)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51443)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51443)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51444)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51444)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51499)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51499)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51409)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51409)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51395)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51395)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51380)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51380)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51518)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51518)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51410)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51410)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51407)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51407)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51436)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51436)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51446)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51446)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51378)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51378)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51451)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51451)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51389)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51389)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51399)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51399)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51381)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51381)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51455)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51455)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51379)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51379)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51470)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51470)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51397)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51397)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51453)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51453)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51384)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51384)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51435)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51435)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51390)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51390)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51456)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51456)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51387)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51387)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51449)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51449)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51377)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51377)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51401)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51401)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51392)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51392)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51450)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51450)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51418)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51418)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51485)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51485)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51501)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51501)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51474)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51474)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51452)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51452)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51438)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51438)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51512)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51512)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51475)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51475)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51441)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51441)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_a4253_00000:
  custom_metrics:
    time_step_max: 4040
    time_step_mean: 3708.8660714285716
    time_step_min: 3400
  date: 2020-10-12_13-34-59
  done: false
  episode_len_mean: 905.6582278481013
  episode_reward_max: 262.01010101010036
  episode_reward_mean: 216.4606188466943
  episode_reward_min: 164.28282828282764
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 152faefc3c1042eeb83414e3d368d4c3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1618427733580272
        entropy_coeff: 0.0005000000000000001
        kl: 0.007736673501009743
        model: {}
        policy_loss: -0.009274243047305694
        total_loss: 407.51319630940753
        vf_explained_var: 0.5518081784248352
        vf_loss: 407.52150472005206
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.40294117647059
    gpu_util_percent0: 0.34205882352941175
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5558823529411767
    vram_util_percent0: 0.08636872262844136
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51491
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17136426279669228
    mean_env_wait_ms: 1.1828545384585176
    mean_inference_ms: 6.192494189529442
    mean_raw_obs_processing_ms: 0.4657840051559725
  time_since_restore: 29.070663452148438
  time_this_iter_s: 29.070663452148438
  time_total_s: 29.070663452148438
  timers:
    learn_throughput: 8391.719
    learn_time_ms: 19279.959
    sample_throughput: 16635.229
    sample_time_ms: 9725.866
    update_time_ms: 27.39
  timestamp: 1602509699
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: a4253_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4253_00000 | RUNNING  | 172.17.0.4:51491 |      1 |          29.0707 | 161792 |  216.461 |               262.01 |              164.283 |            905.658 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4253_00000:
  custom_metrics:
    time_step_max: 4059
    time_step_mean: 3711.3333333333335
    time_step_min: 3400
  date: 2020-10-12_13-35-26
  done: false
  episode_len_mean: 903.626582278481
  episode_reward_max: 262.01010101010036
  episode_reward_mean: 213.76882751566245
  episode_reward_min: 135.0404040404036
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 152faefc3c1042eeb83414e3d368d4c3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1327943404515584
        entropy_coeff: 0.0005000000000000001
        kl: 0.008884161555518707
        model: {}
        policy_loss: -0.010871932929148898
        total_loss: 105.18411636352539
        vf_explained_var: 0.8105942606925964
        vf_loss: 105.19377772013347
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.08387096774194
    gpu_util_percent0: 0.24387096774193548
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7580645161290316
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51491
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1663452281498463
    mean_env_wait_ms: 1.1789462034306255
    mean_inference_ms: 5.839016554132948
    mean_raw_obs_processing_ms: 0.45021876574291625
  time_since_restore: 56.14249801635742
  time_this_iter_s: 27.071834564208984
  time_total_s: 56.14249801635742
  timers:
    learn_throughput: 8406.213
    learn_time_ms: 19246.717
    sample_throughput: 18484.344
    sample_time_ms: 8752.921
    update_time_ms: 28.748
  timestamp: 1602509726
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: a4253_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4253_00000 | RUNNING  | 172.17.0.4:51491 |      2 |          56.1425 | 323584 |  213.769 |               262.01 |               135.04 |            903.627 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4253_00000:
  custom_metrics:
    time_step_max: 4219
    time_step_mean: 3724.5443925233644
    time_step_min: 3400
  date: 2020-10-12_13-35-53
  done: false
  episode_len_mean: 902.0253164556962
  episode_reward_max: 265.9494949494946
  episode_reward_mean: 212.67018284106845
  episode_reward_min: 135.0404040404036
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 152faefc3c1042eeb83414e3d368d4c3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1228645245234172
        entropy_coeff: 0.0005000000000000001
        kl: 0.010275025619193912
        model: {}
        policy_loss: -0.01340144882366682
        total_loss: 46.899818420410156
        vf_explained_var: 0.9017475247383118
        vf_loss: 46.91172504425049
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.651612903225807
    gpu_util_percent0: 0.3216129032258065
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51491
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16313901692142907
    mean_env_wait_ms: 1.1782749757906248
    mean_inference_ms: 5.594447441284696
    mean_raw_obs_processing_ms: 0.43954094086118267
  time_since_restore: 82.64664578437805
  time_this_iter_s: 26.50414776802063
  time_total_s: 82.64664578437805
  timers:
    learn_throughput: 8402.801
    learn_time_ms: 19254.531
    sample_throughput: 19673.657
    sample_time_ms: 8223.789
    update_time_ms: 25.421
  timestamp: 1602509753
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: a4253_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4253_00000 | RUNNING  | 172.17.0.4:51491 |      3 |          82.6466 | 485376 |   212.67 |              265.949 |               135.04 |            902.025 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4253_00000:
  custom_metrics:
    time_step_max: 4219
    time_step_mean: 3719.7542662116043
    time_step_min: 3400
  date: 2020-10-12_13-36-19
  done: false
  episode_len_mean: 897.871835443038
  episode_reward_max: 265.9494949494946
  episode_reward_mean: 213.97596215317688
  episode_reward_min: 135.0404040404036
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 152faefc3c1042eeb83414e3d368d4c3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.106802225112915
        entropy_coeff: 0.0005000000000000001
        kl: 0.011325941421091557
        model: {}
        policy_loss: -0.012830269911016027
        total_loss: 35.69442494710287
        vf_explained_var: 0.9211029410362244
        vf_loss: 35.70554383595785
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.91
    gpu_util_percent0: 0.3416666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.773333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51491
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16089501534650852
    mean_env_wait_ms: 1.1787770929890098
    mean_inference_ms: 5.422026709577889
    mean_raw_obs_processing_ms: 0.43185399498713867
  time_since_restore: 108.81041836738586
  time_this_iter_s: 26.163772583007812
  time_total_s: 108.81041836738586
  timers:
    learn_throughput: 8416.757
    learn_time_ms: 19222.605
    sample_throughput: 20454.649
    sample_time_ms: 7909.791
    update_time_ms: 24.775
  timestamp: 1602509779
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: a4253_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4253_00000 | RUNNING  | 172.17.0.4:51491 |      4 |           108.81 | 647168 |  213.976 |              265.949 |               135.04 |            897.872 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4253_00000:
  custom_metrics:
    time_step_max: 4219
    time_step_mean: 3718.766129032258
    time_step_min: 3400
  date: 2020-10-12_13-36-46
  done: false
  episode_len_mean: 895.1949367088607
  episode_reward_max: 265.9494949494946
  episode_reward_mean: 213.97308528321145
  episode_reward_min: 135.0404040404036
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 152faefc3c1042eeb83414e3d368d4c3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0750388602415721
        entropy_coeff: 0.0005000000000000001
        kl: 0.01077581321199735
        model: {}
        policy_loss: -0.013582793714401001
        total_loss: 29.738055388132732
        vf_explained_var: 0.9400181770324707
        vf_loss: 29.750019709269207
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.61612903225807
    gpu_util_percent0: 0.3658064516129032
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322573
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51491
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15924980002973188
    mean_env_wait_ms: 1.1794911838628006
    mean_inference_ms: 5.292936610713645
    mean_raw_obs_processing_ms: 0.42595551419540756
  time_since_restore: 135.26678133010864
  time_this_iter_s: 26.45636296272278
  time_total_s: 135.26678133010864
  timers:
    learn_throughput: 8405.054
    learn_time_ms: 19249.371
    sample_throughput: 20928.268
    sample_time_ms: 7730.788
    update_time_ms: 27.002
  timestamp: 1602509806
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: a4253_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4253_00000 | RUNNING  | 172.17.0.4:51491 |      5 |          135.267 | 808960 |  213.973 |              265.949 |               135.04 |            895.195 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4253_00000:
  custom_metrics:
    time_step_max: 4219
    time_step_mean: 3718.620614035088
    time_step_min: 3400
  date: 2020-10-12_13-37-12
  done: false
  episode_len_mean: 892.0302713987473
  episode_reward_max: 265.9494949494946
  episode_reward_mean: 214.10774762236093
  episode_reward_min: 135.0404040404036
  episodes_this_iter: 168
  episodes_total: 958
  experiment_id: 152faefc3c1042eeb83414e3d368d4c3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0358026921749115
        entropy_coeff: 0.0005000000000000001
        kl: 0.011226230533793569
        model: {}
        policy_loss: -0.013998372208637496
        total_loss: 28.980687300364178
        vf_explained_var: 0.9519464373588562
        vf_loss: 28.992957909901936
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.48
    gpu_util_percent0: 0.2776666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51491
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15789674954402322
    mean_env_wait_ms: 1.1807496734238072
    mean_inference_ms: 5.187587626543441
    mean_raw_obs_processing_ms: 0.4209374040351763
  time_since_restore: 161.4463860988617
  time_this_iter_s: 26.17960476875305
  time_total_s: 161.4463860988617
  timers:
    learn_throughput: 8406.298
    learn_time_ms: 19246.522
    sample_throughput: 21323.843
    sample_time_ms: 7587.375
    update_time_ms: 25.757
  timestamp: 1602509832
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: a4253_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4253_00000 | RUNNING  | 172.17.0.4:51491 |      6 |          161.446 | 970752 |  214.108 |              265.949 |               135.04 |             892.03 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4253_00000:
  custom_metrics:
    time_step_max: 4219
    time_step_mean: 3707.604938271605
    time_step_min: 3379
  date: 2020-10-12_13-37-38
  done: false
  episode_len_mean: 882.3647898493259
  episode_reward_max: 265.9494949494946
  episode_reward_mean: 215.93435544981892
  episode_reward_min: 135.0404040404036
  episodes_this_iter: 303
  episodes_total: 1261
  experiment_id: 152faefc3c1042eeb83414e3d368d4c3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0417535801728566
        entropy_coeff: 0.0005000000000000001
        kl: 0.011072183183083931
        model: {}
        policy_loss: -0.01288391783600673
        total_loss: 26.67935832341512
        vf_explained_var: 0.9601631760597229
        vf_loss: 26.690548419952393
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.225806451612907
    gpu_util_percent0: 0.34741935483870967
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.761290322580645
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51491
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15616969874747305
    mean_env_wait_ms: 1.1837261494544107
    mean_inference_ms: 5.051132766979761
    mean_raw_obs_processing_ms: 0.41483090413914375
  time_since_restore: 187.74806690216064
  time_this_iter_s: 26.30168080329895
  time_total_s: 187.74806690216064
  timers:
    learn_throughput: 8409.768
    learn_time_ms: 19238.582
    sample_throughput: 21546.917
    sample_time_ms: 7508.824
    update_time_ms: 25.135
  timestamp: 1602509858
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: a4253_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4253_00000 | RUNNING  | 172.17.0.4:51491 |      7 |          187.748 | 1132544 |  215.934 |              265.949 |               135.04 |            882.365 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4253_00000:
  custom_metrics:
    time_step_max: 4219
    time_step_mean: 3698.607558139535
    time_step_min: 3349
  date: 2020-10-12_13-38-04
  done: false
  episode_len_mean: 878.2292545710267
  episode_reward_max: 268.97979797979764
  episode_reward_mean: 217.03290286834547
  episode_reward_min: 135.0404040404036
  episodes_this_iter: 161
  episodes_total: 1422
  experiment_id: 152faefc3c1042eeb83414e3d368d4c3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.018199215332667
        entropy_coeff: 0.0005000000000000001
        kl: 0.01131790247745812
        model: {}
        policy_loss: -0.015187829926920434
        total_loss: 17.6397492090861
        vf_explained_var: 0.9636650085449219
        vf_loss: 17.653183619181316
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.129999999999995
    gpu_util_percent0: 0.40933333333333327
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51491
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1554810103133737
    mean_env_wait_ms: 1.1853248721808423
    mean_inference_ms: 4.997133626874637
    mean_raw_obs_processing_ms: 0.4123994409377489
  time_since_restore: 213.2801125049591
  time_this_iter_s: 25.532045602798462
  time_total_s: 213.2801125049591
  timers:
    learn_throughput: 8443.918
    learn_time_ms: 19160.774
    sample_throughput: 21788.684
    sample_time_ms: 7425.506
    update_time_ms: 24.264
  timestamp: 1602509884
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: a4253_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4253_00000 | RUNNING  | 172.17.0.4:51491 |      8 |           213.28 | 1294336 |  217.033 |               268.98 |               135.04 |            878.229 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4253_00000:
  custom_metrics:
    time_step_max: 4219
    time_step_mean: 3693.315514993481
    time_step_min: 3349
  date: 2020-10-12_13-38-30
  done: false
  episode_len_mean: 876.1208860759493
  episode_reward_max: 268.97979797979764
  episode_reward_mean: 217.22797596215273
  episode_reward_min: 123.22222222222149
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 152faefc3c1042eeb83414e3d368d4c3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.002722293138504
        entropy_coeff: 0.0005000000000000001
        kl: 0.009767126214380065
        model: {}
        policy_loss: -0.01389557949732989
        total_loss: 22.54266627629598
        vf_explained_var: 0.9575715661048889
        vf_loss: 22.555109182993572
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.82
    gpu_util_percent0: 0.36099999999999993
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.77
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51491
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1548994192414851
    mean_env_wait_ms: 1.1868385737809801
    mean_inference_ms: 4.951211626572846
    mean_raw_obs_processing_ms: 0.41030886886994483
  time_since_restore: 239.74961519241333
  time_this_iter_s: 26.469502687454224
  time_total_s: 239.74961519241333
  timers:
    learn_throughput: 8430.232
    learn_time_ms: 19191.88
    sample_throughput: 21945.657
    sample_time_ms: 7372.393
    update_time_ms: 23.703
  timestamp: 1602509910
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: a4253_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4253_00000 | RUNNING  | 172.17.0.4:51491 |      9 |           239.75 | 1456128 |  217.228 |               268.98 |              123.222 |            876.121 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4253_00000:
  custom_metrics:
    time_step_max: 4219
    time_step_mean: 3690.4619019492025
    time_step_min: 3349
  date: 2020-10-12_13-38-57
  done: false
  episode_len_mean: 872.8372627947097
  episode_reward_max: 268.97979797979764
  episode_reward_mean: 217.99952370165093
  episode_reward_min: 123.22222222222149
  episodes_this_iter: 159
  episodes_total: 1739
  experiment_id: 152faefc3c1042eeb83414e3d368d4c3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9705201288064321
        entropy_coeff: 0.0005000000000000001
        kl: 0.009661196808641156
        model: {}
        policy_loss: -0.015201902269230535
        total_loss: 18.153138319651287
        vf_explained_var: 0.9632181525230408
        vf_loss: 18.166893164316814
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.661290322580648
    gpu_util_percent0: 0.30709677419354836
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51491
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15439243087741597
    mean_env_wait_ms: 1.1883301128519503
    mean_inference_ms: 4.910679914358681
    mean_raw_obs_processing_ms: 0.40844323266948895
  time_since_restore: 266.1139190196991
  time_this_iter_s: 26.364303827285767
  time_total_s: 266.1139190196991
  timers:
    learn_throughput: 8421.118
    learn_time_ms: 19212.651
    sample_throughput: 22093.701
    sample_time_ms: 7322.992
    update_time_ms: 24.139
  timestamp: 1602509937
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: a4253_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4253_00000 | RUNNING  | 172.17.0.4:51491 |     10 |          266.114 | 1617920 |      218 |               268.98 |              123.222 |            872.837 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4253_00000:
  custom_metrics:
    time_step_max: 4219
    time_step_mean: 3678.2079055441477
    time_step_min: 3334
  date: 2020-10-12_13-39-23
  done: false
  episode_len_mean: 866.0441323971916
  episode_reward_max: 271.25252525252495
  episode_reward_mean: 219.77042744394757
  episode_reward_min: 123.22222222222149
  episodes_this_iter: 255
  episodes_total: 1994
  experiment_id: 152faefc3c1042eeb83414e3d368d4c3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9280691345532736
        entropy_coeff: 0.0005000000000000001
        kl: 0.008637615324308475
        model: {}
        policy_loss: -0.013847703873276865
        total_loss: 20.080313682556152
        vf_explained_var: 0.9696772694587708
        vf_loss: 20.092897415161133
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.57
    gpu_util_percent0: 0.287
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7599999999999993
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51491
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1537070906054506
    mean_env_wait_ms: 1.1909966619281065
    mean_inference_ms: 4.856394936323097
    mean_raw_obs_processing_ms: 0.4059115881297048
  time_since_restore: 292.34574794769287
  time_this_iter_s: 26.231828927993774
  time_total_s: 292.34574794769287
  timers:
    learn_throughput: 8420.54
    learn_time_ms: 19213.969
    sample_throughput: 22992.38
    sample_time_ms: 7036.766
    update_time_ms: 23.25
  timestamp: 1602509963
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: a4253_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4253_00000 | RUNNING  | 172.17.0.4:51491 |     11 |          292.346 | 1779712 |   219.77 |              271.253 |              123.222 |            866.044 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4253_00000:
  custom_metrics:
    time_step_max: 4219
    time_step_mean: 3666.364727608495
    time_step_min: 3280
  date: 2020-10-12_13-39-50
  done: false
  episode_len_mean: 860.6939421338155
  episode_reward_max: 279.43434343434376
  episode_reward_mean: 221.2815679397954
  episode_reward_min: 123.22222222222149
  episodes_this_iter: 218
  episodes_total: 2212
  experiment_id: 152faefc3c1042eeb83414e3d368d4c3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.929964562257131
        entropy_coeff: 0.0005000000000000001
        kl: 0.009297128223503629
        model: {}
        policy_loss: -0.013476144929882139
        total_loss: 15.816188176472982
        vf_explained_var: 0.9703838229179382
        vf_loss: 15.828269640604654
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.490322580645163
    gpu_util_percent0: 0.3296774193548387
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51491
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15321512828941145
    mean_env_wait_ms: 1.1929625677996871
    mean_inference_ms: 4.816956141416033
    mean_raw_obs_processing_ms: 0.40416877336324164
  time_since_restore: 318.94340658187866
  time_this_iter_s: 26.59765863418579
  time_total_s: 318.94340658187866
  timers:
    learn_throughput: 8408.093
    learn_time_ms: 19242.414
    sample_throughput: 23242.708
    sample_time_ms: 6960.979
    update_time_ms: 22.205
  timestamp: 1602509990
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: a4253_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4253_00000 | RUNNING  | 172.17.0.4:51491 |     12 |          318.943 | 1941504 |  221.282 |              279.434 |              123.222 |            860.694 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4253_00000:
  custom_metrics:
    time_step_max: 4219
    time_step_mean: 3657.643287435456
    time_step_min: 3280
  date: 2020-10-12_13-40-16
  done: false
  episode_len_mean: 856.9075949367088
  episode_reward_max: 279.43434343434376
  episode_reward_mean: 222.56520905255041
  episode_reward_min: 123.22222222222149
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: 152faefc3c1042eeb83414e3d368d4c3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9062146246433258
        entropy_coeff: 0.0005000000000000001
        kl: 0.009518158854916692
        model: {}
        policy_loss: -0.013599073436732093
        total_loss: 12.208461999893188
        vf_explained_var: 0.9715034365653992
        vf_loss: 12.220610539118448
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.85
    gpu_util_percent0: 0.321
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51491
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1529003277546341
    mean_env_wait_ms: 1.194474025015393
    mean_inference_ms: 4.792093734208934
    mean_raw_obs_processing_ms: 0.403030494477968
  time_since_restore: 345.2171583175659
  time_this_iter_s: 26.273751735687256
  time_total_s: 345.2171583175659
  timers:
    learn_throughput: 8404.084
    learn_time_ms: 19251.593
    sample_throughput: 23360.057
    sample_time_ms: 6926.01
    update_time_ms: 24.568
  timestamp: 1602510016
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: a4253_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4253_00000 | RUNNING  | 172.17.0.4:51491 |     13 |          345.217 | 2103296 |  222.565 |              279.434 |              123.222 |            856.908 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4253_00000:
  custom_metrics:
    time_step_max: 4219
    time_step_mean: 3650.072975140337
    time_step_min: 3280
  date: 2020-10-12_13-40-42
  done: false
  episode_len_mean: 853.1102362204724
  episode_reward_max: 279.43434343434376
  episode_reward_mean: 223.59265887218604
  episode_reward_min: 123.22222222222149
  episodes_this_iter: 170
  episodes_total: 2540
  experiment_id: 152faefc3c1042eeb83414e3d368d4c3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8762755393981934
        entropy_coeff: 0.0005000000000000001
        kl: 0.00874017885265251
        model: {}
        policy_loss: -0.012449563558523854
        total_loss: 15.03822922706604
        vf_explained_var: 0.9703531265258789
        vf_loss: 15.049369096755981
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.63666666666667
    gpu_util_percent0: 0.3143333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.77
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51491
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1525882248044361
    mean_env_wait_ms: 1.1961285319914126
    mean_inference_ms: 4.767757731700803
    mean_raw_obs_processing_ms: 0.4019005201185028
  time_since_restore: 371.0290746688843
  time_this_iter_s: 25.81191635131836
  time_total_s: 371.0290746688843
  timers:
    learn_throughput: 8418.887
    learn_time_ms: 19217.742
    sample_throughput: 23367.287
    sample_time_ms: 6923.867
    update_time_ms: 24.549
  timestamp: 1602510042
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: a4253_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4253_00000 | RUNNING  | 172.17.0.4:51491 |     14 |          371.029 | 2265088 |  223.593 |              279.434 |              123.222 |             853.11 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4253_00000:
  custom_metrics:
    time_step_max: 4219
    time_step_mean: 3638.9579590370104
    time_step_min: 3280
  date: 2020-10-12_13-41-09
  done: false
  episode_len_mean: 847.7610463061152
  episode_reward_max: 279.8888888888887
  episode_reward_mean: 225.23979990788013
  episode_reward_min: 123.22222222222149
  episodes_this_iter: 289
  episodes_total: 2829
  experiment_id: 152faefc3c1042eeb83414e3d368d4c3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8531498908996582
        entropy_coeff: 0.0005000000000000001
        kl: 0.009171535338585576
        model: {}
        policy_loss: -0.010889322642469779
        total_loss: 16.91581630706787
        vf_explained_var: 0.9742764830589294
        vf_loss: 16.92529821395874
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.99032258064517
    gpu_util_percent0: 0.33225806451612905
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51491
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15213564889414652
    mean_env_wait_ms: 1.1988508605413517
    mean_inference_ms: 4.73177443629308
    mean_raw_obs_processing_ms: 0.4002370385584447
  time_since_restore: 397.4645082950592
  time_this_iter_s: 26.435433626174927
  time_total_s: 397.4645082950592
  timers:
    learn_throughput: 8417.348
    learn_time_ms: 19221.256
    sample_throughput: 23387.289
    sample_time_ms: 6917.946
    update_time_ms: 23.94
  timestamp: 1602510069
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: a4253_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4253_00000 | RUNNING  | 172.17.0.4:51491 |     15 |          397.465 | 2426880 |   225.24 |              279.889 |              123.222 |            847.761 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4253_00000:
  custom_metrics:
    time_step_max: 4219
    time_step_mean: 3632.68200270636
    time_step_min: 3280
  date: 2020-10-12_13-41-35
  done: false
  episode_len_mean: 845.1155896069287
  episode_reward_max: 279.8888888888887
  episode_reward_mean: 226.2689284584684
  episode_reward_min: 123.22222222222149
  episodes_this_iter: 173
  episodes_total: 3002
  experiment_id: 152faefc3c1042eeb83414e3d368d4c3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8428441087404887
        entropy_coeff: 0.0005000000000000001
        kl: 0.009230436213935414
        model: {}
        policy_loss: -0.012926558304267624
        total_loss: 11.921082496643066
        vf_explained_var: 0.9746169447898865
        vf_loss: 11.932584365208944
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.183333333333334
    gpu_util_percent0: 0.35600000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7766666666666664
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51491
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15190005607005574
    mean_env_wait_ms: 1.200338767855564
    mean_inference_ms: 4.712813670841079
    mean_raw_obs_processing_ms: 0.3993913429663085
  time_since_restore: 423.67454504966736
  time_this_iter_s: 26.210036754608154
  time_total_s: 423.67454504966736
  timers:
    learn_throughput: 8415.315
    learn_time_ms: 19225.899
    sample_throughput: 23394.399
    sample_time_ms: 6915.844
    update_time_ms: 24.144
  timestamp: 1602510095
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: a4253_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4253_00000 | RUNNING  | 172.17.0.4:51491 |     16 |          423.675 | 2588672 |  226.269 |              279.889 |              123.222 |            845.116 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4253_00000:
  custom_metrics:
    time_step_max: 4219
    time_step_mean: 3626.383429672447
    time_step_min: 3280
  date: 2020-10-12_13-42-02
  done: false
  episode_len_mean: 843.0164556962026
  episode_reward_max: 279.8888888888887
  episode_reward_mean: 227.17187699782596
  episode_reward_min: 123.22222222222149
  episodes_this_iter: 158
  episodes_total: 3160
  experiment_id: 152faefc3c1042eeb83414e3d368d4c3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8229580223560333
        entropy_coeff: 0.0005000000000000001
        kl: 0.008402933677037558
        model: {}
        policy_loss: -0.012855454389258133
        total_loss: 11.89345669746399
        vf_explained_var: 0.9735504984855652
        vf_loss: 11.905042807261148
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.212903225806453
    gpu_util_percent0: 0.33322580645161287
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.783870967741935
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51491
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15169932391244145
    mean_env_wait_ms: 1.20167086610702
    mean_inference_ms: 4.696842389466878
    mean_raw_obs_processing_ms: 0.3986534261160949
  time_since_restore: 450.23624753952026
  time_this_iter_s: 26.561702489852905
  time_total_s: 450.23624753952026
  timers:
    learn_throughput: 8405.019
    learn_time_ms: 19249.451
    sample_throughput: 23388.228
    sample_time_ms: 6917.668
    update_time_ms: 24.208
  timestamp: 1602510122
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: a4253_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4253_00000 | RUNNING  | 172.17.0.4:51491 |     17 |          450.236 | 2750464 |  227.172 |              279.889 |              123.222 |            843.016 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4253_00000:
  custom_metrics:
    time_step_max: 4219
    time_step_mean: 3617.8605697151424
    time_step_min: 3278
  date: 2020-10-12_13-42-28
  done: false
  episode_len_mean: 839.7323277136942
  episode_reward_max: 279.8888888888887
  episode_reward_mean: 228.40533103887103
  episode_reward_min: 123.22222222222149
  episodes_this_iter: 221
  episodes_total: 3381
  experiment_id: 152faefc3c1042eeb83414e3d368d4c3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7838106552759806
        entropy_coeff: 0.0005000000000000001
        kl: 0.008587277339150509
        model: {}
        policy_loss: -0.011906572649119576
        total_loss: 16.197141488393147
        vf_explained_var: 0.9726850390434265
        vf_loss: 16.207722107569378
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.46129032258064
    gpu_util_percent0: 0.3661290322580644
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322573
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51491
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15143954166017437
    mean_env_wait_ms: 1.2035276574748
    mean_inference_ms: 4.676432398092084
    mean_raw_obs_processing_ms: 0.3976932448453505
  time_since_restore: 476.5592911243439
  time_this_iter_s: 26.32304358482361
  time_total_s: 476.5592911243439
  timers:
    learn_throughput: 8383.502
    learn_time_ms: 19298.856
    sample_throughput: 23313.966
    sample_time_ms: 6939.703
    update_time_ms: 24.758
  timestamp: 1602510148
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: a4253_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4253_00000 | RUNNING  | 172.17.0.4:51491 |     18 |          476.559 | 2912256 |  228.405 |              279.889 |              123.222 |            839.732 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4253_00000:
  custom_metrics:
    time_step_max: 4219
    time_step_mean: 3607.4278149386846
    time_step_min: 3278
  date: 2020-10-12_13-42-55
  done: false
  episode_len_mean: 836.9171711612548
  episode_reward_max: 279.8888888888887
  episode_reward_mean: 229.92065953981162
  episode_reward_min: 123.22222222222149
  episodes_this_iter: 253
  episodes_total: 3634
  experiment_id: 152faefc3c1042eeb83414e3d368d4c3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.786894828081131
        entropy_coeff: 0.0005000000000000001
        kl: 0.007417023569966356
        model: {}
        policy_loss: -0.01126654728432186
        total_loss: 11.955698092778524
        vf_explained_var: 0.9783071875572205
        vf_loss: 11.965874671936035
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.013333333333332
    gpu_util_percent0: 0.35166666666666674
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7633333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51491
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15117556226500428
    mean_env_wait_ms: 1.2053834857604755
    mean_inference_ms: 4.6555238182358325
    mean_raw_obs_processing_ms: 0.39675054810775395
  time_since_restore: 503.1876881122589
  time_this_iter_s: 26.62839698791504
  time_total_s: 503.1876881122589
  timers:
    learn_throughput: 8382.28
    learn_time_ms: 19301.669
    sample_throughput: 23278.988
    sample_time_ms: 6950.13
    update_time_ms: 26.872
  timestamp: 1602510175
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: a4253_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4253_00000 | RUNNING  | 172.17.0.4:51491 |     19 |          503.188 | 3074048 |  229.921 |              279.889 |              123.222 |            836.917 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4253_00000:
  custom_metrics:
    time_step_max: 4219
    time_step_mean: 3601.6417512012813
    time_step_min: 3278
  date: 2020-10-12_13-43-22
  done: false
  episode_len_mean: 835.2357594936709
  episode_reward_max: 287.6161616161611
  episode_reward_mean: 230.82323232323196
  episode_reward_min: 123.22222222222149
  episodes_this_iter: 158
  episodes_total: 3792
  experiment_id: 152faefc3c1042eeb83414e3d368d4c3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7667305171489716
        entropy_coeff: 0.0005000000000000001
        kl: 0.008109371333072582
        model: {}
        policy_loss: -0.012780876228741059
        total_loss: 11.133415222167969
        vf_explained_var: 0.974933385848999
        vf_loss: 11.144957542419434
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.31290322580646
    gpu_util_percent0: 0.26677419354838705
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774193548387097
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51491
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15102509468211886
    mean_env_wait_ms: 1.206491345264698
    mean_inference_ms: 4.643598880638099
    mean_raw_obs_processing_ms: 0.396202644929922
  time_since_restore: 529.653370141983
  time_this_iter_s: 26.46568202972412
  time_total_s: 529.653370141983
  timers:
    learn_throughput: 8382.604
    learn_time_ms: 19300.923
    sample_throughput: 23243.26
    sample_time_ms: 6960.814
    update_time_ms: 26.258
  timestamp: 1602510202
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: a4253_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4253_00000 | RUNNING  | 172.17.0.4:51491 |     20 |          529.653 | 3235840 |  230.823 |              287.616 |              123.222 |            835.236 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4253_00000:
  custom_metrics:
    time_step_max: 4219
    time_step_mean: 3596.107170196479
    time_step_min: 3251
  date: 2020-10-12_13-43-48
  done: false
  episode_len_mean: 833.4580075662043
  episode_reward_max: 287.6161616161611
  episode_reward_mean: 231.71425477982817
  episode_reward_min: 123.22222222222149
  episodes_this_iter: 173
  episodes_total: 3965
  experiment_id: 152faefc3c1042eeb83414e3d368d4c3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7328726301590601
        entropy_coeff: 0.0005000000000000001
        kl: 0.00830904363344113
        model: {}
        policy_loss: -0.012024667322596846
        total_loss: 10.34760562578837
        vf_explained_var: 0.9788932204246521
        vf_loss: 10.35833509763082
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.54193548387097
    gpu_util_percent0: 0.3709677419354839
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51491
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.150868120658121
    mean_env_wait_ms: 1.2076520337534324
    mean_inference_ms: 4.631277565727224
    mean_raw_obs_processing_ms: 0.39563277494996746
  time_since_restore: 556.0333440303802
  time_this_iter_s: 26.379973888397217
  time_total_s: 556.0333440303802
  timers:
    learn_throughput: 8378.236
    learn_time_ms: 19310.986
    sample_throughput: 23235.366
    sample_time_ms: 6963.178
    update_time_ms: 28.332
  timestamp: 1602510228
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: a4253_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4253_00000 | RUNNING  | 172.17.0.4:51491 |     21 |          556.033 | 3397632 |  231.714 |              287.616 |              123.222 |            833.458 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4253_00000:
  custom_metrics:
    time_step_max: 4219
    time_step_mean: 3587.4301715919923
    time_step_min: 3251
  date: 2020-10-12_13-44-15
  done: false
  episode_len_mean: 830.9582743988684
  episode_reward_max: 287.6161616161611
  episode_reward_mean: 233.09138771019926
  episode_reward_min: 123.22222222222149
  episodes_this_iter: 277
  episodes_total: 4242
  experiment_id: 152faefc3c1042eeb83414e3d368d4c3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.714335431655248
        entropy_coeff: 0.0005000000000000001
        kl: 0.006961250910535455
        model: {}
        policy_loss: -0.010644625988788903
        total_loss: 13.322779655456543
        vf_explained_var: 0.9789154529571533
        vf_loss: 13.332388957341513
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.109677419354835
    gpu_util_percent0: 0.36677419354838714
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.76774193548387
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51491
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15064222213831122
    mean_env_wait_ms: 1.2094340069596374
    mean_inference_ms: 4.613377593091359
    mean_raw_obs_processing_ms: 0.3948104680191211
  time_since_restore: 582.4031662940979
  time_this_iter_s: 26.36982226371765
  time_total_s: 582.4031662940979
  timers:
    learn_throughput: 8390.462
    learn_time_ms: 19282.848
    sample_throughput: 23246.565
    sample_time_ms: 6959.824
    update_time_ms: 36.274
  timestamp: 1602510255
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: a4253_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4253_00000 | RUNNING  | 172.17.0.4:51491 |     22 |          582.403 | 3559424 |  233.091 |              287.616 |              123.222 |            830.958 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4253_00000:
  custom_metrics:
    time_step_max: 4219
    time_step_mean: 3581.884422110553
    time_step_min: 3241
  date: 2020-10-12_13-44-41
  done: true
  episode_len_mean: 829.6460216998191
  episode_reward_max: 287.6161616161611
  episode_reward_mean: 233.8832515936943
  episode_reward_min: 123.22222222222149
  episodes_this_iter: 182
  episodes_total: 4424
  experiment_id: 152faefc3c1042eeb83414e3d368d4c3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7143764893213908
        entropy_coeff: 0.0005000000000000001
        kl: 0.007545994866328935
        model: {}
        policy_loss: -0.011197483613311002
        total_loss: 10.43907912572225
        vf_explained_var: 0.9785223603248596
        vf_loss: 10.449124495188395
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.28666666666667
    gpu_util_percent0: 0.27599999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.783333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51491
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15050756364440007
    mean_env_wait_ms: 1.2104867507576387
    mean_inference_ms: 4.602590990209685
    mean_raw_obs_processing_ms: 0.3943353625079774
  time_since_restore: 608.5565874576569
  time_this_iter_s: 26.15342116355896
  time_total_s: 608.5565874576569
  timers:
    learn_throughput: 8398.452
    learn_time_ms: 19264.503
    sample_throughput: 23223.955
    sample_time_ms: 6966.6
    update_time_ms: 35.238
  timestamp: 1602510281
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: a4253_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4253_00000 | TERMINATED |       |     23 |          608.557 | 3721216 |  233.883 |              287.616 |              123.222 |            829.646 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


[2m[33m(pid=raylet)[0m E1012 13:44:41.533123 51335 51335 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed
[2m[33m(pid=raylet)[0m E1012 13:44:41.533360 51335 51335 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed
[2m[33m(pid=raylet)[0m E1012 13:44:41.533473 51335 51335 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed
[2m[33m(pid=raylet)[0m E1012 13:44:41.533558 51335 51335 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed
[2m[33m(pid=raylet)[0m E1012 13:44:41.533619 51335 51335 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed
[2m[33m(pid=raylet)[0m E1012 13:44:41.533705 51335 51335 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4253_00000 | TERMINATED |       |     23 |          608.557 | 3721216 |  233.883 |              287.616 |              123.222 |            829.646 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


