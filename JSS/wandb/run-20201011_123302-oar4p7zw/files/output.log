2020-10-11 12:33:06,846	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_ead49_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=42621)[0m 2020-10-11 12:33:09,620	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=42628)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42628)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42564)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42564)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42567)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42567)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42569)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42569)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42562)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42562)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42579)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42579)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42631)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42631)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42575)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42575)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42615)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42615)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42598)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42598)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42589)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42589)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42573)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42573)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42571)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42571)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42581)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42581)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42601)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42601)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42595)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42595)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42577)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42577)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42620)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42620)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42588)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42588)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42529)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42529)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42501)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42501)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42492)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42492)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42519)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42519)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42524)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42524)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42570)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42570)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42603)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42603)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42585)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42585)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42493)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42493)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42494)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42494)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42495)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42495)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42506)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42506)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42504)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42504)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42515)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42515)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42614)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42614)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42605)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42605)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42586)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42586)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42520)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42520)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42583)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42583)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42556)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42556)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42559)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42559)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42497)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42497)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42513)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42513)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42594)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42594)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42502)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42502)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42555)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42555)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42498)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42498)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42557)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42557)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42592)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42592)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42527)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42527)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42566)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42566)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42576)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42576)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42517)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42517)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42508)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42508)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42526)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42526)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42596)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42596)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42511)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42511)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42561)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42561)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42568)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42568)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42625)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42625)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42618)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42618)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42604)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42604)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42565)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42565)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42514)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42514)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42591)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42591)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42572)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42572)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42599)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42599)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42510)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42510)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42500)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42500)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42496)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42496)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42521)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42521)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42587)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42587)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42552)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42552)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42563)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42563)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42491)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42491)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42505)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42505)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42512)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42512)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42507)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42507)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42560)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42560)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42574)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42574)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_ead49_00000:
  custom_metrics:
    time_step_max: 4030
    time_step_mean: 3584.5733333333333
    time_step_min: 3342
  date: 2020-10-11_12-33-59
  done: false
  episode_len_mean: 890.4599156118144
  episode_reward_max: 265.262626262626
  episode_reward_mean: 220.14243702851277
  episode_reward_min: 128.4444444444439
  episodes_this_iter: 237
  episodes_total: 237
  experiment_id: d7f0dd186b6a414f93e92ed9326fb937
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.1783365567525228
        entropy_coeff: 0.00010000000000000002
        kl: 0.01057270901898543
        model: {}
        policy_loss: -0.022353537660092116
        total_loss: 494.00855916341146
        vf_explained_var: 0.6055326461791992
        vf_loss: 494.02891845703124
    num_steps_sampled: 242688
    num_steps_trained: 242688
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.66037735849056
    gpu_util_percent0: 0.3633962264150944
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.705660377358492
    vram_util_percent0: 0.09534366355811058
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42621
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.18728649590478408
    mean_env_wait_ms: 1.6239406518562223
    mean_inference_ms: 5.332644911009649
    mean_raw_obs_processing_ms: 0.5488381940812821
  time_since_restore: 44.170440435409546
  time_this_iter_s: 44.170440435409546
  time_total_s: 44.170440435409546
  timers:
    learn_throughput: 6985.737
    learn_time_ms: 34740.5
    sample_throughput: 25963.553
    sample_time_ms: 9347.257
    update_time_ms: 52.902
  timestamp: 1602419639
  timesteps_since_restore: 0
  timesteps_total: 242688
  training_iteration: 1
  trial_id: ead49_00000
  
== Status ==
Memory usage on this node: 28.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ead49_00000 | RUNNING  | 172.17.0.4:42621 |      1 |          44.1704 | 242688 |  220.142 |              265.263 |              128.444 |             890.46 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ead49_00000:
  custom_metrics:
    time_step_max: 4030
    time_step_mean: 3602.891472868217
    time_step_min: 3342
  date: 2020-10-11_12-34-41
  done: false
  episode_len_mean: 893.415611814346
  episode_reward_max: 265.262626262626
  episode_reward_mean: 218.17945275540188
  episode_reward_min: 128.4444444444439
  episodes_this_iter: 237
  episodes_total: 474
  experiment_id: d7f0dd186b6a414f93e92ed9326fb937
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.1440338532129923
        entropy_coeff: 0.00010000000000000002
        kl: 0.01038070364544789
        model: {}
        policy_loss: -0.02316500134766102
        total_loss: 110.14165954589843
        vf_explained_var: 0.8461299538612366
        vf_loss: 110.1628662109375
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.037254901960786
    gpu_util_percent0: 0.3854901960784313
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.9764705882352938
    vram_util_percent0: 0.10897015414890127
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42621
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.18455980029592503
    mean_env_wait_ms: 1.6268930874920258
    mean_inference_ms: 5.196732916846475
    mean_raw_obs_processing_ms: 0.5429301369920915
  time_since_restore: 86.96122360229492
  time_this_iter_s: 42.790783166885376
  time_total_s: 86.96122360229492
  timers:
    learn_throughput: 7037.288
    learn_time_ms: 34486.014
    sample_throughput: 27234.566
    sample_time_ms: 8911.029
    update_time_ms: 38.179
  timestamp: 1602419681
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 2
  trial_id: ead49_00000
  
== Status ==
Memory usage on this node: 29.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ead49_00000 | RUNNING  | 172.17.0.4:42621 |      2 |          86.9612 | 485376 |  218.179 |              265.263 |              128.444 |            893.416 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ead49_00000:
  custom_metrics:
    time_step_max: 4036
    time_step_mean: 3608.4326923076924
    time_step_min: 3328
  date: 2020-10-11_12-35-24
  done: false
  episode_len_mean: 893.5836849507735
  episode_reward_max: 272.68686868686797
  episode_reward_mean: 218.2230320078419
  episode_reward_min: 128.4444444444439
  episodes_this_iter: 237
  episodes_total: 711
  experiment_id: d7f0dd186b6a414f93e92ed9326fb937
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.128836719195048
        entropy_coeff: 0.00010000000000000002
        kl: 0.0121931749706467
        model: {}
        policy_loss: -0.02609602715820074
        total_loss: 31.29148801167806
        vf_explained_var: 0.9494290947914124
        vf_loss: 31.315258916219076
    num_steps_sampled: 728064
    num_steps_trained: 728064
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.02549019607843
    gpu_util_percent0: 0.3776470588235293
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.994117647058824
    vram_util_percent0: 0.10897015414890127
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42621
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.18270607874163985
    mean_env_wait_ms: 1.6276264871745258
    mean_inference_ms: 5.077282387013835
    mean_raw_obs_processing_ms: 0.5372964999280547
  time_since_restore: 129.56005883216858
  time_this_iter_s: 42.59883522987366
  time_total_s: 129.56005883216858
  timers:
    learn_throughput: 7043.437
    learn_time_ms: 34455.905
    sample_throughput: 28159.94
    sample_time_ms: 8618.2
    update_time_ms: 38.701
  timestamp: 1602419724
  timesteps_since_restore: 0
  timesteps_total: 728064
  training_iteration: 3
  trial_id: ead49_00000
  
== Status ==
Memory usage on this node: 29.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ead49_00000 | RUNNING  | 172.17.0.4:42621 |      3 |           129.56 | 728064 |  218.223 |              272.687 |              128.444 |            893.584 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ead49_00000:
  custom_metrics:
    time_step_max: 4036
    time_step_mean: 3603.6411149825785
    time_step_min: 3303
  date: 2020-10-11_12-36-07
  done: false
  episode_len_mean: 893.2373417721519
  episode_reward_max: 272.68686868686797
  episode_reward_mean: 218.81779823551955
  episode_reward_min: 128.4444444444439
  episodes_this_iter: 237
  episodes_total: 948
  experiment_id: d7f0dd186b6a414f93e92ed9326fb937
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.112494460741679
        entropy_coeff: 0.00010000000000000002
        kl: 0.012547395502527555
        model: {}
        policy_loss: -0.02629172249386708
        total_loss: 21.336332194010417
        vf_explained_var: 0.9639291763305664
        vf_loss: 21.36022555033366
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.234
    gpu_util_percent0: 0.3754
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.992
    vram_util_percent0: 0.10897015414890127
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42621
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.18139440498724627
    mean_env_wait_ms: 1.6283248516471858
    mean_inference_ms: 4.987229103851667
    mean_raw_obs_processing_ms: 0.5325322946722844
  time_since_restore: 172.11470127105713
  time_this_iter_s: 42.55464243888855
  time_total_s: 172.11470127105713
  timers:
    learn_throughput: 7041.805
    learn_time_ms: 34463.891
    sample_throughput: 28702.031
    sample_time_ms: 8455.429
    update_time_ms: 38.148
  timestamp: 1602419767
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 4
  trial_id: ead49_00000
  
== Status ==
Memory usage on this node: 29.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ead49_00000 | RUNNING  | 172.17.0.4:42621 |      4 |          172.115 | 970752 |  218.818 |              272.687 |              128.444 |            893.237 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ead49_00000:
  custom_metrics:
    time_step_max: 4306
    time_step_mean: 3602.3296903460837
    time_step_min: 3303
  date: 2020-10-11_12-36-49
  done: false
  episode_len_mean: 894.0506329113924
  episode_reward_max: 272.68686868686797
  episode_reward_mean: 218.9580616289475
  episode_reward_min: 113.59595959595957
  episodes_this_iter: 237
  episodes_total: 1185
  experiment_id: d7f0dd186b6a414f93e92ed9326fb937
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.0827192385991415
        entropy_coeff: 0.00010000000000000002
        kl: 0.011658764195938904
        model: {}
        policy_loss: -0.025812987113992374
        total_loss: 21.956070327758788
        vf_explained_var: 0.9639965891838074
        vf_loss: 21.979660034179688
    num_steps_sampled: 1213440
    num_steps_trained: 1213440
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.774509803921568
    gpu_util_percent0: 0.3752941176470588
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.986274509803921
    vram_util_percent0: 0.10897015414890127
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42621
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.18039385814446982
    mean_env_wait_ms: 1.6285756215631682
    mean_inference_ms: 4.918098246002091
    mean_raw_obs_processing_ms: 0.5286411760355099
  time_since_restore: 214.6497929096222
  time_this_iter_s: 42.53509163856506
  time_total_s: 214.6497929096222
  timers:
    learn_throughput: 7042.879
    learn_time_ms: 34458.633
    sample_throughput: 29061.223
    sample_time_ms: 8350.922
    update_time_ms: 50.313
  timestamp: 1602419809
  timesteps_since_restore: 0
  timesteps_total: 1213440
  training_iteration: 5
  trial_id: ead49_00000
  
== Status ==
Memory usage on this node: 29.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ead49_00000 | RUNNING  | 172.17.0.4:42621 |      5 |           214.65 | 1213440 |  218.958 |              272.687 |              113.596 |            894.051 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ead49_00000:
  custom_metrics:
    time_step_max: 4306
    time_step_mean: 3599.8013442867814
    time_step_min: 3290
  date: 2020-10-11_12-37-32
  done: false
  episode_len_mean: 892.9263674614306
  episode_reward_max: 272.68686868686797
  episode_reward_mean: 220.10930482950099
  episode_reward_min: 113.59595959595957
  episodes_this_iter: 241
  episodes_total: 1426
  experiment_id: d7f0dd186b6a414f93e92ed9326fb937
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.048909878730774
        entropy_coeff: 0.00010000000000000002
        kl: 0.012033107876777648
        model: {}
        policy_loss: -0.027200845691064995
        total_loss: 18.924008814493813
        vf_explained_var: 0.9720413684844971
        vf_loss: 18.948907089233398
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.17
    gpu_util_percent0: 0.35320000000000007
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.9879999999999995
    vram_util_percent0: 0.10897015414890127
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42621
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1795869345795816
    mean_env_wait_ms: 1.6295056103776346
    mean_inference_ms: 4.862424954715773
    mean_raw_obs_processing_ms: 0.5254373512774112
  time_since_restore: 257.3971185684204
  time_this_iter_s: 42.74732565879822
  time_total_s: 257.3971185684204
  timers:
    learn_throughput: 7038.841
    learn_time_ms: 34478.406
    sample_throughput: 29242.214
    sample_time_ms: 8299.235
    update_time_ms: 47.712
  timestamp: 1602419852
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 6
  trial_id: ead49_00000
  
== Status ==
Memory usage on this node: 29.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ead49_00000 | RUNNING  | 172.17.0.4:42621 |      6 |          257.397 | 1456128 |  220.109 |              272.687 |              113.596 |            892.926 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ead49_00000:
  custom_metrics:
    time_step_max: 4306
    time_step_mean: 3592.7351955307263
    time_step_min: 3264
  date: 2020-10-11_12-38-15
  done: false
  episode_len_mean: 888.1134789557805
  episode_reward_max: 277.98989898989896
  episode_reward_mean: 222.14643504840606
  episode_reward_min: 113.59595959595957
  episodes_this_iter: 451
  episodes_total: 1877
  experiment_id: d7f0dd186b6a414f93e92ed9326fb937
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.0502089897791544
        entropy_coeff: 0.00010000000000000002
        kl: 0.010941468241314093
        model: {}
        policy_loss: -0.02485069011648496
        total_loss: 22.713931147257487
        vf_explained_var: 0.9722127914428711
        vf_loss: 22.73669891357422
    num_steps_sampled: 1698816
    num_steps_trained: 1698816
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.050980392156863
    gpu_util_percent0: 0.36941176470588233
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.988235294117647
    vram_util_percent0: 0.10897015414890127
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42621
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17850040587467453
    mean_env_wait_ms: 1.6321961744294544
    mean_inference_ms: 4.787300266256114
    mean_raw_obs_processing_ms: 0.521326713984386
  time_since_restore: 299.8480463027954
  time_this_iter_s: 42.450927734375
  time_total_s: 299.8480463027954
  timers:
    learn_throughput: 7044.754
    learn_time_ms: 34449.466
    sample_throughput: 29359.863
    sample_time_ms: 8265.979
    update_time_ms: 46.876
  timestamp: 1602419895
  timesteps_since_restore: 0
  timesteps_total: 1698816
  training_iteration: 7
  trial_id: ead49_00000
  
== Status ==
Memory usage on this node: 29.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ead49_00000 | RUNNING  | 172.17.0.4:42621 |      7 |          299.848 | 1698816 |  222.146 |               277.99 |              113.596 |            888.113 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ead49_00000:
  custom_metrics:
    time_step_max: 4306
    time_step_mean: 3586.3587487781037
    time_step_min: 3217
  date: 2020-10-11_12-38-57
  done: false
  episode_len_mean: 884.5283638068448
  episode_reward_max: 282.5353535353533
  episode_reward_mean: 223.65257355552694
  episode_reward_min: 113.59595959595957
  episodes_this_iter: 256
  episodes_total: 2133
  experiment_id: d7f0dd186b6a414f93e92ed9326fb937
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.0440319140752157
        entropy_coeff: 0.00010000000000000002
        kl: 0.011247905530035495
        model: {}
        policy_loss: -0.028203373154004414
        total_loss: 12.827454503377279
        vf_explained_var: 0.9781181216239929
        vf_loss: 12.853512700398763
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.144000000000002
    gpu_util_percent0: 0.37499999999999994
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.004
    vram_util_percent0: 0.10897015414890127
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42621
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17803414617062044
    mean_env_wait_ms: 1.6338506191195368
    mean_inference_ms: 4.755389238708717
    mean_raw_obs_processing_ms: 0.5196623325993119
  time_since_restore: 342.4282567501068
  time_this_iter_s: 42.5802104473114
  time_total_s: 342.4282567501068
  timers:
    learn_throughput: 7044.071
    learn_time_ms: 34452.804
    sample_throughput: 29482.956
    sample_time_ms: 8231.468
    update_time_ms: 45.687
  timestamp: 1602419937
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 8
  trial_id: ead49_00000
  
== Status ==
Memory usage on this node: 29.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ead49_00000 | RUNNING  | 172.17.0.4:42621 |      8 |          342.428 | 1941504 |  223.653 |              282.535 |              113.596 |            884.528 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ead49_00000:
  custom_metrics:
    time_step_max: 4306
    time_step_mean: 3579.567674113009
    time_step_min: 3217
  date: 2020-10-11_12-39-40
  done: false
  episode_len_mean: 881.9713080168776
  episode_reward_max: 282.5353535353533
  episode_reward_mean: 224.52979158675342
  episode_reward_min: 113.59595959595957
  episodes_this_iter: 237
  episodes_total: 2370
  experiment_id: d7f0dd186b6a414f93e92ed9326fb937
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.0213545560836792
        entropy_coeff: 0.00010000000000000002
        kl: 0.010888240858912468
        model: {}
        policy_loss: -0.027582661248743534
        total_loss: 15.469853528340657
        vf_explained_var: 0.9749153852462769
        vf_loss: 15.49536075592041
    num_steps_sampled: 2184192
    num_steps_trained: 2184192
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.73725490196078
    gpu_util_percent0: 0.3482352941176471
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.0019607843137255
    vram_util_percent0: 0.10897015414890127
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42621
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1776685768693726
    mean_env_wait_ms: 1.635306667113864
    mean_inference_ms: 4.729978656299205
    mean_raw_obs_processing_ms: 0.5182705308801591
  time_since_restore: 385.02258944511414
  time_this_iter_s: 42.594332695007324
  time_total_s: 385.02258944511414
  timers:
    learn_throughput: 7043.772
    learn_time_ms: 34454.265
    sample_throughput: 29596.982
    sample_time_ms: 8199.755
    update_time_ms: 53.252
  timestamp: 1602419980
  timesteps_since_restore: 0
  timesteps_total: 2184192
  training_iteration: 9
  trial_id: ead49_00000
  
== Status ==
Memory usage on this node: 29.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ead49_00000 | RUNNING  | 172.17.0.4:42621 |      9 |          385.023 | 2184192 |   224.53 |              282.535 |              113.596 |            881.971 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ead49_00000:
  custom_metrics:
    time_step_max: 4306
    time_step_mean: 3572.595238095238
    time_step_min: 3217
  date: 2020-10-11_12-40-23
  done: false
  episode_len_mean: 879.6352128883774
  episode_reward_max: 282.5353535353533
  episode_reward_mean: 225.57170089851317
  episode_reward_min: 113.59595959595957
  episodes_this_iter: 237
  episodes_total: 2607
  experiment_id: d7f0dd186b6a414f93e92ed9326fb937
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 0.9991970419883728
        entropy_coeff: 0.00010000000000000002
        kl: 0.011285836808383465
        model: {}
        policy_loss: -0.02840618280073007
        total_loss: 12.980211448669433
        vf_explained_var: 0.9771373271942139
        vf_loss: 13.006460126241048
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.772549019607844
    gpu_util_percent0: 0.3715686274509804
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.9980392156862745
    vram_util_percent0: 0.10897015414890127
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42621
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1773484715686715
    mean_env_wait_ms: 1.6366231709831847
    mean_inference_ms: 4.707809221933746
    mean_raw_obs_processing_ms: 0.5170246681013101
  time_since_restore: 428.12159037590027
  time_this_iter_s: 43.09900093078613
  time_total_s: 428.12159037590027
  timers:
    learn_throughput: 7036.522
    learn_time_ms: 34489.768
    sample_throughput: 29625.996
    sample_time_ms: 8191.725
    update_time_ms: 57.766
  timestamp: 1602420023
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 10
  trial_id: ead49_00000
  
== Status ==
Memory usage on this node: 29.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ead49_00000 | RUNNING  | 172.17.0.4:42621 |     10 |          428.122 | 2426880 |  225.572 |              282.535 |              113.596 |            879.635 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ead49_00000:
  custom_metrics:
    time_step_max: 4306
    time_step_mean: 3566.162328271873
    time_step_min: 3209
  date: 2020-10-11_12-41-07
  done: false
  episode_len_mean: 877.4279705573081
  episode_reward_max: 282.68686868686854
  episode_reward_mean: 226.51160394693505
  episode_reward_min: 113.59595959595957
  episodes_this_iter: 246
  episodes_total: 2853
  experiment_id: d7f0dd186b6a414f93e92ed9326fb937
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 0.9589223345120748
        entropy_coeff: 0.00010000000000000002
        kl: 0.010765832786758741
        model: {}
        policy_loss: -0.028098660831650097
        total_loss: 15.165049362182618
        vf_explained_var: 0.9768654704093933
        vf_loss: 15.191090901692709
    num_steps_sampled: 2669568
    num_steps_trained: 2669568
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.66078431372549
    gpu_util_percent0: 0.32196078431372543
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.9960784313725486
    vram_util_percent0: 0.10897015414890127
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42621
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17706169741052769
    mean_env_wait_ms: 1.6379581311702904
    mean_inference_ms: 4.687624688974976
    mean_raw_obs_processing_ms: 0.5158705983379641
  time_since_restore: 471.42604970932007
  time_this_iter_s: 43.3044593334198
  time_total_s: 471.42604970932007
  timers:
    learn_throughput: 7031.921
    learn_time_ms: 34512.335
    sample_throughput: 30051.077
    sample_time_ms: 8075.85
    update_time_ms: 57.788
  timestamp: 1602420067
  timesteps_since_restore: 0
  timesteps_total: 2669568
  training_iteration: 11
  trial_id: ead49_00000
  
== Status ==
Memory usage on this node: 29.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ead49_00000 | RUNNING  | 172.17.0.4:42621 |     11 |          471.426 | 2669568 |  226.512 |              282.687 |              113.596 |            877.428 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ead49_00000:
  custom_metrics:
    time_step_max: 4306
    time_step_mean: 3552.9152595372107
    time_step_min: 3209
  date: 2020-10-11_12-41-50
  done: false
  episode_len_mean: 873.1235920852359
  episode_reward_max: 282.68686868686854
  episode_reward_mean: 228.5515889488491
  episode_reward_min: 113.59595959595957
  episodes_this_iter: 432
  episodes_total: 3285
  experiment_id: d7f0dd186b6a414f93e92ed9326fb937
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 0.944955027103424
        entropy_coeff: 0.00010000000000000002
        kl: 0.0102818105990688
        model: {}
        policy_loss: -0.027011997066438198
        total_loss: 17.27292366027832
        vf_explained_var: 0.9787108898162842
        vf_loss: 17.297973251342775
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.869999999999997
    gpu_util_percent0: 0.3645999999999999
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.9879999999999995
    vram_util_percent0: 0.10897015414890127
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42621
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1766317739557413
    mean_env_wait_ms: 1.6402644007144371
    mean_inference_ms: 4.6573885104305255
    mean_raw_obs_processing_ms: 0.5141737984351892
  time_since_restore: 514.3260390758514
  time_this_iter_s: 42.89998936653137
  time_total_s: 514.3260390758514
  timers:
    learn_throughput: 7020.927
    learn_time_ms: 34566.375
    sample_throughput: 30221.354
    sample_time_ms: 8030.348
    update_time_ms: 59.091
  timestamp: 1602420110
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 12
  trial_id: ead49_00000
  
== Status ==
Memory usage on this node: 29.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ead49_00000 | RUNNING  | 172.17.0.4:42621 |     12 |          514.326 | 2912256 |  228.552 |              282.687 |              113.596 |            873.124 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ead49_00000:
  custom_metrics:
    time_step_max: 4306
    time_step_mean: 3546.4855824682813
    time_step_min: 3209
  date: 2020-10-11_12-42-32
  done: false
  episode_len_mean: 871.0101265822785
  episode_reward_max: 282.68686868686854
  episode_reward_mean: 229.51157141030546
  episode_reward_min: 113.59595959595957
  episodes_this_iter: 270
  episodes_total: 3555
  experiment_id: d7f0dd186b6a414f93e92ed9326fb937
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 0.9395496209462484
        entropy_coeff: 0.00010000000000000002
        kl: 0.010890100585917632
        model: {}
        policy_loss: -0.02888241025308768
        total_loss: 11.797765286763509
        vf_explained_var: 0.980598509311676
        vf_loss: 11.82456340789795
    num_steps_sampled: 3154944
    num_steps_trained: 3154944
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.833333333333332
    gpu_util_percent0: 0.33647058823529413
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.9980392156862745
    vram_util_percent0: 0.10897015414890127
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42621
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17639823341184618
    mean_env_wait_ms: 1.64150903949448
    mean_inference_ms: 4.641423151704999
    mean_raw_obs_processing_ms: 0.5132594055672779
  time_since_restore: 556.8386833667755
  time_this_iter_s: 42.51264429092407
  time_total_s: 556.8386833667755
  timers:
    learn_throughput: 7018.933
    learn_time_ms: 34576.195
    sample_throughput: 30263.428
    sample_time_ms: 8019.184
    update_time_ms: 57.232
  timestamp: 1602420152
  timesteps_since_restore: 0
  timesteps_total: 3154944
  training_iteration: 13
  trial_id: ead49_00000
  
== Status ==
Memory usage on this node: 29.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ead49_00000 | RUNNING  | 172.17.0.4:42621 |     13 |          556.839 | 3154944 |  229.512 |              282.687 |              113.596 |             871.01 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ead49_00000:
  custom_metrics:
    time_step_max: 4306
    time_step_mean: 3539.434008097166
    time_step_min: 3197
  date: 2020-10-11_12-43-15
  done: false
  episode_len_mean: 869.0118670886076
  episode_reward_max: 283.7474747474743
  episode_reward_mean: 230.5879922644162
  episode_reward_min: 113.59595959595957
  episodes_this_iter: 237
  episodes_total: 3792
  experiment_id: d7f0dd186b6a414f93e92ed9326fb937
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 0.9231498757998149
        entropy_coeff: 0.00010000000000000002
        kl: 0.010513130885859331
        model: {}
        policy_loss: -0.0292847308019797
        total_loss: 10.523356183369954
        vf_explained_var: 0.9808980226516724
        vf_loss: 10.550630569458008
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.11
    gpu_util_percent0: 0.36719999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.006
    vram_util_percent0: 0.10897015414890127
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42621
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1762129142074376
    mean_env_wait_ms: 1.642569984854073
    mean_inference_ms: 4.628656487717797
    mean_raw_obs_processing_ms: 0.5125317266359993
  time_since_restore: 599.5330848693848
  time_this_iter_s: 42.69440150260925
  time_total_s: 599.5330848693848
  timers:
    learn_throughput: 7018.106
    learn_time_ms: 34580.27
    sample_throughput: 30233.72
    sample_time_ms: 8027.064
    update_time_ms: 57.841
  timestamp: 1602420195
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 14
  trial_id: ead49_00000
  
== Status ==
Memory usage on this node: 29.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ead49_00000 | RUNNING  | 172.17.0.4:42621 |     14 |          599.533 | 3397632 |  230.588 |              283.747 |              113.596 |            869.012 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ead49_00000:
  custom_metrics:
    time_step_max: 4306
    time_step_mean: 3532.4128835911742
    time_step_min: 3197
  date: 2020-10-11_12-43-59
  done: true
  episode_len_mean: 866.985111662531
  episode_reward_max: 283.7474747474743
  episode_reward_mean: 231.6192696192695
  episode_reward_min: 113.59595959595957
  episodes_this_iter: 238
  episodes_total: 4030
  experiment_id: d7f0dd186b6a414f93e92ed9326fb937
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 0.8996091763178508
        entropy_coeff: 0.00010000000000000002
        kl: 0.010627516855796179
        model: {}
        policy_loss: -0.029883176585038505
        total_loss: 9.574038696289062
        vf_explained_var: 0.9820027947425842
        vf_loss: 9.601886431376139
    num_steps_sampled: 3640320
    num_steps_trained: 3640320
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.492307692307694
    gpu_util_percent0: 0.35673076923076924
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.9884615384615385
    vram_util_percent0: 0.10897015414890127
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42621
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17604460070181022
    mean_env_wait_ms: 1.6435849969540404
    mean_inference_ms: 4.616802920436214
    mean_raw_obs_processing_ms: 0.5118444109392117
  time_since_restore: 642.5838487148285
  time_this_iter_s: 43.050763845443726
  time_total_s: 642.5838487148285
  timers:
    learn_throughput: 7009.086
    learn_time_ms: 34624.77
    sample_throughput: 30221.022
    sample_time_ms: 8030.437
    update_time_ms: 52.379
  timestamp: 1602420239
  timesteps_since_restore: 0
  timesteps_total: 3640320
  training_iteration: 15
  trial_id: ead49_00000
  
== Status ==
Memory usage on this node: 29.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ead49_00000 | TERMINATED |       |     15 |          642.584 | 3640320 |  231.619 |              283.747 |              113.596 |            866.985 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 29.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ead49_00000 | TERMINATED |       |     15 |          642.584 | 3640320 |  231.619 |              283.747 |              113.596 |            866.985 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


