2020-10-11 01:18:09,805	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_a0b75_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=35283)[0m 2020-10-11 01:18:12,658	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=35272)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35272)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35261)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35261)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35241)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35241)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35288)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35288)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35162)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35162)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35262)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35262)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35253)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35253)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35235)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35235)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35246)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35246)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35172)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35172)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35280)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35280)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35168)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35168)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35240)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35240)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35171)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35171)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35244)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35244)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35242)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35242)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35175)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35175)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35232)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35232)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35271)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35271)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35269)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35269)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35243)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35243)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35188)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35188)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35247)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35247)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35161)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35161)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35250)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35250)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35165)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35165)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35255)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35255)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35289)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35289)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35236)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35236)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35245)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35245)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35155)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35155)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35258)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35258)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35164)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35164)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35237)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35237)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35263)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35263)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35292)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35292)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35238)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35238)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35215)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35215)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35159)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35159)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35228)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35228)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35166)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35166)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35158)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35158)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35233)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35233)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35227)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35227)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35174)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35174)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35184)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35184)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35160)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35160)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35156)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35156)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35177)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35177)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35169)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35169)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35181)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35181)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35234)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35234)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35225)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35225)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35186)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35186)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35194)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35194)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35277)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35277)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35266)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35266)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35294)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35294)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35183)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35183)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35216)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35216)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35267)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35267)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35173)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35173)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35224)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35224)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35229)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35229)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35192)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35192)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35221)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35221)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35157)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35157)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35199)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35199)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35230)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35230)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35223)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35223)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35239)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35239)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35219)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35219)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35226)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35226)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35191)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35191)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35170)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35170)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35252)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35252)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35274)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35274)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35197)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35197)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35231)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35231)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_a0b75_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_01-18-57
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 2cfb6a8ea2c24c0299abb6534659c12e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1850671427590507
        entropy_coeff: 0.00010000000000000002
        kl: 0.003780785681945937
        model: {}
        policy_loss: -0.0035243150861268596
        total_loss: 628.5095520019531
        vf_explained_var: 0.16818061470985413
        vf_loss: 628.512451171875
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.09574468085107
    gpu_util_percent0: 0.3651063829787234
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0002127659574468085
    ram_util_percent: 6.297872340425529
    vram_util_percent0: 0.19347117645827366
    vram_util_percent1: 0.0009075233687267445
    vram_util_percent2: 0.0009075233687267445
  pid: 35283
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17318187653558348
    mean_env_wait_ms: 1.2041116209816292
    mean_inference_ms: 5.896203861666447
    mean_raw_obs_processing_ms: 0.4657421865813635
  time_since_restore: 39.144495487213135
  time_this_iter_s: 39.144495487213135
  time_total_s: 39.144495487213135
  timers:
    learn_throughput: 5430.063
    learn_time_ms: 29795.605
    sample_throughput: 17457.896
    sample_time_ms: 9267.555
    update_time_ms: 42.635
  timestamp: 1602379137
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: a0b75_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a0b75_00000 | RUNNING  | 172.17.0.4:35283 |      1 |          39.1445 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a0b75_00000:
  custom_metrics:
    time_step_max: 4136
    time_step_mean: 3599.2951388888887
    time_step_min: 3345
  date: 2020-10-11_01-19-35
  done: false
  episode_len_mean: 888.8955696202531
  episode_reward_max: 265.8686868686866
  episode_reward_mean: 218.6352768188209
  episode_reward_min: 139.35353535353494
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 2cfb6a8ea2c24c0299abb6534659c12e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1566115532602583
        entropy_coeff: 0.00010000000000000002
        kl: 0.006090493174269795
        model: {}
        policy_loss: -0.004030361372445311
        total_loss: 269.0631016322545
        vf_explained_var: 0.5869250893592834
        vf_loss: 269.06663731166293
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.793478260869566
    gpu_util_percent0: 0.3713043478260869
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.47391304347826
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35283
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16944922071979265
    mean_env_wait_ms: 1.1981341949724278
    mean_inference_ms: 5.691095688896766
    mean_raw_obs_processing_ms: 0.45729024175205424
  time_since_restore: 76.84468603134155
  time_this_iter_s: 37.70019054412842
  time_total_s: 76.84468603134155
  timers:
    learn_throughput: 5467.672
    learn_time_ms: 29590.656
    sample_throughput: 18553.578
    sample_time_ms: 8720.258
    update_time_ms: 36.7
  timestamp: 1602379175
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: a0b75_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a0b75_00000 | RUNNING  | 172.17.0.4:35283 |      2 |          76.8447 | 323584 |  218.635 |              265.869 |              139.354 |            888.896 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a0b75_00000:
  custom_metrics:
    time_step_max: 4136
    time_step_mean: 3596.020179372197
    time_step_min: 3287
  date: 2020-10-11_01-20-11
  done: false
  episode_len_mean: 884.337552742616
  episode_reward_max: 267.9898989898989
  episode_reward_mean: 219.816711417977
  episode_reward_min: 139.35353535353494
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 2cfb6a8ea2c24c0299abb6534659c12e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1498816694532121
        entropy_coeff: 0.00010000000000000002
        kl: 0.006100973812863231
        model: {}
        policy_loss: -0.0034932499235895064
        total_loss: 116.16643469674247
        vf_explained_var: 0.7947160005569458
        vf_loss: 116.16943032400948
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.040909090909093
    gpu_util_percent0: 0.42863636363636365
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.490909090909091
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35283
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16643746160840547
    mean_env_wait_ms: 1.195530395852882
    mean_inference_ms: 5.507508689591782
    mean_raw_obs_processing_ms: 0.4487887571962642
  time_since_restore: 113.45167350769043
  time_this_iter_s: 36.60698747634888
  time_total_s: 113.45167350769043
  timers:
    learn_throughput: 5494.186
    learn_time_ms: 29447.858
    sample_throughput: 19574.619
    sample_time_ms: 8265.397
    update_time_ms: 37.771
  timestamp: 1602379211
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: a0b75_00000
  
== Status ==
Memory usage on this node: 48.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a0b75_00000 | RUNNING  | 172.17.0.4:35283 |      3 |          113.452 | 485376 |  219.817 |               267.99 |              139.354 |            884.338 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a0b75_00000:
  custom_metrics:
    time_step_max: 4136
    time_step_mean: 3587.657284768212
    time_step_min: 3267
  date: 2020-10-11_01-20-49
  done: false
  episode_len_mean: 879.4588607594936
  episode_reward_max: 271.0202020202017
  episode_reward_mean: 220.77758598644655
  episode_reward_min: 139.35353535353494
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 2cfb6a8ea2c24c0299abb6534659c12e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1414874025753565
        entropy_coeff: 0.00010000000000000002
        kl: 0.006684138273288097
        model: {}
        policy_loss: -0.006561939516229488
        total_loss: 77.48602403913226
        vf_explained_var: 0.8552579879760742
        vf_loss: 77.4920300074986
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.706818181818182
    gpu_util_percent0: 0.4295454545454546
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486363636363635
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35283
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1642854640768576
    mean_env_wait_ms: 1.194549240099875
    mean_inference_ms: 5.366716525879694
    mean_raw_obs_processing_ms: 0.44187052751072114
  time_since_restore: 150.62961959838867
  time_this_iter_s: 37.17794609069824
  time_total_s: 150.62961959838867
  timers:
    learn_throughput: 5481.806
    learn_time_ms: 29514.359
    sample_throughput: 20111.486
    sample_time_ms: 8044.756
    update_time_ms: 36.948
  timestamp: 1602379249
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: a0b75_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a0b75_00000 | RUNNING  | 172.17.0.4:35283 |      4 |           150.63 | 647168 |  220.778 |               271.02 |              139.354 |            879.459 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a0b75_00000:
  custom_metrics:
    time_step_max: 4136
    time_step_mean: 3582.8530183727034
    time_step_min: 3267
  date: 2020-10-11_01-21-26
  done: false
  episode_len_mean: 875.853164556962
  episode_reward_max: 271.0202020202017
  episode_reward_mean: 221.7093082725992
  episode_reward_min: 139.35353535353494
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 2cfb6a8ea2c24c0299abb6534659c12e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1091437935829163
        entropy_coeff: 0.00010000000000000002
        kl: 0.006679240780483399
        model: {}
        policy_loss: -0.004108348742842541
        total_loss: 67.9034069606236
        vf_explained_var: 0.8798657059669495
        vf_loss: 67.9069595336914
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.28
    gpu_util_percent0: 0.35266666666666663
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.495555555555557
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35283
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1626080353390587
    mean_env_wait_ms: 1.195004562935168
    mean_inference_ms: 5.2578320571520925
    mean_raw_obs_processing_ms: 0.43627314280464013
  time_since_restore: 187.66572332382202
  time_this_iter_s: 37.03610372543335
  time_total_s: 187.66572332382202
  timers:
    learn_throughput: 5474.207
    learn_time_ms: 29555.33
    sample_throughput: 20519.284
    sample_time_ms: 7884.875
    update_time_ms: 33.487
  timestamp: 1602379286
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: a0b75_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a0b75_00000 | RUNNING  | 172.17.0.4:35283 |      5 |          187.666 | 808960 |  221.709 |               271.02 |              139.354 |            875.853 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a0b75_00000:
  custom_metrics:
    time_step_max: 4351
    time_step_mean: 3579.145910780669
    time_step_min: 3267
  date: 2020-10-11_01-22-03
  done: false
  episode_len_mean: 868.0353260869565
  episode_reward_max: 271.0202020202017
  episode_reward_mean: 223.16680390865156
  episode_reward_min: 106.77777777777764
  episodes_this_iter: 314
  episodes_total: 1104
  experiment_id: 2cfb6a8ea2c24c0299abb6534659c12e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.097239417689187
        entropy_coeff: 0.00010000000000000002
        kl: 0.006896635883354715
        model: {}
        policy_loss: -0.004682431508886761
        total_loss: 71.13115746634347
        vf_explained_var: 0.9139165878295898
        vf_loss: 71.13525990077427
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.064444444444444
    gpu_util_percent0: 0.3862222222222222
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888889
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35283
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1603254556829833
    mean_env_wait_ms: 1.1980640391223718
    mean_inference_ms: 5.109394607573508
    mean_raw_obs_processing_ms: 0.42872127857417625
  time_since_restore: 225.02013182640076
  time_this_iter_s: 37.354408502578735
  time_total_s: 225.02013182640076
  timers:
    learn_throughput: 5462.012
    learn_time_ms: 29621.319
    sample_throughput: 20774.42
    sample_time_ms: 7788.039
    update_time_ms: 35.424
  timestamp: 1602379323
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: a0b75_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a0b75_00000 | RUNNING  | 172.17.0.4:35283 |      6 |           225.02 | 970752 |  223.167 |               271.02 |              106.778 |            868.035 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a0b75_00000:
  custom_metrics:
    time_step_max: 4351
    time_step_mean: 3576.002427184466
    time_step_min: 3267
  date: 2020-10-11_01-22-40
  done: false
  episode_len_mean: 865.0901898734177
  episode_reward_max: 271.0202020202017
  episode_reward_mean: 223.94298203554516
  episode_reward_min: 106.77777777777764
  episodes_this_iter: 160
  episodes_total: 1264
  experiment_id: 2cfb6a8ea2c24c0299abb6534659c12e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0946285894938879
        entropy_coeff: 0.00010000000000000002
        kl: 0.005858542264572212
        model: {}
        policy_loss: -0.0029121144273501287
        total_loss: 45.090723855154856
        vf_explained_var: 0.9174586534500122
        vf_loss: 45.09315953935896
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.3
    gpu_util_percent0: 0.335909090909091
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35283
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15947142560858668
    mean_env_wait_ms: 1.1993774324733635
    mean_inference_ms: 5.054684705355038
    mean_raw_obs_processing_ms: 0.4259225994889292
  time_since_restore: 262.10357451438904
  time_this_iter_s: 37.08344268798828
  time_total_s: 262.10357451438904
  timers:
    learn_throughput: 5459.045
    learn_time_ms: 29637.416
    sample_throughput: 20979.477
    sample_time_ms: 7711.918
    update_time_ms: 36.21
  timestamp: 1602379360
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: a0b75_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a0b75_00000 | RUNNING  | 172.17.0.4:35283 |      7 |          262.104 | 1132544 |  223.943 |               271.02 |              106.778 |             865.09 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a0b75_00000:
  custom_metrics:
    time_step_max: 4351
    time_step_mean: 3569.3464849354377
    time_step_min: 3252
  date: 2020-10-11_01-23-17
  done: false
  episode_len_mean: 862.1455696202531
  episode_reward_max: 273.2929292929295
  episode_reward_mean: 224.8220389549502
  episode_reward_min: 106.77777777777764
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 2cfb6a8ea2c24c0299abb6534659c12e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0822338717324393
        entropy_coeff: 0.00010000000000000002
        kl: 0.00679927971214056
        model: {}
        policy_loss: -0.005194072873564437
        total_loss: 39.58646610804966
        vf_explained_var: 0.9276193380355835
        vf_loss: 39.59108897617885
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.17777777777778
    gpu_util_percent0: 0.45400000000000007
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888889
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35283
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15875034476975725
    mean_env_wait_ms: 1.200572681267901
    mean_inference_ms: 5.007933122255706
    mean_raw_obs_processing_ms: 0.42352721958408174
  time_since_restore: 299.14327812194824
  time_this_iter_s: 37.039703607559204
  time_total_s: 299.14327812194824
  timers:
    learn_throughput: 5455.588
    learn_time_ms: 29656.196
    sample_throughput: 21186.67
    sample_time_ms: 7636.5
    update_time_ms: 43.095
  timestamp: 1602379397
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: a0b75_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a0b75_00000 | RUNNING  | 172.17.0.4:35283 |      8 |          299.143 | 1294336 |  224.822 |              273.293 |              106.778 |            862.146 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a0b75_00000:
  custom_metrics:
    time_step_max: 4351
    time_step_mean: 3563.465206185567
    time_step_min: 3252
  date: 2020-10-11_01-23-55
  done: false
  episode_len_mean: 858.9310126582278
  episode_reward_max: 273.2929292929295
  episode_reward_mean: 225.91836082342397
  episode_reward_min: 106.77777777777764
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 2cfb6a8ea2c24c0299abb6534659c12e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0652786237852914
        entropy_coeff: 0.00010000000000000002
        kl: 0.0070180572968508515
        model: {}
        policy_loss: -0.004239965757733444
        total_loss: 33.12869930267334
        vf_explained_var: 0.9341571927070618
        vf_loss: 33.13234451838902
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.454545454545457
    gpu_util_percent0: 0.3934090909090909
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.495454545454546
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35283
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15812685724150874
    mean_env_wait_ms: 1.201763077140965
    mean_inference_ms: 4.966956645520788
    mean_raw_obs_processing_ms: 0.4213740929770526
  time_since_restore: 336.28642225265503
  time_this_iter_s: 37.14314413070679
  time_total_s: 336.28642225265503
  timers:
    learn_throughput: 5454.229
    learn_time_ms: 29663.587
    sample_throughput: 21285.953
    sample_time_ms: 7600.881
    update_time_ms: 42.606
  timestamp: 1602379435
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: a0b75_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a0b75_00000 | RUNNING  | 172.17.0.4:35283 |      9 |          336.286 | 1456128 |  225.918 |              273.293 |              106.778 |            858.931 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a0b75_00000:
  custom_metrics:
    time_step_max: 4351
    time_step_mean: 3549.9862788144897
    time_step_min: 3246
  date: 2020-10-11_01-24-32
  done: false
  episode_len_mean: 852.66
  episode_reward_max: 285.5656565656571
  episode_reward_mean: 227.99989079989064
  episode_reward_min: 106.77777777777764
  episodes_this_iter: 270
  episodes_total: 1850
  experiment_id: 2cfb6a8ea2c24c0299abb6534659c12e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0373287456376212
        entropy_coeff: 0.00010000000000000002
        kl: 0.006215786594631416
        model: {}
        policy_loss: -0.005554730733690251
        total_loss: 35.66622679574149
        vf_explained_var: 0.952525794506073
        vf_loss: 35.67126328604562
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.86888888888889
    gpu_util_percent0: 0.3966666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4799999999999995
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35283
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1572749874583803
    mean_env_wait_ms: 1.2043230805399558
    mean_inference_ms: 4.909682261170214
    mean_raw_obs_processing_ms: 0.41835915468261387
  time_since_restore: 373.41818404197693
  time_this_iter_s: 37.1317617893219
  time_total_s: 373.41818404197693
  timers:
    learn_throughput: 5449.57
    learn_time_ms: 29688.95
    sample_throughput: 21422.27
    sample_time_ms: 7552.514
    update_time_ms: 41.877
  timestamp: 1602379472
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: a0b75_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a0b75_00000 | RUNNING  | 172.17.0.4:35283 |     10 |          373.418 | 1617920 |      228 |              285.566 |              106.778 |             852.66 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a0b75_00000:
  custom_metrics:
    time_step_max: 4351
    time_step_mean: 3540.192003948667
    time_step_min: 3214
  date: 2020-10-11_01-25-09
  done: false
  episode_len_mean: 848.0569620253165
  episode_reward_max: 285.5656565656571
  episode_reward_mean: 229.40885977594823
  episode_reward_min: 106.77777777777764
  episodes_this_iter: 204
  episodes_total: 2054
  experiment_id: 2cfb6a8ea2c24c0299abb6534659c12e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0451579008783614
        entropy_coeff: 0.00010000000000000002
        kl: 0.006087222502433828
        model: {}
        policy_loss: -0.0042065426989990684
        total_loss: 22.285853113446915
        vf_explained_var: 0.9586721658706665
        vf_loss: 22.28955500466483
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.043181818181818
    gpu_util_percent0: 0.3893181818181819
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.495454545454546
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35283
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1567028636727758
    mean_env_wait_ms: 1.2059694298313353
    mean_inference_ms: 4.873260347846693
    mean_raw_obs_processing_ms: 0.4164478365006501
  time_since_restore: 410.08782386779785
  time_this_iter_s: 36.66963982582092
  time_total_s: 410.08782386779785
  timers:
    learn_throughput: 5461.042
    learn_time_ms: 29626.581
    sample_throughput: 21987.479
    sample_time_ms: 7358.37
    update_time_ms: 41.274
  timestamp: 1602379509
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: a0b75_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a0b75_00000 | RUNNING  | 172.17.0.4:35283 |     11 |          410.088 | 1779712 |  229.409 |              285.566 |              106.778 |            848.057 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a0b75_00000:
  custom_metrics:
    time_step_max: 4351
    time_step_mean: 3533.6497252747254
    time_step_min: 3214
  date: 2020-10-11_01-25-46
  done: false
  episode_len_mean: 844.631555153707
  episode_reward_max: 285.5656565656571
  episode_reward_mean: 230.3584534312381
  episode_reward_min: 106.77777777777764
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 2cfb6a8ea2c24c0299abb6534659c12e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0294900621686662
        entropy_coeff: 0.00010000000000000002
        kl: 0.005456243009705629
        model: {}
        policy_loss: -0.004540032305937659
        total_loss: 18.8357355935233
        vf_explained_var: 0.961233913898468
        vf_loss: 18.839833123343332
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.565909090909088
    gpu_util_percent0: 0.36113636363636364
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.493181818181819
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35283
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15632573210454803
    mean_env_wait_ms: 1.2072915735562602
    mean_inference_ms: 4.848707731064401
    mean_raw_obs_processing_ms: 0.4151674556686981
  time_since_restore: 447.38928866386414
  time_this_iter_s: 37.301464796066284
  time_total_s: 447.38928866386414
  timers:
    learn_throughput: 5453.043
    learn_time_ms: 29670.04
    sample_throughput: 22224.224
    sample_time_ms: 7279.984
    update_time_ms: 41.968
  timestamp: 1602379546
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: a0b75_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a0b75_00000 | RUNNING  | 172.17.0.4:35283 |     12 |          447.389 | 1941504 |  230.358 |              285.566 |              106.778 |            844.632 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a0b75_00000:
  custom_metrics:
    time_step_max: 4351
    time_step_mean: 3527.4120409906063
    time_step_min: 3214
  date: 2020-10-11_01-26-23
  done: false
  episode_len_mean: 841.4396624472574
  episode_reward_max: 285.5656565656571
  episode_reward_mean: 231.21768316072098
  episode_reward_min: 106.77777777777764
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: 2cfb6a8ea2c24c0299abb6534659c12e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.9987459097589765
        entropy_coeff: 0.00010000000000000002
        kl: 0.006640322473166245
        model: {}
        policy_loss: -0.005973982302488626
        total_loss: 18.222550528390066
        vf_explained_var: 0.9656186103820801
        vf_loss: 18.22796058654785
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.85111111111111
    gpu_util_percent0: 0.37711111111111106
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.493333333333333
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35283
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1559881981128447
    mean_env_wait_ms: 1.20865616444295
    mean_inference_ms: 4.826327198953552
    mean_raw_obs_processing_ms: 0.413973750179702
  time_since_restore: 484.45659947395325
  time_this_iter_s: 37.06731081008911
  time_total_s: 484.45659947395325
  timers:
    learn_throughput: 5441.543
    learn_time_ms: 29732.743
    sample_throughput: 22298.007
    sample_time_ms: 7255.895
    update_time_ms: 47.913
  timestamp: 1602379583
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: a0b75_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a0b75_00000 | RUNNING  | 172.17.0.4:35283 |     13 |          484.457 | 2103296 |  231.218 |              285.566 |              106.778 |             841.44 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a0b75_00000:
  custom_metrics:
    time_step_max: 4351
    time_step_mean: 3517.481746330448
    time_step_min: 3214
  date: 2020-10-11_01-27-01
  done: false
  episode_len_mean: 835.7243947858473
  episode_reward_max: 285.5656565656571
  episode_reward_mean: 232.85683652164087
  episode_reward_min: 106.77777777777764
  episodes_this_iter: 315
  episodes_total: 2685
  experiment_id: 2cfb6a8ea2c24c0299abb6534659c12e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.973167074578149
        entropy_coeff: 0.00010000000000000002
        kl: 0.005407357654933419
        model: {}
        policy_loss: -0.0039664504085002205
        total_loss: 22.00582844870431
        vf_explained_var: 0.9706190824508667
        vf_loss: 22.009351185389928
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.58181818181818
    gpu_util_percent0: 0.3890909090909091
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488636363636363
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35283
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15540446497854024
    mean_env_wait_ms: 1.2113830125592961
    mean_inference_ms: 4.787717398347845
    mean_raw_obs_processing_ms: 0.41194765468871475
  time_since_restore: 521.8225498199463
  time_this_iter_s: 37.36595034599304
  time_total_s: 521.8225498199463
  timers:
    learn_throughput: 5438.097
    learn_time_ms: 29751.583
    sample_throughput: 22302.602
    sample_time_ms: 7254.4
    update_time_ms: 48.229
  timestamp: 1602379621
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: a0b75_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a0b75_00000 | RUNNING  | 172.17.0.4:35283 |     14 |          521.823 | 2265088 |  232.857 |              285.566 |              106.778 |            835.724 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a0b75_00000:
  custom_metrics:
    time_step_max: 4351
    time_step_mean: 3513.614346590909
    time_step_min: 3214
  date: 2020-10-11_01-27-38
  done: false
  episode_len_mean: 833.1575246132209
  episode_reward_max: 285.5656565656571
  episode_reward_mean: 233.59814388611844
  episode_reward_min: 106.77777777777764
  episodes_this_iter: 159
  episodes_total: 2844
  experiment_id: 2cfb6a8ea2c24c0299abb6534659c12e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.9685512908867427
        entropy_coeff: 0.00010000000000000002
        kl: 0.005958456346499068
        model: {}
        policy_loss: -0.005853109735263777
        total_loss: 17.9513977595738
        vf_explained_var: 0.9651384353637695
        vf_loss: 17.956751550946915
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.551111111111112
    gpu_util_percent0: 0.3980000000000001
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.493333333333333
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35283
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1551509880438537
    mean_env_wait_ms: 1.212629644803908
    mean_inference_ms: 4.770784719344726
    mean_raw_obs_processing_ms: 0.4110564979998982
  time_since_restore: 558.792852640152
  time_this_iter_s: 36.97030282020569
  time_total_s: 558.792852640152
  timers:
    learn_throughput: 5439.929
    learn_time_ms: 29741.563
    sample_throughput: 22299.945
    sample_time_ms: 7255.265
    update_time_ms: 50.087
  timestamp: 1602379658
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: a0b75_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a0b75_00000 | RUNNING  | 172.17.0.4:35283 |     15 |          558.793 | 2426880 |  233.598 |              285.566 |              106.778 |            833.158 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a0b75_00000:
  custom_metrics:
    time_step_max: 4351
    time_step_mean: 3509.091123066577
    time_step_min: 3214
  date: 2020-10-11_01-28-15
  done: false
  episode_len_mean: 830.875416389074
  episode_reward_max: 285.5656565656571
  episode_reward_mean: 234.3093224045921
  episode_reward_min: 106.77777777777764
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: 2cfb6a8ea2c24c0299abb6534659c12e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.9572034137589591
        entropy_coeff: 0.00010000000000000002
        kl: 0.005209679449243205
        model: {}
        policy_loss: -0.005433289222959762
        total_loss: 15.782883099147252
        vf_explained_var: 0.9675723314285278
        vf_loss: 15.787890706743513
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.436363636363634
    gpu_util_percent0: 0.4002272727272728
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.504545454545456
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35283
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15491799995804414
    mean_env_wait_ms: 1.2138134751354501
    mean_inference_ms: 4.755160950846546
    mean_raw_obs_processing_ms: 0.4102141302748913
  time_since_restore: 595.6729879379272
  time_this_iter_s: 36.88013529777527
  time_total_s: 595.6729879379272
  timers:
    learn_throughput: 5443.487
    learn_time_ms: 29722.127
    sample_throughput: 22380.05
    sample_time_ms: 7229.296
    update_time_ms: 47.831
  timestamp: 1602379695
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: a0b75_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a0b75_00000 | RUNNING  | 172.17.0.4:35283 |     16 |          595.673 | 2588672 |  234.309 |              285.566 |              106.778 |            830.875 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a0b75_00000:
  custom_metrics:
    time_step_max: 4351
    time_step_mean: 3502.2454851545763
    time_step_min: 3214
  date: 2020-10-11_01-28-52
  done: true
  episode_len_mean: 826.8227617602428
  episode_reward_max: 285.5656565656571
  episode_reward_mean: 235.26409772995498
  episode_reward_min: 106.77777777777764
  episodes_this_iter: 293
  episodes_total: 3295
  experiment_id: 2cfb6a8ea2c24c0299abb6534659c12e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.9150391902242389
        entropy_coeff: 0.00010000000000000002
        kl: 0.0047774008209151885
        model: {}
        policy_loss: -0.004342857509202856
        total_loss: 28.7151095526559
        vf_explained_var: 0.9630002975463867
        vf_loss: 28.719065529959543
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.82888888888889
    gpu_util_percent0: 0.4026666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888889
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35283
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15454499537709526
    mean_env_wait_ms: 1.2161219253899527
    mean_inference_ms: 4.729418098218311
    mean_raw_obs_processing_ms: 0.40885910824596355
  time_since_restore: 632.8903365135193
  time_this_iter_s: 37.21734857559204
  time_total_s: 632.8903365135193
  timers:
    learn_throughput: 5442.71
    learn_time_ms: 29726.368
    sample_throughput: 22355.07
    sample_time_ms: 7237.374
    update_time_ms: 47.829
  timestamp: 1602379732
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: a0b75_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a0b75_00000 | TERMINATED |       |     17 |           632.89 | 2750464 |  235.264 |              285.566 |              106.778 |            826.823 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


2020-10-11 01:28:52,917	WARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff7b2861ac01000000.
== Status ==
Memory usage on this node: 48.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a0b75_00000 | TERMINATED |       |     17 |           632.89 | 2750464 |  235.264 |              285.566 |              106.778 |            826.823 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


[2m[36m(pid=35170)[0m 2020-10-11 01:28:52,893	ERROR worker.py:372 -- SystemExit was raised from the worker
[2m[36m(pid=35170)[0m Traceback (most recent call last):
[2m[36m(pid=35170)[0m   File "python/ray/_raylet.pyx", line 483, in ray._raylet.execute_task
[2m[36m(pid=35170)[0m   File "python/ray/_raylet.pyx", line 484, in ray._raylet.execute_task
[2m[36m(pid=35170)[0m   File "python/ray/_raylet.pyx", line 438, in ray._raylet.execute_task.function_executor
[2m[36m(pid=35170)[0m   File "/root/miniconda3/lib/python3.8/site-packages/ray/function_manager.py", line 553, in actor_method_executor
[2m[36m(pid=35170)[0m     return method(actor, *args, **kwargs)
[2m[36m(pid=35170)[0m   File "/root/miniconda3/lib/python3.8/site-packages/ray/actor.py", line 929, in __ray_terminate__
[2m[36m(pid=35170)[0m     ray.actor.exit_actor()
[2m[36m(pid=35170)[0m   File "/root/miniconda3/lib/python3.8/site-packages/ray/actor.py", line 996, in exit_actor
[2m[36m(pid=35170)[0m     raise exit
[2m[36m(pid=35170)[0m SystemExit: 0
[2m[36m(pid=35170)[0m 
[2m[36m(pid=35170)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=35170)[0m 
[2m[36m(pid=35170)[0m Traceback (most recent call last):
[2m[36m(pid=35170)[0m   File "python/ray/_raylet.pyx", line 553, in ray._raylet.task_execution_handler
[2m[36m(pid=35170)[0m   File "python/ray/_raylet.pyx", line 440, in ray._raylet.execute_task
[2m[36m(pid=35170)[0m   File "python/ray/_raylet.pyx", line 479, in ray._raylet.execute_task
[2m[36m(pid=35170)[0m   File "python/ray/includes/libcoreworker.pxi", line 42, in ray._raylet.ProfileEvent.__exit__
[2m[36m(pid=35170)[0m   File "/root/miniconda3/lib/python3.8/json/__init__.py", line 231, in dumps
[2m[36m(pid=35170)[0m     return _default_encoder.encode(obj)
[2m[36m(pid=35170)[0m   File "/root/miniconda3/lib/python3.8/json/encoder.py", line 199, in encode
[2m[36m(pid=35170)[0m     chunks = self.iterencode(o, _one_shot=True)
[2m[36m(pid=35170)[0m   File "/root/miniconda3/lib/python3.8/json/encoder.py", line 224, in iterencode
[2m[36m(pid=35170)[0m     _repr=float.__repr__, _inf=INFINITY, _neginf=-INFINITY):
[2m[36m(pid=35170)[0m   File "/root/miniconda3/lib/python3.8/site-packages/ray/worker.py", line 369, in sigterm_handler
[2m[36m(pid=35170)[0m     sys.exit(1)
[2m[36m(pid=35170)[0m SystemExit: 1
