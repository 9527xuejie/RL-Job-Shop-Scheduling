2020-10-10 19:35:44,651	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_cadfc_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=12737)[0m 2020-10-10 19:35:47,616	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=12623)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12623)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12709)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12709)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12743)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12743)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12741)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12741)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12701)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12701)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12677)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12677)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12730)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12730)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12714)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12714)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12699)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12699)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12694)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12694)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12691)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12691)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12689)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12689)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12705)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12705)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12716)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12716)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12703)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12703)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12702)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12702)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12744)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12744)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12711)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12711)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12724)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12724)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12688)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12688)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12612)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12612)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12626)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12626)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12606)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12606)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12681)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12681)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12692)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12692)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12684)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12684)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12674)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12674)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12659)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12659)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12731)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12731)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12635)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12635)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12720)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12720)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12642)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12642)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12615)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12615)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12608)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12608)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12686)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12686)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12673)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12673)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12732)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12732)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12680)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12680)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12637)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12637)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12620)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12620)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12624)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12624)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12614)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12614)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12631)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12631)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12725)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12725)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12639)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12639)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12604)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12604)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12609)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12609)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12672)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12672)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12687)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12687)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12695)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12695)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12728)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12728)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12605)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12605)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12610)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12610)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12671)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12671)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12698)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12698)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12685)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12685)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12619)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12619)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12628)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12628)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12634)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12634)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12667)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12667)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12708)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12708)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12617)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12617)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12666)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12666)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12641)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12641)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12690)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12690)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12683)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12683)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12621)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12621)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12647)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12647)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12722)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12722)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12622)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12622)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12643)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12643)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12663)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12663)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12616)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12616)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12669)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12669)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12676)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12676)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12607)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12607)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12670)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12670)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12662)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12662)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12611)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12611)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_cadfc_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-10_19-36-26
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: cd0ec222c7014d9f98ef47f997b97438
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1852084142821175
        entropy_coeff: 0.00010000000000000002
        kl: 0.0041837623076779505
        model: {}
        policy_loss: -0.004395543364807963
        total_loss: 19.85631833757673
        vf_explained_var: 0.45542749762535095
        vf_loss: 19.85999502454485
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.648717948717948
    gpu_util_percent0: 0.2720512820512821
    gpu_util_percent1: 0.0002564102564102564
    gpu_util_percent2: 0.0002564102564102564
    ram_util_percent: 6.287179487179488
    vram_util_percent0: 0.19117659425957234
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 12737
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16864367346956466
    mean_env_wait_ms: 1.180578380795532
    mean_inference_ms: 5.7724942775301145
    mean_raw_obs_processing_ms: 0.4503981409782463
  time_since_restore: 33.55749154090881
  time_this_iter_s: 33.55749154090881
  time_total_s: 33.55749154090881
  timers:
    learn_throughput: 6722.579
    learn_time_ms: 24066.953
    sample_throughput: 17166.926
    sample_time_ms: 9424.635
    update_time_ms: 28.658
  timestamp: 1602358586
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: cadfc_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cadfc_00000 | RUNNING  | 172.17.0.4:12737 |      1 |          33.5575 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cadfc_00000:
  custom_metrics:
    time_step_max: 4072
    time_step_mean: 3609.7256944444443
    time_step_min: 3258
  date: 2020-10-10_19-36-58
  done: false
  episode_len_mean: 882.2816455696203
  episode_reward_max: 272.38383838383845
  episode_reward_mean: 217.53679197033605
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: cd0ec222c7014d9f98ef47f997b97438
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1561597670827592
        entropy_coeff: 0.00010000000000000002
        kl: 0.006612227564411504
        model: {}
        policy_loss: -0.004669488062583176
        total_loss: 12.03408418382917
        vf_explained_var: 0.7770267128944397
        vf_loss: 12.038208212171282
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.24473684210526
    gpu_util_percent0: 0.2971052631578947
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.46578947368421
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 12737
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16459290474079924
    mean_env_wait_ms: 1.1832445987385207
    mean_inference_ms: 5.520610507301305
    mean_raw_obs_processing_ms: 0.44033787470051994
  time_since_restore: 65.39327716827393
  time_this_iter_s: 31.835785627365112
  time_total_s: 65.39327716827393
  timers:
    learn_throughput: 6767.706
    learn_time_ms: 23906.474
    sample_throughput: 18571.885
    sample_time_ms: 8711.663
    update_time_ms: 36.284
  timestamp: 1602358618
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: cadfc_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cadfc_00000 | RUNNING  | 172.17.0.4:12737 |      2 |          65.3933 | 323584 |  217.537 |              272.384 |              145.717 |            882.282 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cadfc_00000:
  custom_metrics:
    time_step_max: 4072
    time_step_mean: 3598.5022421524664
    time_step_min: 3258
  date: 2020-10-10_19-37-30
  done: false
  episode_len_mean: 872.4662447257384
  episode_reward_max: 272.38383838383845
  episode_reward_mean: 219.49418232962518
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: cd0ec222c7014d9f98ef47f997b97438
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1367451889174325
        entropy_coeff: 0.00010000000000000002
        kl: 0.008535952573376042
        model: {}
        policy_loss: -0.005150384980619752
        total_loss: 13.599771567753383
        vf_explained_var: 0.8601665496826172
        vf_loss: 13.60418210710798
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.716216216216218
    gpu_util_percent0: 0.2127027027027027
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491891891891891
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 12737
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1622385974228681
    mean_env_wait_ms: 1.186398264069763
    mean_inference_ms: 5.344210942095627
    mean_raw_obs_processing_ms: 0.4338486544228532
  time_since_restore: 97.00580334663391
  time_this_iter_s: 31.612526178359985
  time_total_s: 97.00580334663391
  timers:
    learn_throughput: 6752.555
    learn_time_ms: 23960.116
    sample_throughput: 19498.744
    sample_time_ms: 8297.56
    update_time_ms: 32.897
  timestamp: 1602358650
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: cadfc_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cadfc_00000 | RUNNING  | 172.17.0.4:12737 |      3 |          97.0058 | 485376 |  219.494 |              272.384 |              145.717 |            872.466 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cadfc_00000:
  custom_metrics:
    time_step_max: 4270
    time_step_mean: 3594.975165562914
    time_step_min: 3240
  date: 2020-10-10_19-38-01
  done: false
  episode_len_mean: 863.7373417721519
  episode_reward_max: 279.6565656565654
  episode_reward_mean: 220.7322752844903
  episode_reward_min: 119.05050505050464
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: cd0ec222c7014d9f98ef47f997b97438
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1092459985188075
        entropy_coeff: 0.00010000000000000002
        kl: 0.005715708913547652
        model: {}
        policy_loss: -0.004874360556381622
        total_loss: 15.537880420684814
        vf_explained_var: 0.8963156342506409
        vf_loss: 15.542293889181954
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.470270270270266
    gpu_util_percent0: 0.29108108108108105
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486486486486486
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 12737
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1605609944622923
    mean_env_wait_ms: 1.19052173078073
    mean_inference_ms: 5.217880675312182
    mean_raw_obs_processing_ms: 0.42869652686269755
  time_since_restore: 128.27230167388916
  time_this_iter_s: 31.26649832725525
  time_total_s: 128.27230167388916
  timers:
    learn_throughput: 6766.801
    learn_time_ms: 23909.672
    sample_throughput: 20025.162
    sample_time_ms: 8079.435
    update_time_ms: 33.782
  timestamp: 1602358681
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: cadfc_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cadfc_00000 | RUNNING  | 172.17.0.4:12737 |      4 |          128.272 | 647168 |  220.732 |              279.657 |              119.051 |            863.737 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cadfc_00000:
  custom_metrics:
    time_step_max: 4270
    time_step_mean: 3586.156906077348
    time_step_min: 3240
  date: 2020-10-10_19-38-33
  done: false
  episode_len_mean: 848.1757770632369
  episode_reward_max: 279.6565656565654
  episode_reward_mean: 222.59349118191545
  episode_reward_min: 119.05050505050464
  episodes_this_iter: 301
  episodes_total: 933
  experiment_id: cd0ec222c7014d9f98ef47f997b97438
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0822963118553162
        entropy_coeff: 0.00010000000000000002
        kl: 0.004587719050635185
        model: {}
        policy_loss: -0.004281712471440967
        total_loss: 21.47432586124965
        vf_explained_var: 0.9357311129570007
        vf_loss: 21.478257179260254
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.605405405405406
    gpu_util_percent0: 0.3013513513513514
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.481081081081081
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 12737
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1585623097394956
    mean_env_wait_ms: 1.1994796457287862
    mean_inference_ms: 5.061772134555684
    mean_raw_obs_processing_ms: 0.42208764093703555
  time_since_restore: 159.4777626991272
  time_this_iter_s: 31.205461025238037
  time_total_s: 159.4777626991272
  timers:
    learn_throughput: 6778.4
    learn_time_ms: 23868.758
    sample_throughput: 20357.341
    sample_time_ms: 7947.6
    update_time_ms: 30.95
  timestamp: 1602358713
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: cadfc_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cadfc_00000 | RUNNING  | 172.17.0.4:12737 |      5 |          159.478 | 808960 |  222.593 |              279.657 |              119.051 |            848.176 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cadfc_00000:
  custom_metrics:
    time_step_max: 4270
    time_step_mean: 3584.2291280148424
    time_step_min: 3240
  date: 2020-10-10_19-39-04
  done: false
  episode_len_mean: 841.0650994575045
  episode_reward_max: 279.6565656565654
  episode_reward_mean: 223.25607795860947
  episode_reward_min: 119.05050505050464
  episodes_this_iter: 173
  episodes_total: 1106
  experiment_id: cd0ec222c7014d9f98ef47f997b97438
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 1.0675264767238073
        entropy_coeff: 0.00010000000000000002
        kl: 0.00513859954662621
        model: {}
        policy_loss: -0.0037233642183959353
        total_loss: 15.525576319013323
        vf_explained_var: 0.9425222277641296
        vf_loss: 15.529149532318115
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.58378378378378
    gpu_util_percent0: 0.2556756756756757
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494594594594595
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 12737
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15774974788140364
    mean_env_wait_ms: 1.2034136610721198
    mean_inference_ms: 5.000218912905361
    mean_raw_obs_processing_ms: 0.4195018916959382
  time_since_restore: 190.9416971206665
  time_this_iter_s: 31.463934421539307
  time_total_s: 190.9416971206665
  timers:
    learn_throughput: 6775.21
    learn_time_ms: 23879.997
    sample_throughput: 20575.89
    sample_time_ms: 7863.184
    update_time_ms: 32.075
  timestamp: 1602358744
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: cadfc_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cadfc_00000 | RUNNING  | 172.17.0.4:12737 |      6 |          190.942 | 970752 |  223.256 |              279.657 |              119.051 |            841.065 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cadfc_00000:
  custom_metrics:
    time_step_max: 4270
    time_step_mean: 3577.9320388349515
    time_step_min: 3240
  date: 2020-10-10_19-39-35
  done: false
  episode_len_mean: 835.6930379746835
  episode_reward_max: 279.6565656565654
  episode_reward_mean: 223.6072273366576
  episode_reward_min: 119.05050505050464
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: cd0ec222c7014d9f98ef47f997b97438
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 1.0422822322164262
        entropy_coeff: 0.00010000000000000002
        kl: 0.004976426118186542
        model: {}
        policy_loss: -0.00435679269971193
        total_loss: 13.466025761195592
        vf_explained_var: 0.9594665765762329
        vf_loss: 13.470238072531563
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.155555555555555
    gpu_util_percent0: 0.35694444444444445
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4833333333333325
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 12737
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15712671021950736
    mean_env_wait_ms: 1.2067021041427235
    mean_inference_ms: 4.9526821000001915
    mean_raw_obs_processing_ms: 0.41734572246474533
  time_since_restore: 222.12857389450073
  time_this_iter_s: 31.18687677383423
  time_total_s: 222.12857389450073
  timers:
    learn_throughput: 6782.078
    learn_time_ms: 23855.815
    sample_throughput: 20754.378
    sample_time_ms: 7795.56
    update_time_ms: 32.956
  timestamp: 1602358775
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: cadfc_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cadfc_00000 | RUNNING  | 172.17.0.4:12737 |      7 |          222.129 | 1132544 |  223.607 |              279.657 |              119.051 |            835.693 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cadfc_00000:
  custom_metrics:
    time_step_max: 4270
    time_step_mean: 3573.3407460545195
    time_step_min: 3240
  date: 2020-10-10_19-40-06
  done: false
  episode_len_mean: 831.3431786216596
  episode_reward_max: 279.6565656565654
  episode_reward_mean: 224.26115586242156
  episode_reward_min: 119.05050505050464
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: cd0ec222c7014d9f98ef47f997b97438
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 1.0e-05
        entropy: 0.9954175693648202
        entropy_coeff: 0.00010000000000000002
        kl: 0.005134001440767731
        model: {}
        policy_loss: -0.004425333385630178
        total_loss: 11.576691627502441
        vf_explained_var: 0.9731841683387756
        vf_loss: 11.581087793622698
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.0972972972973
    gpu_util_percent0: 0.27243243243243237
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.48918918918919
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 12737
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1565870345269462
    mean_env_wait_ms: 1.2099502223446423
    mean_inference_ms: 4.911200734541301
    mean_raw_obs_processing_ms: 0.41537946368267714
  time_since_restore: 253.1147072315216
  time_this_iter_s: 30.986133337020874
  time_total_s: 253.1147072315216
  timers:
    learn_throughput: 6785.916
    learn_time_ms: 23842.322
    sample_throughput: 20973.558
    sample_time_ms: 7714.094
    update_time_ms: 33.89
  timestamp: 1602358806
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: cadfc_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cadfc_00000 | RUNNING  | 172.17.0.4:12737 |      8 |          253.115 | 1294336 |  224.261 |              279.657 |              119.051 |            831.343 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cadfc_00000:
  custom_metrics:
    time_step_max: 4270
    time_step_mean: 3572.133918128655
    time_step_min: 3240
  date: 2020-10-10_19-40-38
  done: false
  episode_len_mean: 824.084004602992
  episode_reward_max: 279.6565656565654
  episode_reward_mean: 224.96290871895005
  episode_reward_min: 119.05050505050464
  episodes_this_iter: 316
  episodes_total: 1738
  experiment_id: cd0ec222c7014d9f98ef47f997b97438
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 1.0e-05
        entropy: 0.9662974604538509
        entropy_coeff: 0.00010000000000000002
        kl: 0.005635110894218087
        model: {}
        policy_loss: -0.002474603085179946
        total_loss: 14.737199238368444
        vf_explained_var: 0.977534294128418
        vf_loss: 14.739629677363805
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.59444444444445
    gpu_util_percent0: 0.28555555555555556
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.475
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 12737
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15572260240361507
    mean_env_wait_ms: 1.2159972284003289
    mean_inference_ms: 4.845028446815156
    mean_raw_obs_processing_ms: 0.41235999699856246
  time_since_restore: 284.24435234069824
  time_this_iter_s: 31.129645109176636
  time_total_s: 284.24435234069824
  timers:
    learn_throughput: 6787.312
    learn_time_ms: 23837.418
    sample_throughput: 21120.472
    sample_time_ms: 7660.435
    update_time_ms: 34.856
  timestamp: 1602358838
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: cadfc_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cadfc_00000 | RUNNING  | 172.17.0.4:12737 |      9 |          284.244 | 1456128 |  224.963 |              279.657 |              119.051 |            824.084 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cadfc_00000:
  custom_metrics:
    time_step_max: 4270
    time_step_mean: 3571.2200214132763
    time_step_min: 3240
  date: 2020-10-10_19-41-09
  done: false
  episode_len_mean: 821.1418776371308
  episode_reward_max: 279.6565656565654
  episode_reward_mean: 225.15514320419376
  episode_reward_min: 119.05050505050464
  episodes_this_iter: 158
  episodes_total: 1896
  experiment_id: cd0ec222c7014d9f98ef47f997b97438
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 1.0e-05
        entropy: 0.9143142827919551
        entropy_coeff: 0.00010000000000000002
        kl: 0.005390113685280085
        model: {}
        policy_loss: -0.005274239071046135
        total_loss: 8.117160422461373
        vf_explained_var: 0.9839610457420349
        vf_loss: 8.122391394206456
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.48108108108108
    gpu_util_percent0: 0.3986486486486487
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486486486486487
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 12737
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15537641447741754
    mean_env_wait_ms: 1.2184847112856452
    mean_inference_ms: 4.818150238251384
    mean_raw_obs_processing_ms: 0.41108539325955973
  time_since_restore: 315.22459602355957
  time_this_iter_s: 30.980243682861328
  time_total_s: 315.22459602355957
  timers:
    learn_throughput: 6790.796
    learn_time_ms: 23825.188
    sample_throughput: 21268.773
    sample_time_ms: 7607.021
    update_time_ms: 39.075
  timestamp: 1602358869
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: cadfc_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cadfc_00000 | RUNNING  | 172.17.0.4:12737 |     10 |          315.225 | 1617920 |  225.155 |              279.657 |              119.051 |            821.142 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cadfc_00000:
  custom_metrics:
    time_step_max: 4270
    time_step_mean: 3569.788252714709
    time_step_min: 3240
  date: 2020-10-10_19-41-40
  done: false
  episode_len_mean: 818.547711781889
  episode_reward_max: 279.6565656565654
  episode_reward_mean: 225.41052688521037
  episode_reward_min: 119.05050505050464
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: cd0ec222c7014d9f98ef47f997b97438
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 1.0e-05
        entropy: 0.8810192176273891
        entropy_coeff: 0.00010000000000000002
        kl: 0.004917973818789635
        model: {}
        policy_loss: -0.004740208765724674
        total_loss: 6.597178356988089
        vf_explained_var: 0.9875577688217163
        vf_loss: 6.601883854184832
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.769444444444442
    gpu_util_percent0: 0.35000000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497222222222223
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 12737
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1550602295422993
    mean_env_wait_ms: 1.220841773004976
    mean_inference_ms: 4.793933203740181
    mean_raw_obs_processing_ms: 0.40989707309006806
  time_since_restore: 346.1447501182556
  time_this_iter_s: 30.920154094696045
  time_total_s: 346.1447501182556
  timers:
    learn_throughput: 6799.603
    learn_time_ms: 23794.329
    sample_throughput: 21944.715
    sample_time_ms: 7372.709
    update_time_ms: 38.891
  timestamp: 1602358900
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: cadfc_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cadfc_00000 | RUNNING  | 172.17.0.4:12737 |     11 |          346.145 | 1779712 |  225.411 |              279.657 |              119.051 |            818.548 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cadfc_00000:
  custom_metrics:
    time_step_max: 4270
    time_step_mean: 3568.0115483319078
    time_step_min: 3240
  date: 2020-10-10_19-42-11
  done: false
  episode_len_mean: 814.3486897717667
  episode_reward_max: 279.6565656565654
  episode_reward_mean: 225.53037133806362
  episode_reward_min: 119.05050505050464
  episodes_this_iter: 312
  episodes_total: 2366
  experiment_id: cd0ec222c7014d9f98ef47f997b97438
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.012500000000000002
        cur_lr: 1.0e-05
        entropy: 0.844686780657087
        entropy_coeff: 0.00010000000000000002
        kl: 0.004463694956419724
        model: {}
        policy_loss: -0.004414605126969816
        total_loss: 8.655857631138392
        vf_explained_var: 0.9896771311759949
        vf_loss: 8.660300799778529
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.055555555555554
    gpu_util_percent0: 0.23111111111111113
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486111111111111
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 12737
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15452540162285974
    mean_env_wait_ms: 1.2253392265303327
    mean_inference_ms: 4.75328966210991
    mean_raw_obs_processing_ms: 0.4079502518767279
  time_since_restore: 377.34026193618774
  time_this_iter_s: 31.19551181793213
  time_total_s: 377.34026193618774
  timers:
    learn_throughput: 6799.364
    learn_time_ms: 23795.166
    sample_throughput: 22136.711
    sample_time_ms: 7308.764
    update_time_ms: 36.858
  timestamp: 1602358931
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: cadfc_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cadfc_00000 | RUNNING  | 172.17.0.4:12737 |     12 |           377.34 | 1941504 |   225.53 |              279.657 |              119.051 |            814.349 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cadfc_00000:
  custom_metrics:
    time_step_max: 4270
    time_step_mean: 3567.3956
    time_step_min: 3240
  date: 2020-10-10_19-42-42
  done: false
  episode_len_mean: 812.4054588607595
  episode_reward_max: 279.6565656565654
  episode_reward_mean: 225.53005529983375
  episode_reward_min: 119.05050505050464
  episodes_this_iter: 162
  episodes_total: 2528
  experiment_id: cd0ec222c7014d9f98ef47f997b97438
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.006250000000000001
        cur_lr: 1.0e-05
        entropy: 0.7968450742108482
        entropy_coeff: 0.00010000000000000002
        kl: 0.003622929831700666
        model: {}
        policy_loss: -0.002791926056878375
        total_loss: 5.57886494909014
        vf_explained_var: 0.9906096458435059
        vf_loss: 5.581713948931013
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.188888888888886
    gpu_util_percent0: 0.3302777777777778
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494444444444444
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 12737
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15429020566724158
    mean_env_wait_ms: 1.2274296905804563
    mean_inference_ms: 4.73524373526177
    mean_raw_obs_processing_ms: 0.4071066793153895
  time_since_restore: 408.4168927669525
  time_this_iter_s: 31.07663083076477
  time_total_s: 408.4168927669525
  timers:
    learn_throughput: 6806.097
    learn_time_ms: 23771.627
    sample_throughput: 22228.624
    sample_time_ms: 7278.543
    update_time_ms: 36.436
  timestamp: 1602358962
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: cadfc_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cadfc_00000 | RUNNING  | 172.17.0.4:12737 |     13 |          408.417 | 2103296 |   225.53 |              279.657 |              119.051 |            812.405 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cadfc_00000:
  custom_metrics:
    time_step_max: 4270
    time_step_mean: 3567.4477050413843
    time_step_min: 3240
  date: 2020-10-10_19-43-13
  done: false
  episode_len_mean: 810.7755026061058
  episode_reward_max: 279.6565656565654
  episode_reward_mean: 225.61913250148544
  episode_reward_min: 119.05050505050464
  episodes_this_iter: 158
  episodes_total: 2686
  experiment_id: cd0ec222c7014d9f98ef47f997b97438
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0031250000000000006
        cur_lr: 1.0e-05
        entropy: 0.7902350297995976
        entropy_coeff: 0.00010000000000000002
        kl: 0.0032940867988924894
        model: {}
        policy_loss: -0.0028724680752410287
        total_loss: 4.587453297206333
        vf_explained_var: 0.9918591380119324
        vf_loss: 4.590394565037319
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.555555555555557
    gpu_util_percent0: 0.31666666666666665
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491666666666666
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 12737
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15407375599659337
    mean_env_wait_ms: 1.2293721343783524
    mean_inference_ms: 4.719069669274905
    mean_raw_obs_processing_ms: 0.40631726767022175
  time_since_restore: 439.39023637771606
  time_this_iter_s: 30.97334361076355
  time_total_s: 439.39023637771606
  timers:
    learn_throughput: 6808.017
    learn_time_ms: 23764.924
    sample_throughput: 22301.443
    sample_time_ms: 7254.777
    update_time_ms: 36.567
  timestamp: 1602358993
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: cadfc_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cadfc_00000 | RUNNING  | 172.17.0.4:12737 |     14 |           439.39 | 2265088 |  225.619 |              279.657 |              119.051 |            810.776 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cadfc_00000:
  custom_metrics:
    time_step_max: 4270
    time_step_mean: 3566.3361980061877
    time_step_min: 3240
  date: 2020-10-10_19-43-44
  done: false
  episode_len_mean: 808.4123255022131
  episode_reward_max: 279.6565656565654
  episode_reward_mean: 225.65794822587472
  episode_reward_min: 119.05050505050464
  episodes_this_iter: 251
  episodes_total: 2937
  experiment_id: cd0ec222c7014d9f98ef47f997b97438
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0015625000000000003
        cur_lr: 1.0e-05
        entropy: 0.7773092346532005
        entropy_coeff: 0.00010000000000000002
        kl: 0.0031839401261614902
        model: {}
        policy_loss: -0.0032763606494492187
        total_loss: 5.952784402029855
        vf_explained_var: 0.9925915002822876
        vf_loss: 5.956133229391916
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.178378378378376
    gpu_util_percent0: 0.3408108108108108
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486486486486487
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 12737
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15376598681635462
    mean_env_wait_ms: 1.2324273132870123
    mean_inference_ms: 4.696106963608442
    mean_raw_obs_processing_ms: 0.40517170855767287
  time_since_restore: 470.2856800556183
  time_this_iter_s: 30.89544367790222
  time_total_s: 470.2856800556183
  timers:
    learn_throughput: 6807.674
    learn_time_ms: 23766.119
    sample_throughput: 22403.52
    sample_time_ms: 7221.722
    update_time_ms: 36.614
  timestamp: 1602359024
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: cadfc_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cadfc_00000 | RUNNING  | 172.17.0.4:12737 |     15 |          470.286 | 2426880 |  225.658 |              279.657 |              119.051 |            808.412 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cadfc_00000:
  custom_metrics:
    time_step_max: 4270
    time_step_mean: 3565.4738186462323
    time_step_min: 3240
  date: 2020-10-10_19-44-15
  done: false
  episode_len_mean: 806.5696202531645
  episode_reward_max: 279.6565656565654
  episode_reward_mean: 225.91035353535355
  episode_reward_min: 119.05050505050464
  episodes_this_iter: 223
  episodes_total: 3160
  experiment_id: cd0ec222c7014d9f98ef47f997b97438
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0007812500000000002
        cur_lr: 1.0e-05
        entropy: 0.7209977209568024
        entropy_coeff: 0.00010000000000000002
        kl: 0.003142187970557383
        model: {}
        policy_loss: -0.0027102644837993595
        total_loss: 4.677991560527256
        vf_explained_var: 0.9925717711448669
        vf_loss: 4.680771453039987
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.263888888888886
    gpu_util_percent0: 0.3913888888888889
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497222222222222
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 12737
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15352648875268826
    mean_env_wait_ms: 1.2348278684918814
    mean_inference_ms: 4.678041588291085
    mean_raw_obs_processing_ms: 0.40431556715289296
  time_since_restore: 501.20559191703796
  time_this_iter_s: 30.919911861419678
  time_total_s: 501.20559191703796
  timers:
    learn_throughput: 6814.667
    learn_time_ms: 23741.734
    sample_throughput: 22497.213
    sample_time_ms: 7191.646
    update_time_ms: 34.938
  timestamp: 1602359055
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: cadfc_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cadfc_00000 | RUNNING  | 172.17.0.4:12737 |     16 |          501.206 | 2588672 |   225.91 |              279.657 |              119.051 |             806.57 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cadfc_00000:
  custom_metrics:
    time_step_max: 4270
    time_step_mean: 3563.7203647416413
    time_step_min: 3240
  date: 2020-10-10_19-44-47
  done: false
  episode_len_mean: 805.3037974683544
  episode_reward_max: 279.6565656565654
  episode_reward_mean: 226.24446088370144
  episode_reward_min: 119.05050505050464
  episodes_this_iter: 158
  episodes_total: 3318
  experiment_id: cd0ec222c7014d9f98ef47f997b97438
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0003906250000000001
        cur_lr: 1.0e-05
        entropy: 0.7194737153393882
        entropy_coeff: 0.00010000000000000002
        kl: 0.0028658984561583827
        model: {}
        policy_loss: -0.0038804229365528692
        total_loss: 3.5074977363858904
        vf_explained_var: 0.9934480786323547
        vf_loss: 3.511448928288051
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.024324324324322
    gpu_util_percent0: 0.3562162162162162
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.489189189189189
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 12737
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1533710617132797
    mean_env_wait_ms: 1.2364355656275101
    mean_inference_ms: 4.666374492810339
    mean_raw_obs_processing_ms: 0.4037560312124263
  time_since_restore: 532.3934581279755
  time_this_iter_s: 31.1878662109375
  time_total_s: 532.3934581279755
  timers:
    learn_throughput: 6809.958
    learn_time_ms: 23758.149
    sample_throughput: 22553.721
    sample_time_ms: 7173.628
    update_time_ms: 35.556
  timestamp: 1602359087
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: cadfc_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cadfc_00000 | RUNNING  | 172.17.0.4:12737 |     17 |          532.393 | 2750464 |  226.244 |              279.657 |              119.051 |            805.304 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cadfc_00000:
  custom_metrics:
    time_step_max: 4270
    time_step_mean: 3561.986490370796
    time_step_min: 3240
  date: 2020-10-10_19-45-18
  done: false
  episode_len_mean: 803.8346164813231
  episode_reward_max: 279.6565656565654
  episode_reward_mean: 226.58573761567774
  episode_reward_min: 119.05050505050464
  episodes_this_iter: 189
  episodes_total: 3507
  experiment_id: cd0ec222c7014d9f98ef47f997b97438
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.00019531250000000004
        cur_lr: 1.0e-05
        entropy: 0.7175424524715969
        entropy_coeff: 0.00010000000000000002
        kl: 0.003030416904948652
        model: {}
        policy_loss: -0.0038596166954708417
        total_loss: 3.7598051854542325
        vf_explained_var: 0.9943675398826599
        vf_loss: 3.7637358563286916
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.46944444444445
    gpu_util_percent0: 0.25277777777777777
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491666666666666
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 12737
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1532006469699928
    mean_env_wait_ms: 1.2383126791564003
    mean_inference_ms: 4.653255096012216
    mean_raw_obs_processing_ms: 0.4031050265839826
  time_since_restore: 563.4346969127655
  time_this_iter_s: 31.04123878479004
  time_total_s: 563.4346969127655
  timers:
    learn_throughput: 6810.825
    learn_time_ms: 23755.125
    sample_throughput: 22528.063
    sample_time_ms: 7181.798
    update_time_ms: 35.051
  timestamp: 1602359118
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: cadfc_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cadfc_00000 | RUNNING  | 172.17.0.4:12737 |     18 |          563.435 | 2912256 |  226.586 |              279.657 |              119.051 |            803.835 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cadfc_00000:
  custom_metrics:
    time_step_max: 4270
    time_step_mean: 3558.3262486716258
    time_step_min: 3240
  date: 2020-10-10_19-45-49
  done: false
  episode_len_mean: 801.6867088607595
  episode_reward_max: 279.6565656565654
  episode_reward_mean: 227.2554980181563
  episode_reward_min: 119.05050505050464
  episodes_this_iter: 285
  episodes_total: 3792
  experiment_id: cd0ec222c7014d9f98ef47f997b97438
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 9.765625000000002e-05
        cur_lr: 1.0e-05
        entropy: 0.6591458150318691
        entropy_coeff: 0.00010000000000000002
        kl: 0.002743369932951672
        model: {}
        policy_loss: -0.003552372145350091
        total_loss: 3.9185114758355275
        vf_explained_var: 0.9939747452735901
        vf_loss: 3.922129511833191
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.208333333333332
    gpu_util_percent0: 0.31805555555555554
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491666666666666
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 12737
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15296419383998197
    mean_env_wait_ms: 1.2410127433855123
    mean_inference_ms: 4.635688099392808
    mean_raw_obs_processing_ms: 0.4022622855960838
  time_since_restore: 594.3439717292786
  time_this_iter_s: 30.90927481651306
  time_total_s: 594.3439717292786
  timers:
    learn_throughput: 6815.822
    learn_time_ms: 23737.71
    sample_throughput: 22540.702
    sample_time_ms: 7177.771
    update_time_ms: 32.733
  timestamp: 1602359149
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: cadfc_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cadfc_00000 | RUNNING  | 172.17.0.4:12737 |     19 |          594.344 | 3074048 |  227.255 |              279.657 |              119.051 |            801.687 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cadfc_00000:
  custom_metrics:
    time_step_max: 4270
    time_step_mean: 3555.274604793473
    time_step_min: 3240
  date: 2020-10-10_19-46-20
  done: true
  episode_len_mean: 800.6412658227848
  episode_reward_max: 279.6565656565654
  episode_reward_mean: 227.63999488556453
  episode_reward_min: 119.05050505050464
  episodes_this_iter: 158
  episodes_total: 3950
  experiment_id: cd0ec222c7014d9f98ef47f997b97438
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 4.882812500000001e-05
        cur_lr: 1.0e-05
        entropy: 0.657125289951052
        entropy_coeff: 0.00010000000000000002
        kl: 0.0026875266672245096
        model: {}
        policy_loss: -0.002386018095421605
        total_loss: 2.811689461980547
        vf_explained_var: 0.9942289590835571
        vf_loss: 2.8141410691397533
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.905405405405407
    gpu_util_percent0: 0.32918918918918916
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486486486486487
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 12737
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1528449748663824
    mean_env_wait_ms: 1.2423791233615027
    mean_inference_ms: 4.626755311751482
    mean_raw_obs_processing_ms: 0.401829551675734
  time_since_restore: 625.3474943637848
  time_this_iter_s: 31.003522634506226
  time_total_s: 625.3474943637848
  timers:
    learn_throughput: 6817.709
    learn_time_ms: 23731.138
    sample_throughput: 22501.373
    sample_time_ms: 7190.317
    update_time_ms: 28.819
  timestamp: 1602359180
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: cadfc_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cadfc_00000 | TERMINATED |       |     20 |          625.347 | 3235840 |   227.64 |              279.657 |              119.051 |            800.641 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cadfc_00000 | TERMINATED |       |     20 |          625.347 | 3235840 |   227.64 |              279.657 |              119.051 |            800.641 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


