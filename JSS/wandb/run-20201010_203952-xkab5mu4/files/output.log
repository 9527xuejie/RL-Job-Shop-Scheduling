2020-10-10 20:39:54,295	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_c166d_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=55473)[0m 2020-10-10 20:39:57,160	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=55438)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55438)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55430)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55430)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55439)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55439)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55456)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55456)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55445)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55445)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55453)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55453)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55419)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55419)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55413)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55413)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55451)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55451)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55433)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55433)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55414)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55414)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55415)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55415)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55406)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55406)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55427)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55427)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55393)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55393)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55437)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55437)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55404)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55404)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55424)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55424)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55332)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55332)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55338)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55338)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55403)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55403)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55405)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55405)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55364)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55364)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55432)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55432)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55447)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55447)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55425)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55425)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55374)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55374)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55421)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55421)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55372)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55372)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55342)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55342)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55340)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55340)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55363)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55363)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55347)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55347)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55469)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55469)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55370)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55370)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55349)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55349)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55360)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55360)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55410)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55410)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55341)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55341)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55431)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55431)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55416)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55416)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55422)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55422)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55399)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55399)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55345)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55345)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55417)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55417)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55368)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55368)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55367)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55367)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55398)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55398)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55407)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55407)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55333)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55333)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55411)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55411)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55460)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55460)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55358)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55358)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55354)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55354)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55396)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55396)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55458)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55458)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55334)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55334)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55409)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55409)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55412)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55412)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55449)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55449)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55400)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55400)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55402)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55402)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55408)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55408)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55357)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55357)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55441)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55441)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55418)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55418)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55351)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55351)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55339)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55339)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55401)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55401)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55346)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55346)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55335)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55335)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55443)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55443)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55336)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55336)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55395)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55395)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55330)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55330)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55344)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55344)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55356)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55356)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55466)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55466)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55331)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55331)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_c166d_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-10_20-40-36
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 8ac9006923dc45e29b7ba77973c0ecd0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1873074173927307
        entropy_coeff: 0.00010000000000000002
        kl: 0.0020635960390791297
        model: {}
        policy_loss: -0.0024755259634860393
        total_loss: 701.1914978027344
        vf_explained_var: 0.005364171229302883
        vf_loss: 701.1936819893973
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.689743589743586
    gpu_util_percent0: 0.32974358974358975
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.284615384615386
    vram_util_percent0: 0.19117659425957234
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 55473
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17677001800018904
    mean_env_wait_ms: 1.212189195332022
    mean_inference_ms: 6.4754338189384475
    mean_raw_obs_processing_ms: 0.48434857271011317
  time_since_restore: 33.673739194869995
  time_this_iter_s: 33.673739194869995
  time_total_s: 33.673739194869995
  timers:
    learn_throughput: 6845.742
    learn_time_ms: 23633.961
    sample_throughput: 16222.555
    sample_time_ms: 9973.275
    update_time_ms: 28.792
  timestamp: 1602362436
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: c166d_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c166d_00000 | RUNNING  | 172.17.0.4:55473 |      1 |          33.6737 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c166d_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3609.0104166666665
    time_step_min: 3305
  date: 2020-10-10_20-41-07
  done: false
  episode_len_mean: 889.253164556962
  episode_reward_max: 265.26262626262616
  episode_reward_mean: 218.3485487789283
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 8ac9006923dc45e29b7ba77973c0ecd0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1622162801878793
        entropy_coeff: 0.00010000000000000002
        kl: 0.0028016024069594486
        model: {}
        policy_loss: -0.0015914190527317779
        total_loss: 364.8630850655692
        vf_explained_var: 0.4177275002002716
        vf_loss: 364.8645237513951
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.57027027027027
    gpu_util_percent0: 0.3272972972972973
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.467567567567568
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 55473
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17180487516153417
    mean_env_wait_ms: 1.2023080861564044
    mean_inference_ms: 6.073777872672578
    mean_raw_obs_processing_ms: 0.46953202322958304
  time_since_restore: 65.14151191711426
  time_this_iter_s: 31.467772722244263
  time_total_s: 65.14151191711426
  timers:
    learn_throughput: 6871.974
    learn_time_ms: 23543.744
    sample_throughput: 18069.033
    sample_time_ms: 8954.104
    update_time_ms: 23.181
  timestamp: 1602362467
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: c166d_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c166d_00000 | RUNNING  | 172.17.0.4:55473 |      2 |          65.1415 | 323584 |  218.349 |              265.263 |              100.263 |            889.253 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c166d_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3598.652466367713
    time_step_min: 3305
  date: 2020-10-10_20-41-39
  done: false
  episode_len_mean: 884.6286919831224
  episode_reward_max: 270.26262626262593
  episode_reward_mean: 220.54551847589795
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 8ac9006923dc45e29b7ba77973c0ecd0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 1.156989233834403
        entropy_coeff: 0.00010000000000000002
        kl: 0.0036516543644081268
        model: {}
        policy_loss: -0.002803932542779616
        total_loss: 164.46989004952567
        vf_explained_var: 0.6956451535224915
        vf_loss: 164.4726300920759
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.589189189189188
    gpu_util_percent0: 0.37378378378378385
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.489189189189189
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 55473
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16848095074833339
    mean_env_wait_ms: 1.1984052987265565
    mean_inference_ms: 5.803457711169357
    mean_raw_obs_processing_ms: 0.45880461558511965
  time_since_restore: 96.38442945480347
  time_this_iter_s: 31.24291753768921
  time_total_s: 96.38442945480347
  timers:
    learn_throughput: 6839.74
    learn_time_ms: 23654.701
    sample_throughput: 19279.282
    sample_time_ms: 8392.014
    update_time_ms: 32.215
  timestamp: 1602362499
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: c166d_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c166d_00000 | RUNNING  | 172.17.0.4:55473 |      3 |          96.3844 | 485376 |  220.546 |              270.263 |              100.263 |            884.629 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c166d_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3591.3526490066224
    time_step_min: 3305
  date: 2020-10-10_20-42-10
  done: false
  episode_len_mean: 879.9493670886076
  episode_reward_max: 270.26262626262593
  episode_reward_mean: 222.37233090397623
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 8ac9006923dc45e29b7ba77973c0ecd0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 1.0e-05
        entropy: 1.1496972611972265
        entropy_coeff: 0.00010000000000000002
        kl: 0.004537380633077451
        model: {}
        policy_loss: -0.0051304227589363495
        total_loss: 93.71456146240234
        vf_explained_var: 0.8152980804443359
        vf_loss: 93.71969441005162
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.855555555555558
    gpu_util_percent0: 0.3194444444444445
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4944444444444445
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 55473
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16609128096462106
    mean_env_wait_ms: 1.1966080807853772
    mean_inference_ms: 5.6112714186414685
    mean_raw_obs_processing_ms: 0.4503175777620619
  time_since_restore: 127.35645937919617
  time_this_iter_s: 30.9720299243927
  time_total_s: 127.35645937919617
  timers:
    learn_throughput: 6836.155
    learn_time_ms: 23667.106
    sample_throughput: 20001.828
    sample_time_ms: 8088.861
    update_time_ms: 32.045
  timestamp: 1602362530
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: c166d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c166d_00000 | RUNNING  | 172.17.0.4:55473 |      4 |          127.356 | 647168 |  222.372 |              270.263 |              100.263 |            879.949 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c166d_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3588.736220472441
    time_step_min: 3285
  date: 2020-10-10_20-42-41
  done: false
  episode_len_mean: 875.7405063291139
  episode_reward_max: 270.26262626262593
  episode_reward_mean: 222.96017133358882
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 8ac9006923dc45e29b7ba77973c0ecd0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.012500000000000002
        cur_lr: 1.0e-05
        entropy: 1.126914152077266
        entropy_coeff: 0.00010000000000000002
        kl: 0.004462935263291001
        model: {}
        policy_loss: -0.003668712883414368
        total_loss: 78.06558772495815
        vf_explained_var: 0.860072672367096
        vf_loss: 78.06931250435966
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.925
    gpu_util_percent0: 0.2597222222222222
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494444444444444
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 55473
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1642591953503438
    mean_env_wait_ms: 1.1964507197163377
    mean_inference_ms: 5.467262794918539
    mean_raw_obs_processing_ms: 0.44353324774933806
  time_since_restore: 158.47588872909546
  time_this_iter_s: 31.119429349899292
  time_total_s: 158.47588872909546
  timers:
    learn_throughput: 6836.852
    learn_time_ms: 23664.692
    sample_throughput: 20353.001
    sample_time_ms: 7949.295
    update_time_ms: 30.544
  timestamp: 1602362561
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: c166d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c166d_00000 | RUNNING  | 172.17.0.4:55473 |      5 |          158.476 | 808960 |   222.96 |              270.263 |              100.263 |            875.741 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c166d_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3579.2562674094706
    time_step_min: 3207
  date: 2020-10-10_20-43-12
  done: false
  episode_len_mean: 866.09592760181
  episode_reward_max: 283.4444444444442
  episode_reward_mean: 224.53357100415906
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 315
  episodes_total: 1105
  experiment_id: 8ac9006923dc45e29b7ba77973c0ecd0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.006250000000000001
        cur_lr: 1.0e-05
        entropy: 1.1254908783095223
        entropy_coeff: 0.00010000000000000002
        kl: 0.004099821804889611
        model: {}
        policy_loss: -0.003864848344944351
        total_loss: 83.49456623622349
        vf_explained_var: 0.8955941796302795
        vf_loss: 83.49851662772042
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.288888888888888
    gpu_util_percent0: 0.3261111111111111
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486111111111111
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 55473
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16176496387886807
    mean_env_wait_ms: 1.1991481919522453
    mean_inference_ms: 5.274599982165517
    mean_raw_obs_processing_ms: 0.4346700722697865
  time_since_restore: 189.4213411808014
  time_this_iter_s: 30.945452451705933
  time_total_s: 189.4213411808014
  timers:
    learn_throughput: 6837.244
    learn_time_ms: 23663.337
    sample_throughput: 20669.813
    sample_time_ms: 7827.454
    update_time_ms: 29.025
  timestamp: 1602362592
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: c166d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c166d_00000 | RUNNING  | 172.17.0.4:55473 |      6 |          189.421 | 970752 |  224.534 |              283.444 |              100.263 |            866.096 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c166d_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3570.4368932038833
    time_step_min: 3207
  date: 2020-10-10_20-43-43
  done: false
  episode_len_mean: 861.2555379746835
  episode_reward_max: 283.4444444444442
  episode_reward_mean: 225.94060861782359
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 159
  episodes_total: 1264
  experiment_id: 8ac9006923dc45e29b7ba77973c0ecd0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0031250000000000006
        cur_lr: 1.0e-05
        entropy: 1.1276012573923384
        entropy_coeff: 0.00010000000000000002
        kl: 0.004429342923685908
        model: {}
        policy_loss: -0.0038549922028323635
        total_loss: 54.83245440891811
        vf_explained_var: 0.891270637512207
        vf_loss: 54.83640888759068
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.333333333333336
    gpu_util_percent0: 0.2652777777777777
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.499999999999999
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 55473
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1608624009531785
    mean_env_wait_ms: 1.2004324186987543
    mean_inference_ms: 5.2050086189315135
    mean_raw_obs_processing_ms: 0.4313847706334479
  time_since_restore: 220.6443645954132
  time_this_iter_s: 31.223023414611816
  time_total_s: 220.6443645954132
  timers:
    learn_throughput: 6823.558
    learn_time_ms: 23710.796
    sample_throughput: 20929.796
    sample_time_ms: 7730.224
    update_time_ms: 28.482
  timestamp: 1602362623
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: c166d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c166d_00000 | RUNNING  | 172.17.0.4:55473 |      7 |          220.644 | 1132544 |  225.941 |              283.444 |              100.263 |            861.256 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c166d_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3559.9304160688666
    time_step_min: 3151
  date: 2020-10-10_20-44-14
  done: false
  episode_len_mean: 857.2524613220816
  episode_reward_max: 288.595959595959
  episode_reward_mean: 227.17681029706327
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 8ac9006923dc45e29b7ba77973c0ecd0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0015625000000000003
        cur_lr: 1.0e-05
        entropy: 1.1150874495506287
        entropy_coeff: 0.00010000000000000002
        kl: 0.003974244347773492
        model: {}
        policy_loss: -0.0035831595471661004
        total_loss: 54.49585941859654
        vf_explained_var: 0.8924027681350708
        vf_loss: 54.49954768589565
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.641666666666666
    gpu_util_percent0: 0.2822222222222222
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4944444444444445
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 55473
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16008457988182095
    mean_env_wait_ms: 1.2017022907742836
    mean_inference_ms: 5.14544230199281
    mean_raw_obs_processing_ms: 0.42849635773752853
  time_since_restore: 251.59280443191528
  time_this_iter_s: 30.948439836502075
  time_total_s: 251.59280443191528
  timers:
    learn_throughput: 6819.269
    learn_time_ms: 23725.709
    sample_throughput: 21169.761
    sample_time_ms: 7642.599
    update_time_ms: 29.579
  timestamp: 1602362654
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: c166d_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c166d_00000 | RUNNING  | 172.17.0.4:55473 |      8 |          251.593 | 1294336 |  227.177 |              288.596 |              100.263 |            857.252 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c166d_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3551.0244845360826
    time_step_min: 3151
  date: 2020-10-10_20-44-46
  done: false
  episode_len_mean: 853.0689873417722
  episode_reward_max: 288.595959595959
  episode_reward_mean: 228.5646976090012
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 8ac9006923dc45e29b7ba77973c0ecd0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0007812500000000002
        cur_lr: 1.0e-05
        entropy: 1.0849848645074027
        entropy_coeff: 0.00010000000000000002
        kl: 0.0038502484426966737
        model: {}
        policy_loss: -0.0022216487642643707
        total_loss: 46.922092710222515
        vf_explained_var: 0.9051581025123596
        vf_loss: 46.924419675554546
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.386111111111106
    gpu_util_percent0: 0.3833333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4833333333333325
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 55473
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1594012760760406
    mean_env_wait_ms: 1.2030887700616493
    mean_inference_ms: 5.093558563082828
    mean_raw_obs_processing_ms: 0.4259075740759342
  time_since_restore: 282.80553436279297
  time_this_iter_s: 31.212729930877686
  time_total_s: 282.80553436279297
  timers:
    learn_throughput: 6816.188
    learn_time_ms: 23736.435
    sample_throughput: 21293.425
    sample_time_ms: 7598.214
    update_time_ms: 28.604
  timestamp: 1602362686
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: c166d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c166d_00000 | RUNNING  | 172.17.0.4:55473 |      9 |          282.806 | 1456128 |  228.565 |              288.596 |              100.263 |            853.069 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c166d_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3536.9379014989295
    time_step_min: 3151
  date: 2020-10-10_20-45-17
  done: false
  episode_len_mean: 845.5226793248945
  episode_reward_max: 288.595959595959
  episode_reward_mean: 230.7766270297914
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 316
  episodes_total: 1896
  experiment_id: 8ac9006923dc45e29b7ba77973c0ecd0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0003906250000000001
        cur_lr: 1.0e-05
        entropy: 1.076273841517312
        entropy_coeff: 0.00010000000000000002
        kl: 0.004205631690898112
        model: {}
        policy_loss: -0.0022618804442962365
        total_loss: 50.323801040649414
        vf_explained_var: 0.9342614412307739
        vf_loss: 50.32617024012974
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.51111111111111
    gpu_util_percent0: 0.34111111111111114
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.477777777777778
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 55473
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15830741205278617
    mean_env_wait_ms: 1.206194381709416
    mean_inference_ms: 5.009928133938143
    mean_raw_obs_processing_ms: 0.4218398477725044
  time_since_restore: 313.7603199481964
  time_this_iter_s: 30.954785585403442
  time_total_s: 313.7603199481964
  timers:
    learn_throughput: 6816.662
    learn_time_ms: 23734.783
    sample_throughput: 21440.226
    sample_time_ms: 7546.189
    update_time_ms: 28.257
  timestamp: 1602362717
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: c166d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c166d_00000 | RUNNING  | 172.17.0.4:55473 |     10 |           313.76 | 1617920 |  230.777 |              288.596 |              100.263 |            845.523 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c166d_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3529.901776900296
    time_step_min: 3151
  date: 2020-10-10_20-45-47
  done: false
  episode_len_mean: 842.0423563777994
  episode_reward_max: 288.595959595959
  episode_reward_mean: 231.85250263098345
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 8ac9006923dc45e29b7ba77973c0ecd0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.00019531250000000004
        cur_lr: 1.0e-05
        entropy: 1.0737578783716475
        entropy_coeff: 0.00010000000000000002
        kl: 0.003783294149408383
        model: {}
        policy_loss: -0.004276136510140661
        total_loss: 33.29253796168736
        vf_explained_var: 0.9342599511146545
        vf_loss: 33.296920912606375
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.14571428571428
    gpu_util_percent0: 0.32399999999999995
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491428571428571
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 55473
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15785316453045858
    mean_env_wait_ms: 1.2076153011472335
    mean_inference_ms: 4.975707769025352
    mean_raw_obs_processing_ms: 0.4201618492152994
  time_since_restore: 344.26328325271606
  time_this_iter_s: 30.502963304519653
  time_total_s: 344.26328325271606
  timers:
    learn_throughput: 6823.399
    learn_time_ms: 23711.351
    sample_throughput: 22311.85
    sample_time_ms: 7251.393
    update_time_ms: 27.229
  timestamp: 1602362747
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: c166d_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c166d_00000 | RUNNING  | 172.17.0.4:55473 |     11 |          344.263 | 1779712 |  231.853 |              288.596 |              100.263 |            842.042 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c166d_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3526.41804029304
    time_step_min: 3151
  date: 2020-10-10_20-46-18
  done: false
  episode_len_mean: 838.8187160940325
  episode_reward_max: 288.595959595959
  episode_reward_mean: 232.613303012037
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 8ac9006923dc45e29b7ba77973c0ecd0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 9.765625000000002e-05
        cur_lr: 1.0e-05
        entropy: 1.0603217227118356
        entropy_coeff: 0.00010000000000000002
        kl: 0.003855027923626559
        model: {}
        policy_loss: -0.00371374208771158
        total_loss: 32.77641677856445
        vf_explained_var: 0.9338550567626953
        vf_loss: 32.78023610796247
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.22222222222222
    gpu_util_percent0: 0.3425
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497222222222222
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 55473
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15744199918849858
    mean_env_wait_ms: 1.2089699252836346
    mean_inference_ms: 4.94475850351419
    mean_raw_obs_processing_ms: 0.4186043372201858
  time_since_restore: 374.79025387763977
  time_this_iter_s: 30.526970624923706
  time_total_s: 374.79025387763977
  timers:
    learn_throughput: 6829.835
    learn_time_ms: 23689.006
    sample_throughput: 22535.789
    sample_time_ms: 7179.336
    update_time_ms: 27.73
  timestamp: 1602362778
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: c166d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c166d_00000 | RUNNING  | 172.17.0.4:55473 |     12 |           374.79 | 1941504 |  232.613 |              288.596 |              100.263 |            838.819 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c166d_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3519.8012552301257
    time_step_min: 3151
  date: 2020-10-10_20-46-48
  done: false
  episode_len_mean: 834.9247311827957
  episode_reward_max: 288.595959595959
  episode_reward_mean: 233.6417650449907
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 206
  episodes_total: 2418
  experiment_id: 8ac9006923dc45e29b7ba77973c0ecd0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 4.882812500000001e-05
        cur_lr: 1.0e-05
        entropy: 1.019412875175476
        entropy_coeff: 0.00010000000000000002
        kl: 0.0037593759396778686
        model: {}
        policy_loss: -0.0030141745436204864
        total_loss: 36.07479504176548
        vf_explained_var: 0.9472951292991638
        vf_loss: 36.077910559517996
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.122857142857143
    gpu_util_percent0: 0.3382857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.482857142857143
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 55473
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15696732111650039
    mean_env_wait_ms: 1.2109231604134967
    mean_inference_ms: 4.908748221892908
    mean_raw_obs_processing_ms: 0.41678327055323466
  time_since_restore: 405.13970923423767
  time_this_iter_s: 30.3494553565979
  time_total_s: 405.13970923423767
  timers:
    learn_throughput: 6847.418
    learn_time_ms: 23628.177
    sample_throughput: 22626.239
    sample_time_ms: 7150.636
    update_time_ms: 26.734
  timestamp: 1602362808
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: c166d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c166d_00000 | RUNNING  | 172.17.0.4:55473 |     13 |           405.14 | 2103296 |  233.642 |              288.596 |              100.263 |            834.925 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c166d_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3511.3363431151242
    time_step_min: 3151
  date: 2020-10-10_20-47-19
  done: false
  episode_len_mean: 830.4076693968726
  episode_reward_max: 288.595959595959
  episode_reward_mean: 234.88129996916282
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 268
  episodes_total: 2686
  experiment_id: 8ac9006923dc45e29b7ba77973c0ecd0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 2.4414062500000005e-05
        cur_lr: 1.0e-05
        entropy: 1.0291070171764918
        entropy_coeff: 0.00010000000000000002
        kl: 0.003918815803314958
        model: {}
        policy_loss: -0.002831766040929194
        total_loss: 23.69036075047084
        vf_explained_var: 0.9602026343345642
        vf_loss: 23.693296568734304
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.628571428571426
    gpu_util_percent0: 0.34085714285714286
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488571428571428
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 55473
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15643048288648964
    mean_env_wait_ms: 1.2132174978292594
    mean_inference_ms: 4.868526600183221
    mean_raw_obs_processing_ms: 0.4147329152450763
  time_since_restore: 435.5740406513214
  time_this_iter_s: 30.43433141708374
  time_total_s: 435.5740406513214
  timers:
    learn_throughput: 6859.939
    learn_time_ms: 23585.051
    sample_throughput: 22658.935
    sample_time_ms: 7140.318
    update_time_ms: 26.115
  timestamp: 1602362839
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: c166d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c166d_00000 | RUNNING  | 172.17.0.4:55473 |     14 |          435.574 | 2265088 |  234.881 |              288.596 |              100.263 |            830.408 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c166d_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3506.2819602272725
    time_step_min: 3151
  date: 2020-10-10_20-47-49
  done: false
  episode_len_mean: 828.0341068917019
  episode_reward_max: 288.595959595959
  episode_reward_mean: 235.5454652005283
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 8ac9006923dc45e29b7ba77973c0ecd0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 1.2207031250000002e-05
        cur_lr: 1.0e-05
        entropy: 1.015389280659812
        entropy_coeff: 0.00010000000000000002
        kl: 0.003506734634616545
        model: {}
        policy_loss: -0.004160868594096557
        total_loss: 22.387037413460867
        vf_explained_var: 0.954590916633606
        vf_loss: 22.391299656459264
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.711428571428574
    gpu_util_percent0: 0.268
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491428571428571
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 55473
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15615515379872769
    mean_env_wait_ms: 1.2144722960250776
    mean_inference_ms: 4.847606001667535
    mean_raw_obs_processing_ms: 0.41367061017005063
  time_since_restore: 465.93563771247864
  time_this_iter_s: 30.361597061157227
  time_total_s: 465.93563771247864
  timers:
    learn_throughput: 6871.836
    learn_time_ms: 23544.217
    sample_throughput: 22771.111
    sample_time_ms: 7105.143
    update_time_ms: 25.718
  timestamp: 1602362869
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: c166d_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c166d_00000 | RUNNING  | 172.17.0.4:55473 |     15 |          465.936 | 2426880 |  235.545 |              288.596 |              100.263 |            828.034 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c166d_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3500.8736559139784
    time_step_min: 3151
  date: 2020-10-10_20-48-20
  done: false
  episode_len_mean: 825.8169107856191
  episode_reward_max: 288.595959595959
  episode_reward_mean: 236.3206095576267
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 160
  episodes_total: 3004
  experiment_id: 8ac9006923dc45e29b7ba77973c0ecd0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 6.103515625000001e-06
        cur_lr: 1.0e-05
        entropy: 0.9862413619245801
        entropy_coeff: 0.00010000000000000002
        kl: 0.003649017307907343
        model: {}
        policy_loss: -0.004248126389159422
        total_loss: 21.275061198643275
        vf_explained_var: 0.9599407911300659
        vf_loss: 21.27940777369908
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.05142857142857
    gpu_util_percent0: 0.2588571428571429
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.502857142857143
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 55473
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1558982788773386
    mean_env_wait_ms: 1.2157433493741883
    mean_inference_ms: 4.8281183186894
    mean_raw_obs_processing_ms: 0.4126645768833272
  time_since_restore: 496.4164197444916
  time_this_iter_s: 30.48078203201294
  time_total_s: 496.4164197444916
  timers:
    learn_throughput: 6881.88
    learn_time_ms: 23509.856
    sample_throughput: 22811.735
    sample_time_ms: 7092.49
    update_time_ms: 25.387
  timestamp: 1602362900
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: c166d_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c166d_00000 | RUNNING  | 172.17.0.4:55473 |     16 |          496.416 | 2588672 |  236.321 |              288.596 |              100.263 |            825.817 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c166d_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3490.782978723404
    time_step_min: 3151
  date: 2020-10-10_20-48-51
  done: false
  episode_len_mean: 821.832127787824
  episode_reward_max: 288.595959595959
  episode_reward_mean: 237.77545801596415
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 314
  episodes_total: 3318
  experiment_id: 8ac9006923dc45e29b7ba77973c0ecd0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 3.0517578125000006e-06
        cur_lr: 1.0e-05
        entropy: 0.9705815528120313
        entropy_coeff: 0.00010000000000000002
        kl: 0.003707046221409525
        model: {}
        policy_loss: -0.003081625044744994
        total_loss: 23.058461325509207
        vf_explained_var: 0.9682430028915405
        vf_loss: 23.061639649527415
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.840000000000003
    gpu_util_percent0: 0.25599999999999995
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.482857142857142
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 55473
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15545069663609729
    mean_env_wait_ms: 1.218099825797762
    mean_inference_ms: 4.7939813158851345
    mean_raw_obs_processing_ms: 0.41093024290062685
  time_since_restore: 526.9572024345398
  time_this_iter_s: 30.540782690048218
  time_total_s: 526.9572024345398
  timers:
    learn_throughput: 6899.642
    learn_time_ms: 23449.331
    sample_throughput: 22841.638
    sample_time_ms: 7083.205
    update_time_ms: 26.698
  timestamp: 1602362931
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: c166d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c166d_00000 | RUNNING  | 172.17.0.4:55473 |     17 |          526.957 | 2750464 |  237.775 |              288.596 |              100.263 |            821.832 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c166d_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3485.847157772622
    time_step_min: 3151
  date: 2020-10-10_20-49-21
  done: false
  episode_len_mean: 820.0745109321059
  episode_reward_max: 288.595959595959
  episode_reward_mean: 238.48777184968193
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 158
  episodes_total: 3476
  experiment_id: 8ac9006923dc45e29b7ba77973c0ecd0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 1.5258789062500003e-06
        cur_lr: 1.0e-05
        entropy: 0.973125764301845
        entropy_coeff: 0.00010000000000000002
        kl: 0.0036041484979380456
        model: {}
        policy_loss: -0.0037694094831489827
        total_loss: 15.071707248687744
        vf_explained_var: 0.9697252511978149
        vf_loss: 15.075574057442802
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.91388888888889
    gpu_util_percent0: 0.27555555555555555
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491666666666666
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 55473
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1552463612585171
    mean_env_wait_ms: 1.219167440778991
    mean_inference_ms: 4.778733486079256
    mean_raw_obs_processing_ms: 0.4101471843453795
  time_since_restore: 557.4628639221191
  time_this_iter_s: 30.505661487579346
  time_total_s: 557.4628639221191
  timers:
    learn_throughput: 6911.545
    learn_time_ms: 23408.95
    sample_throughput: 22853.277
    sample_time_ms: 7079.597
    update_time_ms: 25.004
  timestamp: 1602362961
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: c166d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c166d_00000 | RUNNING  | 172.17.0.4:55473 |     18 |          557.463 | 2912256 |  238.488 |              288.596 |              100.263 |            820.075 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c166d_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3480.7229617304492
    time_step_min: 3151
  date: 2020-10-10_20-49-52
  done: false
  episode_len_mean: 818.455971381398
  episode_reward_max: 288.595959595959
  episode_reward_mean: 239.18917852159444
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: 8ac9006923dc45e29b7ba77973c0ecd0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 7.629394531250001e-07
        cur_lr: 1.0e-05
        entropy: 0.9508826008864811
        entropy_coeff: 0.00010000000000000002
        kl: 0.0035347315383010675
        model: {}
        policy_loss: -0.0024742844481287257
        total_loss: 16.24584456852504
        vf_explained_var: 0.965994656085968
        vf_loss: 16.248413835253036
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.685714285714287
    gpu_util_percent0: 0.24771428571428578
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.502857142857143
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 55473
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15505394217150975
    mean_env_wait_ms: 1.2201820979688247
    mean_inference_ms: 4.764433208759616
    mean_raw_obs_processing_ms: 0.4093987879218581
  time_since_restore: 587.8843462467194
  time_this_iter_s: 30.42148232460022
  time_total_s: 587.8843462467194
  timers:
    learn_throughput: 6929.169
    learn_time_ms: 23349.41
    sample_throughput: 22899.809
    sample_time_ms: 7065.212
    update_time_ms: 26.492
  timestamp: 1602362992
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: c166d_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c166d_00000 | RUNNING  | 172.17.0.4:55473 |     19 |          587.884 | 3074048 |  239.189 |              288.596 |              100.263 |            818.456 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c166d_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3472.525255102041
    time_step_min: 3151
  date: 2020-10-10_20-50-23
  done: true
  episode_len_mean: 815.5238095238095
  episode_reward_max: 288.595959595959
  episode_reward_mean: 240.51346289644147
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 314
  episodes_total: 3948
  experiment_id: 8ac9006923dc45e29b7ba77973c0ecd0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 3.814697265625001e-07
        cur_lr: 1.0e-05
        entropy: 0.9213444675718035
        entropy_coeff: 0.00010000000000000002
        kl: 0.003496163458164249
        model: {}
        policy_loss: -0.003382129079130079
        total_loss: 21.339890480041504
        vf_explained_var: 0.9712041020393372
        vf_loss: 21.343364306858607
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.561111111111114
    gpu_util_percent0: 0.2802777777777778
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.483333333333333
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 55473
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15470861926956309
    mean_env_wait_ms: 1.2221487764096577
    mean_inference_ms: 4.738770342088905
    mean_raw_obs_processing_ms: 0.40806656146350856
  time_since_restore: 618.563996553421
  time_this_iter_s: 30.67965030670166
  time_total_s: 618.563996553421
  timers:
    learn_throughput: 6938.145
    learn_time_ms: 23319.2
    sample_throughput: 22895.578
    sample_time_ms: 7066.517
    update_time_ms: 33.582
  timestamp: 1602363023
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: c166d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c166d_00000 | TERMINATED |       |     20 |          618.564 | 3235840 |  240.513 |              288.596 |              100.263 |            815.524 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c166d_00000 | TERMINATED |       |     20 |          618.564 | 3235840 |  240.513 |              288.596 |              100.263 |            815.524 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


