2020-11-01 11:53:57,683	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 12.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_ed52d_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=20230)[0m 2020-11-01 11:54:00,466	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=20215)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20215)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20191)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20191)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20206)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20206)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20222)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20222)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20202)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20202)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20171)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20171)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20193)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20193)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20199)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20199)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20235)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20235)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20233)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20233)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20232)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20232)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20198)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20198)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20211)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20211)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20205)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20205)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20226)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20226)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20187)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20187)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20207)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20207)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20216)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20216)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20237)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20237)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20166)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20166)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20236)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20236)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20247)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20247)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20151)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20151)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20175)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20175)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20138)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20138)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20174)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20174)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20178)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20178)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20116)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20116)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20128)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20128)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20181)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20181)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20123)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20123)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20142)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20142)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20169)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20169)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20196)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20196)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20209)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20209)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20188)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20188)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20112)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20112)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20120)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20120)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20210)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20210)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20131)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20131)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20127)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20127)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20134)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20134)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20170)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20170)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20125)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20125)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20129)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20129)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20212)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20212)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20203)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20203)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20180)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20180)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20194)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20194)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20150)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20150)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20219)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20219)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20197)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20197)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20176)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20176)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20192)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20192)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20130)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20130)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20149)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20149)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20195)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20195)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20124)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20124)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20132)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20132)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20240)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20240)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20200)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20200)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20117)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20117)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20173)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20173)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20183)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20183)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20184)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20184)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20145)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20145)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20141)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20141)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20148)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20148)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20122)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20122)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20118)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20118)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20115)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20115)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20214)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20214)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20147)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20147)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20135)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20135)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20114)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20114)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20119)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20119)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20241)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20241)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20113)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20113)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20225)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20225)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_ed52d_00000:
  custom_metrics:
    time_step_max: 1737
    time_step_mean: 1434.4832653061223
    time_step_min: 1245
  date: 2020-11-01_11-54-27
  done: false
  episode_len_mean: 116.93913043478261
  episode_reward_max: 45.68367346938774
  episode_reward_mean: 35.80144389771718
  episode_reward_min: 15.734693877551013
  episodes_this_iter: 1265
  episodes_total: 1265
  experiment_id: 620cee76ed6f483492f5b5ea167d8862
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1484567523002625
        entropy_coeff: 0.0005000000000000001
        kl: 0.006624576014777024
        model: {}
        policy_loss: -0.007466505475652714
        total_loss: 52.51902961730957
        vf_explained_var: 0.7593300342559814
        vf_loss: 52.52574666341146
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.92222222222222
    gpu_util_percent0: 0.3044444444444444
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.4370370370370376
    vram_util_percent0: 0.0819728386963546
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20230
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17175637313856013
    mean_env_wait_ms: 0.6787065283307273
    mean_inference_ms: 5.169812775871786
    mean_raw_obs_processing_ms: 0.45531381926816505
  time_since_restore: 22.264521837234497
  time_this_iter_s: 22.264521837234497
  time_total_s: 22.264521837234497
  timers:
    learn_throughput: 11076.145
    learn_time_ms: 14607.249
    sample_throughput: 21315.374
    sample_time_ms: 7590.39
    update_time_ms: 20.181
  timestamp: 1604231667
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: ed52d_00000
  
== Status ==
Memory usage on this node: 26.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |      1 |          22.2645 | 161792 |  35.8014 |              45.6837 |              15.7347 |            116.939 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed52d_00000:
  custom_metrics:
    time_step_max: 1737
    time_step_mean: 1426.9196226415095
    time_step_min: 1245
  date: 2020-11-01_11-54-49
  done: false
  episode_len_mean: 115.78401486988848
  episode_reward_max: 45.68367346938774
  episode_reward_mean: 36.37903042257795
  episode_reward_min: 15.734693877551013
  episodes_this_iter: 1425
  episodes_total: 2690
  experiment_id: 620cee76ed6f483492f5b5ea167d8862
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.130055993795395
        entropy_coeff: 0.0005000000000000001
        kl: 0.00956034411986669
        model: {}
        policy_loss: -0.011216347149456851
        total_loss: 10.385109821955362
        vf_explained_var: 0.894355058670044
        vf_loss: 10.394978761672974
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.388
    gpu_util_percent0: 0.3824
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5120000000000005
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20230
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16652532875458848
    mean_env_wait_ms: 0.6684123457284149
    mean_inference_ms: 4.952915318761355
    mean_raw_obs_processing_ms: 0.44064388796599707
  time_since_restore: 43.21846151351929
  time_this_iter_s: 20.95393967628479
  time_total_s: 43.21846151351929
  timers:
    learn_throughput: 11096.611
    learn_time_ms: 14580.307
    sample_throughput: 23271.686
    sample_time_ms: 6952.311
    update_time_ms: 21.999
  timestamp: 1604231689
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: ed52d_00000
  
== Status ==
Memory usage on this node: 26.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |      2 |          43.2185 | 323584 |   36.379 |              45.6837 |              15.7347 |            115.784 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed52d_00000:
  custom_metrics:
    time_step_max: 1737
    time_step_mean: 1408.408178256611
    time_step_min: 1222
  date: 2020-11-01_11-55-09
  done: false
  episode_len_mean: 114.67119301648884
  episode_reward_max: 46.85714285714286
  episode_reward_mean: 37.28042419683683
  episode_reward_min: 15.734693877551013
  episodes_this_iter: 1434
  episodes_total: 4124
  experiment_id: 620cee76ed6f483492f5b5ea167d8862
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1140848398208618
        entropy_coeff: 0.0005000000000000001
        kl: 0.009810077414537469
        model: {}
        policy_loss: -0.015473847355072698
        total_loss: 7.254512945810954
        vf_explained_var: 0.9246422648429871
        vf_loss: 7.2685816287994385
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.775000000000002
    gpu_util_percent0: 0.34500000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.516666666666667
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20230
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16318379996682947
    mean_env_wait_ms: 0.662199655734115
    mean_inference_ms: 4.788160816000921
    mean_raw_obs_processing_ms: 0.43056477316095654
  time_since_restore: 63.56497097015381
  time_this_iter_s: 20.34650945663452
  time_total_s: 63.56497097015381
  timers:
    learn_throughput: 11127.786
    learn_time_ms: 14539.46
    sample_throughput: 24626.159
    sample_time_ms: 6569.924
    update_time_ms: 21.5
  timestamp: 1604231709
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: ed52d_00000
  
== Status ==
Memory usage on this node: 26.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |      3 |           63.565 | 485376 |  37.2804 |              46.8571 |              15.7347 |            114.671 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed52d_00000:
  custom_metrics:
    time_step_max: 1737
    time_step_mean: 1389.7721856660146
    time_step_min: 1222
  date: 2020-11-01_11-55-30
  done: false
  episode_len_mean: 113.25304608864559
  episode_reward_max: 46.857142857142875
  episode_reward_mean: 38.234928122758895
  episode_reward_min: 15.734693877551013
  episodes_this_iter: 1539
  episodes_total: 5663
  experiment_id: 620cee76ed6f483492f5b5ea167d8862
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0880944629510243
        entropy_coeff: 0.0005000000000000001
        kl: 0.009488985563317934
        model: {}
        policy_loss: -0.01440603454830125
        total_loss: 5.48736047744751
        vf_explained_var: 0.9440011978149414
        vf_loss: 5.500412583351135
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.516666666666666
    gpu_util_percent0: 0.34874999999999995
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5125000000000006
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20230
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16068983053902333
    mean_env_wait_ms: 0.6583389151369388
    mean_inference_ms: 4.664128900411232
    mean_raw_obs_processing_ms: 0.42299876801925573
  time_since_restore: 84.06657981872559
  time_this_iter_s: 20.501608848571777
  time_total_s: 84.06657981872559
  timers:
    learn_throughput: 11095.44
    learn_time_ms: 14581.846
    sample_throughput: 25479.527
    sample_time_ms: 6349.882
    update_time_ms: 24.143
  timestamp: 1604231730
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: ed52d_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |      4 |          84.0666 | 647168 |  38.2349 |              46.8571 |              15.7347 |            113.253 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed52d_00000:
  custom_metrics:
    time_step_max: 1737
    time_step_mean: 1374.424760022586
    time_step_min: 1222
  date: 2020-11-01_11-55-50
  done: false
  episode_len_mean: 112.05460415496911
  episode_reward_max: 46.857142857142875
  episode_reward_mean: 39.03776398262842
  episode_reward_min: 15.734693877551013
  episodes_this_iter: 1461
  episodes_total: 7124
  experiment_id: 620cee76ed6f483492f5b5ea167d8862
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0627730786800385
        entropy_coeff: 0.0005000000000000001
        kl: 0.009283728742351135
        model: {}
        policy_loss: -0.015454331073366726
        total_loss: 4.347856322924296
        vf_explained_var: 0.9541513323783875
        vf_loss: 4.3619853258132935
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.604166666666668
    gpu_util_percent0: 0.3541666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5124999999999997
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20230
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15895058912495744
    mean_env_wait_ms: 0.6558977259961688
    mean_inference_ms: 4.577574740810779
    mean_raw_obs_processing_ms: 0.4175203436251983
  time_since_restore: 104.25312542915344
  time_this_iter_s: 20.186545610427856
  time_total_s: 104.25312542915344
  timers:
    learn_throughput: 11116.23
    learn_time_ms: 14554.575
    sample_throughput: 26067.237
    sample_time_ms: 6206.718
    update_time_ms: 26.186
  timestamp: 1604231750
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: ed52d_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |      5 |          104.253 | 808960 |  39.0378 |              46.8571 |              15.7347 |            112.055 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed52d_00000:
  custom_metrics:
    time_step_max: 1737
    time_step_mean: 1360.2383485601943
    time_step_min: 1222
  date: 2020-11-01_11-56-11
  done: false
  episode_len_mean: 110.9338091400944
  episode_reward_max: 46.85714285714288
  episode_reward_mean: 39.78162771958098
  episode_reward_min: 15.734693877551013
  episodes_this_iter: 1563
  episodes_total: 8687
  experiment_id: 620cee76ed6f483492f5b5ea167d8862
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0209535757700603
        entropy_coeff: 0.0005000000000000001
        kl: 0.009677846527968844
        model: {}
        policy_loss: -0.013495485666984072
        total_loss: 3.3039915561676025
        vf_explained_var: 0.9663781523704529
        vf_loss: 3.3160619735717773
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.1
    gpu_util_percent0: 0.3948
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.52
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20230
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15752045783718058
    mean_env_wait_ms: 0.6540636684528683
    mean_inference_ms: 4.50681489407211
    mean_raw_obs_processing_ms: 0.4129356375354034
  time_since_restore: 124.68163776397705
  time_this_iter_s: 20.42851233482361
  time_total_s: 124.68163776397705
  timers:
    learn_throughput: 11114.998
    learn_time_ms: 14556.188
    sample_throughput: 26385.183
    sample_time_ms: 6131.926
    update_time_ms: 25.903
  timestamp: 1604231771
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: ed52d_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |      6 |          124.682 | 970752 |  39.7816 |              46.8571 |              15.7347 |            110.934 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed52d_00000:
  custom_metrics:
    time_step_max: 1737
    time_step_mean: 1346.8549304058029
    time_step_min: 1222
  date: 2020-11-01_11-56-31
  done: false
  episode_len_mean: 109.96026166764304
  episode_reward_max: 46.85714285714288
  episode_reward_mean: 40.448761402627824
  episode_reward_min: 15.734693877551013
  episodes_this_iter: 1555
  episodes_total: 10242
  experiment_id: 620cee76ed6f483492f5b5ea167d8862
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9796850432952245
        entropy_coeff: 0.0005000000000000001
        kl: 0.008622131776064634
        model: {}
        policy_loss: -0.012602110786247067
        total_loss: 2.7198241551717124
        vf_explained_var: 0.9723749160766602
        vf_loss: 2.731191635131836
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.520833333333332
    gpu_util_percent0: 0.36541666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5208333333333335
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20230
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15640676678928592
    mean_env_wait_ms: 0.6528313389539068
    mean_inference_ms: 4.45161866768078
    mean_raw_obs_processing_ms: 0.40931756815016995
  time_since_restore: 145.21865725517273
  time_this_iter_s: 20.53701949119568
  time_total_s: 145.21865725517273
  timers:
    learn_throughput: 11103.013
    learn_time_ms: 14571.9
    sample_throughput: 26614.769
    sample_time_ms: 6079.031
    update_time_ms: 25.131
  timestamp: 1604231791
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: ed52d_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |      7 |          145.219 | 1132544 |  40.4488 |              46.8571 |              15.7347 |             109.96 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed52d_00000:
  custom_metrics:
    time_step_max: 1737
    time_step_mean: 1335.6309301139263
    time_step_min: 1222
  date: 2020-11-01_11-56-52
  done: false
  episode_len_mean: 109.09913573970513
  episode_reward_max: 46.8571428571429
  episode_reward_mean: 41.02892366911177
  episode_reward_min: 15.734693877551013
  episodes_this_iter: 1560
  episodes_total: 11802
  experiment_id: 620cee76ed6f483492f5b5ea167d8862
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.937453493475914
        entropy_coeff: 0.0005000000000000001
        kl: 0.007955724994341532
        model: {}
        policy_loss: -0.01194375741033582
        total_loss: 2.2597323656082153
        vf_explained_var: 0.9770286083221436
        vf_loss: 2.2705536683400473
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.436000000000003
    gpu_util_percent0: 0.3632
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20230
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1554915965562696
    mean_env_wait_ms: 0.6518904790353526
    mean_inference_ms: 4.406507393012131
    mean_raw_obs_processing_ms: 0.40631830746764874
  time_since_restore: 166.04925441741943
  time_this_iter_s: 20.830597162246704
  time_total_s: 166.04925441741943
  timers:
    learn_throughput: 11082.871
    learn_time_ms: 14598.383
    sample_throughput: 26705.585
    sample_time_ms: 6058.358
    update_time_ms: 26.617
  timestamp: 1604231812
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: ed52d_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |      8 |          166.049 | 1294336 |  41.0289 |              46.8571 |              15.7347 |            109.099 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed52d_00000:
  custom_metrics:
    time_step_max: 1737
    time_step_mean: 1325.960990247562
    time_step_min: 1222
  date: 2020-11-01_11-57-13
  done: false
  episode_len_mean: 108.36514584891549
  episode_reward_max: 46.8571428571429
  episode_reward_mean: 41.523987605513405
  episode_reward_min: 15.734693877551013
  episodes_this_iter: 1568
  episodes_total: 13370
  experiment_id: 620cee76ed6f483492f5b5ea167d8862
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8931734959284464
        entropy_coeff: 0.0005000000000000001
        kl: 0.007821322418749332
        model: {}
        policy_loss: -0.011547995522657098
        total_loss: 1.8110616604487102
        vf_explained_var: 0.9818581938743591
        vf_loss: 1.8214919765790303
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.3625
    gpu_util_percent0: 0.34625
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5749999999999997
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20230
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15472443847934
    mean_env_wait_ms: 0.6512116120864969
    mean_inference_ms: 4.368900491259558
    mean_raw_obs_processing_ms: 0.40380683055783845
  time_since_restore: 186.4968512058258
  time_this_iter_s: 20.447596788406372
  time_total_s: 186.4968512058258
  timers:
    learn_throughput: 11083.852
    learn_time_ms: 14597.092
    sample_throughput: 26872.567
    sample_time_ms: 6020.713
    update_time_ms: 27.945
  timestamp: 1604231833
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: ed52d_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |      9 |          186.497 | 1456128 |   41.524 |              46.8571 |              15.7347 |            108.365 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed52d_00000:
  custom_metrics:
    time_step_max: 1737
    time_step_mean: 1317.3690564013145
    time_step_min: 1222
  date: 2020-11-01_11-57-34
  done: false
  episode_len_mean: 107.72182462711524
  episode_reward_max: 46.8571428571429
  episode_reward_mean: 41.96634652790953
  episode_reward_min: 15.734693877551013
  episodes_this_iter: 1581
  episodes_total: 14951
  experiment_id: 620cee76ed6f483492f5b5ea167d8862
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8531899998585383
        entropy_coeff: 0.0005000000000000001
        kl: 0.007403539726510644
        model: {}
        policy_loss: -0.011224584576363364
        total_loss: 1.351464072863261
        vf_explained_var: 0.9865902066230774
        vf_loss: 1.3616345326105754
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.612
    gpu_util_percent0: 0.37999999999999995
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.572
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20230
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15406610086889994
    mean_env_wait_ms: 0.6506878167628722
    mean_inference_ms: 4.336866675743429
    mean_raw_obs_processing_ms: 0.4016399376622533
  time_since_restore: 207.11356925964355
  time_this_iter_s: 20.61671805381775
  time_total_s: 207.11356925964355
  timers:
    learn_throughput: 11075.434
    learn_time_ms: 14608.186
    sample_throughput: 27020.124
    sample_time_ms: 5987.833
    update_time_ms: 29.042
  timestamp: 1604231854
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: ed52d_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     10 |          207.114 | 1617920 |  41.9663 |              46.8571 |              15.7347 |            107.722 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed52d_00000:
  custom_metrics:
    time_step_max: 1737
    time_step_mean: 1309.7214852504694
    time_step_min: 1222
  date: 2020-11-01_11-57-55
  done: false
  episode_len_mean: 107.15910326907971
  episode_reward_max: 46.857142857142904
  episode_reward_mean: 42.36176364315742
  episode_reward_min: 15.734693877551013
  episodes_this_iter: 1598
  episodes_total: 16549
  experiment_id: 620cee76ed6f483492f5b5ea167d8862
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8141860415538152
        entropy_coeff: 0.0005000000000000001
        kl: 0.006707225965025525
        model: {}
        policy_loss: -0.011368195065491212
        total_loss: 1.1314103106657665
        vf_explained_var: 0.9888380169868469
        vf_loss: 1.1418441633383434
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.291666666666668
    gpu_util_percent0: 0.38208333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5749999999999997
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20230
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15349391695430212
    mean_env_wait_ms: 0.6503003794675789
    mean_inference_ms: 4.309108284972775
    mean_raw_obs_processing_ms: 0.3997656568156822
  time_since_restore: 227.4893569946289
  time_this_iter_s: 20.37578773498535
  time_total_s: 227.4893569946289
  timers:
    learn_throughput: 11080.893
    learn_time_ms: 14600.989
    sample_throughput: 27896.222
    sample_time_ms: 5799.782
    update_time_ms: 29.058
  timestamp: 1604231875
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: ed52d_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     11 |          227.489 | 1779712 |  42.3618 |              46.8571 |              15.7347 |            107.159 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed52d_00000:
  custom_metrics:
    time_step_max: 1737
    time_step_mean: 1303.0352388842862
    time_step_min: 1222
  date: 2020-11-01_11-58-16
  done: false
  episode_len_mean: 106.65836318545054
  episode_reward_max: 46.857142857142904
  episode_reward_mean: 42.7044331097002
  episode_reward_min: 15.734693877551013
  episodes_this_iter: 1596
  episodes_total: 18145
  experiment_id: 620cee76ed6f483492f5b5ea167d8862
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7753126074870428
        entropy_coeff: 0.0005000000000000001
        kl: 0.006863077365172406
        model: {}
        policy_loss: -0.012638252902737198
        total_loss: 0.8784026602904002
        vf_explained_var: 0.9913859963417053
        vf_loss: 0.8900559494892756
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.460000000000004
    gpu_util_percent0: 0.35159999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5679999999999996
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20230
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15300041083206697
    mean_env_wait_ms: 0.6500163020439707
    mean_inference_ms: 4.28507024712119
    mean_raw_obs_processing_ms: 0.39814727184542376
  time_since_restore: 248.12101984024048
  time_this_iter_s: 20.631662845611572
  time_total_s: 248.12101984024048
  timers:
    learn_throughput: 11075.423
    learn_time_ms: 14608.2
    sample_throughput: 28116.695
    sample_time_ms: 5754.304
    update_time_ms: 29.472
  timestamp: 1604231896
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: ed52d_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     12 |          248.121 | 1941504 |  42.7044 |              46.8571 |              15.7347 |            106.658 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed52d_00000:
  custom_metrics:
    time_step_max: 1737
    time_step_mean: 1297.1705583756345
    time_step_min: 1222
  date: 2020-11-01_11-58-37
  done: false
  episode_len_mean: 106.2274062816616
  episode_reward_max: 46.857142857142904
  episode_reward_mean: 43.00436542398114
  episode_reward_min: 15.734693877551013
  episodes_this_iter: 1595
  episodes_total: 19740
  experiment_id: 620cee76ed6f483492f5b5ea167d8862
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7383754253387451
        entropy_coeff: 0.0005000000000000001
        kl: 0.006651315527657668
        model: {}
        policy_loss: -0.010724902463455996
        total_loss: 0.7107721914847692
        vf_explained_var: 0.9930524230003357
        vf_loss: 0.720536028345426
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.279166666666665
    gpu_util_percent0: 0.3491666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5749999999999997
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20230
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15256633452651727
    mean_env_wait_ms: 0.649802245161823
    mean_inference_ms: 4.264010160654567
    mean_raw_obs_processing_ms: 0.39671502855945817
  time_since_restore: 268.6334173679352
  time_this_iter_s: 20.512397527694702
  time_total_s: 268.6334173679352
  timers:
    learn_throughput: 11061.736
    learn_time_ms: 14626.276
    sample_throughput: 28152.503
    sample_time_ms: 5746.985
    update_time_ms: 29.255
  timestamp: 1604231917
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: ed52d_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     13 |          268.633 | 2103296 |  43.0044 |              46.8571 |              15.7347 |            106.227 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed52d_00000:
  custom_metrics:
    time_step_max: 1737
    time_step_mean: 1292.0809922014469
    time_step_min: 1222
  date: 2020-11-01_11-58-58
  done: false
  episode_len_mean: 105.85140204445278
  episode_reward_max: 46.857142857142904
  episode_reward_mean: 43.26472333282933
  episode_reward_min: 15.734693877551013
  episodes_this_iter: 1586
  episodes_total: 21326
  experiment_id: 620cee76ed6f483492f5b5ea167d8862
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7001272787650427
        entropy_coeff: 0.0005000000000000001
        kl: 0.0061410532022515936
        model: {}
        policy_loss: -0.010832997679244727
        total_loss: 0.6119682043790817
        vf_explained_var: 0.9940410256385803
        vf_loss: 0.621923049290975
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.02
    gpu_util_percent0: 0.368
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20230
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15218124195639093
    mean_env_wait_ms: 0.6496403257727554
    mean_inference_ms: 4.245421485662705
    mean_raw_obs_processing_ms: 0.3954453584998017
  time_since_restore: 289.35663652420044
  time_this_iter_s: 20.72321915626526
  time_total_s: 289.35663652420044
  timers:
    learn_throughput: 11062.187
    learn_time_ms: 14625.679
    sample_throughput: 28102.045
    sample_time_ms: 5757.304
    update_time_ms: 34.762
  timestamp: 1604231938
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: ed52d_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     14 |          289.357 | 2265088 |  43.2647 |              46.8571 |              15.7347 |            105.851 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed52d_00000:
  custom_metrics:
    time_step_max: 1737
    time_step_mean: 1287.5182239314745
    time_step_min: 1222
  date: 2020-11-01_11-59-18
  done: false
  episode_len_mean: 105.5031847133758
  episode_reward_max: 46.857142857142904
  episode_reward_mean: 43.497414924437614
  episode_reward_min: 15.734693877551013
  episodes_this_iter: 1596
  episodes_total: 22922
  experiment_id: 620cee76ed6f483492f5b5ea167d8862
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.6637579500675201
        entropy_coeff: 0.0005000000000000001
        kl: 0.005367214015374581
        model: {}
        policy_loss: -0.009309418620735718
        total_loss: 0.47650496910015744
        vf_explained_var: 0.9953997731208801
        vf_loss: 0.4850728213787079
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.845833333333335
    gpu_util_percent0: 0.40166666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5749999999999997
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20230
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15183678083046764
    mean_env_wait_ms: 0.6495392872625815
    mean_inference_ms: 4.2286469238398325
    mean_raw_obs_processing_ms: 0.39431499646823304
  time_since_restore: 309.672310590744
  time_this_iter_s: 20.31567406654358
  time_total_s: 309.672310590744
  timers:
    learn_throughput: 11054.878
    learn_time_ms: 14635.35
    sample_throughput: 28119.821
    sample_time_ms: 5753.664
    update_time_ms: 33.135
  timestamp: 1604231958
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: ed52d_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     15 |          309.672 | 2426880 |  43.4974 |              46.8571 |              15.7347 |            105.503 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed52d_00000:
  custom_metrics:
    time_step_max: 1737
    time_step_mean: 1283.4805964052287
    time_step_min: 1222
  date: 2020-11-01_11-59-39
  done: false
  episode_len_mean: 105.19265905383361
  episode_reward_max: 46.857142857142904
  episode_reward_mean: 43.70432092086426
  episode_reward_min: 15.734693877551013
  episodes_this_iter: 1598
  episodes_total: 24520
  experiment_id: 620cee76ed6f483492f5b5ea167d8862
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.6296272675196329
        entropy_coeff: 0.0005000000000000001
        kl: 0.0055771675348902745
        model: {}
        policy_loss: -0.009812832868192345
        total_loss: 0.3527320822079976
        vf_explained_var: 0.9965917468070984
        vf_loss: 0.3617442895968755
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.162500000000005
    gpu_util_percent0: 0.42416666666666664
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.570833333333333
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20230
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1515236024097143
    mean_env_wait_ms: 0.6494728987544927
    mean_inference_ms: 4.213501380549204
    mean_raw_obs_processing_ms: 0.3932868129355243
  time_since_restore: 330.0610761642456
  time_this_iter_s: 20.388765573501587
  time_total_s: 330.0610761642456
  timers:
    learn_throughput: 11058.672
    learn_time_ms: 14630.328
    sample_throughput: 28143.68
    sample_time_ms: 5748.786
    update_time_ms: 32.726
  timestamp: 1604231979
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: ed52d_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     16 |          330.061 | 2588672 |  43.7043 |              46.8571 |              15.7347 |            105.193 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed52d_00000:
  custom_metrics:
    time_step_max: 1737
    time_step_mean: 1279.8473329245862
    time_step_min: 1222
  date: 2020-11-01_12-00-00
  done: false
  episode_len_mean: 104.910927456382
  episode_reward_max: 46.857142857142904
  episode_reward_mean: 43.890595815920484
  episode_reward_min: 15.734693877551013
  episodes_this_iter: 1616
  episodes_total: 26136
  experiment_id: 620cee76ed6f483492f5b5ea167d8862
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.5843918571869532
        entropy_coeff: 0.0005000000000000001
        kl: 0.005636528095540901
        model: {}
        policy_loss: -0.009946482673209781
        total_loss: 0.2803831646839778
        vf_explained_var: 0.9972963333129883
        vf_loss: 0.28949454923470813
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.984
    gpu_util_percent0: 0.36920000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20230
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15123654271663214
    mean_env_wait_ms: 0.6494373187304042
    mean_inference_ms: 4.199623866436883
    mean_raw_obs_processing_ms: 0.3923463354120984
  time_since_restore: 350.56322145462036
  time_this_iter_s: 20.502145290374756
  time_total_s: 350.56322145462036
  timers:
    learn_throughput: 11060.535
    learn_time_ms: 14627.863
    sample_throughput: 28221.412
    sample_time_ms: 5732.952
    update_time_ms: 40.383
  timestamp: 1604232000
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: ed52d_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     17 |          350.563 | 2750464 |  43.8906 |              46.8571 |              15.7347 |            104.911 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed52d_00000:
  custom_metrics:
    time_step_max: 1737
    time_step_mean: 1276.563322872705
    time_step_min: 1222
  date: 2020-11-01_12-00-21
  done: false
  episode_len_mean: 104.65475633036776
  episode_reward_max: 46.857142857142904
  episode_reward_mean: 44.05809376302477
  episode_reward_min: 15.734693877551013
  episodes_this_iter: 1627
  episodes_total: 27763
  experiment_id: 620cee76ed6f483492f5b5ea167d8862
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.5512450536092123
        entropy_coeff: 0.0005000000000000001
        kl: 0.0052360318368300796
        model: {}
        policy_loss: -0.00858212105807373
        total_loss: 0.2300113836924235
        vf_explained_var: 0.997800350189209
        vf_loss: 0.2378219154973825
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.133333333333336
    gpu_util_percent0: 0.3545833333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5749999999999997
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20230
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15097539441634178
    mean_env_wait_ms: 0.649425583111441
    mean_inference_ms: 4.186930579711764
    mean_raw_obs_processing_ms: 0.3914892612304368
  time_since_restore: 371.091876745224
  time_this_iter_s: 20.528655290603638
  time_total_s: 371.091876745224
  timers:
    learn_throughput: 11066.918
    learn_time_ms: 14619.428
    sample_throughput: 28359.109
    sample_time_ms: 5705.116
    update_time_ms: 40.411
  timestamp: 1604232021
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: ed52d_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     18 |          371.092 | 2912256 |  44.0581 |              46.8571 |              15.7347 |            104.655 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed52d_00000:
  custom_metrics:
    time_step_max: 1737
    time_step_mean: 1273.6519278628166
    time_step_min: 1222
  date: 2020-11-01_12-00-43
  done: false
  episode_len_mean: 104.42508426105607
  episode_reward_max: 46.857142857142904
  episode_reward_mean: 44.20715088200534
  episode_reward_min: 15.734693877551013
  episodes_this_iter: 1610
  episodes_total: 29373
  experiment_id: 620cee76ed6f483492f5b5ea167d8862
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.525387316942215
        entropy_coeff: 0.0005000000000000001
        kl: 0.004920089112905164
        model: {}
        policy_loss: -0.008422184953815304
        total_loss: 0.1757721391816934
        vf_explained_var: 0.9983048439025879
        vf_loss: 0.1834729996820291
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.212000000000003
    gpu_util_percent0: 0.336
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20230
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15073736984322064
    mean_env_wait_ms: 0.649427266881627
    mean_inference_ms: 4.175450336968136
    mean_raw_obs_processing_ms: 0.3907110068982923
  time_since_restore: 391.7044517993927
  time_this_iter_s: 20.6125750541687
  time_total_s: 391.7044517993927
  timers:
    learn_throughput: 11052.788
    learn_time_ms: 14638.117
    sample_throughput: 28425.972
    sample_time_ms: 5691.696
    update_time_ms: 45.734
  timestamp: 1604232043
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: ed52d_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     19 |          391.704 | 3074048 |  44.2072 |              46.8571 |              15.7347 |            104.425 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed52d_00000:
  custom_metrics:
    time_step_max: 1737
    time_step_mean: 1271.0431296475913
    time_step_min: 1222
  date: 2020-11-01_12-01-04
  done: false
  episode_len_mean: 104.21682273167582
  episode_reward_max: 46.857142857142904
  episode_reward_mean: 44.34093230446844
  episode_reward_min: 15.734693877551013
  episodes_this_iter: 1597
  episodes_total: 30970
  experiment_id: 620cee76ed6f483492f5b5ea167d8862
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.49314410984516144
        entropy_coeff: 0.0005000000000000001
        kl: 0.005798064754344523
        model: {}
        policy_loss: -0.009414856787770987
        total_loss: 0.13895704535146555
        vf_explained_var: 0.9986486434936523
        vf_loss: 0.1480386642118295
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.116666666666664
    gpu_util_percent0: 0.35833333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5749999999999997
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20230
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15052181952677304
    mean_env_wait_ms: 0.649438443211961
    mean_inference_ms: 4.164995515225137
    mean_raw_obs_processing_ms: 0.3900008446460127
  time_since_restore: 412.16121435165405
  time_this_iter_s: 20.456762552261353
  time_total_s: 412.16121435165405
  timers:
    learn_throughput: 11057.384
    learn_time_ms: 14632.032
    sample_throughput: 28470.363
    sample_time_ms: 5682.822
    update_time_ms: 44.871
  timestamp: 1604232064
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: ed52d_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     20 |          412.161 | 3235840 |  44.3409 |              46.8571 |              15.7347 |            104.217 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed52d_00000:
  custom_metrics:
    time_step_max: 1737
    time_step_mean: 1268.6647814593964
    time_step_min: 1222
  date: 2020-11-01_12-01-24
  done: false
  episode_len_mean: 104.02566464051084
  episode_reward_max: 46.857142857142904
  episode_reward_mean: 44.4626028897468
  episode_reward_min: 15.734693877551013
  episodes_this_iter: 1604
  episodes_total: 32574
  experiment_id: 620cee76ed6f483492f5b5ea167d8862
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.46102594832579297
        entropy_coeff: 0.0005000000000000001
        kl: 0.005838079610839486
        model: {}
        policy_loss: -0.00808940147787022
        total_loss: 0.11789208464324474
        vf_explained_var: 0.9988470077514648
        vf_loss: 0.12562819197773933
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.463999999999995
    gpu_util_percent0: 0.3728
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5679999999999996
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20230
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15032141681707573
    mean_env_wait_ms: 0.6494592765291238
    mean_inference_ms: 4.155300920389142
    mean_raw_obs_processing_ms: 0.3893410843403339
  time_since_restore: 432.50473642349243
  time_this_iter_s: 20.34352207183838
  time_total_s: 432.50473642349243
  timers:
    learn_throughput: 11057.81
    learn_time_ms: 14631.468
    sample_throughput: 28523.95
    sample_time_ms: 5672.146
    update_time_ms: 46.215
  timestamp: 1604232084
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: ed52d_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     21 |          432.505 | 3397632 |  44.4626 |              46.8571 |              15.7347 |            104.026 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed52d_00000:
  custom_metrics:
    time_step_max: 1737
    time_step_mean: 1266.4863559173157
    time_step_min: 1222
  date: 2020-11-01_12-01-46
  done: false
  episode_len_mean: 103.8470199450196
  episode_reward_max: 46.857142857142904
  episode_reward_mean: 44.57447720270771
  episode_reward_min: 15.734693877551013
  episodes_this_iter: 1620
  episodes_total: 34194
  experiment_id: 620cee76ed6f483492f5b5ea167d8862
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.43294235815604526
        entropy_coeff: 0.0005000000000000001
        kl: 0.005431869920964043
        model: {}
        policy_loss: -0.009014388362023359
        total_loss: 0.08529840596020222
        vf_explained_var: 0.9991478323936462
        vf_loss: 0.09398608033855756
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.592
    gpu_util_percent0: 0.35
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.572
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20230
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1501333983360748
    mean_env_wait_ms: 0.6494934869624449
    mean_inference_ms: 4.146224608744544
    mean_raw_obs_processing_ms: 0.3887246826845676
  time_since_restore: 453.3322539329529
  time_this_iter_s: 20.82751750946045
  time_total_s: 453.3322539329529
  timers:
    learn_throughput: 11039.758
    learn_time_ms: 14655.394
    sample_throughput: 28584.579
    sample_time_ms: 5660.115
    update_time_ms: 47.568
  timestamp: 1604232106
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: ed52d_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     22 |          453.332 | 3559424 |  44.5745 |              46.8571 |              15.7347 |            103.847 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed52d_00000:
  custom_metrics:
    time_step_max: 1737
    time_step_mean: 1264.481222756231
    time_step_min: 1222
  date: 2020-11-01_12-02-07
  done: false
  episode_len_mean: 103.68064083956682
  episode_reward_max: 46.857142857142904
  episode_reward_mean: 44.67719666296796
  episode_reward_min: 15.734693877551013
  episodes_this_iter: 1634
  episodes_total: 35828
  experiment_id: 620cee76ed6f483492f5b5ea167d8862
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.4028966749707858
        entropy_coeff: 0.0005000000000000001
        kl: 0.0056398319235692424
        model: {}
        policy_loss: -0.010392234045866644
        total_loss: 0.08119491549829642
        vf_explained_var: 0.9991843700408936
        vf_loss: 0.0912246151516835
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.024999999999995
    gpu_util_percent0: 0.36624999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5749999999999997
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20230
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14995601669875397
    mean_env_wait_ms: 0.6495352227224097
    mean_inference_ms: 4.137711997351269
    mean_raw_obs_processing_ms: 0.38814230126504
  time_since_restore: 473.85256695747375
  time_this_iter_s: 20.520313024520874
  time_total_s: 473.85256695747375
  timers:
    learn_throughput: 11045.845
    learn_time_ms: 14647.318
    sample_throughput: 28580.616
    sample_time_ms: 5660.9
    update_time_ms: 49.009
  timestamp: 1604232127
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: ed52d_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     23 |          473.853 | 3721216 |  44.6772 |              46.8571 |              15.7347 |            103.681 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed52d_00000:
  custom_metrics:
    time_step_max: 1737
    time_step_mean: 1262.6683067707777
    time_step_min: 1222
  date: 2020-11-01_12-02-28
  done: false
  episode_len_mean: 103.53063895715354
  episode_reward_max: 46.857142857142904
  episode_reward_mean: 44.77006117651676
  episode_reward_min: 15.734693877551013
  episodes_this_iter: 1608
  episodes_total: 37436
  experiment_id: 620cee76ed6f483492f5b5ea167d8862
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.3745071937640508
        entropy_coeff: 0.0005000000000000001
        kl: 0.005321652473260959
        model: {}
        policy_loss: -0.007234078652497071
        total_loss: 0.05749547202140093
        vf_explained_var: 0.9994208812713623
        vf_loss: 0.06438463802138965
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.864
    gpu_util_percent0: 0.39199999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20230
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14979390065628823
    mean_env_wait_ms: 0.649588420666768
    mean_inference_ms: 4.1299192587977664
    mean_raw_obs_processing_ms: 0.38760946260698614
  time_since_restore: 494.24922704696655
  time_this_iter_s: 20.396660089492798
  time_total_s: 494.24922704696655
  timers:
    learn_throughput: 11054.341
    learn_time_ms: 14636.061
    sample_throughput: 28685.318
    sample_time_ms: 5640.237
    update_time_ms: 42.265
  timestamp: 1604232148
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: ed52d_00000
  
2020-11-01 12:02:29,652	WARNING util.py:136 -- The `process_trial` operation took 0.5228226184844971 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     24 |          494.249 | 3883008 |  44.7701 |              46.8571 |              15.7347 |            103.531 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed52d_00000:
  custom_metrics:
    time_step_max: 1737
    time_step_mean: 1261.0109236371095
    time_step_min: 1222
  date: 2020-11-01_12-02-50
  done: false
  episode_len_mean: 103.39151595880936
  episode_reward_max: 46.857142857142904
  episode_reward_mean: 44.854644767892296
  episode_reward_min: 15.734693877551013
  episodes_this_iter: 1602
  episodes_total: 39038
  experiment_id: 620cee76ed6f483492f5b5ea167d8862
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.3481475959221522
        entropy_coeff: 0.0005000000000000001
        kl: 0.004828551318496466
        model: {}
        policy_loss: -0.0070124387663478656
        total_loss: 0.06740419659763575
        vf_explained_var: 0.9993410706520081
        vf_loss: 0.07410785431663196
    num_steps_sampled: 4044800
    num_steps_trained: 4044800
  iterations_since_restore: 25
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.944000000000003
    gpu_util_percent0: 0.3452
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5679999999999996
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20230
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14964195104865902
    mean_env_wait_ms: 0.6496402901027807
    mean_inference_ms: 4.122656867380491
    mean_raw_obs_processing_ms: 0.3871109943323948
  time_since_restore: 514.7466752529144
  time_this_iter_s: 20.497448205947876
  time_total_s: 514.7466752529144
  timers:
    learn_throughput: 11049.552
    learn_time_ms: 14642.403
    sample_throughput: 28661.043
    sample_time_ms: 5645.014
    update_time_ms: 44.89
  timestamp: 1604232170
  timesteps_since_restore: 0
  timesteps_total: 4044800
  training_iteration: 25
  trial_id: ed52d_00000
  
2020-11-01 12:02:51,023	WARNING util.py:136 -- The `process_trial` operation took 0.5479519367218018 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     25 |          514.747 | 4044800 |  44.8546 |              46.8571 |              15.7347 |            103.392 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed52d_00000:
  custom_metrics:
    time_step_max: 1737
    time_step_mean: 1259.4838947990543
    time_step_min: 1222
  date: 2020-11-01_12-03-11
  done: false
  episode_len_mean: 103.26077543790592
  episode_reward_max: 46.857142857142904
  episode_reward_mean: 44.933213572774115
  episode_reward_min: 15.734693877551013
  episodes_this_iter: 1610
  episodes_total: 40648
  experiment_id: 620cee76ed6f483492f5b5ea167d8862
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.0e-05
        entropy: 0.32285959521929425
        entropy_coeff: 0.0005000000000000001
        kl: 0.005153231516790886
        model: {}
        policy_loss: -0.006437089536727096
        total_loss: 0.04760071821510792
        vf_explained_var: 0.9995192885398865
        vf_loss: 0.05394157860428095
    num_steps_sampled: 4206592
    num_steps_trained: 4206592
  iterations_since_restore: 26
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.183333333333334
    gpu_util_percent0: 0.30583333333333335
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.570833333333333
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20230
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14949842842548025
    mean_env_wait_ms: 0.6496982049535759
    mean_inference_ms: 4.115822249881849
    mean_raw_obs_processing_ms: 0.3866408622949027
  time_since_restore: 535.2055022716522
  time_this_iter_s: 20.458827018737793
  time_total_s: 535.2055022716522
  timers:
    learn_throughput: 11044.133
    learn_time_ms: 14649.588
    sample_throughput: 28693.76
    sample_time_ms: 5638.578
    update_time_ms: 44.672
  timestamp: 1604232191
  timesteps_since_restore: 0
  timesteps_total: 4206592
  training_iteration: 26
  trial_id: ed52d_00000
  
2020-11-01 12:03:12,271	WARNING util.py:136 -- The `process_trial` operation took 0.5345759391784668 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     26 |          535.206 | 4206592 |  44.9332 |              46.8571 |              15.7347 |            103.261 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed52d_00000:
  custom_metrics:
    time_step_max: 1737
    time_step_mean: 1258.0401912516568
    time_step_min: 1222
  date: 2020-11-01_12-03-32
  done: false
  episode_len_mean: 103.137958758986
  episode_reward_max: 46.857142857142904
  episode_reward_mean: 45.007320067641125
  episode_reward_min: 15.734693877551013
  episodes_this_iter: 1640
  episodes_total: 42288
  experiment_id: 620cee76ed6f483492f5b5ea167d8862
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.0e-05
        entropy: 0.2982073624928792
        entropy_coeff: 0.0005000000000000001
        kl: 0.004597992869094014
        model: {}
        policy_loss: -0.007848733845700432
        total_loss: 0.03614849457517266
        vf_explained_var: 0.9996141791343689
        vf_loss: 0.043916432497402035
    num_steps_sampled: 4368384
    num_steps_trained: 4368384
  iterations_since_restore: 27
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.736
    gpu_util_percent0: 0.4024000000000001
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20230
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14936013846680316
    mean_env_wait_ms: 0.6497567301190108
    mean_inference_ms: 4.109265721932972
    mean_raw_obs_processing_ms: 0.38618524014647837
  time_since_restore: 555.6780240535736
  time_this_iter_s: 20.472521781921387
  time_total_s: 555.6780240535736
  timers:
    learn_throughput: 11047.092
    learn_time_ms: 14645.664
    sample_throughput: 28676.643
    sample_time_ms: 5641.943
    update_time_ms: 36.998
  timestamp: 1604232212
  timesteps_since_restore: 0
  timesteps_total: 4368384
  training_iteration: 27
  trial_id: ed52d_00000
  
2020-11-01 12:03:33,510	WARNING util.py:136 -- The `process_trial` operation took 0.567908525466919 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     27 |          555.678 | 4368384 |  45.0073 |              46.8571 |              15.7347 |            103.138 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed52d_00000:
  custom_metrics:
    time_step_max: 1737
    time_step_mean: 1256.7130644903914
    time_step_min: 1222
  date: 2020-11-01_12-03-53
  done: false
  episode_len_mean: 103.02484797412713
  episode_reward_max: 46.857142857142904
  episode_reward_mean: 45.07519232440738
  episode_reward_min: 15.734693877551013
  episodes_this_iter: 1619
  episodes_total: 43907
  experiment_id: 620cee76ed6f483492f5b5ea167d8862
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 5.0e-05
        entropy: 0.27154965202013653
        entropy_coeff: 0.0005000000000000001
        kl: 0.004386523951931546
        model: {}
        policy_loss: -0.006109707096281151
        total_loss: 0.029498847822348278
        vf_explained_var: 0.9996840357780457
        vf_loss: 0.03563466699173053
    num_steps_sampled: 4530176
    num_steps_trained: 4530176
  iterations_since_restore: 28
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.215999999999998
    gpu_util_percent0: 0.35719999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5679999999999996
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20230
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14923164336873793
    mean_env_wait_ms: 0.6498215067723312
    mean_inference_ms: 4.103192802934885
    mean_raw_obs_processing_ms: 0.3857616555198185
  time_since_restore: 576.108469247818
  time_this_iter_s: 20.430445194244385
  time_total_s: 576.108469247818
  timers:
    learn_throughput: 11053.539
    learn_time_ms: 14637.122
    sample_throughput: 28704.812
    sample_time_ms: 5636.407
    update_time_ms: 34.761
  timestamp: 1604232233
  timesteps_since_restore: 0
  timesteps_total: 4530176
  training_iteration: 28
  trial_id: ed52d_00000
  
2020-11-01 12:03:54,833	WARNING util.py:136 -- The `process_trial` operation took 0.5623390674591064 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     28 |          576.108 | 4530176 |  45.0752 |              46.8571 |              15.7347 |            103.025 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed52d_00000:
  custom_metrics:
    time_step_max: 1737
    time_step_mean: 1255.498240520806
    time_step_min: 1222
  date: 2020-11-01_12-04-15
  done: false
  episode_len_mean: 102.92078315900501
  episode_reward_max: 46.857142857142904
  episode_reward_mean: 45.13765263071036
  episode_reward_min: 15.734693877551013
  episodes_this_iter: 1601
  episodes_total: 45508
  experiment_id: 620cee76ed6f483492f5b5ea167d8862
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.012500000000000002
        cur_lr: 5.0e-05
        entropy: 0.25443976496656734
        entropy_coeff: 0.0005000000000000001
        kl: 0.004423999693244696
        model: {}
        policy_loss: -0.005417319412420814
        total_loss: 0.024296301572273176
        vf_explained_var: 0.9997418522834778
        vf_loss: 0.02978554057578246
    num_steps_sampled: 4691968
    num_steps_trained: 4691968
  iterations_since_restore: 29
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.112
    gpu_util_percent0: 0.33520000000000005
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5679999999999996
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20230
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1491126560484596
    mean_env_wait_ms: 0.6498944683718904
    mean_inference_ms: 4.097513752031446
    mean_raw_obs_processing_ms: 0.38536978766235913
  time_since_restore: 596.6098058223724
  time_this_iter_s: 20.501336574554443
  time_total_s: 596.6098058223724
  timers:
    learn_throughput: 11066.443
    learn_time_ms: 14620.054
    sample_throughput: 28671.129
    sample_time_ms: 5643.029
    update_time_ms: 27.975
  timestamp: 1604232255
  timesteps_since_restore: 0
  timesteps_total: 4691968
  training_iteration: 29
  trial_id: ed52d_00000
  
2020-11-01 12:04:16,277	WARNING util.py:136 -- The `process_trial` operation took 0.5899343490600586 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     29 |           596.61 | 4691968 |  45.1377 |              46.8571 |              15.7347 |            102.921 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed52d_00000:
  custom_metrics:
    time_step_max: 1737
    time_step_mean: 1254.3588893845729
    time_step_min: 1222
  date: 2020-11-01_12-04-36
  done: true
  episode_len_mean: 102.82308492348184
  episode_reward_max: 46.857142857142904
  episode_reward_mean: 45.196090857543105
  episode_reward_min: 15.734693877551013
  episodes_this_iter: 1605
  episodes_total: 47113
  experiment_id: 620cee76ed6f483492f5b5ea167d8862
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.006250000000000001
        cur_lr: 5.0e-05
        entropy: 0.23119975750645003
        entropy_coeff: 0.0005000000000000001
        kl: 0.004294859090199073
        model: {}
        policy_loss: -0.006582304151379503
        total_loss: 0.016346099126773577
        vf_explained_var: 0.9998031258583069
        vf_loss: 0.02301716012880206
    num_steps_sampled: 4853760
    num_steps_trained: 4853760
  iterations_since_restore: 30
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.433333333333334
    gpu_util_percent0: 0.3558333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.570833333333333
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20230
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1489996674476156
    mean_env_wait_ms: 0.6499679628512286
    mean_inference_ms: 4.0921381946019215
    mean_raw_obs_processing_ms: 0.38499719572571234
  time_since_restore: 616.9446895122528
  time_this_iter_s: 20.33488368988037
  time_total_s: 616.9446895122528
  timers:
    learn_throughput: 11076.785
    learn_time_ms: 14606.404
    sample_throughput: 28687.763
    sample_time_ms: 5639.757
    update_time_ms: 27.238
  timestamp: 1604232276
  timesteps_since_restore: 0
  timesteps_total: 4853760
  training_iteration: 30
  trial_id: ed52d_00000
  
2020-11-01 12:04:37,528	WARNING util.py:136 -- The `process_trial` operation took 0.6967248916625977 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 24.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed52d_00000 | TERMINATED |       |     30 |          616.945 | 4853760 |  45.1961 |              46.8571 |              15.7347 |            102.823 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 24.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed52d_00000 | TERMINATED |       |     30 |          616.945 | 4853760 |  45.1961 |              46.8571 |              15.7347 |            102.823 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


