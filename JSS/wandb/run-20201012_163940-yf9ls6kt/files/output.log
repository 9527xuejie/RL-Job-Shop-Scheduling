2020-10-12 16:39:44,063	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_891e1_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=72573)[0m 2020-10-12 16:39:46,954	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=72513)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72513)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72490)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72490)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72452)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72452)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72545)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72545)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72517)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72517)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72525)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72525)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72543)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72543)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72454)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72454)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72472)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72472)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72523)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72523)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72563)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72563)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72531)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72531)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72553)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72553)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72585)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72585)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72548)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72548)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72530)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72530)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72527)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72527)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72570)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72570)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72511)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72511)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72558)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72558)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72574)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72574)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72556)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72556)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72522)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72522)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72564)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72564)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72552)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72552)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72582)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72582)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72482)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72482)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72474)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72474)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72534)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72534)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72524)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72524)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72528)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72528)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72521)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72521)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72508)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72508)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72547)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72547)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72468)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72468)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72477)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72477)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72568)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72568)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72450)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72450)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72460)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72460)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72459)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72459)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72480)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72480)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72451)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72451)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72539)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72539)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72537)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72537)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72469)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72469)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72461)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72461)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72542)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72542)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72562)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72562)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72533)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72533)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72457)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72457)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72532)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72532)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72455)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72455)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72467)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72467)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72509)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72509)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72526)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72526)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72470)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72470)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72479)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72479)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72561)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72561)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72453)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72453)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72578)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72578)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72486)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72486)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72546)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72546)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72456)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72456)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72458)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72458)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72462)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72462)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72535)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72535)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72463)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72463)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72466)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72466)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72473)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72473)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72515)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72515)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72555)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72555)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72529)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72529)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72489)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72489)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72519)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72519)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72577)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72577)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72471)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72471)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72559)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72559)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72541)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72541)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72538)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72538)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_891e1_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3561.048780487805
    time_step_min: 3288
  date: 2020-10-12_16-40-21
  done: false
  episode_len_mean: 897.367088607595
  episode_reward_max: 273.50505050505103
  episode_reward_mean: 205.7902442142946
  episode_reward_min: 128.35353535353502
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 3ebc0295a6ab42bc8a98f089926215f2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1785882810751598
        entropy_coeff: 0.009999999999999998
        kl: 0.006706703958722453
        model: {}
        policy_loss: -0.008831985736226974
        total_loss: 417.50346120198566
        vf_explained_var: 0.5535116195678711
        vf_loss: 417.5227355957031
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.341176470588238
    gpu_util_percent0: 0.2817647058823529
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5676470588235296
    vram_util_percent0: 0.08664846719271507
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72573
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.169603221760226
    mean_env_wait_ms: 1.1657359873155417
    mean_inference_ms: 5.79688758532108
    mean_raw_obs_processing_ms: 0.4515812182801856
  time_since_restore: 29.130961179733276
  time_this_iter_s: 29.130961179733276
  time_total_s: 29.130961179733276
  timers:
    learn_throughput: 8161.9
    learn_time_ms: 19822.835
    sample_throughput: 17522.941
    sample_time_ms: 9233.153
    update_time_ms: 43.809
  timestamp: 1602520821
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 891e1_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_891e1_00000 | RUNNING  | 172.17.0.4:72573 |      1 |           29.131 | 161792 |   205.79 |              273.505 |              128.354 |            897.367 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_891e1_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3573.306049822064
    time_step_min: 3203
  date: 2020-10-12_16-40-48
  done: false
  episode_len_mean: 897.7405063291139
  episode_reward_max: 273.50505050505103
  episode_reward_mean: 205.5950965349697
  episode_reward_min: 128.35353535353502
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 3ebc0295a6ab42bc8a98f089926215f2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1490242679913838
        entropy_coeff: 0.009999999999999998
        kl: 0.008353104504446188
        model: {}
        policy_loss: -0.011560303973965347
        total_loss: 102.48162269592285
        vf_explained_var: 0.8230600953102112
        vf_loss: 102.50300470987956
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.09354838709678
    gpu_util_percent0: 0.32193548387096776
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7548387096774185
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72573
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1651276626989633
    mean_env_wait_ms: 1.161414117668024
    mean_inference_ms: 5.548521035004857
    mean_raw_obs_processing_ms: 0.4394777246287609
  time_since_restore: 56.30393671989441
  time_this_iter_s: 27.172975540161133
  time_total_s: 56.30393671989441
  timers:
    learn_throughput: 8247.368
    learn_time_ms: 19617.411
    sample_throughput: 19136.884
    sample_time_ms: 8454.459
    update_time_ms: 41.745
  timestamp: 1602520848
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 891e1_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_891e1_00000 | RUNNING  | 172.17.0.4:72573 |      2 |          56.3039 | 323584 |  205.595 |              273.505 |              128.354 |            897.741 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_891e1_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3567.7835990888384
    time_step_min: 3203
  date: 2020-10-12_16-41-15
  done: false
  episode_len_mean: 892.6708860759494
  episode_reward_max: 273.50505050505103
  episode_reward_mean: 207.36293312875566
  episode_reward_min: 123.05050505050464
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 3ebc0295a6ab42bc8a98f089926215f2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1385955214500427
        entropy_coeff: 0.009999999999999998
        kl: 0.010756941046565771
        model: {}
        policy_loss: -0.013618720307325324
        total_loss: 50.10755920410156
        vf_explained_var: 0.8967936635017395
        vf_loss: 50.130411783854164
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.278125
    gpu_util_percent0: 0.3090625
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.771875
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72573
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16232026734078112
    mean_env_wait_ms: 1.1605509823051918
    mean_inference_ms: 5.367327761447367
    mean_raw_obs_processing_ms: 0.43112677600291044
  time_since_restore: 83.02741432189941
  time_this_iter_s: 26.723477602005005
  time_total_s: 83.02741432189941
  timers:
    learn_throughput: 8279.884
    learn_time_ms: 19540.369
    sample_throughput: 20135.654
    sample_time_ms: 8035.101
    update_time_ms: 55.857
  timestamp: 1602520875
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 891e1_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_891e1_00000 | RUNNING  | 172.17.0.4:72573 |      3 |          83.0274 | 485376 |  207.363 |              273.505 |              123.051 |            892.671 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_891e1_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3558.061976549414
    time_step_min: 3203
  date: 2020-10-12_16-41-42
  done: false
  episode_len_mean: 889.2816455696203
  episode_reward_max: 273.50505050505103
  episode_reward_mean: 208.59782956143695
  episode_reward_min: 111.08080808080757
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 3ebc0295a6ab42bc8a98f089926215f2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1314318776130676
        entropy_coeff: 0.009999999999999998
        kl: 0.010051772541676959
        model: {}
        policy_loss: -0.01295024734766533
        total_loss: 37.251620292663574
        vf_explained_var: 0.920976459980011
        vf_loss: 37.27387523651123
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.458064516129035
    gpu_util_percent0: 0.29225806451612907
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774193548387097
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72573
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16028407277210727
    mean_env_wait_ms: 1.1609211954071366
    mean_inference_ms: 5.23179426952255
    mean_raw_obs_processing_ms: 0.424743883528653
  time_since_restore: 109.67284774780273
  time_this_iter_s: 26.64543342590332
  time_total_s: 109.67284774780273
  timers:
    learn_throughput: 8297.163
    learn_time_ms: 19499.677
    sample_throughput: 20683.578
    sample_time_ms: 7822.244
    update_time_ms: 51.61
  timestamp: 1602520902
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 891e1_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_891e1_00000 | RUNNING  | 172.17.0.4:72573 |      4 |          109.673 | 647168 |  208.598 |              273.505 |              111.081 |            889.282 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_891e1_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3549.9602649006624
    time_step_min: 3203
  date: 2020-10-12_16-42-08
  done: false
  episode_len_mean: 885.6607594936709
  episode_reward_max: 273.50505050505103
  episode_reward_mean: 209.6978007927373
  episode_reward_min: 111.08080808080757
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 3ebc0295a6ab42bc8a98f089926215f2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1040861407915752
        entropy_coeff: 0.009999999999999998
        kl: 0.009942340975006422
        model: {}
        policy_loss: -0.01375953498063609
        total_loss: 31.38749122619629
        vf_explained_var: 0.9320996403694153
        vf_loss: 31.410302480061848
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.31612903225807
    gpu_util_percent0: 0.3016129032258065
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.777419354838709
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72573
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15875096289496773
    mean_env_wait_ms: 1.1620560938187274
    mean_inference_ms: 5.128842005566981
    mean_raw_obs_processing_ms: 0.41980891613772364
  time_since_restore: 136.11974358558655
  time_this_iter_s: 26.446895837783813
  time_total_s: 136.11974358558655
  timers:
    learn_throughput: 8298.262
    learn_time_ms: 19497.094
    sample_throughput: 21195.696
    sample_time_ms: 7633.248
    update_time_ms: 47.197
  timestamp: 1602520928
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 891e1_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_891e1_00000 | RUNNING  | 172.17.0.4:72573 |      5 |           136.12 | 808960 |  209.698 |              273.505 |              111.081 |            885.661 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_891e1_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3533.7526987242395
    time_step_min: 3203
  date: 2020-10-12_16-42-35
  done: false
  episode_len_mean: 876.5445920303605
  episode_reward_max: 273.50505050505103
  episode_reward_mean: 212.733818258486
  episode_reward_min: 111.08080808080757
  episodes_this_iter: 264
  episodes_total: 1054
  experiment_id: 3ebc0295a6ab42bc8a98f089926215f2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0658138891061146
        entropy_coeff: 0.009999999999999998
        kl: 0.00933318391131858
        model: {}
        policy_loss: -0.012393430360437682
        total_loss: 36.47573630015055
        vf_explained_var: 0.9486215710639954
        vf_loss: 36.49692185719808
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.464516129032262
    gpu_util_percent0: 0.325483870967742
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770967741935483
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72573
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15692584677885404
    mean_env_wait_ms: 1.1654452330028462
    mean_inference_ms: 5.006102571483418
    mean_raw_obs_processing_ms: 0.41396165525727174
  time_since_restore: 163.02931189537048
  time_this_iter_s: 26.909568309783936
  time_total_s: 163.02931189537048
  timers:
    learn_throughput: 8286.273
    learn_time_ms: 19525.305
    sample_throughput: 21423.646
    sample_time_ms: 7552.029
    update_time_ms: 45.782
  timestamp: 1602520955
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 891e1_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_891e1_00000 | RUNNING  | 172.17.0.4:72573 |      6 |          163.029 | 970752 |  212.734 |              273.505 |              111.081 |            876.545 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_891e1_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3512.858421480879
    time_step_min: 3169
  date: 2020-10-12_16-43-02
  done: false
  episode_len_mean: 869.867088607595
  episode_reward_max: 275.3232323232323
  episode_reward_mean: 215.16104877892835
  episode_reward_min: 111.08080808080757
  episodes_this_iter: 210
  episodes_total: 1264
  experiment_id: 3ebc0295a6ab42bc8a98f089926215f2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0825717051823933
        entropy_coeff: 0.009999999999999998
        kl: 0.008545656688511372
        model: {}
        policy_loss: -0.011160410174246257
        total_loss: 22.244722366333008
        vf_explained_var: 0.9555189609527588
        vf_loss: 22.26499891281128
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.845161290322586
    gpu_util_percent0: 0.2906451612903226
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72573
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15593181354800392
    mean_env_wait_ms: 1.167873566268038
    mean_inference_ms: 4.935556685000799
    mean_raw_obs_processing_ms: 0.4107411395920688
  time_since_restore: 189.63326239585876
  time_this_iter_s: 26.60395050048828
  time_total_s: 189.63326239585876
  timers:
    learn_throughput: 8286.79
    learn_time_ms: 19524.086
    sample_throughput: 21649.993
    sample_time_ms: 7473.074
    update_time_ms: 44.724
  timestamp: 1602520982
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 891e1_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_891e1_00000 | RUNNING  | 172.17.0.4:72573 |      7 |          189.633 | 1132544 |  215.161 |              275.323 |              111.081 |            869.867 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_891e1_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3502.7923576063445
    time_step_min: 3158
  date: 2020-10-12_16-43-28
  done: false
  episode_len_mean: 864.210970464135
  episode_reward_max: 275.3232323232323
  episode_reward_mean: 217.01994629842716
  episode_reward_min: 111.08080808080757
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 3ebc0295a6ab42bc8a98f089926215f2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0544531146685283
        entropy_coeff: 0.009999999999999998
        kl: 0.008751809829846025
        model: {}
        policy_loss: -0.013738216968098035
        total_loss: 18.00612958272298
        vf_explained_var: 0.958373486995697
        vf_loss: 18.02866220474243
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.174193548387098
    gpu_util_percent0: 0.31483870967741934
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7741935483870965
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72573
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15530189734244068
    mean_env_wait_ms: 1.1696483936071564
    mean_inference_ms: 4.891815698823182
    mean_raw_obs_processing_ms: 0.40866171428333414
  time_since_restore: 216.2066674232483
  time_this_iter_s: 26.573405027389526
  time_total_s: 216.2066674232483
  timers:
    learn_throughput: 8293.495
    learn_time_ms: 19508.301
    sample_throughput: 21788.677
    sample_time_ms: 7425.508
    update_time_ms: 43.328
  timestamp: 1602521008
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 891e1_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_891e1_00000 | RUNNING  | 172.17.0.4:72573 |      8 |          216.207 | 1294336 |   217.02 |              275.323 |              111.081 |            864.211 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_891e1_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3489.740453074434
    time_step_min: 3140
  date: 2020-10-12_16-43-55
  done: false
  episode_len_mean: 858.8974683544304
  episode_reward_max: 275.3232323232323
  episode_reward_mean: 218.94722541874427
  episode_reward_min: 111.08080808080757
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 3ebc0295a6ab42bc8a98f089926215f2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0277750591437023
        entropy_coeff: 0.009999999999999998
        kl: 0.008797148164982596
        model: {}
        policy_loss: -0.013695253253293535
        total_loss: 15.086629629135132
        vf_explained_var: 0.9629938006401062
        vf_loss: 15.108842770258585
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.71612903225807
    gpu_util_percent0: 0.3829032258064516
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.777419354838709
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72573
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1547513538814944
    mean_env_wait_ms: 1.1714391871462795
    mean_inference_ms: 4.853505582400465
    mean_raw_obs_processing_ms: 0.4067647640838373
  time_since_restore: 242.7223253250122
  time_this_iter_s: 26.515657901763916
  time_total_s: 242.7223253250122
  timers:
    learn_throughput: 8296.49
    learn_time_ms: 19501.258
    sample_throughput: 21960.448
    sample_time_ms: 7367.427
    update_time_ms: 50.813
  timestamp: 1602521035
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 891e1_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_891e1_00000 | RUNNING  | 172.17.0.4:72573 |      9 |          242.722 | 1456128 |  218.947 |              275.323 |              111.081 |            858.897 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_891e1_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3472.4761382336806
    time_step_min: 3140
  date: 2020-10-12_16-44-22
  done: false
  episode_len_mean: 851.2739504843918
  episode_reward_max: 275.3232323232323
  episode_reward_mean: 221.56552608974556
  episode_reward_min: 111.08080808080757
  episodes_this_iter: 278
  episodes_total: 1858
  experiment_id: 3ebc0295a6ab42bc8a98f089926215f2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9885738243659338
        entropy_coeff: 0.009999999999999998
        kl: 0.008387341513298452
        model: {}
        policy_loss: -0.012453877308871597
        total_loss: 22.581890900929768
        vf_explained_var: 0.965716540813446
        vf_loss: 22.602553685506184
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.670000000000005
    gpu_util_percent0: 0.2876666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.763333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72573
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15394005877270417
    mean_env_wait_ms: 1.1747358272602177
    mean_inference_ms: 4.797655407167501
    mean_raw_obs_processing_ms: 0.4040442559791502
  time_since_restore: 269.2099735736847
  time_this_iter_s: 26.487648248672485
  time_total_s: 269.2099735736847
  timers:
    learn_throughput: 8293.571
    learn_time_ms: 19508.123
    sample_throughput: 22122.61
    sample_time_ms: 7313.423
    update_time_ms: 49.691
  timestamp: 1602521062
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 891e1_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_891e1_00000 | RUNNING  | 172.17.0.4:72573 |     10 |           269.21 | 1617920 |  221.566 |              275.323 |              111.081 |            851.274 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_891e1_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3459.4388311045072
    time_step_min: 3114
  date: 2020-10-12_16-44-48
  done: false
  episode_len_mean: 846.1684518013632
  episode_reward_max: 275.47474747474763
  episode_reward_mean: 223.412843134362
  episode_reward_min: 111.08080808080757
  episodes_this_iter: 196
  episodes_total: 2054
  experiment_id: 3ebc0295a6ab42bc8a98f089926215f2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9878408014774323
        entropy_coeff: 0.009999999999999998
        kl: 0.00939009765473505
        model: {}
        policy_loss: -0.013306313776411116
        total_loss: 13.694687763849894
        vf_explained_var: 0.9715245366096497
        vf_loss: 13.715994596481323
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.016129032258068
    gpu_util_percent0: 0.23258064516129032
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7838709677419353
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72573
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.153484695997282
    mean_env_wait_ms: 1.1768558890342675
    mean_inference_ms: 4.765460634642789
    mean_raw_obs_processing_ms: 0.40250087355968434
  time_since_restore: 295.86342668533325
  time_this_iter_s: 26.65345311164856
  time_total_s: 295.86342668533325
  timers:
    learn_throughput: 8301.504
    learn_time_ms: 19489.48
    sample_throughput: 22842.253
    sample_time_ms: 7083.014
    update_time_ms: 48.975
  timestamp: 1602521088
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 891e1_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_891e1_00000 | RUNNING  | 172.17.0.4:72573 |     11 |          295.863 | 1779712 |  223.413 |              275.475 |              111.081 |            846.168 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_891e1_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3450.0730362884706
    time_step_min: 3077
  date: 2020-10-12_16-45-15
  done: false
  episode_len_mean: 842.506329113924
  episode_reward_max: 281.0808080808079
  episode_reward_mean: 224.73025462582413
  episode_reward_min: 111.08080808080757
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 3ebc0295a6ab42bc8a98f089926215f2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9741780012845993
        entropy_coeff: 0.009999999999999998
        kl: 0.008219406241551042
        model: {}
        policy_loss: -0.01533693818297858
        total_loss: 13.70467726389567
        vf_explained_var: 0.9678465723991394
        vf_loss: 13.72811230023702
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.345161290322583
    gpu_util_percent0: 0.3216129032258064
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.777419354838709
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72573
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15314905455669475
    mean_env_wait_ms: 1.1784297444560163
    mean_inference_ms: 4.74228013005998
    mean_raw_obs_processing_ms: 0.40135138970216655
  time_since_restore: 322.5093014240265
  time_this_iter_s: 26.645874738693237
  time_total_s: 322.5093014240265
  timers:
    learn_throughput: 8288.972
    learn_time_ms: 19518.947
    sample_throughput: 23116.319
    sample_time_ms: 6999.038
    update_time_ms: 49.376
  timestamp: 1602521115
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 891e1_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_891e1_00000 | RUNNING  | 172.17.0.4:72573 |     12 |          322.509 | 1941504 |   224.73 |              281.081 |              111.081 |            842.506 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_891e1_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3442.335036185611
    time_step_min: 3077
  date: 2020-10-12_16-45-42
  done: false
  episode_len_mean: 839.0335570469799
  episode_reward_max: 281.0808080808079
  episode_reward_mean: 225.79767049691534
  episode_reward_min: 111.08080808080757
  episodes_this_iter: 172
  episodes_total: 2384
  experiment_id: 3ebc0295a6ab42bc8a98f089926215f2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9363573590914408
        entropy_coeff: 0.009999999999999998
        kl: 0.007771769616131981
        model: {}
        policy_loss: -0.014156669426787024
        total_loss: 18.613755385080974
        vf_explained_var: 0.9657605290412903
        vf_loss: 18.63572104771932
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.573333333333338
    gpu_util_percent0: 0.3686666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7733333333333325
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72573
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15282178170912228
    mean_env_wait_ms: 1.1801264237572675
    mean_inference_ms: 4.719431866762651
    mean_raw_obs_processing_ms: 0.4001940221076802
  time_since_restore: 348.9082782268524
  time_this_iter_s: 26.398976802825928
  time_total_s: 348.9082782268524
  timers:
    learn_throughput: 8285.124
    learn_time_ms: 19528.012
    sample_throughput: 23239.422
    sample_time_ms: 6961.963
    update_time_ms: 45.167
  timestamp: 1602521142
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 891e1_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_891e1_00000 | RUNNING  | 172.17.0.4:72573 |     13 |          348.908 | 2103296 |  225.798 |              281.081 |              111.081 |            839.034 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_891e1_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3432.2861457153645
    time_step_min: 3075
  date: 2020-10-12_16-46-08
  done: false
  episode_len_mean: 833.9336810730254
  episode_reward_max: 281.38383838383845
  episode_reward_mean: 227.4817022685874
  episode_reward_min: 111.08080808080757
  episodes_this_iter: 300
  episodes_total: 2684
  experiment_id: 3ebc0295a6ab42bc8a98f089926215f2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9387146979570389
        entropy_coeff: 0.009999999999999998
        kl: 0.006999079875337581
        model: {}
        policy_loss: -0.010212986225572726
        total_loss: 17.698159217834473
        vf_explained_var: 0.9726449847221375
        vf_loss: 17.71635977427165
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.870967741935484
    gpu_util_percent0: 0.32451612903225807
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.764516129032258
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72573
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15231553825376895
    mean_env_wait_ms: 1.1828969310334512
    mean_inference_ms: 4.68482793824521
    mean_raw_obs_processing_ms: 0.3985025661076887
  time_since_restore: 375.5391192436218
  time_this_iter_s: 26.63084101676941
  time_total_s: 375.5391192436218
  timers:
    learn_throughput: 8275.688
    learn_time_ms: 19550.277
    sample_throughput: 23326.243
    sample_time_ms: 6936.051
    update_time_ms: 44.241
  timestamp: 1602521168
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 891e1_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_891e1_00000 | RUNNING  | 172.17.0.4:72573 |     14 |          375.539 | 2265088 |  227.482 |              281.384 |              111.081 |            833.934 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_891e1_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3426.5307938768246
    time_step_min: 3075
  date: 2020-10-12_16-46-35
  done: false
  episode_len_mean: 831.1691279887482
  episode_reward_max: 281.38383838383845
  episode_reward_mean: 228.4270020883944
  episode_reward_min: 111.08080808080757
  episodes_this_iter: 160
  episodes_total: 2844
  experiment_id: 3ebc0295a6ab42bc8a98f089926215f2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9264985670646032
        entropy_coeff: 0.009999999999999998
        kl: 0.007578051765449345
        model: {}
        policy_loss: -0.01108121887470285
        total_loss: 11.389791011810303
        vf_explained_var: 0.9742998480796814
        vf_loss: 11.408621549606323
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.84193548387097
    gpu_util_percent0: 0.3148387096774193
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7774193548387096
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72573
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1520837573426285
    mean_env_wait_ms: 1.1842212483317964
    mean_inference_ms: 4.668703744915274
    mean_raw_obs_processing_ms: 0.39770789971118725
  time_since_restore: 402.10248494148254
  time_this_iter_s: 26.563365697860718
  time_total_s: 402.10248494148254
  timers:
    learn_throughput: 8271.604
    learn_time_ms: 19559.931
    sample_throughput: 23319.767
    sample_time_ms: 6937.977
    update_time_ms: 43.835
  timestamp: 1602521195
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 891e1_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_891e1_00000 | RUNNING  | 172.17.0.4:72573 |     15 |          402.102 | 2426880 |  228.427 |              281.384 |              111.081 |            831.169 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_891e1_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3419.5929919137466
    time_step_min: 3075
  date: 2020-10-12_16-47-02
  done: false
  episode_len_mean: 828.6500166500166
  episode_reward_max: 281.38383838383845
  episode_reward_mean: 229.4585414585414
  episode_reward_min: 111.08080808080757
  episodes_this_iter: 159
  episodes_total: 3003
  experiment_id: 3ebc0295a6ab42bc8a98f089926215f2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9071687211592993
        entropy_coeff: 0.009999999999999998
        kl: 0.008514888895054659
        model: {}
        policy_loss: -0.015256169717758894
        total_loss: 12.385631163914999
        vf_explained_var: 0.9717957973480225
        vf_loss: 12.40825605392456
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.174193548387095
    gpu_util_percent0: 0.30451612903225805
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7774193548387096
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72573
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15186847942467843
    mean_env_wait_ms: 1.1854940461906447
    mean_inference_ms: 4.6538450399022375
    mean_raw_obs_processing_ms: 0.39696581396205133
  time_since_restore: 428.576052904129
  time_this_iter_s: 26.473567962646484
  time_total_s: 428.576052904129
  timers:
    learn_throughput: 8279.602
    learn_time_ms: 19541.037
    sample_throughput: 23406.902
    sample_time_ms: 6912.149
    update_time_ms: 44.531
  timestamp: 1602521222
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 891e1_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_891e1_00000 | RUNNING  | 172.17.0.4:72573 |     16 |          428.576 | 2588672 |  229.459 |              281.384 |              111.081 |             828.65 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_891e1_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3407.7668092909535
    time_step_min: 3061
  date: 2020-10-12_16-47-28
  done: false
  episode_len_mean: 824.2848503175084
  episode_reward_max: 289.5656565656569
  episode_reward_mean: 231.22962005907272
  episode_reward_min: 111.08080808080757
  episodes_this_iter: 304
  episodes_total: 3307
  experiment_id: 3ebc0295a6ab42bc8a98f089926215f2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8863463848829269
        entropy_coeff: 0.009999999999999998
        kl: 0.007271085982210934
        model: {}
        policy_loss: -0.014064821569869915
        total_loss: 17.1190923055013
        vf_explained_var: 0.9735561013221741
        vf_loss: 17.14056666692098
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.525806451612905
    gpu_util_percent0: 0.35258064516129034
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.761290322580645
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72573
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15150428274997205
    mean_env_wait_ms: 1.1879175860451394
    mean_inference_ms: 4.628701081570186
    mean_raw_obs_processing_ms: 0.3957397974744396
  time_since_restore: 455.2013928890228
  time_this_iter_s: 26.6253399848938
  time_total_s: 455.2013928890228
  timers:
    learn_throughput: 8281.981
    learn_time_ms: 19535.424
    sample_throughput: 23380.673
    sample_time_ms: 6919.903
    update_time_ms: 43.122
  timestamp: 1602521248
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 891e1_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_891e1_00000 | RUNNING  | 172.17.0.4:72573 |     17 |          455.201 | 2750464 |   231.23 |              289.566 |              111.081 |            824.285 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_891e1_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3401.706480674223
    time_step_min: 3061
  date: 2020-10-12_16-47-55
  done: false
  episode_len_mean: 822.3233601841197
  episode_reward_max: 289.5656565656569
  episode_reward_mean: 232.09643035649935
  episode_reward_min: 111.08080808080757
  episodes_this_iter: 169
  episodes_total: 3476
  experiment_id: 3ebc0295a6ab42bc8a98f089926215f2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8915900538365046
        entropy_coeff: 0.009999999999999998
        kl: 0.007430075978239377
        model: {}
        policy_loss: -0.011621108278632164
        total_loss: 11.667680501937866
        vf_explained_var: 0.9752277731895447
        vf_loss: 11.686731656392416
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.880645161290325
    gpu_util_percent0: 0.3467741935483871
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72573
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15132681444330123
    mean_env_wait_ms: 1.1891064449579958
    mean_inference_ms: 4.61610075701187
    mean_raw_obs_processing_ms: 0.3951374729171953
  time_since_restore: 481.7853105068207
  time_this_iter_s: 26.58391761779785
  time_total_s: 481.7853105068207
  timers:
    learn_throughput: 8271.489
    learn_time_ms: 19560.203
    sample_throughput: 23466.346
    sample_time_ms: 6894.64
    update_time_ms: 43.376
  timestamp: 1602521275
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 891e1_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_891e1_00000 | RUNNING  | 172.17.0.4:72573 |     18 |          481.785 | 2912256 |  232.096 |              289.566 |              111.081 |            822.323 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_891e1_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3396.456515698805
    time_step_min: 3061
  date: 2020-10-12_16-48-22
  done: false
  episode_len_mean: 820.3425976884976
  episode_reward_max: 291.83838383838395
  episode_reward_mean: 232.93822373431613
  episode_reward_min: 111.08080808080757
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: 3ebc0295a6ab42bc8a98f089926215f2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8742641061544418
        entropy_coeff: 0.009999999999999998
        kl: 0.0075407834180320306
        model: {}
        policy_loss: -0.01620564019928376
        total_loss: 11.384954849878946
        vf_explained_var: 0.9729453921318054
        vf_loss: 11.408395290374756
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.312903225806455
    gpu_util_percent0: 0.31548387096774194
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7903225806451615
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72573
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15117058696434998
    mean_env_wait_ms: 1.1901815318537636
    mean_inference_ms: 4.60516831374946
    mean_raw_obs_processing_ms: 0.3945976667687628
  time_since_restore: 508.61775159835815
  time_this_iter_s: 26.832441091537476
  time_total_s: 508.61775159835815
  timers:
    learn_throughput: 8262.701
    learn_time_ms: 19581.005
    sample_throughput: 23405.17
    sample_time_ms: 6912.661
    update_time_ms: 36.161
  timestamp: 1602521302
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 891e1_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_891e1_00000 | RUNNING  | 172.17.0.4:72573 |     19 |          508.618 | 3074048 |  232.938 |              291.838 |              111.081 |            820.343 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_891e1_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3387.2594594594593
    time_step_min: 3061
  date: 2020-10-12_16-48-49
  done: false
  episode_len_mean: 817.1372448979591
  episode_reward_max: 291.83838383838395
  episode_reward_mean: 234.28245464852603
  episode_reward_min: 111.08080808080757
  episodes_this_iter: 286
  episodes_total: 3920
  experiment_id: 3ebc0295a6ab42bc8a98f089926215f2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8362529228130976
        entropy_coeff: 0.009999999999999998
        kl: 0.0076954882048691315
        model: {}
        policy_loss: -0.012459692855676016
        total_loss: 17.20366144180298
        vf_explained_var: 0.9729202389717102
        vf_loss: 17.222944418589275
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.170967741935485
    gpu_util_percent0: 0.34709677419354845
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72573
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15091302699402595
    mean_env_wait_ms: 1.1920957456965522
    mean_inference_ms: 4.587080211465181
    mean_raw_obs_processing_ms: 0.3937106454681282
  time_since_restore: 535.0694677829742
  time_this_iter_s: 26.45171618461609
  time_total_s: 535.0694677829742
  timers:
    learn_throughput: 8268.65
    learn_time_ms: 19566.919
    sample_throughput: 23368.345
    sample_time_ms: 6923.554
    update_time_ms: 34.348
  timestamp: 1602521329
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 891e1_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_891e1_00000 | RUNNING  | 172.17.0.4:72573 |     20 |          535.069 | 3235840 |  234.282 |              291.838 |              111.081 |            817.137 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_891e1_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3381.0545052786642
    time_step_min: 3012
  date: 2020-10-12_16-49-15
  done: false
  episode_len_mean: 815.1621226874391
  episode_reward_max: 291.83838383838395
  episode_reward_mean: 235.17658572088948
  episode_reward_min: 111.08080808080757
  episodes_this_iter: 188
  episodes_total: 4108
  experiment_id: 3ebc0295a6ab42bc8a98f089926215f2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8512863467137018
        entropy_coeff: 0.009999999999999998
        kl: 0.007142226056506236
        model: {}
        policy_loss: -0.013910578846359082
        total_loss: 10.331612586975098
        vf_explained_var: 0.9774993062019348
        vf_loss: 10.352607568105062
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.787096774193547
    gpu_util_percent0: 0.2890322580645161
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903227
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72573
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15075707139925426
    mean_env_wait_ms: 1.1932224909948832
    mean_inference_ms: 4.576359505441465
    mean_raw_obs_processing_ms: 0.39319578789087367
  time_since_restore: 561.5730936527252
  time_this_iter_s: 26.503625869750977
  time_total_s: 561.5730936527252
  timers:
    learn_throughput: 8281.9
    learn_time_ms: 19535.614
    sample_throughput: 23313.914
    sample_time_ms: 6939.718
    update_time_ms: 32.924
  timestamp: 1602521355
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 891e1_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_891e1_00000 | RUNNING  | 172.17.0.4:72573 |     21 |          561.573 | 3397632 |  235.177 |              291.838 |              111.081 |            815.162 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_891e1_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3376.5876654064273
    time_step_min: 3012
  date: 2020-10-12_16-49-42
  done: false
  episode_len_mean: 813.849074291071
  episode_reward_max: 291.83838383838395
  episode_reward_mean: 235.8982584220456
  episode_reward_min: 111.08080808080757
  episodes_this_iter: 159
  episodes_total: 4267
  experiment_id: 3ebc0295a6ab42bc8a98f089926215f2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8472106059392294
        entropy_coeff: 0.009999999999999998
        kl: 0.007981859574404856
        model: {}
        policy_loss: -0.014169434454136839
        total_loss: 10.69970432917277
        vf_explained_var: 0.9742863178253174
        vf_loss: 10.720749537150065
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.256666666666668
    gpu_util_percent0: 0.287
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7733333333333325
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72573
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15063369354705047
    mean_env_wait_ms: 1.1941274950532494
    mean_inference_ms: 4.567804475772659
    mean_raw_obs_processing_ms: 0.3927753957349708
  time_since_restore: 587.96235704422
  time_this_iter_s: 26.38926339149475
  time_total_s: 587.96235704422
  timers:
    learn_throughput: 8295.498
    learn_time_ms: 19503.592
    sample_throughput: 23290.637
    sample_time_ms: 6946.654
    update_time_ms: 32.13
  timestamp: 1602521382
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 891e1_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_891e1_00000 | RUNNING  | 172.17.0.4:72573 |     22 |          587.962 | 3559424 |  235.898 |              291.838 |              111.081 |            813.849 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_891e1_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3370.0071380771806
    time_step_min: 3012
  date: 2020-10-12_16-50-09
  done: true
  episode_len_mean: 811.9192120407259
  episode_reward_max: 291.83838383838395
  episode_reward_mean: 236.925644224449
  episode_reward_min: 111.08080808080757
  episodes_this_iter: 251
  episodes_total: 4518
  experiment_id: 3ebc0295a6ab42bc8a98f089926215f2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8106556634108225
        entropy_coeff: 0.009999999999999998
        kl: 0.007435576058924198
        model: {}
        policy_loss: -0.013565221355141452
        total_loss: 13.031897942225138
        vf_explained_var: 0.9776559472084045
        vf_loss: 13.052082697550455
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.9741935483871
    gpu_util_percent0: 0.3219354838709678
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72573
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1504540136895418
    mean_env_wait_ms: 1.1954996480316398
    mean_inference_ms: 4.555243484198918
    mean_raw_obs_processing_ms: 0.3921438062533349
  time_since_restore: 614.5409679412842
  time_this_iter_s: 26.57861089706421
  time_total_s: 614.5409679412842
  timers:
    learn_throughput: 8296.459
    learn_time_ms: 19501.333
    sample_throughput: 23219.301
    sample_time_ms: 6967.996
    update_time_ms: 29.886
  timestamp: 1602521409
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 891e1_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_891e1_00000 | TERMINATED |       |     23 |          614.541 | 3721216 |  236.926 |              291.838 |              111.081 |            811.919 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.42 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_891e1_00000 | TERMINATED |       |     23 |          614.541 | 3721216 |  236.926 |              291.838 |              111.081 |            811.919 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


