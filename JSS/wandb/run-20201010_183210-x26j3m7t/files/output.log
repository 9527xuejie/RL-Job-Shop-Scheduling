2020-10-10 18:32:12,374	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_ea9de_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=49204)[0m 2020-10-10 18:32:15,401	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=49235)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49235)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49218)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49218)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49231)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49231)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49233)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49233)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49248)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49248)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49205)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49205)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49143)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49143)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49260)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49260)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49211)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49211)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49195)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49195)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49226)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49226)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49151)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49151)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49188)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49188)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49159)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49159)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49198)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49198)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49220)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49220)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49149)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49149)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49125)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49125)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49237)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49237)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49197)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49197)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49217)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49217)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49192)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49192)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49253)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49253)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49194)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49194)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49138)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49138)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49134)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49134)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49133)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49133)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49221)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49221)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49131)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49131)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49152)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49152)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49203)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49203)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49123)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49123)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49215)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49215)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49144)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49144)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49124)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49124)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49122)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49122)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49181)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49181)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49136)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49136)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49224)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49224)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49184)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49184)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49213)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49213)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49193)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49193)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49209)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49209)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49185)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49185)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49121)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49121)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49225)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49225)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49200)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49200)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49118)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49118)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49186)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49186)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49229)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49229)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49216)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49216)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49178)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49178)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49158)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49158)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49129)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49129)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49242)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49242)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49239)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49239)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49189)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49189)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49119)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49119)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49145)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49145)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49228)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49228)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49120)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49120)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49202)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49202)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49191)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49191)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49175)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49175)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49140)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49140)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49127)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49127)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49251)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49251)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49156)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49156)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49187)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49187)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49196)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49196)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49117)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49117)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49182)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49182)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49132)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49132)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49155)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49155)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49128)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49128)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49208)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49208)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49207)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49207)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49141)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49141)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49199)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49199)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_ea9de_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-10_18-32-53
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: c07ce6918d564552a7e4999a75f3bc01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1873117004122054
        entropy_coeff: 0.0
        kl: 0.0020592938443379743
        model: {}
        policy_loss: -0.0024745503906160593
        total_loss: 701.191646030971
        vf_explained_var: 0.005364171229302883
        vf_loss: 701.1936819893973
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.148717948717948
    gpu_util_percent0: 0.3474358974358975
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0002564102564102564
    ram_util_percent: 6.276923076923078
    vram_util_percent0: 0.19107567844858767
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 49204
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17514946063972983
    mean_env_wait_ms: 1.2078913982800032
    mean_inference_ms: 5.835605443499272
    mean_raw_obs_processing_ms: 0.4678951762789154
  time_since_restore: 32.430253982543945
  time_this_iter_s: 32.430253982543945
  time_total_s: 32.430253982543945
  timers:
    learn_throughput: 6964.693
    learn_time_ms: 23230.314
    sample_throughput: 17718.324
    sample_time_ms: 9131.338
    update_time_ms: 25.379
  timestamp: 1602354773
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: ea9de_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ea9de_00000 | RUNNING  | 172.17.0.4:49204 |      1 |          32.4303 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ea9de_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3602.722222222222
    time_step_min: 3305
  date: 2020-10-10_18-33-24
  done: false
  episode_len_mean: 889.1139240506329
  episode_reward_max: 265.26262626262616
  episode_reward_mean: 218.38211226185882
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: c07ce6918d564552a7e4999a75f3bc01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1625066144125802
        entropy_coeff: 0.0
        kl: 0.002808195006634508
        model: {}
        policy_loss: -0.0015453535597771406
        total_loss: 365.47469438825334
        vf_explained_var: 0.4167321026325226
        vf_loss: 365.47596740722656
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.25135135135135
    gpu_util_percent0: 0.322972972972973
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4648648648648654
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 49204
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16929694355128433
    mean_env_wait_ms: 1.1974058765720055
    mean_inference_ms: 5.561140590621122
    mean_raw_obs_processing_ms: 0.45327291837800576
  time_since_restore: 62.94582176208496
  time_this_iter_s: 30.515567779541016
  time_total_s: 62.94582176208496
  timers:
    learn_throughput: 7025.46
    learn_time_ms: 23029.38
    sample_throughput: 19317.641
    sample_time_ms: 8375.35
    update_time_ms: 23.385
  timestamp: 1602354804
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: ea9de_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ea9de_00000 | RUNNING  | 172.17.0.4:49204 |      2 |          62.9458 | 323584 |  218.382 |              265.263 |              100.263 |            889.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ea9de_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3595.2578475336322
    time_step_min: 3304
  date: 2020-10-10_18-33-55
  done: false
  episode_len_mean: 885.3185654008439
  episode_reward_max: 266.9292929292931
  episode_reward_mean: 221.32962536759982
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: c07ce6918d564552a7e4999a75f3bc01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 1.1577754020690918
        entropy_coeff: 0.0
        kl: 0.0032783799771485584
        model: {}
        policy_loss: -0.0026319802740804982
        total_loss: 152.05094146728516
        vf_explained_var: 0.7035121917724609
        vf_loss: 152.05341121128626
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.371052631578948
    gpu_util_percent0: 0.43210526315789477
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.478947368421053
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 49204
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16592663471486296
    mean_env_wait_ms: 1.1932709837592173
    mean_inference_ms: 5.370346227608177
    mean_raw_obs_processing_ms: 0.44329832876973246
  time_since_restore: 93.75172305107117
  time_this_iter_s: 30.805901288986206
  time_total_s: 93.75172305107117
  timers:
    learn_throughput: 7000.576
    learn_time_ms: 23111.242
    sample_throughput: 20107.502
    sample_time_ms: 8046.35
    update_time_ms: 44.844
  timestamp: 1602354835
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: ea9de_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ea9de_00000 | RUNNING  | 172.17.0.4:49204 |      3 |          93.7517 | 485376 |   221.33 |              266.929 |              100.263 |            885.319 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ea9de_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3585.478476821192
    time_step_min: 3304
  date: 2020-10-10_18-34-25
  done: false
  episode_len_mean: 880.7041139240506
  episode_reward_max: 266.9292929292931
  episode_reward_mean: 222.9534586370027
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: c07ce6918d564552a7e4999a75f3bc01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 1.0e-05
        entropy: 1.1490683129855566
        entropy_coeff: 0.0
        kl: 0.0037155255808361937
        model: {}
        policy_loss: -0.004032705746275107
        total_loss: 93.38081904820034
        vf_explained_var: 0.8130138516426086
        vf_loss: 93.38475690569196
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.258333333333336
    gpu_util_percent0: 0.40944444444444444
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.480555555555555
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 49204
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16359364273657093
    mean_env_wait_ms: 1.191389157169052
    mean_inference_ms: 5.236264976037851
    mean_raw_obs_processing_ms: 0.43611433525062976
  time_since_restore: 124.05129599571228
  time_this_iter_s: 30.299572944641113
  time_total_s: 124.05129599571228
  timers:
    learn_throughput: 7017.612
    learn_time_ms: 23055.135
    sample_throughput: 20558.072
    sample_time_ms: 7869.999
    update_time_ms: 38.675
  timestamp: 1602354865
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: ea9de_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ea9de_00000 | RUNNING  | 172.17.0.4:49204 |      4 |          124.051 | 647168 |  222.953 |              266.929 |              100.263 |            880.704 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ea9de_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3580.6259842519685
    time_step_min: 3304
  date: 2020-10-10_18-34-55
  done: false
  episode_len_mean: 877.6544303797468
  episode_reward_max: 267.5353535353536
  episode_reward_mean: 223.6082342411454
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: c07ce6918d564552a7e4999a75f3bc01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.012500000000000002
        cur_lr: 1.0e-05
        entropy: 1.1231615202767509
        entropy_coeff: 0.0
        kl: 0.004765029497710722
        model: {}
        policy_loss: -0.004165318262364183
        total_loss: 76.46962029593331
        vf_explained_var: 0.8560459017753601
        vf_loss: 76.47372436523438
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.45675675675676
    gpu_util_percent0: 0.3245945945945946
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.481081081081081
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 49204
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16190601912739697
    mean_env_wait_ms: 1.1907183155209717
    mean_inference_ms: 5.136530380194684
    mean_raw_obs_processing_ms: 0.4306661354375889
  time_since_restore: 154.53309321403503
  time_this_iter_s: 30.481797218322754
  time_total_s: 154.53309321403503
  timers:
    learn_throughput: 7019.596
    learn_time_ms: 23048.62
    sample_throughput: 20816.263
    sample_time_ms: 7772.385
    update_time_ms: 35.398
  timestamp: 1602354895
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: ea9de_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ea9de_00000 | RUNNING  | 172.17.0.4:49204 |      5 |          154.533 | 808960 |  223.608 |              267.535 |              100.263 |            877.654 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ea9de_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3568.9692164179105
    time_step_min: 3251
  date: 2020-10-10_18-35-26
  done: false
  episode_len_mean: 869.7327272727273
  episode_reward_max: 273.4444444444444
  episode_reward_mean: 225.470890725436
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 310
  episodes_total: 1100
  experiment_id: c07ce6918d564552a7e4999a75f3bc01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.006250000000000001
        cur_lr: 1.0e-05
        entropy: 1.1213042991501945
        entropy_coeff: 0.0
        kl: 0.004042014047237379
        model: {}
        policy_loss: -0.002242571991830898
        total_loss: 89.07893753051758
        vf_explained_var: 0.8908900022506714
        vf_loss: 89.08115495954242
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.859459459459462
    gpu_util_percent0: 0.31351351351351353
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.478378378378379
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 49204
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15972604562681517
    mean_env_wait_ms: 1.192500220455659
    mean_inference_ms: 5.00571008088099
    mean_raw_obs_processing_ms: 0.4238217365260327
  time_since_restore: 185.13388419151306
  time_this_iter_s: 30.600790977478027
  time_total_s: 185.13388419151306
  timers:
    learn_throughput: 7014.434
    learn_time_ms: 23065.583
    sample_throughput: 20998.544
    sample_time_ms: 7704.915
    update_time_ms: 32.794
  timestamp: 1602354926
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: ea9de_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ea9de_00000 | RUNNING  | 172.17.0.4:49204 |      6 |          185.134 | 970752 |  225.471 |              273.444 |              100.263 |            869.733 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ea9de_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3565.3616504854367
    time_step_min: 3251
  date: 2020-10-10_18-35-57
  done: false
  episode_len_mean: 865.0237341772151
  episode_reward_max: 286.6262626262623
  episode_reward_mean: 226.40618207390338
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 164
  episodes_total: 1264
  experiment_id: c07ce6918d564552a7e4999a75f3bc01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0031250000000000006
        cur_lr: 1.0e-05
        entropy: 1.13227493422372
        entropy_coeff: 0.0
        kl: 0.004255540003733975
        model: {}
        policy_loss: -0.002615453642127769
        total_loss: 61.795571735927034
        vf_explained_var: 0.8849116563796997
        vf_loss: 61.79817172459194
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.758333333333336
    gpu_util_percent0: 0.3977777777777778
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4833333333333325
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 49204
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15887435331364555
    mean_env_wait_ms: 1.1934374829033862
    mean_inference_ms: 4.956104608802309
    mean_raw_obs_processing_ms: 0.42114853728754476
  time_since_restore: 215.52573108673096
  time_this_iter_s: 30.391846895217896
  time_total_s: 215.52573108673096
  timers:
    learn_throughput: 7014.056
    learn_time_ms: 23066.824
    sample_throughput: 21181.283
    sample_time_ms: 7638.442
    update_time_ms: 31.016
  timestamp: 1602354957
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: ea9de_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ea9de_00000 | RUNNING  | 172.17.0.4:49204 |      7 |          215.526 | 1132544 |  226.406 |              286.626 |              100.263 |            865.024 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ea9de_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3559.2324246771877
    time_step_min: 3251
  date: 2020-10-10_18-36-27
  done: false
  episode_len_mean: 860.9275668073136
  episode_reward_max: 286.6262626262623
  episode_reward_mean: 227.15134467033178
  episode_reward_min: 67.38383838383834
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: c07ce6918d564552a7e4999a75f3bc01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0015625000000000003
        cur_lr: 1.0e-05
        entropy: 1.1166328702654158
        entropy_coeff: 0.0
        kl: 0.00405842496547848
        model: {}
        policy_loss: -0.003832788865630781
        total_loss: 62.88402203151158
        vf_explained_var: 0.8854403495788574
        vf_loss: 62.887848717825754
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.381081081081078
    gpu_util_percent0: 0.3108108108108108
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.489189189189189
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 49204
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1581798700643757
    mean_env_wait_ms: 1.1944110854034773
    mean_inference_ms: 4.915118988024619
    mean_raw_obs_processing_ms: 0.41896346728737893
  time_since_restore: 245.84270858764648
  time_this_iter_s: 30.316977500915527
  time_total_s: 245.84270858764648
  timers:
    learn_throughput: 7016.357
    learn_time_ms: 23059.261
    sample_throughput: 21320.172
    sample_time_ms: 7588.682
    update_time_ms: 29.331
  timestamp: 1602354987
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: ea9de_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ea9de_00000 | RUNNING  | 172.17.0.4:49204 |      8 |          245.843 | 1294336 |  227.151 |              286.626 |              67.3838 |            860.928 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ea9de_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3551.165592783505
    time_step_min: 3231
  date: 2020-10-10_18-36-57
  done: false
  episode_len_mean: 857.1981012658227
  episode_reward_max: 286.6262626262623
  episode_reward_mean: 228.28055875207752
  episode_reward_min: 67.38383838383834
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: c07ce6918d564552a7e4999a75f3bc01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0007812500000000002
        cur_lr: 1.0e-05
        entropy: 1.089797420161111
        entropy_coeff: 0.0
        kl: 0.0042021876267556635
        model: {}
        policy_loss: -0.00411780462101368
        total_loss: 48.23212569100516
        vf_explained_var: 0.9026455283164978
        vf_loss: 48.236239842006135
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.222222222222218
    gpu_util_percent0: 0.37166666666666665
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4833333333333325
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 49204
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1575798077359573
    mean_env_wait_ms: 1.1954894837127887
    mean_inference_ms: 4.8795730718871875
    mean_raw_obs_processing_ms: 0.41699702786802695
  time_since_restore: 276.02364563941956
  time_this_iter_s: 30.18093705177307
  time_total_s: 276.02364563941956
  timers:
    learn_throughput: 7019.568
    learn_time_ms: 23048.712
    sample_throughput: 21459.955
    sample_time_ms: 7539.252
    update_time_ms: 28.619
  timestamp: 1602355017
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: ea9de_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ea9de_00000 | RUNNING  | 172.17.0.4:49204 |      9 |          276.024 | 1456128 |  228.281 |              286.626 |              67.3838 |            857.198 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ea9de_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3539.7412019491067
    time_step_min: 3231
  date: 2020-10-10_18-37-28
  done: false
  episode_len_mean: 850.7114666666666
  episode_reward_max: 286.6262626262623
  episode_reward_mean: 229.83094949494932
  episode_reward_min: 67.38383838383834
  episodes_this_iter: 295
  episodes_total: 1875
  experiment_id: c07ce6918d564552a7e4999a75f3bc01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0003906250000000001
        cur_lr: 1.0e-05
        entropy: 1.0631579160690308
        entropy_coeff: 0.0
        kl: 0.0041352007538080215
        model: {}
        policy_loss: -0.0040379497638371375
        total_loss: 54.14264188494001
        vf_explained_var: 0.9324994683265686
        vf_loss: 54.14667837960379
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.63243243243243
    gpu_util_percent0: 0.3337837837837838
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.475675675675675
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 49204
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15668242494681756
    mean_env_wait_ms: 1.1981522029879201
    mean_inference_ms: 4.825733713965509
    mean_raw_obs_processing_ms: 0.41404899025702985
  time_since_restore: 306.61169147491455
  time_this_iter_s: 30.588045835494995
  time_total_s: 306.61169147491455
  timers:
    learn_throughput: 7020.068
    learn_time_ms: 23047.07
    sample_throughput: 21477.158
    sample_time_ms: 7533.213
    update_time_ms: 28.238
  timestamp: 1602355048
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: ea9de_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ea9de_00000 | RUNNING  | 172.17.0.4:49204 |     10 |          306.612 | 1617920 |  229.831 |              286.626 |              67.3838 |            850.711 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ea9de_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3534.246791707799
    time_step_min: 3231
  date: 2020-10-10_18-37-59
  done: false
  episode_len_mean: 847.0433300876339
  episode_reward_max: 286.6262626262623
  episode_reward_mean: 230.73590825489543
  episode_reward_min: 67.38383838383834
  episodes_this_iter: 179
  episodes_total: 2054
  experiment_id: c07ce6918d564552a7e4999a75f3bc01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.00019531250000000004
        cur_lr: 1.0e-05
        entropy: 1.0802378569330489
        entropy_coeff: 0.0
        kl: 0.0039682322447853425
        model: {}
        policy_loss: -0.003400132924850498
        total_loss: 36.33242416381836
        vf_explained_var: 0.9319892525672913
        vf_loss: 36.335824148995535
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.097297297297295
    gpu_util_percent0: 0.3518918918918919
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.489189189189189
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 49204
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15622285695864296
    mean_env_wait_ms: 1.199526235984774
    mean_inference_ms: 4.798556796109351
    mean_raw_obs_processing_ms: 0.41255998053083626
  time_since_restore: 337.64889192581177
  time_this_iter_s: 31.037200450897217
  time_total_s: 337.64889192581177
  timers:
    learn_throughput: 7014.511
    learn_time_ms: 23065.33
    sample_throughput: 21940.122
    sample_time_ms: 7374.253
    update_time_ms: 27.923
  timestamp: 1602355079
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: ea9de_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ea9de_00000 | RUNNING  | 172.17.0.4:49204 |     11 |          337.649 | 1779712 |  230.736 |              286.626 |              67.3838 |            847.043 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ea9de_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3529.0082417582416
    time_step_min: 3231
  date: 2020-10-10_18-38-30
  done: false
  episode_len_mean: 843.9195298372514
  episode_reward_max: 286.6262626262623
  episode_reward_mean: 231.60900140646962
  episode_reward_min: 67.38383838383834
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: c07ce6918d564552a7e4999a75f3bc01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 9.765625000000002e-05
        cur_lr: 1.0e-05
        entropy: 1.0675095660345895
        entropy_coeff: 0.0
        kl: 0.003968158587148147
        model: {}
        policy_loss: -0.003321110237655895
        total_loss: 31.45696517399379
        vf_explained_var: 0.9387170672416687
        vf_loss: 31.460285323006765
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.564864864864866
    gpu_util_percent0: 0.3940540540540541
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.489189189189188
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 49204
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1558666876227894
    mean_env_wait_ms: 1.2007069425487804
    mean_inference_ms: 4.7773075479995715
    mean_raw_obs_processing_ms: 0.41139195704727993
  time_since_restore: 368.4405381679535
  time_this_iter_s: 30.791646242141724
  time_total_s: 368.4405381679535
  timers:
    learn_throughput: 7003.256
    learn_time_ms: 23102.398
    sample_throughput: 21975.028
    sample_time_ms: 7362.539
    update_time_ms: 29.266
  timestamp: 1602355110
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: ea9de_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ea9de_00000 | RUNNING  | 172.17.0.4:49204 |     12 |          368.441 | 1941504 |  231.609 |              286.626 |              67.3838 |             843.92 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ea9de_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3523.4891165172853
    time_step_min: 3194
  date: 2020-10-10_18-39-00
  done: false
  episode_len_mean: 841.0666385491354
  episode_reward_max: 286.6262626262623
  episode_reward_mean: 232.3976415355579
  episode_reward_min: 67.38383838383834
  episodes_this_iter: 159
  episodes_total: 2371
  experiment_id: c07ce6918d564552a7e4999a75f3bc01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 4.882812500000001e-05
        cur_lr: 1.0e-05
        entropy: 1.0377438919884818
        entropy_coeff: 0.0
        kl: 0.0037957170113388982
        model: {}
        policy_loss: -0.003217692069093963
        total_loss: 29.14142635890416
        vf_explained_var: 0.9472803473472595
        vf_loss: 29.144643102373397
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.63783783783784
    gpu_util_percent0: 0.32351351351351354
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.489189189189189
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 49204
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15554540528656424
    mean_env_wait_ms: 1.2019162532419752
    mean_inference_ms: 4.757945195419206
    mean_raw_obs_processing_ms: 0.41033155853284703
  time_since_restore: 398.8297915458679
  time_this_iter_s: 30.38925337791443
  time_total_s: 398.8297915458679
  timers:
    learn_throughput: 7011.44
    learn_time_ms: 23075.43
    sample_throughput: 22000.854
    sample_time_ms: 7353.896
    update_time_ms: 22.662
  timestamp: 1602355140
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: ea9de_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ea9de_00000 | RUNNING  | 172.17.0.4:49204 |     13 |           398.83 | 2103296 |  232.398 |              286.626 |              67.3838 |            841.067 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ea9de_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3512.479683972912
    time_step_min: 3194
  date: 2020-10-10_18-39-31
  done: false
  episode_len_mean: 836.0033507073715
  episode_reward_max: 286.6262626262623
  episode_reward_mean: 233.96611686485087
  episode_reward_min: 67.38383838383834
  episodes_this_iter: 315
  episodes_total: 2686
  experiment_id: c07ce6918d564552a7e4999a75f3bc01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 2.4414062500000005e-05
        cur_lr: 1.0e-05
        entropy: 1.0240076099123274
        entropy_coeff: 0.0
        kl: 0.003599906340241432
        model: {}
        policy_loss: -0.0012101738740446827
        total_loss: 31.713197708129883
        vf_explained_var: 0.9599391222000122
        vf_loss: 31.714407784598215
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.64324324324324
    gpu_util_percent0: 0.3145945945945946
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486486486486487
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 49204
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15498768723020317
    mean_env_wait_ms: 1.2042782165961305
    mean_inference_ms: 4.72498456187721
    mean_raw_obs_processing_ms: 0.40855718181154216
  time_since_restore: 429.5027301311493
  time_this_iter_s: 30.672938585281372
  time_total_s: 429.5027301311493
  timers:
    learn_throughput: 7005.523
    learn_time_ms: 23094.92
    sample_throughput: 21949.913
    sample_time_ms: 7370.963
    update_time_ms: 22.597
  timestamp: 1602355171
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: ea9de_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ea9de_00000 | RUNNING  | 172.17.0.4:49204 |     14 |          429.503 | 2265088 |  233.966 |              286.626 |              67.3838 |            836.003 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ea9de_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3506.0923295454545
    time_step_min: 3194
  date: 2020-10-10_18-40-02
  done: false
  episode_len_mean: 833.520393811533
  episode_reward_max: 286.6262626262623
  episode_reward_mean: 234.93072070920158
  episode_reward_min: 67.38383838383834
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: c07ce6918d564552a7e4999a75f3bc01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 1.2207031250000002e-05
        cur_lr: 1.0e-05
        entropy: 1.0149245687893458
        entropy_coeff: 0.0
        kl: 0.0035095485426219447
        model: {}
        policy_loss: -0.0035479203548415433
        total_loss: 18.154382024492538
        vf_explained_var: 0.9635961651802063
        vf_loss: 18.15792942047119
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.75135135135135
    gpu_util_percent0: 0.3770270270270271
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486486486486487
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 49204
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1547478891240871
    mean_env_wait_ms: 1.205365272597036
    mean_inference_ms: 4.7107587260538715
    mean_raw_obs_processing_ms: 0.40779601362994405
  time_since_restore: 459.98815155029297
  time_this_iter_s: 30.485421419143677
  time_total_s: 459.98815155029297
  timers:
    learn_throughput: 7000.051
    learn_time_ms: 23112.976
    sample_throughput: 22005.078
    sample_time_ms: 7352.485
    update_time_ms: 22.904
  timestamp: 1602355202
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: ea9de_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ea9de_00000 | RUNNING  | 172.17.0.4:49204 |     15 |          459.988 | 2426880 |  234.931 |              286.626 |              67.3838 |             833.52 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ea9de_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3501.147276395427
    time_step_min: 3168
  date: 2020-10-10_18-40-32
  done: false
  episode_len_mean: 831.2878081279147
  episode_reward_max: 286.6262626262623
  episode_reward_mean: 235.68047900726097
  episode_reward_min: 67.38383838383834
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: c07ce6918d564552a7e4999a75f3bc01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 6.103515625000001e-06
        cur_lr: 1.0e-05
        entropy: 1.004614953483854
        entropy_coeff: 0.0
        kl: 0.0037731296781982693
        model: {}
        policy_loss: -0.0025628694898581932
        total_loss: 17.760318483625138
        vf_explained_var: 0.9630495309829712
        vf_loss: 17.7628812789917
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.236111111111114
    gpu_util_percent0: 0.33527777777777784
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497222222222223
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 49204
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15452689617957582
    mean_env_wait_ms: 1.2064061301564075
    mean_inference_ms: 4.697645484435151
    mean_raw_obs_processing_ms: 0.4070743514536926
  time_since_restore: 490.30896949768066
  time_this_iter_s: 30.320817947387695
  time_total_s: 490.30896949768066
  timers:
    learn_throughput: 7005.447
    learn_time_ms: 23095.173
    sample_throughput: 22039.545
    sample_time_ms: 7340.986
    update_time_ms: 24.657
  timestamp: 1602355232
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: ea9de_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ea9de_00000 | RUNNING  | 172.17.0.4:49204 |     16 |          490.309 | 2588672 |   235.68 |              286.626 |              67.3838 |            831.288 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ea9de_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3493.2050889025136
    time_step_min: 3168
  date: 2020-10-10_18-41-03
  done: false
  episode_len_mean: 827.4401215805472
  episode_reward_max: 287.08080808080825
  episode_reward_mean: 236.934911424273
  episode_reward_min: 67.38383838383834
  episodes_this_iter: 288
  episodes_total: 3290
  experiment_id: c07ce6918d564552a7e4999a75f3bc01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 3.0517578125000006e-06
        cur_lr: 1.0e-05
        entropy: 0.9621241050107139
        entropy_coeff: 0.0
        kl: 0.0036627750211794463
        model: {}
        policy_loss: -0.0030481948550524457
        total_loss: 23.398586954389298
        vf_explained_var: 0.9687341451644897
        vf_loss: 23.401634761265345
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.586111111111112
    gpu_util_percent0: 0.3816666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.475
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 49204
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1541657106313835
    mean_env_wait_ms: 1.2084226082423228
    mean_inference_ms: 4.676239558134515
    mean_raw_obs_processing_ms: 0.405919407701492
  time_since_restore: 520.4852182865143
  time_this_iter_s: 30.176248788833618
  time_total_s: 520.4852182865143
  timers:
    learn_throughput: 7009.464
    learn_time_ms: 23081.936
    sample_throughput: 22066.058
    sample_time_ms: 7332.166
    update_time_ms: 24.845
  timestamp: 1602355263
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: ea9de_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ea9de_00000 | RUNNING  | 172.17.0.4:49204 |     17 |          520.485 | 2750464 |  236.935 |              287.081 |              67.3838 |             827.44 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ea9de_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3487.5617749419953
    time_step_min: 3168
  date: 2020-10-10_18-41-33
  done: false
  episode_len_mean: 825.2120253164557
  episode_reward_max: 287.08080808080825
  episode_reward_mean: 237.80695621345782
  episode_reward_min: 67.38383838383834
  episodes_this_iter: 186
  episodes_total: 3476
  experiment_id: c07ce6918d564552a7e4999a75f3bc01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 1.5258789062500003e-06
        cur_lr: 1.0e-05
        entropy: 0.9623528506074633
        entropy_coeff: 0.0
        kl: 0.0035909602884203196
        model: {}
        policy_loss: -0.002879030112775841
        total_loss: 14.313999448503766
        vf_explained_var: 0.9723127484321594
        vf_loss: 14.316878523145403
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.091891891891887
    gpu_util_percent0: 0.3602702702702702
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.489189189189189
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 49204
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15395768111232586
    mean_env_wait_ms: 1.2095366550667674
    mean_inference_ms: 4.66384288672084
    mean_raw_obs_processing_ms: 0.405247045717294
  time_since_restore: 550.8731756210327
  time_this_iter_s: 30.387957334518433
  time_total_s: 550.8731756210327
  timers:
    learn_throughput: 7001.558
    learn_time_ms: 23108.0
    sample_throughput: 22138.126
    sample_time_ms: 7308.297
    update_time_ms: 28.064
  timestamp: 1602355293
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: ea9de_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ea9de_00000 | RUNNING  | 172.17.0.4:49204 |     18 |          550.873 | 2912256 |  237.807 |              287.081 |              67.3838 |            825.212 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ea9de_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3483.13283416528
    time_step_min: 3168
  date: 2020-10-10_18-42-04
  done: false
  episode_len_mean: 823.3706659328564
  episode_reward_max: 287.08080808080825
  episode_reward_mean: 238.47246265628203
  episode_reward_min: 67.38383838383834
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: c07ce6918d564552a7e4999a75f3bc01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 7.629394531250001e-07
        cur_lr: 1.0e-05
        entropy: 0.9649886744362968
        entropy_coeff: 0.0
        kl: 0.003526220563799143
        model: {}
        policy_loss: -0.0038240708402424517
        total_loss: 13.885855402265276
        vf_explained_var: 0.9697858095169067
        vf_loss: 13.88967936379569
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.355555555555554
    gpu_util_percent0: 0.31805555555555554
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491666666666666
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 49204
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15379446201438615
    mean_env_wait_ms: 1.210498579831542
    mean_inference_ms: 4.654039918246559
    mean_raw_obs_processing_ms: 0.4047095392228454
  time_since_restore: 581.1527471542358
  time_this_iter_s: 30.279571533203125
  time_total_s: 581.1527471542358
  timers:
    learn_throughput: 6996.292
    learn_time_ms: 23125.393
    sample_throughput: 22167.677
    sample_time_ms: 7298.554
    update_time_ms: 29.03
  timestamp: 1602355324
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: ea9de_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ea9de_00000 | RUNNING  | 172.17.0.4:49204 |     19 |          581.153 | 3074048 |  238.472 |              287.081 |              67.3838 |            823.371 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ea9de_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3479.013910761155
    time_step_min: 3168
  date: 2020-10-10_18-42-34
  done: true
  episode_len_mean: 821.1753517457009
  episode_reward_max: 287.08080808080825
  episode_reward_mean: 239.0935356693563
  episode_reward_min: 67.38383838383834
  episodes_this_iter: 204
  episodes_total: 3838
  experiment_id: c07ce6918d564552a7e4999a75f3bc01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 3.814697265625001e-07
        cur_lr: 1.0e-05
        entropy: 0.9313622074467796
        entropy_coeff: 0.0
        kl: 0.0032704471211348262
        model: {}
        policy_loss: -0.004593311093880662
        total_loss: 19.360017776489258
        vf_explained_var: 0.9711862802505493
        vf_loss: 19.364611216953822
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.613888888888894
    gpu_util_percent0: 0.3888888888888889
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4833333333333325
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 49204
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1535907658042128
    mean_env_wait_ms: 1.2117870001569275
    mean_inference_ms: 4.641974327654824
    mean_raw_obs_processing_ms: 0.4040318189844546
  time_since_restore: 611.3125829696655
  time_this_iter_s: 30.159835815429688
  time_total_s: 611.3125829696655
  timers:
    learn_throughput: 6996.516
    learn_time_ms: 23124.652
    sample_throughput: 22299.252
    sample_time_ms: 7255.49
    update_time_ms: 28.869
  timestamp: 1602355354
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: ea9de_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ea9de_00000 | TERMINATED |       |     20 |          611.313 | 3235840 |  239.094 |              287.081 |              67.3838 |            821.175 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ea9de_00000 | TERMINATED |       |     20 |          611.313 | 3235840 |  239.094 |              287.081 |              67.3838 |            821.175 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


