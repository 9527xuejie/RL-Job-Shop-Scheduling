2020-10-11 04:40:49,714	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_f098a_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=24812)[0m 2020-10-11 04:40:52,628	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=24691)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24691)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24774)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24774)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24799)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24799)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24702)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24702)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24769)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24769)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24758)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24758)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24713)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24713)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24786)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24786)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24703)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24703)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24697)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24697)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24784)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24784)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24838)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24838)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24835)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24835)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24775)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24775)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24814)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24814)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24830)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24830)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24762)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24762)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24766)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24766)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24794)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24794)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24816)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24816)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24699)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24699)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24704)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24704)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24726)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24726)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24692)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24692)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24696)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24696)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24764)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24764)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24804)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24804)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24771)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24771)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24821)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24821)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24787)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24787)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24803)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24803)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24710)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24710)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24693)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24693)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24723)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24723)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24806)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24806)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24698)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24698)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24767)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24767)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24728)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24728)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24705)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24705)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24716)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24716)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24832)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24832)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24791)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24791)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24776)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24776)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24810)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24810)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24778)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24778)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24777)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24777)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24765)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24765)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24800)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24800)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24708)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24708)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24695)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24695)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24700)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24700)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24694)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24694)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24827)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24827)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24805)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24805)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24768)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24768)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24732)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24732)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24731)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24731)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24756)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24756)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24788)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24788)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24735)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24735)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24783)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24783)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24711)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24711)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24760)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24760)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24772)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24772)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24709)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24709)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24823)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24823)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24763)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24763)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24801)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24801)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24717)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24717)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24707)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24707)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24759)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24759)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24798)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24798)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24715)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24715)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24819)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24819)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24757)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24757)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24796)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24796)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24761)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24761)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24770)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24770)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24724)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24724)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_f098a_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_04-41-30
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 87bf98d51df6425ab864ba4a2aad52ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1822227920804704
        entropy_coeff: 0.00010000000000000002
        kl: 0.007228604717446225
        model: {}
        policy_loss: -0.013825313886627555
        total_loss: 499.54748099190846
        vf_explained_var: 0.5819914937019348
        vf_loss: 499.55997358049666
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.715384615384625
    gpu_util_percent0: 0.34307692307692306
    gpu_util_percent1: 0.0002564102564102564
    gpu_util_percent2: 0.0002564102564102564
    ram_util_percent: 6.282051282051283
    vram_util_percent0: 0.19117659425957234
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 24812
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17416302750750287
    mean_env_wait_ms: 1.2115188144025482
    mean_inference_ms: 5.739485801609623
    mean_raw_obs_processing_ms: 0.4665727223758162
  time_since_restore: 32.24724841117859
  time_this_iter_s: 32.24724841117859
  time_total_s: 32.24724841117859
  timers:
    learn_throughput: 6977.01
    learn_time_ms: 23189.304
    sample_throughput: 18012.002
    sample_time_ms: 8982.455
    update_time_ms: 44.812
  timestamp: 1602391290
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: f098a_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f098a_00000 | RUNNING  | 172.17.0.4:24812 |      1 |          32.2472 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f098a_00000:
  custom_metrics:
    time_step_max: 4072
    time_step_mean: 3625.940972222222
    time_step_min: 3210
  date: 2020-10-11_04-42-02
  done: false
  episode_len_mean: 889.7246835443038
  episode_reward_max: 279.65656565656525
  episode_reward_mean: 216.22829561437132
  episode_reward_min: 131.7777777777776
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 87bf98d51df6425ab864ba4a2aad52ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1495991945266724
        entropy_coeff: 0.00010000000000000002
        kl: 0.009182739869824477
        model: {}
        policy_loss: -0.014291224485662366
        total_loss: 124.0285415649414
        vf_explained_var: 0.8172682523727417
        vf_loss: 124.04111099243164
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.61052631578947
    gpu_util_percent0: 0.3357894736842106
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.46578947368421
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 24812
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17011915621496657
    mean_env_wait_ms: 1.2046448434328547
    mean_inference_ms: 5.607412086262463
    mean_raw_obs_processing_ms: 0.4596171311431859
  time_since_restore: 63.781559467315674
  time_this_iter_s: 31.534311056137085
  time_total_s: 63.781559467315674
  timers:
    learn_throughput: 6986.721
    learn_time_ms: 23157.071
    sample_throughput: 18698.909
    sample_time_ms: 8652.483
    update_time_ms: 38.48
  timestamp: 1602391322
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: f098a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f098a_00000 | RUNNING  | 172.17.0.4:24812 |      2 |          63.7816 | 323584 |  216.228 |              279.657 |              131.778 |            889.725 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f098a_00000:
  custom_metrics:
    time_step_max: 4072
    time_step_mean: 3620.560538116592
    time_step_min: 3210
  date: 2020-10-11_04-42-33
  done: false
  episode_len_mean: 886.2151898734177
  episode_reward_max: 279.65656565656525
  episode_reward_mean: 217.6769594680985
  episode_reward_min: 131.7777777777776
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 87bf98d51df6425ab864ba4a2aad52ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1372472558702742
        entropy_coeff: 0.00010000000000000002
        kl: 0.010522086772003345
        model: {}
        policy_loss: -0.017943488381466262
        total_loss: 47.21737943376814
        vf_explained_var: 0.9179927706718445
        vf_loss: 47.23333304268973
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.27027027027027
    gpu_util_percent0: 0.36810810810810807
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.478378378378378
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 24812
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.167181945714631
    mean_env_wait_ms: 1.201454294289138
    mean_inference_ms: 5.457943766804831
    mean_raw_obs_processing_ms: 0.45192323870708545
  time_since_restore: 94.37398743629456
  time_this_iter_s: 30.592427968978882
  time_total_s: 94.37398743629456
  timers:
    learn_throughput: 7013.874
    learn_time_ms: 23067.422
    sample_throughput: 19521.5
    sample_time_ms: 8287.888
    update_time_ms: 37.679
  timestamp: 1602391353
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: f098a_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f098a_00000 | RUNNING  | 172.17.0.4:24812 |      3 |           94.374 | 485376 |  217.677 |              279.657 |              131.778 |            886.215 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f098a_00000:
  custom_metrics:
    time_step_max: 4072
    time_step_mean: 3608.774834437086
    time_step_min: 3210
  date: 2020-10-11_04-43-03
  done: false
  episode_len_mean: 881.9651898734177
  episode_reward_max: 279.65656565656525
  episode_reward_mean: 219.2557217747089
  episode_reward_min: 123.44444444444406
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 87bf98d51df6425ab864ba4a2aad52ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.118048139980861
        entropy_coeff: 0.00010000000000000002
        kl: 0.011479395774326153
        model: {}
        policy_loss: -0.020627345623714582
        total_loss: 28.63037667955671
        vf_explained_var: 0.9466565251350403
        vf_loss: 28.648819787161692
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.336111111111112
    gpu_util_percent0: 0.3383333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.483333333333333
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 24812
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1649474118721184
    mean_env_wait_ms: 1.2000714731215698
    mean_inference_ms: 5.336225570919386
    mean_raw_obs_processing_ms: 0.44529273583212714
  time_since_restore: 124.68406343460083
  time_this_iter_s: 30.310075998306274
  time_total_s: 124.68406343460083
  timers:
    learn_throughput: 7031.436
    learn_time_ms: 23009.809
    sample_throughput: 20056.251
    sample_time_ms: 8066.911
    update_time_ms: 33.12
  timestamp: 1602391383
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: f098a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f098a_00000 | RUNNING  | 172.17.0.4:24812 |      4 |          124.684 | 647168 |  219.256 |              279.657 |              123.444 |            881.965 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f098a_00000:
  custom_metrics:
    time_step_max: 4072
    time_step_mean: 3595.5341207349084
    time_step_min: 3210
  date: 2020-10-11_04-43-33
  done: false
  episode_len_mean: 876.7189873417722
  episode_reward_max: 279.65656565656525
  episode_reward_mean: 221.74191279887467
  episode_reward_min: 123.44444444444406
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 87bf98d51df6425ab864ba4a2aad52ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.082310744694301
        entropy_coeff: 0.00010000000000000002
        kl: 0.011241063542131866
        model: {}
        policy_loss: -0.01796395265098129
        total_loss: 22.274053028651647
        vf_explained_var: 0.9589284658432007
        vf_loss: 22.289875984191895
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.397222222222226
    gpu_util_percent0: 0.3469444444444444
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491666666666667
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 24812
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16325615902226942
    mean_env_wait_ms: 1.2001672089996855
    mean_inference_ms: 5.238996627126697
    mean_raw_obs_processing_ms: 0.4397503011913651
  time_since_restore: 154.95454382896423
  time_this_iter_s: 30.270480394363403
  time_total_s: 154.95454382896423
  timers:
    learn_throughput: 7031.294
    learn_time_ms: 23010.274
    sample_throughput: 20502.336
    sample_time_ms: 7891.393
    update_time_ms: 30.264
  timestamp: 1602391413
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: f098a_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f098a_00000 | RUNNING  | 172.17.0.4:24812 |      5 |          154.955 | 808960 |  221.742 |              279.657 |              123.444 |            876.719 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f098a_00000:
  custom_metrics:
    time_step_max: 4072
    time_step_mean: 3573.1443202979517
    time_step_min: 3206
  date: 2020-10-11_04-44-04
  done: false
  episode_len_mean: 866.1805807622504
  episode_reward_max: 280.26262626262604
  episode_reward_mean: 225.554794771673
  episode_reward_min: 123.44444444444406
  episodes_this_iter: 312
  episodes_total: 1102
  experiment_id: 87bf98d51df6425ab864ba4a2aad52ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0729226469993591
        entropy_coeff: 0.00010000000000000002
        kl: 0.01037551908354674
        model: {}
        policy_loss: -0.018359925265290906
        total_loss: 24.290331976754324
        vf_explained_var: 0.9690165519714355
        vf_loss: 24.30672345842634
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.263888888888893
    gpu_util_percent0: 0.3202777777777778
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.483333333333333
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 24812
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.161031631004493
    mean_env_wait_ms: 1.2025412230564916
    mean_inference_ms: 5.106012051931004
    mean_raw_obs_processing_ms: 0.43234760759555807
  time_since_restore: 185.21483206748962
  time_this_iter_s: 30.26028823852539
  time_total_s: 185.21483206748962
  timers:
    learn_throughput: 7038.053
    learn_time_ms: 22988.176
    sample_throughput: 20759.853
    sample_time_ms: 7793.504
    update_time_ms: 29.038
  timestamp: 1602391444
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: f098a_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f098a_00000 | RUNNING  | 172.17.0.4:24812 |      6 |          185.215 | 970752 |  225.555 |              280.263 |              123.444 |            866.181 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f098a_00000:
  custom_metrics:
    time_step_max: 4072
    time_step_mean: 3561.9773462783173
    time_step_min: 3206
  date: 2020-10-11_04-44-34
  done: false
  episode_len_mean: 861.6677215189874
  episode_reward_max: 283.59595959595924
  episode_reward_mean: 227.43022791203154
  episode_reward_min: 123.44444444444406
  episodes_this_iter: 162
  episodes_total: 1264
  experiment_id: 87bf98d51df6425ab864ba4a2aad52ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.054556471960885
        entropy_coeff: 0.00010000000000000002
        kl: 0.010637797082641296
        model: {}
        policy_loss: -0.01957727221971644
        total_loss: 14.46366378239223
        vf_explained_var: 0.9728155136108398
        vf_loss: 14.481219019208636
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.745945945945948
    gpu_util_percent0: 0.3521621621621621
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494594594594594
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 24812
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.160166957599979
    mean_env_wait_ms: 1.2035223624078446
    mean_inference_ms: 5.05522236020963
    mean_raw_obs_processing_ms: 0.429506381267856
  time_since_restore: 215.78161430358887
  time_this_iter_s: 30.566782236099243
  time_total_s: 215.78161430358887
  timers:
    learn_throughput: 7029.989
    learn_time_ms: 23014.544
    sample_throughput: 20946.743
    sample_time_ms: 7723.969
    update_time_ms: 29.913
  timestamp: 1602391474
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: f098a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f098a_00000 | RUNNING  | 172.17.0.4:24812 |      7 |          215.782 | 1132544 |   227.43 |              283.596 |              123.444 |            861.668 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f098a_00000:
  custom_metrics:
    time_step_max: 4072
    time_step_mean: 3550.692969870875
    time_step_min: 3206
  date: 2020-10-11_04-45-05
  done: false
  episode_len_mean: 857.4050632911392
  episode_reward_max: 283.59595959595924
  episode_reward_mean: 229.09973149213639
  episode_reward_min: 123.44444444444406
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 87bf98d51df6425ab864ba4a2aad52ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0292455639157976
        entropy_coeff: 0.00010000000000000002
        kl: 0.01137650605025036
        model: {}
        policy_loss: -0.020151573748859977
        total_loss: 12.433163438524518
        vf_explained_var: 0.9752405285835266
        vf_loss: 12.45114278793335
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.416216216216213
    gpu_util_percent0: 0.30297297297297293
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494594594594594
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 24812
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15946734982173522
    mean_env_wait_ms: 1.204470075585419
    mean_inference_ms: 5.012749624513429
    mean_raw_obs_processing_ms: 0.427094827951253
  time_since_restore: 246.74115586280823
  time_this_iter_s: 30.95954155921936
  time_total_s: 246.74115586280823
  timers:
    learn_throughput: 7016.187
    learn_time_ms: 23059.819
    sample_throughput: 21027.119
    sample_time_ms: 7694.444
    update_time_ms: 31.175
  timestamp: 1602391505
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: f098a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f098a_00000 | RUNNING  | 172.17.0.4:24812 |      8 |          246.741 | 1294336 |    229.1 |              283.596 |              123.444 |            857.405 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f098a_00000:
  custom_metrics:
    time_step_max: 4072
    time_step_mean: 3539.215206185567
    time_step_min: 3206
  date: 2020-10-11_04-45-36
  done: false
  episode_len_mean: 854.2398734177215
  episode_reward_max: 283.59595959595924
  episode_reward_mean: 230.61600179005225
  episode_reward_min: 123.44444444444406
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 87bf98d51df6425ab864ba4a2aad52ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9933968654700688
        entropy_coeff: 0.00010000000000000002
        kl: 0.0110725091238107
        model: {}
        policy_loss: -0.019353568387616957
        total_loss: 13.340245110648018
        vf_explained_var: 0.9747479557991028
        vf_loss: 13.357483863830566
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.43783783783784
    gpu_util_percent0: 0.3383783783783785
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486486486486487
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 24812
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15885498559387676
    mean_env_wait_ms: 1.2054068446897184
    mean_inference_ms: 4.975429018216823
    mean_raw_obs_processing_ms: 0.42492085925785494
  time_since_restore: 277.3358883857727
  time_this_iter_s: 30.594732522964478
  time_total_s: 277.3358883857727
  timers:
    learn_throughput: 7015.373
    learn_time_ms: 23062.495
    sample_throughput: 21115.273
    sample_time_ms: 7662.321
    update_time_ms: 33.695
  timestamp: 1602391536
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: f098a_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f098a_00000 | RUNNING  | 172.17.0.4:24812 |      9 |          277.336 | 1456128 |  230.616 |              283.596 |              123.444 |             854.24 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f098a_00000:
  custom_metrics:
    time_step_max: 4072
    time_step_mean: 3522.1831442463535
    time_step_min: 3206
  date: 2020-10-11_04-46-06
  done: false
  episode_len_mean: 848.197977647685
  episode_reward_max: 283.59595959595924
  episode_reward_mean: 233.19140849689
  episode_reward_min: 123.44444444444406
  episodes_this_iter: 299
  episodes_total: 1879
  experiment_id: 87bf98d51df6425ab864ba4a2aad52ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9651425991739545
        entropy_coeff: 0.00010000000000000002
        kl: 0.009806867555848189
        model: {}
        policy_loss: -0.017040171082563966
        total_loss: 18.05064650944301
        vf_explained_var: 0.9765798449516296
        vf_loss: 18.065821511404856
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.147222222222222
    gpu_util_percent0: 0.3644444444444445
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.477777777777778
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 24812
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15790333610335558
    mean_env_wait_ms: 1.2075316713423425
    mean_inference_ms: 4.917653911434697
    mean_raw_obs_processing_ms: 0.4216486523844951
  time_since_restore: 307.75790190696716
  time_this_iter_s: 30.422013521194458
  time_total_s: 307.75790190696716
  timers:
    learn_throughput: 7016.593
    learn_time_ms: 23058.486
    sample_throughput: 21210.081
    sample_time_ms: 7628.071
    update_time_ms: 32.599
  timestamp: 1602391566
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: f098a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f098a_00000 | RUNNING  | 172.17.0.4:24812 |     10 |          307.758 | 1617920 |  233.191 |              283.596 |              123.444 |            848.198 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f098a_00000:
  custom_metrics:
    time_step_max: 4072
    time_step_mean: 3513.2275419545904
    time_step_min: 3206
  date: 2020-10-11_04-46-37
  done: false
  episode_len_mean: 845.2108081791627
  episode_reward_max: 283.59595959595924
  episode_reward_mean: 234.4990017015332
  episode_reward_min: 123.44444444444406
  episodes_this_iter: 175
  episodes_total: 2054
  experiment_id: 87bf98d51df6425ab864ba4a2aad52ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9591652878693172
        entropy_coeff: 0.00010000000000000002
        kl: 0.009383771834628922
        model: {}
        policy_loss: -0.018306918292572454
        total_loss: 11.961616447993688
        vf_explained_var: 0.9777143597602844
        vf_loss: 11.978142602103096
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.42702702702703
    gpu_util_percent0: 0.2827027027027027
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.489189189189189
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 24812
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15742951013513726
    mean_env_wait_ms: 1.2084515426796025
    mean_inference_ms: 4.889784380224027
    mean_raw_obs_processing_ms: 0.42004988478718625
  time_since_restore: 338.35616993904114
  time_this_iter_s: 30.598268032073975
  time_total_s: 338.35616993904114
  timers:
    learn_throughput: 7015.397
    learn_time_ms: 23062.415
    sample_throughput: 21712.869
    sample_time_ms: 7451.434
    update_time_ms: 31.627
  timestamp: 1602391597
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: f098a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f098a_00000 | RUNNING  | 172.17.0.4:24812 |     11 |          338.356 | 1779712 |  234.499 |              283.596 |              123.444 |            845.211 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f098a_00000:
  custom_metrics:
    time_step_max: 4072
    time_step_mean: 3506.2522893772893
    time_step_min: 3187
  date: 2020-10-11_04-47-08
  done: false
  episode_len_mean: 843.1378842676311
  episode_reward_max: 283.59595959595924
  episode_reward_mean: 235.5162018010118
  episode_reward_min: 123.44444444444406
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 87bf98d51df6425ab864ba4a2aad52ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9398730312074933
        entropy_coeff: 0.00010000000000000002
        kl: 0.009640441741794348
        model: {}
        policy_loss: -0.017326365690678358
        total_loss: 11.40019600731986
        vf_explained_var: 0.977282702922821
        vf_loss: 11.415688650948661
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.16111111111111
    gpu_util_percent0: 0.3502777777777778
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888888
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 24812
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15704677806014103
    mean_env_wait_ms: 1.2093081905353031
    mean_inference_ms: 4.867256504731077
    mean_raw_obs_processing_ms: 0.41875441063204427
  time_since_restore: 368.9550483226776
  time_this_iter_s: 30.598878383636475
  time_total_s: 368.9550483226776
  timers:
    learn_throughput: 7016.45
    learn_time_ms: 23058.954
    sample_throughput: 21980.005
    sample_time_ms: 7360.872
    update_time_ms: 31.985
  timestamp: 1602391628
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: f098a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f098a_00000 | RUNNING  | 172.17.0.4:24812 |     12 |          368.955 | 1941504 |  235.516 |              283.596 |              123.444 |            843.138 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f098a_00000:
  custom_metrics:
    time_step_max: 4072
    time_step_mean: 3498.6550255536627
    time_step_min: 3165
  date: 2020-10-11_04-47-39
  done: false
  episode_len_mean: 840.7866161616162
  episode_reward_max: 286.47474747474746
  episode_reward_mean: 236.65725436179966
  episode_reward_min: 123.44444444444406
  episodes_this_iter: 164
  episodes_total: 2376
  experiment_id: 87bf98d51df6425ab864ba4a2aad52ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.901526187147413
        entropy_coeff: 0.00010000000000000002
        kl: 0.01042998196291072
        model: {}
        policy_loss: -0.01930196732947869
        total_loss: 10.995412281581334
        vf_explained_var: 0.9796980619430542
        vf_loss: 11.01271847316197
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.299999999999997
    gpu_util_percent0: 0.35675675675675667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4837837837837835
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 24812
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15668228738209244
    mean_env_wait_ms: 1.2101718282147516
    mean_inference_ms: 4.845834875153829
    mean_raw_obs_processing_ms: 0.4174922094246963
  time_since_restore: 399.59209990501404
  time_this_iter_s: 30.637051582336426
  time_total_s: 399.59209990501404
  timers:
    learn_throughput: 7012.392
    learn_time_ms: 23072.297
    sample_throughput: 21995.116
    sample_time_ms: 7355.815
    update_time_ms: 32.884
  timestamp: 1602391659
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: f098a_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f098a_00000 | RUNNING  | 172.17.0.4:24812 |     13 |          399.592 | 2103296 |  236.657 |              286.475 |              123.444 |            840.787 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f098a_00000:
  custom_metrics:
    time_step_max: 4072
    time_step_mean: 3485.7026822818284
    time_step_min: 3165
  date: 2020-10-11_04-48-09
  done: false
  episode_len_mean: 837.9682242990655
  episode_reward_max: 286.47474747474746
  episode_reward_mean: 238.2789955631076
  episode_reward_min: 123.44444444444406
  episodes_this_iter: 299
  episodes_total: 2675
  experiment_id: 87bf98d51df6425ab864ba4a2aad52ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8820224702358246
        entropy_coeff: 0.00010000000000000002
        kl: 0.008289109715925795
        model: {}
        policy_loss: -0.015435850663509752
        total_loss: 15.766195297241211
        vf_explained_var: 0.9792585372924805
        vf_loss: 15.78006192616054
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.819444444444443
    gpu_util_percent0: 0.34888888888888886
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.483333333333333
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 24812
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1561330219035994
    mean_env_wait_ms: 1.211696091248397
    mean_inference_ms: 4.812582680572161
    mean_raw_obs_processing_ms: 0.4156285475431766
  time_since_restore: 429.8623492717743
  time_this_iter_s: 30.270249366760254
  time_total_s: 429.8623492717743
  timers:
    learn_throughput: 7007.008
    learn_time_ms: 23090.028
    sample_throughput: 22067.952
    sample_time_ms: 7331.537
    update_time_ms: 34.793
  timestamp: 1602391689
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: f098a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f098a_00000 | RUNNING  | 172.17.0.4:24812 |     14 |          429.862 | 2265088 |  238.279 |              286.475 |              123.444 |            837.968 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f098a_00000:
  custom_metrics:
    time_step_max: 4072
    time_step_mean: 3479.6352982954545
    time_step_min: 3130
  date: 2020-10-11_04-48-40
  done: false
  episode_len_mean: 836.7770745428974
  episode_reward_max: 291.77777777777754
  episode_reward_mean: 239.1855048374034
  episode_reward_min: 123.44444444444406
  episodes_this_iter: 169
  episodes_total: 2844
  experiment_id: 87bf98d51df6425ab864ba4a2aad52ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8713245945317405
        entropy_coeff: 0.00010000000000000002
        kl: 0.009180805778929166
        model: {}
        policy_loss: -0.018415691863213266
        total_loss: 9.784980297088623
        vf_explained_var: 0.9817479252815247
        vf_loss: 9.80164657320295
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.405555555555555
    gpu_util_percent0: 0.35750000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888889
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 24812
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1558441625287883
    mean_env_wait_ms: 1.2123891730845924
    mean_inference_ms: 4.795510845383685
    mean_raw_obs_processing_ms: 0.4146307234035295
  time_since_restore: 460.36489963531494
  time_this_iter_s: 30.50255036354065
  time_total_s: 460.36489963531494
  timers:
    learn_throughput: 7004.136
    learn_time_ms: 23099.496
    sample_throughput: 22034.746
    sample_time_ms: 7342.585
    update_time_ms: 36.74
  timestamp: 1602391720
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: f098a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f098a_00000 | RUNNING  | 172.17.0.4:24812 |     15 |          460.365 | 2426880 |  239.186 |              291.778 |              123.444 |            836.777 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f098a_00000:
  custom_metrics:
    time_step_max: 4072
    time_step_mean: 3475.2370544720916
    time_step_min: 3130
  date: 2020-10-11_04-49-10
  done: false
  episode_len_mean: 835.5536309127249
  episode_reward_max: 291.77777777777754
  episode_reward_mean: 239.7757791102227
  episode_reward_min: 123.44444444444406
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: 87bf98d51df6425ab864ba4a2aad52ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8589124849864415
        entropy_coeff: 0.00010000000000000002
        kl: 0.009340690182788032
        model: {}
        policy_loss: -0.01678032275023205
        total_loss: 11.716068472181048
        vf_explained_var: 0.9775177240371704
        vf_loss: 11.731066635676793
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.40555555555555
    gpu_util_percent0: 0.3797222222222222
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888889
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 24812
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15559768411763114
    mean_env_wait_ms: 1.2130052127106874
    mean_inference_ms: 4.780818752995902
    mean_raw_obs_processing_ms: 0.4137723384548529
  time_since_restore: 490.69294238090515
  time_this_iter_s: 30.32804274559021
  time_total_s: 490.69294238090515
  timers:
    learn_throughput: 6995.778
    learn_time_ms: 23127.092
    sample_throughput: 22098.006
    sample_time_ms: 7321.566
    update_time_ms: 36.773
  timestamp: 1602391750
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: f098a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f098a_00000 | RUNNING  | 172.17.0.4:24812 |     16 |          490.693 | 2588672 |  239.776 |              291.778 |              123.444 |            835.554 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f098a_00000:
  custom_metrics:
    time_step_max: 4072
    time_step_mean: 3470.6466284987278
    time_step_min: 3130
  date: 2020-10-11_04-49-41
  done: false
  episode_len_mean: 834.2641866330391
  episode_reward_max: 291.77777777777754
  episode_reward_mean: 240.5436840027003
  episode_reward_min: 123.44444444444406
  episodes_this_iter: 170
  episodes_total: 3172
  experiment_id: 87bf98d51df6425ab864ba4a2aad52ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8314950295857021
        entropy_coeff: 0.00010000000000000002
        kl: 0.009005246883524316
        model: {}
        policy_loss: -0.016771671195913638
        total_loss: 13.198036534445626
        vf_explained_var: 0.9775308966636658
        vf_loss: 13.213090079171318
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.970270270270273
    gpu_util_percent0: 0.35162162162162164
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494594594594595
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 24812
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15534264344230186
    mean_env_wait_ms: 1.2136371657195004
    mean_inference_ms: 4.765672331732033
    mean_raw_obs_processing_ms: 0.4128539895999657
  time_since_restore: 521.1954517364502
  time_this_iter_s: 30.502509355545044
  time_total_s: 521.1954517364502
  timers:
    learn_throughput: 6998.495
    learn_time_ms: 23118.112
    sample_throughput: 22094.725
    sample_time_ms: 7322.653
    update_time_ms: 37.142
  timestamp: 1602391781
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: f098a_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f098a_00000 | RUNNING  | 172.17.0.4:24812 |     17 |          521.195 | 2750464 |  240.544 |              291.778 |              123.444 |            834.264 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f098a_00000:
  custom_metrics:
    time_step_max: 4072
    time_step_mean: 3462.17199302731
    time_step_min: 3130
  date: 2020-10-11_04-50-11
  done: false
  episode_len_mean: 832.0002881844381
  episode_reward_max: 291.77777777777754
  episode_reward_mean: 241.73075131720657
  episode_reward_min: 123.44444444444406
  episodes_this_iter: 298
  episodes_total: 3470
  experiment_id: 87bf98d51df6425ab864ba4a2aad52ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8193267370973315
        entropy_coeff: 0.00010000000000000002
        kl: 0.008230858482420444
        model: {}
        policy_loss: -0.015437678169941396
        total_loss: 13.931944234030587
        vf_explained_var: 0.9806793332099915
        vf_loss: 13.94581685747419
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.447222222222226
    gpu_util_percent0: 0.28472222222222215
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491666666666667
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 24812
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15497652659454011
    mean_env_wait_ms: 1.2147917171473162
    mean_inference_ms: 4.742845744841569
    mean_raw_obs_processing_ms: 0.4115480421860005
  time_since_restore: 551.6523716449738
  time_this_iter_s: 30.45691990852356
  time_total_s: 551.6523716449738
  timers:
    learn_throughput: 7001.021
    learn_time_ms: 23109.771
    sample_throughput: 22221.402
    sample_time_ms: 7280.909
    update_time_ms: 36.257
  timestamp: 1602391811
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: f098a_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f098a_00000 | RUNNING  | 172.17.0.4:24812 |     18 |          551.652 | 2912256 |  241.731 |              291.778 |              123.444 |                832 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f098a_00000:
  custom_metrics:
    time_step_max: 4072
    time_step_mean: 3457.918191902385
    time_step_min: 3130
  date: 2020-10-11_04-50-42
  done: false
  episode_len_mean: 830.856631810677
  episode_reward_max: 291.77777777777754
  episode_reward_mean: 242.37003774675753
  episode_reward_min: 123.44444444444406
  episodes_this_iter: 164
  episodes_total: 3634
  experiment_id: 87bf98d51df6425ab864ba4a2aad52ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8076299599238804
        entropy_coeff: 0.00010000000000000002
        kl: 0.008737285621464252
        model: {}
        policy_loss: -0.016955881379544735
        total_loss: 8.693195274897985
        vf_explained_var: 0.983235239982605
        vf_loss: 8.70848458153861
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.397222222222222
    gpu_util_percent0: 0.33722222222222226
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497222222222222
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 24812
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15478196625014523
    mean_env_wait_ms: 1.21530694508792
    mean_inference_ms: 4.730982188290963
    mean_raw_obs_processing_ms: 0.4108484692716758
  time_since_restore: 581.9367668628693
  time_this_iter_s: 30.284395217895508
  time_total_s: 581.9367668628693
  timers:
    learn_throughput: 7002.936
    learn_time_ms: 23103.453
    sample_throughput: 22297.174
    sample_time_ms: 7256.166
    update_time_ms: 34.015
  timestamp: 1602391842
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: f098a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f098a_00000 | RUNNING  | 172.17.0.4:24812 |     19 |          581.937 | 3074048 |   242.37 |              291.778 |              123.444 |            830.857 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f098a_00000:
  custom_metrics:
    time_step_max: 4072
    time_step_mean: 3454.8995749202977
    time_step_min: 3130
  date: 2020-10-11_04-51-12
  done: true
  episode_len_mean: 829.7887658227849
  episode_reward_max: 291.77777777777754
  episode_reward_mean: 242.76953874184878
  episode_reward_min: 123.44444444444406
  episodes_this_iter: 158
  episodes_total: 3792
  experiment_id: 87bf98d51df6425ab864ba4a2aad52ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.7956187384469169
        entropy_coeff: 0.00010000000000000002
        kl: 0.00932775464441095
        model: {}
        policy_loss: -0.016888405395937816
        total_loss: 11.526309762682233
        vf_explained_var: 0.9777116179466248
        vf_loss: 11.541412217276436
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.513513513513512
    gpu_util_percent0: 0.36702702702702705
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 24812
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15460946306749498
    mean_env_wait_ms: 1.2158185816467957
    mean_inference_ms: 4.720452279073216
    mean_raw_obs_processing_ms: 0.4102255152980764
  time_since_restore: 612.3072848320007
  time_this_iter_s: 30.37051796913147
  time_total_s: 612.3072848320007
  timers:
    learn_throughput: 7003.987
    learn_time_ms: 23099.985
    sample_throughput: 22309.386
    sample_time_ms: 7252.194
    update_time_ms: 35.826
  timestamp: 1602391872
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: f098a_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f098a_00000 | TERMINATED |       |     20 |          612.307 | 3235840 |   242.77 |              291.778 |              123.444 |            829.789 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f098a_00000 | TERMINATED |       |     20 |          612.307 | 3235840 |   242.77 |              291.778 |              123.444 |            829.789 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


