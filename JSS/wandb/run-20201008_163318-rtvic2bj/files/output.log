2020-10-08 16:33:20,925	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8270[39m[22m
== Status ==
Memory usage on this node: 57.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_fb185_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=54371)[0m 2020-10-08 16:33:23,913	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=54312)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54312)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54360)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54360)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54303)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54303)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54375)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54375)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54232)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54232)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54314)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54314)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54368)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54368)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54257)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54257)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54294)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54294)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54353)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54353)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54318)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54318)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54363)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54363)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54332)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54332)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54328)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54328)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54388)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54388)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54361)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54361)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54357)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54357)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54349)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54349)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54290)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54290)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54242)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54242)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54352)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54352)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54335)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54335)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54321)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54321)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54255)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54255)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54307)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54307)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54334)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54334)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54369)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54369)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54234)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54234)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54243)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54243)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54246)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54246)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54264)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54264)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54306)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54306)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54386)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54386)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54267)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54267)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54230)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54230)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54237)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54237)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54389)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54389)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54341)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54341)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54235)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54235)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54325)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54325)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54296)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54296)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54231)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54231)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54346)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54346)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54240)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54240)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54236)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54236)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54317)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54317)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54233)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54233)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54272)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54272)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54252)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54252)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54319)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54319)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54338)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54338)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54258)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54258)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54251)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54251)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54313)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54313)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54327)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54327)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54241)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54241)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54315)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54315)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54320)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54320)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54316)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54316)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54244)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54244)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54299)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54299)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54302)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54302)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54247)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54247)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54339)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54339)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54343)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54343)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54292)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54292)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54249)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54249)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54271)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54271)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54269)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54269)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54239)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54239)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54323)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54323)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54347)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54347)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54366)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54366)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54331)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54331)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54245)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54245)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54238)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54238)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54326)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54326)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54265)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54265)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54340)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54340)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_fb185_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3225.0
  date: 2020-10-08_16-34-17
  done: false
  episode_len_mean: 875.496835443038
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 227.93504666922368
  episode_reward_min: 147.0606060606061
  episodes_this_iter: 316
  episodes_total: 316
  experiment_id: f1f9ce69a3b04ef89e1adc9b7438716d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.164182335138321
        entropy_coeff: 0.0
        kl: 0.005434836400672794
        model: {}
        policy_loss: -0.009786928351968528
        total_loss: 7.511050510406494
        vf_explained_var: 0.7778908014297485
        vf_loss: 7.519750428199768
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.43272727272727
    gpu_util_percent0: 0.27163636363636356
    gpu_util_percent1: 0.00018181818181818183
    gpu_util_percent2: 0.0
    ram_util_percent: 9.785454545454547
    vram_util_percent0: 0.2759459137123946
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54371
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.24744401856976256
    mean_env_wait_ms: 3.27305626228806
    mean_inference_ms: 9.582594618012633
    mean_raw_obs_processing_ms: 0.8788552332822465
  time_since_restore: 47.254398822784424
  time_this_iter_s: 47.254398822784424
  time_total_s: 47.254398822784424
  timers:
    learn_throughput: 10574.838
    learn_time_ms: 30599.429
    sample_throughput: 19522.671
    sample_time_ms: 16574.781
    update_time_ms: 24.549
  timestamp: 1602174857
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 1
  trial_id: fb185_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 75.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_fb185_00000 | RUNNING  | 172.17.0.4:54371 |      1 |          47.2544 | 323584 |  227.935 |              284.798 |              147.061 |            875.497 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_fb185_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3225.0
  date: 2020-10-08_16-35-02
  done: false
  episode_len_mean: 869.1740506329114
  episode_reward_max: 295.23232323232304
  episode_reward_mean: 228.57749968034761
  episode_reward_min: 111.5454545454545
  episodes_this_iter: 316
  episodes_total: 632
  experiment_id: f1f9ce69a3b04ef89e1adc9b7438716d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.1358363330364227
        entropy_coeff: 0.0
        kl: 0.006681498442776501
        model: {}
        policy_loss: -0.01258821411174722
        total_loss: 6.392654204368592
        vf_explained_var: 0.9081117510795593
        vf_loss: 6.403906083106994
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.66346153846154
    gpu_util_percent0: 0.2936538461538462
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.15192307692308
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54371
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.24113553580090927
    mean_env_wait_ms: 3.257913709661973
    mean_inference_ms: 9.083167793138466
    mean_raw_obs_processing_ms: 0.8548684138062012
  time_since_restore: 92.04471564292908
  time_this_iter_s: 44.79031682014465
  time_total_s: 92.04471564292908
  timers:
    learn_throughput: 10654.082
    learn_time_ms: 30371.833
    sample_throughput: 20866.385
    sample_time_ms: 15507.43
    update_time_ms: 33.769
  timestamp: 1602174902
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 2
  trial_id: fb185_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_fb185_00000 | RUNNING  | 172.17.0.4:54371 |      2 |          92.0447 | 647168 |  228.577 |              295.232 |              111.545 |            869.174 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_fb185_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3220.0
  date: 2020-10-08_16-35-46
  done: false
  episode_len_mean: 863.7457805907173
  episode_reward_max: 295.23232323232304
  episode_reward_mean: 229.05943400247182
  episode_reward_min: 111.5454545454545
  episodes_this_iter: 316
  episodes_total: 948
  experiment_id: f1f9ce69a3b04ef89e1adc9b7438716d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.1233164846897126
        entropy_coeff: 0.0
        kl: 0.0071658816188573836
        model: {}
        policy_loss: -0.014200279209762811
        total_loss: 6.096204090118408
        vf_explained_var: 0.9497032165527344
        vf_loss: 6.10897126197815
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.798039215686277
    gpu_util_percent0: 0.28372549019607846
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.182352941176472
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54371
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.23771949061854913
    mean_env_wait_ms: 3.2534219144031016
    mean_inference_ms: 8.767393702310974
    mean_raw_obs_processing_ms: 0.8404341871645528
  time_since_restore: 136.53362607955933
  time_this_iter_s: 44.48891043663025
  time_total_s: 136.53362607955933
  timers:
    learn_throughput: 10651.478
    learn_time_ms: 30379.257
    sample_throughput: 21581.013
    sample_time_ms: 14993.92
    update_time_ms: 36.05
  timestamp: 1602174946
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 3
  trial_id: fb185_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_fb185_00000 | RUNNING  | 172.17.0.4:54371 |      3 |          136.534 | 970752 |  229.059 |              295.232 |              111.545 |            863.746 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_fb185_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3220.0
  date: 2020-10-08_16-36-31
  done: false
  episode_len_mean: 858.506329113924
  episode_reward_max: 295.23232323232304
  episode_reward_mean: 229.29232195371424
  episode_reward_min: 111.5454545454545
  episodes_this_iter: 316
  episodes_total: 1264
  experiment_id: f1f9ce69a3b04ef89e1adc9b7438716d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.096629148721695
        entropy_coeff: 0.0
        kl: 0.007442292128689587
        model: {}
        policy_loss: -0.015304845664650202
        total_loss: 5.8688503980636595
        vf_explained_var: 0.9670330882072449
        vf_loss: 5.882666826248169
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.85294117647059
    gpu_util_percent0: 0.2780392156862745
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.17843137254902
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54371
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.2353850094563621
    mean_env_wait_ms: 3.254368802976481
    mean_inference_ms: 8.554176696873267
    mean_raw_obs_processing_ms: 0.8302876230245398
  time_since_restore: 180.82403779029846
  time_this_iter_s: 44.290411710739136
  time_total_s: 180.82403779029846
  timers:
    learn_throughput: 10675.302
    learn_time_ms: 30311.462
    sample_throughput: 21925.679
    sample_time_ms: 14758.22
    update_time_ms: 38.136
  timestamp: 1602174991
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 4
  trial_id: fb185_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_fb185_00000 | RUNNING  | 172.17.0.4:54371 |      4 |          180.824 | 1294336 |  229.292 |              295.232 |              111.545 |            858.506 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_fb185_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3178.0
  date: 2020-10-08_16-37-15
  done: false
  episode_len_mean: 848.3839957035445
  episode_reward_max: 295.23232323232304
  episode_reward_mean: 230.21770877409963
  episode_reward_min: 111.5454545454545
  episodes_this_iter: 598
  episodes_total: 1862
  experiment_id: f1f9ce69a3b04ef89e1adc9b7438716d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.0676456332206725
        entropy_coeff: 0.0
        kl: 0.0068112610606476665
        model: {}
        policy_loss: -0.015369512472534552
        total_loss: 8.57252836227417
        vf_explained_var: 0.9776443243026733
        vf_loss: 8.586535835266114
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.00196078431373
    gpu_util_percent0: 0.31823529411764706
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.211764705882352
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54371
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.23269811870160934
    mean_env_wait_ms: 3.262829215824495
    mean_inference_ms: 8.300609951847692
    mean_raw_obs_processing_ms: 0.8181242572860928
  time_since_restore: 224.74492406845093
  time_this_iter_s: 43.920886278152466
  time_total_s: 224.74492406845093
  timers:
    learn_throughput: 10695.664
    learn_time_ms: 30253.754
    sample_throughput: 22221.528
    sample_time_ms: 14561.735
    update_time_ms: 36.873
  timestamp: 1602175035
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 5
  trial_id: fb185_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_fb185_00000 | RUNNING  | 172.17.0.4:54371 |      5 |          224.745 | 1617920 |  230.218 |              295.232 |              111.545 |            848.384 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_fb185_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3178.0
  date: 2020-10-08_16-37-59
  done: false
  episode_len_mean: 842.8386075949367
  episode_reward_max: 295.23232323232304
  episode_reward_mean: 230.64890770270506
  episode_reward_min: 111.5454545454545
  episodes_this_iter: 350
  episodes_total: 2212
  experiment_id: f1f9ce69a3b04ef89e1adc9b7438716d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.065030151605606
        entropy_coeff: 0.0
        kl: 0.00705519390758127
        model: {}
        policy_loss: -0.016833867016248404
        total_loss: 4.52697069644928
        vf_explained_var: 0.984390377998352
        vf_loss: 4.542393541336059
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.221568627450985
    gpu_util_percent0: 0.36078431372549025
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.184313725490195
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54371
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.23162395272501432
    mean_env_wait_ms: 3.2688765059934344
    mean_inference_ms: 8.202218457126685
    mean_raw_obs_processing_ms: 0.8142930914981685
  time_since_restore: 269.08233666419983
  time_this_iter_s: 44.3374125957489
  time_total_s: 269.08233666419983
  timers:
    learn_throughput: 10690.556
    learn_time_ms: 30268.212
    sample_throughput: 22400.011
    sample_time_ms: 14445.707
    update_time_ms: 37.222
  timestamp: 1602175079
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 6
  trial_id: fb185_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_fb185_00000 | RUNNING  | 172.17.0.4:54371 |      6 |          269.082 | 1941504 |  230.649 |              295.232 |              111.545 |            842.839 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_fb185_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3178.0
  date: 2020-10-08_16-38-43
  done: false
  episode_len_mean: 838.2298259493671
  episode_reward_max: 295.23232323232304
  episode_reward_mean: 231.01269418872255
  episode_reward_min: 111.5454545454545
  episodes_this_iter: 316
  episodes_total: 2528
  experiment_id: f1f9ce69a3b04ef89e1adc9b7438716d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.0429168403148652
        entropy_coeff: 0.0
        kl: 0.006264695758000016
        model: {}
        policy_loss: -0.01745682265609503
        total_loss: 4.3312856435775755
        vf_explained_var: 0.9869125485420227
        vf_loss: 4.347489464282989
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.24901960784313
    gpu_util_percent0: 0.29745098039215684
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.196078431372548
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54371
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.23082524176222222
    mean_env_wait_ms: 3.274338890864568
    mean_inference_ms: 8.127627044225438
    mean_raw_obs_processing_ms: 0.8111482381641796
  time_since_restore: 313.36609530448914
  time_this_iter_s: 44.28375864028931
  time_total_s: 313.36609530448914
  timers:
    learn_throughput: 10690.019
    learn_time_ms: 30269.732
    sample_throughput: 22540.826
    sample_time_ms: 14355.463
    update_time_ms: 35.548
  timestamp: 1602175123
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 7
  trial_id: fb185_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_fb185_00000 | RUNNING  | 172.17.0.4:54371 |      7 |          313.366 | 2265088 |  231.013 |              295.232 |              111.545 |             838.23 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_fb185_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3178.0
  date: 2020-10-08_16-39-28
  done: false
  episode_len_mean: 834.4757383966245
  episode_reward_max: 295.23232323232304
  episode_reward_mean: 231.69725738396616
  episode_reward_min: 111.5454545454545
  episodes_this_iter: 316
  episodes_total: 2844
  experiment_id: f1f9ce69a3b04ef89e1adc9b7438716d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.0078375458717346
        entropy_coeff: 0.0
        kl: 0.006123754056170582
        model: {}
        policy_loss: -0.01720845774980262
        total_loss: 4.43843023777008
        vf_explained_var: 0.9884738922119141
        vf_loss: 4.454413938522339
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.936
    gpu_util_percent0: 0.325
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.177999999999999
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54371
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.23016902998647648
    mean_env_wait_ms: 3.280054762056938
    mean_inference_ms: 8.063730151519312
    mean_raw_obs_processing_ms: 0.80838080285478
  time_since_restore: 357.53028202056885
  time_this_iter_s: 44.16418671607971
  time_total_s: 357.53028202056885
  timers:
    learn_throughput: 10695.809
    learn_time_ms: 30253.346
    sample_throughput: 22633.263
    sample_time_ms: 14296.834
    update_time_ms: 36.547
  timestamp: 1602175168
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 8
  trial_id: fb185_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_fb185_00000 | RUNNING  | 172.17.0.4:54371 |      8 |           357.53 | 2588672 |  231.697 |              295.232 |              111.545 |            834.476 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_fb185_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3178.0
  date: 2020-10-08_16-40-12
  done: false
  episode_len_mean: 828.5825661680092
  episode_reward_max: 295.23232323232304
  episode_reward_mean: 232.6593960316629
  episode_reward_min: 111.5454545454545
  episodes_this_iter: 632
  episodes_total: 3476
  experiment_id: f1f9ce69a3b04ef89e1adc9b7438716d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 0.9783800303936004
        entropy_coeff: 0.0
        kl: 0.005720684421248734
        model: {}
        policy_loss: -0.014918826008215546
        total_loss: 5.423507642745972
        vf_explained_var: 0.9914833307266235
        vf_loss: 5.437282395362854
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.70588235294118
    gpu_util_percent0: 0.3392156862745098
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.176470588235293
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54371
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.22913708757962448
    mean_env_wait_ms: 3.2907820948719544
    mean_inference_ms: 7.9624820814868755
    mean_raw_obs_processing_ms: 0.8040928491333845
  time_since_restore: 401.76697158813477
  time_this_iter_s: 44.23668956756592
  time_total_s: 401.76697158813477
  timers:
    learn_throughput: 10698.253
    learn_time_ms: 30246.434
    sample_throughput: 22701.24
    sample_time_ms: 14254.023
    update_time_ms: 36.632
  timestamp: 1602175212
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 9
  trial_id: fb185_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_fb185_00000 | RUNNING  | 172.17.0.4:54371 |      9 |          401.767 | 2912256 |  232.659 |              295.232 |              111.545 |            828.583 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_fb185_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3178.0
  date: 2020-10-08_16-40-56
  done: false
  episode_len_mean: 826.4841772151899
  episode_reward_max: 295.23232323232304
  episode_reward_mean: 233.0667274005881
  episode_reward_min: 111.5454545454545
  episodes_this_iter: 316
  episodes_total: 3792
  experiment_id: f1f9ce69a3b04ef89e1adc9b7438716d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 0.9694692403078079
        entropy_coeff: 0.0
        kl: 0.0056906518060714
        model: {}
        policy_loss: -0.016346936766058206
        total_loss: 3.6473479151725767
        vf_explained_var: 0.9917066693305969
        vf_loss: 3.6625567078590393
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.651999999999994
    gpu_util_percent0: 0.2804
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.2
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54371
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.22873103344187137
    mean_env_wait_ms: 3.295544926668675
    mean_inference_ms: 7.921445533607502
    mean_raw_obs_processing_ms: 0.8024075266460824
  time_since_restore: 445.805047750473
  time_this_iter_s: 44.03807616233826
  time_total_s: 445.805047750473
  timers:
    learn_throughput: 10698.409
    learn_time_ms: 30245.992
    sample_throughput: 22793.253
    sample_time_ms: 14196.482
    update_time_ms: 35.575
  timestamp: 1602175256
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 10
  trial_id: fb185_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_fb185_00000 | RUNNING  | 172.17.0.4:54371 |     10 |          445.805 | 3235840 |  233.067 |              295.232 |              111.545 |            826.484 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_fb185_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3178.0
  date: 2020-10-08_16-41-40
  done: false
  episode_len_mean: 824.7400194741967
  episode_reward_max: 295.23232323232304
  episode_reward_mean: 233.6770184808159
  episode_reward_min: 111.5454545454545
  episodes_this_iter: 316
  episodes_total: 4108
  experiment_id: f1f9ce69a3b04ef89e1adc9b7438716d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 0.9550300866365433
        entropy_coeff: 0.0
        kl: 0.005446311947889626
        model: {}
        policy_loss: -0.016941330302506684
        total_loss: 3.2832759618759155
        vf_explained_var: 0.9924384355545044
        vf_loss: 3.299128019809723
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.884
    gpu_util_percent0: 0.3034
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.188
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54371
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.2283579456602271
    mean_env_wait_ms: 3.299916876835858
    mean_inference_ms: 7.8842286350094115
    mean_raw_obs_processing_ms: 0.8008257840492474
  time_since_restore: 489.82833909988403
  time_this_iter_s: 44.02329134941101
  time_total_s: 489.82833909988403
  timers:
    learn_throughput: 10712.75
    learn_time_ms: 30205.504
    sample_throughput: 23263.963
    sample_time_ms: 13909.238
    update_time_ms: 35.483
  timestamp: 1602175300
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 11
  trial_id: fb185_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_fb185_00000 | RUNNING  | 172.17.0.4:54371 |     11 |          489.828 | 3559424 |  233.677 |              295.232 |              111.545 |             824.74 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_fb185_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3178.0
  date: 2020-10-08_16-42-25
  done: false
  episode_len_mean: 823.0946188340807
  episode_reward_max: 295.23232323232304
  episode_reward_mean: 234.3911083933505
  episode_reward_min: 111.5454545454545
  episodes_this_iter: 352
  episodes_total: 4460
  experiment_id: f1f9ce69a3b04ef89e1adc9b7438716d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 0.9146486341953277
        entropy_coeff: 0.0
        kl: 0.005636754562146962
        model: {}
        policy_loss: -0.01648179511539638
        total_loss: 3.5726980805397033
        vf_explained_var: 0.9940611124038696
        vf_loss: 3.588052451610565
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.305999999999997
    gpu_util_percent0: 0.315
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.192
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54371
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.22796161884300037
    mean_env_wait_ms: 3.304503149386991
    mean_inference_ms: 7.846363433455653
    mean_raw_obs_processing_ms: 0.7990071262199212
  time_since_restore: 533.777999162674
  time_this_iter_s: 43.94966006278992
  time_total_s: 533.777999162674
  timers:
    learn_throughput: 10711.408
    learn_time_ms: 30209.287
    sample_throughput: 23402.196
    sample_time_ms: 13827.079
    update_time_ms: 35.158
  timestamp: 1602175345
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 12
  trial_id: fb185_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_fb185_00000 | RUNNING  | 172.17.0.4:54371 |     12 |          533.778 | 3883008 |  234.391 |              295.232 |              111.545 |            823.095 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_fb185_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3178.0
  date: 2020-10-08_16-43-09
  done: false
  episode_len_mean: 820.8587816455696
  episode_reward_max: 295.23232323232304
  episode_reward_mean: 235.29453154967393
  episode_reward_min: 111.5454545454545
  episodes_this_iter: 596
  episodes_total: 5056
  experiment_id: f1f9ce69a3b04ef89e1adc9b7438716d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 0.8918835788965225
        entropy_coeff: 0.0
        kl: 0.00526195929851383
        model: {}
        policy_loss: -0.014734815014526248
        total_loss: 3.8446401238441466
        vf_explained_var: 0.993273913860321
        vf_loss: 3.8583225846290587
    num_steps_sampled: 4206592
    num_steps_trained: 4206592
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.190196078431374
    gpu_util_percent0: 0.3705882352941176
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.168627450980393
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54371
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.22742898271329137
    mean_env_wait_ms: 3.3118319137370307
    mean_inference_ms: 7.7923858756678355
    mean_raw_obs_processing_ms: 0.7967284926660493
  time_since_restore: 577.9711999893188
  time_this_iter_s: 44.1932008266449
  time_total_s: 577.9711999893188
  timers:
    learn_throughput: 10713.751
    learn_time_ms: 30202.68
    sample_throughput: 23441.64
    sample_time_ms: 13803.813
    update_time_ms: 33.317
  timestamp: 1602175389
  timesteps_since_restore: 0
  timesteps_total: 4206592
  training_iteration: 13
  trial_id: fb185_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_fb185_00000 | RUNNING  | 172.17.0.4:54371 |     13 |          577.971 | 4206592 |  235.295 |              295.232 |              111.545 |            820.859 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_fb185_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3178.0
  date: 2020-10-08_16-43-53
  done: true
  episode_len_mean: 819.8307892777364
  episode_reward_max: 295.23232323232304
  episode_reward_mean: 235.8319042998864
  episode_reward_min: 111.5454545454545
  episodes_this_iter: 316
  episodes_total: 5372
  experiment_id: f1f9ce69a3b04ef89e1adc9b7438716d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 0.8823808252811431
        entropy_coeff: 0.0
        kl: 0.005259334831498564
        model: {}
        policy_loss: -0.016858076793141663
        total_loss: 2.605477035045624
        vf_explained_var: 0.9944881200790405
        vf_loss: 2.621283233165741
    num_steps_sampled: 4530176
    num_steps_trained: 4530176
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.221999999999998
    gpu_util_percent0: 0.3322
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.206
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54371
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.22717947331683772
    mean_env_wait_ms: 3.3152333429568563
    mean_inference_ms: 7.767442296259985
    mean_raw_obs_processing_ms: 0.7956294835718717
  time_since_restore: 622.0877892971039
  time_this_iter_s: 44.116589307785034
  time_total_s: 622.0877892971039
  timers:
    learn_throughput: 10712.825
    learn_time_ms: 30205.292
    sample_throughput: 23475.805
    sample_time_ms: 13783.723
    update_time_ms: 31.123
  timestamp: 1602175433
  timesteps_since_restore: 0
  timesteps_total: 4530176
  training_iteration: 14
  trial_id: fb185_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_fb185_00000 | TERMINATED |       |     14 |          622.088 | 4530176 |  235.832 |              295.232 |              111.545 |            819.831 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 76.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_fb185_00000 | TERMINATED |       |     14 |          622.088 | 4530176 |  235.832 |              295.232 |              111.545 |            819.831 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


