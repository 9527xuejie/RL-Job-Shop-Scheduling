2020-10-10 18:53:13,024	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_d9fbb_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=12307)[0m 2020-10-10 18:53:15,978	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=12311)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12311)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12290)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12290)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12313)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12313)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12314)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12314)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12258)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12258)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12253)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12253)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12187)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12187)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12265)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12265)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12283)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12283)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12268)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12268)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12289)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12289)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12198)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12198)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12274)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12274)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12247)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12247)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12285)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12285)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12300)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12300)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12292)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12292)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12288)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12288)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12269)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12269)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12261)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12261)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12215)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12215)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12271)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12271)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12190)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12190)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12276)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12276)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12221)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12221)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12298)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12298)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12266)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12266)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12316)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12316)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12267)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12267)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12197)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12197)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12211)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12211)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12195)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12195)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12306)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12306)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12202)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12202)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12201)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12201)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12213)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12213)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12217)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12217)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12302)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12302)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12184)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12184)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12188)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12188)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12196)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12196)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12254)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12254)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12260)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12260)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12281)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12281)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12320)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12320)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12223)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12223)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12248)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12248)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12249)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12249)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12185)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12185)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12204)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12204)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12186)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12186)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12193)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12193)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12287)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12287)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12191)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12191)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12200)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12200)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12255)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12255)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12199)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12199)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12208)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12208)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12275)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12275)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12225)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12225)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12222)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12222)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12220)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12220)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12207)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12207)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12257)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12257)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12263)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12263)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12264)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12264)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12250)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12250)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12278)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12278)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12251)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12251)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12183)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12183)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12256)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12256)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12273)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12273)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12192)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12192)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12301)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12301)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12252)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12252)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12259)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12259)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12270)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12270)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12262)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12262)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12309)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12309)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_d9fbb_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-10_18-54-02
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 0c88386d5b464bc4806d654f895630cb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1867478745324271
        entropy_coeff: 0.0
        kl: 0.002088837026219283
        model: {}
        policy_loss: -0.0028433590362380657
        total_loss: 628.5100184849331
        vf_explained_var: 0.16818061470985413
        vf_loss: 628.512451171875
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.512765957446803
    gpu_util_percent0: 0.37574468085106383
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0002127659574468085
    ram_util_percent: 6.299999999999997
    vram_util_percent0: 0.19347117645827366
    vram_util_percent1: 0.0009075233687267445
    vram_util_percent2: 0.0009075233687267445
  pid: 12307
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17583839096158843
    mean_env_wait_ms: 1.2156109929121584
    mean_inference_ms: 6.322906396388271
    mean_raw_obs_processing_ms: 0.481745130156764
  time_since_restore: 40.39164710044861
  time_this_iter_s: 40.39164710044861
  time_total_s: 40.39164710044861
  timers:
    learn_throughput: 5323.857
    learn_time_ms: 30390.0
    sample_throughput: 16287.387
    sample_time_ms: 9933.577
    update_time_ms: 25.438
  timestamp: 1602356042
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: d9fbb_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d9fbb_00000 | RUNNING  | 172.17.0.4:12307 |      1 |          40.3916 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d9fbb_00000:
  custom_metrics:
    time_step_max: 4501
    time_step_mean: 3610.5763888888887
    time_step_min: 3348
  date: 2020-10-10_18-54-39
  done: false
  episode_len_mean: 888.8955696202531
  episode_reward_max: 264.95959595959573
  episode_reward_mean: 218.61657716404525
  episode_reward_min: 84.05050505050527
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 0c88386d5b464bc4806d654f895630cb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1631659354482378
        entropy_coeff: 0.0
        kl: 0.0030377229309773873
        model: {}
        policy_loss: -0.003828160577021273
        total_loss: 282.87828063964844
        vf_explained_var: 0.5747933983802795
        vf_loss: 282.8818032400949
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.34444444444444
    gpu_util_percent0: 0.3166666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.473333333333334
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 12307
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17031982446273572
    mean_env_wait_ms: 1.2065526214554982
    mean_inference_ms: 5.936909237041749
    mean_raw_obs_processing_ms: 0.4650232052401194
  time_since_restore: 78.27953672409058
  time_this_iter_s: 37.88788962364197
  time_total_s: 78.27953672409058
  timers:
    learn_throughput: 5347.497
    learn_time_ms: 30255.649
    sample_throughput: 18367.79
    sample_time_ms: 8808.463
    update_time_ms: 30.231
  timestamp: 1602356079
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: d9fbb_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d9fbb_00000 | RUNNING  | 172.17.0.4:12307 |      2 |          78.2795 | 323584 |  218.617 |               264.96 |              84.0505 |            888.896 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d9fbb_00000:
  custom_metrics:
    time_step_max: 4501
    time_step_mean: 3604.0941704035877
    time_step_min: 3307
  date: 2020-10-10_18-55-17
  done: false
  episode_len_mean: 883.9303797468355
  episode_reward_max: 266.1717171717169
  episode_reward_mean: 219.99188083365274
  episode_reward_min: 84.05050505050527
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 0c88386d5b464bc4806d654f895630cb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 1.1602336253438676
        entropy_coeff: 0.0
        kl: 0.004007017306451287
        model: {}
        policy_loss: -0.0030694745853127514
        total_loss: 115.12564250401088
        vf_explained_var: 0.7951586842536926
        vf_loss: 115.12851006644112
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.172727272727272
    gpu_util_percent0: 0.3325
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488636363636363
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 12307
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16679958815130463
    mean_env_wait_ms: 1.202452231460606
    mean_inference_ms: 5.681140382685036
    mean_raw_obs_processing_ms: 0.454147069688832
  time_since_restore: 115.94032549858093
  time_this_iter_s: 37.660788774490356
  time_total_s: 115.94032549858093
  timers:
    learn_throughput: 5345.946
    learn_time_ms: 30264.431
    sample_throughput: 19490.431
    sample_time_ms: 8301.099
    update_time_ms: 34.55
  timestamp: 1602356117
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: d9fbb_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d9fbb_00000 | RUNNING  | 172.17.0.4:12307 |      3 |           115.94 | 485376 |  219.992 |              266.172 |              84.0505 |             883.93 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d9fbb_00000:
  custom_metrics:
    time_step_max: 4501
    time_step_mean: 3600.0761589403974
    time_step_min: 3307
  date: 2020-10-10_18-55-55
  done: false
  episode_len_mean: 879.5300632911392
  episode_reward_max: 266.1717171717169
  episode_reward_mean: 221.39539381153284
  episode_reward_min: 84.05050505050527
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 0c88386d5b464bc4806d654f895630cb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 1.0e-05
        entropy: 1.1451412098748344
        entropy_coeff: 0.0
        kl: 0.004999774674485836
        model: {}
        policy_loss: -0.005014794288269643
        total_loss: 74.19565309797015
        vf_explained_var: 0.8565484285354614
        vf_loss: 74.20054408482143
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.075555555555557
    gpu_util_percent0: 0.3984444444444445
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4911111111111115
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 12307
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16438632675764264
    mean_env_wait_ms: 1.2004180256201826
    mean_inference_ms: 5.504459488403988
    mean_raw_obs_processing_ms: 0.44595789940117403
  time_since_restore: 153.79929566383362
  time_this_iter_s: 37.858970165252686
  time_total_s: 153.79929566383362
  timers:
    learn_throughput: 5346.591
    learn_time_ms: 30260.78
    sample_throughput: 19958.686
    sample_time_ms: 8106.345
    update_time_ms: 34.424
  timestamp: 1602356155
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: d9fbb_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d9fbb_00000 | RUNNING  | 172.17.0.4:12307 |      4 |          153.799 | 647168 |  221.395 |              266.172 |              84.0505 |             879.53 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d9fbb_00000:
  custom_metrics:
    time_step_max: 4501
    time_step_mean: 3587.299212598425
    time_step_min: 3275
  date: 2020-10-10_18-56-33
  done: false
  episode_len_mean: 875.6025316455696
  episode_reward_max: 269.8080808080807
  episode_reward_mean: 222.97704897071964
  episode_reward_min: 84.05050505050527
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 0c88386d5b464bc4806d654f895630cb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.012500000000000002
        cur_lr: 1.0e-05
        entropy: 1.1201871378081185
        entropy_coeff: 0.0
        kl: 0.004287239929128971
        model: {}
        policy_loss: -0.0036323301277921666
        total_loss: 66.34971618652344
        vf_explained_var: 0.8795056939125061
        vf_loss: 66.35329273768834
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.245454545454546
    gpu_util_percent0: 0.32295454545454544
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488636363636363
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 12307
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16261833713921603
    mean_env_wait_ms: 1.200091743854984
    mean_inference_ms: 5.374835591283279
    mean_raw_obs_processing_ms: 0.4397010129354274
  time_since_restore: 191.38921785354614
  time_this_iter_s: 37.589922189712524
  time_total_s: 191.38921785354614
  timers:
    learn_throughput: 5349.807
    learn_time_ms: 30242.584
    sample_throughput: 20343.306
    sample_time_ms: 7953.083
    update_time_ms: 33.829
  timestamp: 1602356193
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: d9fbb_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d9fbb_00000 | RUNNING  | 172.17.0.4:12307 |      5 |          191.389 | 808960 |  222.977 |              269.808 |              84.0505 |            875.603 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d9fbb_00000:
  custom_metrics:
    time_step_max: 4501
    time_step_mean: 3571.158774373259
    time_step_min: 3275
  date: 2020-10-10_18-57-11
  done: false
  episode_len_mean: 865.7393665158371
  episode_reward_max: 274.20202020202026
  episode_reward_mean: 225.10274692627615
  episode_reward_min: 84.05050505050527
  episodes_this_iter: 315
  episodes_total: 1105
  experiment_id: 0c88386d5b464bc4806d654f895630cb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.006250000000000001
        cur_lr: 1.0e-05
        entropy: 1.120083817413875
        entropy_coeff: 0.0
        kl: 0.004376330545970372
        model: {}
        policy_loss: -0.004211367511223736
        total_loss: 67.7007064819336
        vf_explained_var: 0.9151621460914612
        vf_loss: 67.70489065987724
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.93555555555556
    gpu_util_percent0: 0.3946666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486666666666666
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 12307
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1602700634613413
    mean_env_wait_ms: 1.202114449544908
    mean_inference_ms: 5.203791332571774
    mean_raw_obs_processing_ms: 0.43178344446795786
  time_since_restore: 229.16881132125854
  time_this_iter_s: 37.7795934677124
  time_total_s: 229.16881132125854
  timers:
    learn_throughput: 5351.799
    learn_time_ms: 30231.327
    sample_throughput: 20533.928
    sample_time_ms: 7879.252
    update_time_ms: 34.407
  timestamp: 1602356231
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: d9fbb_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d9fbb_00000 | RUNNING  | 172.17.0.4:12307 |      6 |          229.169 | 970752 |  225.103 |              274.202 |              84.0505 |            865.739 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d9fbb_00000:
  custom_metrics:
    time_step_max: 4501
    time_step_mean: 3564.1593851132684
    time_step_min: 3196
  date: 2020-10-10_18-57-48
  done: false
  episode_len_mean: 861.4897151898734
  episode_reward_max: 281.77777777777845
  episode_reward_mean: 226.03842219664986
  episode_reward_min: 84.05050505050527
  episodes_this_iter: 159
  episodes_total: 1264
  experiment_id: 0c88386d5b464bc4806d654f895630cb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0031250000000000006
        cur_lr: 1.0e-05
        entropy: 1.1167838062558855
        entropy_coeff: 0.0
        kl: 0.004021314937355263
        model: {}
        policy_loss: -0.004371225185293172
        total_loss: 49.39475795200893
        vf_explained_var: 0.9087238907814026
        vf_loss: 49.39911624363491
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.26818181818182
    gpu_util_percent0: 0.3570454545454545
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.495454545454546
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 12307
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15943019102731956
    mean_env_wait_ms: 1.2031317620328037
    mean_inference_ms: 5.142073500696209
    mean_raw_obs_processing_ms: 0.4289098137346787
  time_since_restore: 266.6756663322449
  time_this_iter_s: 37.50685501098633
  time_total_s: 266.6756663322449
  timers:
    learn_throughput: 5356.023
    learn_time_ms: 30207.489
    sample_throughput: 20726.589
    sample_time_ms: 7806.012
    update_time_ms: 33.241
  timestamp: 1602356268
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: d9fbb_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d9fbb_00000 | RUNNING  | 172.17.0.4:12307 |      7 |          266.676 | 1132544 |  226.038 |              281.778 |              84.0505 |             861.49 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d9fbb_00000:
  custom_metrics:
    time_step_max: 4501
    time_step_mean: 3555.2274031563843
    time_step_min: 3196
  date: 2020-10-10_18-58-26
  done: false
  episode_len_mean: 857.3790436005626
  episode_reward_max: 281.77777777777845
  episode_reward_mean: 227.48367642671423
  episode_reward_min: 84.05050505050527
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 0c88386d5b464bc4806d654f895630cb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0015625000000000003
        cur_lr: 1.0e-05
        entropy: 1.1066821558134896
        entropy_coeff: 0.0
        kl: 0.0037788708661017673
        model: {}
        policy_loss: -0.004733241321186402
        total_loss: 36.4413092476981
        vf_explained_var: 0.9263450503349304
        vf_loss: 36.446037020002095
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.868888888888886
    gpu_util_percent0: 0.35266666666666663
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4911111111111115
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 12307
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15870413848608475
    mean_env_wait_ms: 1.2040464318500002
    mean_inference_ms: 5.089451439296763
    mean_raw_obs_processing_ms: 0.4264149338841317
  time_since_restore: 304.42692971229553
  time_this_iter_s: 37.75126338005066
  time_total_s: 304.42692971229553
  timers:
    learn_throughput: 5354.326
    learn_time_ms: 30217.061
    sample_throughput: 20867.18
    sample_time_ms: 7753.42
    update_time_ms: 33.199
  timestamp: 1602356306
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: d9fbb_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d9fbb_00000 | RUNNING  | 172.17.0.4:12307 |      8 |          304.427 | 1294336 |  227.484 |              281.778 |              84.0505 |            857.379 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d9fbb_00000:
  custom_metrics:
    time_step_max: 4501
    time_step_mean: 3549.138530927835
    time_step_min: 3196
  date: 2020-10-10_18-59-04
  done: false
  episode_len_mean: 853.3658227848101
  episode_reward_max: 281.77777777777845
  episode_reward_mean: 228.72781613604383
  episode_reward_min: 84.05050505050527
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 0c88386d5b464bc4806d654f895630cb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0007812500000000002
        cur_lr: 1.0e-05
        entropy: 1.0781752041407995
        entropy_coeff: 0.0
        kl: 0.004215758160821029
        model: {}
        policy_loss: -0.003286214449742277
        total_loss: 37.70637321472168
        vf_explained_var: 0.9253243803977966
        vf_loss: 37.70965712411063
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.993333333333332
    gpu_util_percent0: 0.33355555555555555
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486666666666666
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 12307
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15808455087181847
    mean_env_wait_ms: 1.205132151261226
    mean_inference_ms: 5.043705236528577
    mean_raw_obs_processing_ms: 0.4241869983353532
  time_since_restore: 342.4581425189972
  time_this_iter_s: 38.03121280670166
  time_total_s: 342.4581425189972
  timers:
    learn_throughput: 5351.461
    learn_time_ms: 30233.237
    sample_throughput: 20925.194
    sample_time_ms: 7731.924
    update_time_ms: 34.23
  timestamp: 1602356344
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: d9fbb_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d9fbb_00000 | RUNNING  | 172.17.0.4:12307 |      9 |          342.458 | 1456128 |  228.728 |              281.778 |              84.0505 |            853.366 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d9fbb_00000:
  custom_metrics:
    time_step_max: 4501
    time_step_mean: 3533.440450643777
    time_step_min: 3196
  date: 2020-10-10_18-59-42
  done: false
  episode_len_mean: 846.0576109936575
  episode_reward_max: 281.77777777777845
  episode_reward_mean: 230.89751639011666
  episode_reward_min: 84.05050505050527
  episodes_this_iter: 312
  episodes_total: 1892
  experiment_id: 0c88386d5b464bc4806d654f895630cb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0003906250000000001
        cur_lr: 1.0e-05
        entropy: 1.067080625465938
        entropy_coeff: 0.0
        kl: 0.0040475288738629645
        model: {}
        policy_loss: -0.0054684489233685395
        total_loss: 38.54603467668806
        vf_explained_var: 0.9505006074905396
        vf_loss: 38.5515022277832
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.049999999999997
    gpu_util_percent0: 0.3938636363636363
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4818181818181815
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 12307
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15708489579785864
    mean_env_wait_ms: 1.2077670181507008
    mean_inference_ms: 4.970544534243251
    mean_raw_obs_processing_ms: 0.4207088217915109
  time_since_restore: 380.51433062553406
  time_this_iter_s: 38.056188106536865
  time_total_s: 380.51433062553406
  timers:
    learn_throughput: 5349.226
    learn_time_ms: 30245.87
    sample_throughput: 20956.991
    sample_time_ms: 7720.192
    update_time_ms: 33.18
  timestamp: 1602356382
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: d9fbb_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d9fbb_00000 | RUNNING  | 172.17.0.4:12307 |     10 |          380.514 | 1617920 |  230.898 |              281.778 |              84.0505 |            846.058 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d9fbb_00000:
  custom_metrics:
    time_step_max: 4501
    time_step_mean: 3526.7408687068114
    time_step_min: 3196
  date: 2020-10-10_19-00-20
  done: false
  episode_len_mean: 842.6475170399221
  episode_reward_max: 287.3838383838381
  episode_reward_mean: 231.94264455656847
  episode_reward_min: 84.05050505050527
  episodes_this_iter: 162
  episodes_total: 2054
  experiment_id: 0c88386d5b464bc4806d654f895630cb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.00019531250000000004
        cur_lr: 1.0e-05
        entropy: 1.0605422002928597
        entropy_coeff: 0.0
        kl: 0.004064861518730011
        model: {}
        policy_loss: -0.0030560524152990964
        total_loss: 21.62539836338588
        vf_explained_var: 0.9583903551101685
        vf_loss: 21.628453527178085
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.813636363636366
    gpu_util_percent0: 0.4597727272727272
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.495454545454546
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 12307
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1566533379020555
    mean_env_wait_ms: 1.2090426203627074
    mean_inference_ms: 4.939324914946806
    mean_raw_obs_processing_ms: 0.41920761945421714
  time_since_restore: 418.0023980140686
  time_this_iter_s: 37.488067388534546
  time_total_s: 418.0023980140686
  timers:
    learn_throughput: 5352.124
    learn_time_ms: 30229.492
    sample_throughput: 21729.912
    sample_time_ms: 7445.589
    update_time_ms: 32.549
  timestamp: 1602356420
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: d9fbb_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d9fbb_00000 | RUNNING  | 172.17.0.4:12307 |     11 |          418.002 | 1779712 |  231.943 |              287.384 |              84.0505 |            842.648 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d9fbb_00000:
  custom_metrics:
    time_step_max: 4501
    time_step_mean: 3520.2582417582416
    time_step_min: 3196
  date: 2020-10-10_19-00-58
  done: false
  episode_len_mean: 839.6062386980109
  episode_reward_max: 287.3838383838381
  episode_reward_mean: 233.14983926059855
  episode_reward_min: 84.05050505050527
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 0c88386d5b464bc4806d654f895630cb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 9.765625000000002e-05
        cur_lr: 1.0e-05
        entropy: 1.0490674035889762
        entropy_coeff: 0.0
        kl: 0.0038801136293581556
        model: {}
        policy_loss: -0.0026383442735615453
        total_loss: 20.71143627166748
        vf_explained_var: 0.9559246301651001
        vf_loss: 20.714073862348283
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.415909090909093
    gpu_util_percent0: 0.4352272727272728
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497727272727274
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 12307
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15627835010601085
    mean_env_wait_ms: 1.2102304605593626
    mean_inference_ms: 4.911769605340959
    mean_raw_obs_processing_ms: 0.41785788391320167
  time_since_restore: 455.68510007858276
  time_this_iter_s: 37.68270206451416
  time_total_s: 455.68510007858276
  timers:
    learn_throughput: 5349.829
    learn_time_ms: 30242.461
    sample_throughput: 21826.574
    sample_time_ms: 7412.615
    update_time_ms: 31.074
  timestamp: 1602356458
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: d9fbb_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d9fbb_00000 | RUNNING  | 172.17.0.4:12307 |     12 |          455.685 | 1941504 |   233.15 |              287.384 |              84.0505 |            839.606 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d9fbb_00000:
  custom_metrics:
    time_step_max: 4501
    time_step_mean: 3512.36149642707
    time_step_min: 3196
  date: 2020-10-10_19-01-35
  done: false
  episode_len_mean: 835.970502700457
  episode_reward_max: 287.3838383838381
  episode_reward_mean: 234.48698451066528
  episode_reward_min: 84.05050505050527
  episodes_this_iter: 195
  episodes_total: 2407
  experiment_id: 0c88386d5b464bc4806d654f895630cb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 4.882812500000001e-05
        cur_lr: 1.0e-05
        entropy: 1.0081694849899836
        entropy_coeff: 0.0
        kl: 0.0036496840184554458
        model: {}
        policy_loss: -0.004236857606364148
        total_loss: 23.73152651105608
        vf_explained_var: 0.9622970223426819
        vf_loss: 23.73576327732631
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.090697674418603
    gpu_util_percent0: 0.3223255813953489
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.493023255813955
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 12307
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15586548078996382
    mean_env_wait_ms: 1.2118405011313143
    mean_inference_ms: 4.8813451513581745
    mean_raw_obs_processing_ms: 0.41632426802529116
  time_since_restore: 492.9896295070648
  time_this_iter_s: 37.304529428482056
  time_total_s: 492.9896295070648
  timers:
    learn_throughput: 5352.635
    learn_time_ms: 30226.607
    sample_throughput: 21880.564
    sample_time_ms: 7394.325
    update_time_ms: 28.765
  timestamp: 1602356495
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: d9fbb_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d9fbb_00000 | RUNNING  | 172.17.0.4:12307 |     13 |           492.99 | 2103296 |  234.487 |              287.384 |              84.0505 |            835.971 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d9fbb_00000:
  custom_metrics:
    time_step_max: 4501
    time_step_mean: 3500.2565838976675
    time_step_min: 3161
  date: 2020-10-10_19-02-13
  done: false
  episode_len_mean: 831.1909903201787
  episode_reward_max: 287.3838383838381
  episode_reward_mean: 236.0676985792398
  episode_reward_min: 84.05050505050527
  episodes_this_iter: 279
  episodes_total: 2686
  experiment_id: 0c88386d5b464bc4806d654f895630cb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 2.4414062500000005e-05
        cur_lr: 1.0e-05
        entropy: 1.0077664170946394
        entropy_coeff: 0.0
        kl: 0.003775838779152504
        model: {}
        policy_loss: -0.0032385437433341785
        total_loss: 20.641237667628697
        vf_explained_var: 0.9665399193763733
        vf_loss: 20.644476073128835
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.68409090909091
    gpu_util_percent0: 0.38795454545454544
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.493181818181819
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 12307
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1553603325586059
    mean_env_wait_ms: 1.2138944058056416
    mean_inference_ms: 4.843671187446704
    mean_raw_obs_processing_ms: 0.4144581201986491
  time_since_restore: 530.5002748966217
  time_this_iter_s: 37.510645389556885
  time_total_s: 530.5002748966217
  timers:
    learn_throughput: 5353.147
    learn_time_ms: 30223.715
    sample_throughput: 21973.629
    sample_time_ms: 7363.008
    update_time_ms: 27.092
  timestamp: 1602356533
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: d9fbb_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d9fbb_00000 | RUNNING  | 172.17.0.4:12307 |     14 |            530.5 | 2265088 |  236.068 |              287.384 |              84.0505 |            831.191 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d9fbb_00000:
  custom_metrics:
    time_step_max: 4501
    time_step_mean: 3493.6615767045455
    time_step_min: 3161
  date: 2020-10-10_19-02-50
  done: false
  episode_len_mean: 828.7398030942335
  episode_reward_max: 290.41414141414145
  episode_reward_mean: 236.98006435664652
  episode_reward_min: 84.05050505050527
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 0c88386d5b464bc4806d654f895630cb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 1.2207031250000002e-05
        cur_lr: 1.0e-05
        entropy: 1.0078568969454085
        entropy_coeff: 0.0
        kl: 0.0034394068643450737
        model: {}
        policy_loss: -0.003539323532355151
        total_loss: 17.13435854230608
        vf_explained_var: 0.9641901850700378
        vf_loss: 17.137897491455078
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.461363636363636
    gpu_util_percent0: 0.4127272727272727
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.493181818181818
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 12307
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15511048209122258
    mean_env_wait_ms: 1.2149713050933992
    mean_inference_ms: 4.824972948179684
    mean_raw_obs_processing_ms: 0.4135265632791706
  time_since_restore: 567.7013812065125
  time_this_iter_s: 37.20110630989075
  time_total_s: 567.7013812065125
  timers:
    learn_throughput: 5356.301
    learn_time_ms: 30205.92
    sample_throughput: 22037.395
    sample_time_ms: 7341.703
    update_time_ms: 25.956
  timestamp: 1602356570
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: d9fbb_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d9fbb_00000 | RUNNING  | 172.17.0.4:12307 |     15 |          567.701 | 2426880 |   236.98 |              290.414 |              84.0505 |             828.74 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d9fbb_00000:
  custom_metrics:
    time_step_max: 4501
    time_step_mean: 3487.9401680672268
    time_step_min: 3161
  date: 2020-10-10_19-03-28
  done: true
  episode_len_mean: 826.3603063603064
  episode_reward_max: 290.41414141414145
  episode_reward_mean: 237.85513476422557
  episode_reward_min: 84.05050505050527
  episodes_this_iter: 159
  episodes_total: 3003
  experiment_id: 0c88386d5b464bc4806d654f895630cb
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 6.103515625000001e-06
        cur_lr: 1.0e-05
        entropy: 0.9809747891766685
        entropy_coeff: 0.0
        kl: 0.0036900364461221863
        model: {}
        policy_loss: -0.005425376385184271
        total_loss: 16.737820080348424
        vf_explained_var: 0.9668890237808228
        vf_loss: 16.743244988577707
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.94318181818182
    gpu_util_percent0: 0.44431818181818183
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.502272727272728
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 12307
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15487639121614974
    mean_env_wait_ms: 1.2160451505872247
    mean_inference_ms: 4.8074948360749
    mean_raw_obs_processing_ms: 0.41262962183938723
  time_since_restore: 605.0584037303925
  time_this_iter_s: 37.357022523880005
  time_total_s: 605.0584037303925
  timers:
    learn_throughput: 5359.561
    learn_time_ms: 30187.545
    sample_throughput: 22111.292
    sample_time_ms: 7317.166
    update_time_ms: 26.051
  timestamp: 1602356608
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: d9fbb_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d9fbb_00000 | TERMINATED |       |     16 |          605.058 | 2588672 |  237.855 |              290.414 |              84.0505 |             826.36 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d9fbb_00000 | TERMINATED |       |     16 |          605.058 | 2588672 |  237.855 |              290.414 |              84.0505 |             826.36 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


