2020-10-12 01:27:37,705	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_1d9bd_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=55021)[0m 2020-10-12 01:27:40,455	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=55022)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55022)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54980)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54980)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54962)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54962)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55024)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55024)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54984)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54984)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54963)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54963)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55026)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55026)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54954)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54954)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55012)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55012)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55015)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55015)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55019)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55019)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55008)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55008)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55034)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55034)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54951)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54951)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54987)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54987)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55027)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55027)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54960)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54960)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54964)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54964)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54970)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54970)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54976)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54976)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54978)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54978)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54919)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54919)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54900)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54900)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54982)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54982)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54974)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54974)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54903)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54903)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54924)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54924)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54927)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54927)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54969)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54969)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55032)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55032)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54913)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54913)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54909)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54909)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54972)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54972)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54921)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54921)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54950)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54950)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54949)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54949)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55000)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55000)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54967)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54967)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55002)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55002)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54899)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54899)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54997)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54997)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54991)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54991)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54897)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54897)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54898)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54898)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54914)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54914)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54911)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54911)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55004)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55004)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54977)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54977)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54975)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54975)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55007)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55007)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54925)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54925)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54923)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54923)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54916)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54916)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54915)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54915)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54929)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54929)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54958)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54958)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54908)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54908)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54931)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54931)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54906)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54906)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54910)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54910)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54895)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54895)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54896)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54896)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55001)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55001)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54988)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54988)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54901)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54901)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54968)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54968)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54992)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54992)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54904)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54904)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54912)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54912)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54905)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54905)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55005)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55005)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55018)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55018)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54981)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54981)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54928)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54928)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54971)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54971)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54973)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54973)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55010)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55010)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55020)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55020)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54894)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54894)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_1d9bd_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_01-28-22
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: b4a49dfbd4174160b09786899fce316e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1736208200454712
        entropy_coeff: 0.0001
        kl: 0.0156350201771905
        model: {}
        policy_loss: -0.014613036779337563
        total_loss: 500.41115315755206
        vf_explained_var: 0.5819632411003113
        vf_loss: 500.42430623372394
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.766666666666666
    gpu_util_percent0: 0.3147619047619048
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5952380952380945
    vram_util_percent0: 0.09112277249371378
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55021
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1696721990007646
    mean_env_wait_ms: 1.167198515630276
    mean_inference_ms: 5.6464571863017206
    mean_raw_obs_processing_ms: 0.45455138232097764
  time_since_restore: 36.17819166183472
  time_this_iter_s: 36.17819166183472
  time_total_s: 36.17819166183472
  timers:
    learn_throughput: 5948.492
    learn_time_ms: 27198.825
    sample_throughput: 18153.793
    sample_time_ms: 8912.297
    update_time_ms: 26.105
  timestamp: 1602466102
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 1d9bd_00000
  
== Status ==
Memory usage on this node: 27.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1d9bd_00000 | RUNNING  | 172.17.0.4:55021 |      1 |          36.1782 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1d9bd_00000:
  custom_metrics:
    time_step_max: 4489
    time_step_mean: 3612.121527777778
    time_step_min: 3376
  date: 2020-10-12_01-28-56
  done: false
  episode_len_mean: 889.9018987341772
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.3491241529214
  episode_reward_min: 85.8686868686868
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: b4a49dfbd4174160b09786899fce316e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.135892818371455
        entropy_coeff: 0.0001
        kl: 0.01734822119275729
        model: {}
        policy_loss: -0.018694894543538492
        total_loss: 121.42188771565755
        vf_explained_var: 0.8192997574806213
        vf_loss: 121.43896357218425
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.18536585365854
    gpu_util_percent0: 0.3853658536585366
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765853658536586
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55021
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1653764962071472
    mean_env_wait_ms: 1.1639593137253677
    mean_inference_ms: 5.451824180267738
    mean_raw_obs_processing_ms: 0.44390944368328356
  time_since_restore: 71.03214645385742
  time_this_iter_s: 34.853954792022705
  time_total_s: 71.03214645385742
  timers:
    learn_throughput: 5956.428
    learn_time_ms: 27162.589
    sample_throughput: 19543.104
    sample_time_ms: 8278.726
    update_time_ms: 33.059
  timestamp: 1602466136
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 1d9bd_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1d9bd_00000 | RUNNING  | 172.17.0.4:55021 |      2 |          71.0321 | 323584 |  216.349 |              258.596 |              85.8687 |            889.902 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1d9bd_00000:
  custom_metrics:
    time_step_max: 4489
    time_step_mean: 3607.013452914798
    time_step_min: 3324
  date: 2020-10-12_01-29-31
  done: false
  episode_len_mean: 888.0147679324895
  episode_reward_max: 262.3838383838382
  episode_reward_mean: 217.3294975067125
  episode_reward_min: 85.8686868686868
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: b4a49dfbd4174160b09786899fce316e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.115936319033305
        entropy_coeff: 0.0001
        kl: 0.020006298708419006
        model: {}
        policy_loss: -0.021225152304396033
        total_loss: 48.727572758992515
        vf_explained_var: 0.916059672832489
        vf_loss: 48.74690914154053
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.690243902439022
    gpu_util_percent0: 0.3385365853658537
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7804878048780495
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55021
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16242609282080211
    mean_env_wait_ms: 1.1630825211614069
    mean_inference_ms: 5.289384366838449
    mean_raw_obs_processing_ms: 0.4356121022041768
  time_since_restore: 105.3439588546753
  time_this_iter_s: 34.31181240081787
  time_total_s: 105.3439588546753
  timers:
    learn_throughput: 5962.254
    learn_time_ms: 27136.045
    sample_throughput: 20468.57
    sample_time_ms: 7904.412
    update_time_ms: 28.761
  timestamp: 1602466171
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 1d9bd_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1d9bd_00000 | RUNNING  | 172.17.0.4:55021 |      3 |          105.344 | 485376 |  217.329 |              262.384 |              85.8687 |            888.015 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1d9bd_00000:
  custom_metrics:
    time_step_max: 4489
    time_step_mean: 3606.046357615894
    time_step_min: 3324
  date: 2020-10-12_01-30-05
  done: false
  episode_len_mean: 885.6139240506329
  episode_reward_max: 270.26262626262644
  episode_reward_mean: 217.59145249968017
  episode_reward_min: 85.8686868686868
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: b4a49dfbd4174160b09786899fce316e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 1.0877360304196675
        entropy_coeff: 0.0001
        kl: 0.01614658534526825
        model: {}
        policy_loss: -0.020327600960930187
        total_loss: 31.601375897725422
        vf_explained_var: 0.9466071128845215
        vf_loss: 31.6193904876709
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.0825
    gpu_util_percent0: 0.34325
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7825
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55021
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16037039986710597
    mean_env_wait_ms: 1.1631014966565454
    mean_inference_ms: 5.1677164473365655
    mean_raw_obs_processing_ms: 0.4292260666782263
  time_since_restore: 139.39996457099915
  time_this_iter_s: 34.05600571632385
  time_total_s: 139.39996457099915
  timers:
    learn_throughput: 5971.548
    learn_time_ms: 27093.81
    sample_throughput: 21059.486
    sample_time_ms: 7682.619
    update_time_ms: 27.082
  timestamp: 1602466205
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 1d9bd_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1d9bd_00000 | RUNNING  | 172.17.0.4:55021 |      4 |            139.4 | 647168 |  217.591 |              270.263 |              85.8687 |            885.614 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1d9bd_00000:
  custom_metrics:
    time_step_max: 4489
    time_step_mean: 3600.443569553806
    time_step_min: 3275
  date: 2020-10-12_01-30-39
  done: false
  episode_len_mean: 882.2405063291139
  episode_reward_max: 271.02020202020213
  episode_reward_mean: 219.07697225418727
  episode_reward_min: 85.8686868686868
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: b4a49dfbd4174160b09786899fce316e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 1.0441696643829346
        entropy_coeff: 0.0001
        kl: 0.016008691086123388
        model: {}
        policy_loss: -0.01843688377023985
        total_loss: 24.42422040303548
        vf_explained_var: 0.9580565094947815
        vf_loss: 24.440360228220623
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.744999999999997
    gpu_util_percent0: 0.3175
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7825
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55021
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15882586812719196
    mean_env_wait_ms: 1.1637596269964834
    mean_inference_ms: 5.073674997341339
    mean_raw_obs_processing_ms: 0.42401352812265497
  time_since_restore: 173.62785172462463
  time_this_iter_s: 34.22788715362549
  time_total_s: 173.62785172462463
  timers:
    learn_throughput: 5967.49
    learn_time_ms: 27112.238
    sample_throughput: 21456.515
    sample_time_ms: 7540.46
    update_time_ms: 25.86
  timestamp: 1602466239
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 1d9bd_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1d9bd_00000 | RUNNING  | 172.17.0.4:55021 |      5 |          173.628 | 808960 |  219.077 |               271.02 |              85.8687 |            882.241 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1d9bd_00000:
  custom_metrics:
    time_step_max: 4489
    time_step_mean: 3585.6116970278044
    time_step_min: 3275
  date: 2020-10-12_01-31-13
  done: false
  episode_len_mean: 871.6750700280112
  episode_reward_max: 280.8686868686867
  episode_reward_mean: 222.2043120278413
  episode_reward_min: 85.8686868686868
  episodes_this_iter: 281
  episodes_total: 1071
  experiment_id: b4a49dfbd4174160b09786899fce316e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 1.0165199240048726
        entropy_coeff: 0.0001
        kl: 0.015175150552143654
        model: {}
        policy_loss: -0.020343689946457744
        total_loss: 25.425098419189453
        vf_explained_var: 0.970008373260498
        vf_loss: 25.443267186482746
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.7825
    gpu_util_percent0: 0.366
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7775
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55021
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15684245403568967
    mean_env_wait_ms: 1.167296762878568
    mean_inference_ms: 4.955128400516288
    mean_raw_obs_processing_ms: 0.41755302504152964
  time_since_restore: 207.68000626564026
  time_this_iter_s: 34.052154541015625
  time_total_s: 207.68000626564026
  timers:
    learn_throughput: 5973.084
    learn_time_ms: 27086.844
    sample_throughput: 21708.013
    sample_time_ms: 7453.101
    update_time_ms: 25.661
  timestamp: 1602466273
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 1d9bd_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1d9bd_00000 | RUNNING  | 172.17.0.4:55021 |      6 |           207.68 | 970752 |  222.204 |              280.869 |              85.8687 |            871.675 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1d9bd_00000:
  custom_metrics:
    time_step_max: 4489
    time_step_mean: 3574.4093851132684
    time_step_min: 3262
  date: 2020-10-12_01-31-48
  done: false
  episode_len_mean: 865.4659810126582
  episode_reward_max: 280.8686868686867
  episode_reward_mean: 224.200941375783
  episode_reward_min: 85.8686868686868
  episodes_this_iter: 193
  episodes_total: 1264
  experiment_id: b4a49dfbd4174160b09786899fce316e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 1.007215529680252
        entropy_coeff: 0.0001
        kl: 0.01522530677417914
        model: {}
        policy_loss: -0.01961467434496929
        total_loss: 14.211057186126709
        vf_explained_var: 0.9750437140464783
        vf_loss: 14.228488763173422
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.95
    gpu_util_percent0: 0.3725
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55021
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15590207711112486
    mean_env_wait_ms: 1.1693605634117288
    mean_inference_ms: 4.897161690576572
    mean_raw_obs_processing_ms: 0.41445095081655353
  time_since_restore: 241.99379134178162
  time_this_iter_s: 34.31378507614136
  time_total_s: 241.99379134178162
  timers:
    learn_throughput: 5967.449
    learn_time_ms: 27112.424
    sample_throughput: 21909.215
    sample_time_ms: 7384.655
    update_time_ms: 25.388
  timestamp: 1602466308
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 1d9bd_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1d9bd_00000 | RUNNING  | 172.17.0.4:55021 |      7 |          241.994 | 1132544 |  224.201 |              280.869 |              85.8687 |            865.466 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1d9bd_00000:
  custom_metrics:
    time_step_max: 4489
    time_step_mean: 3564.1140602582495
    time_step_min: 3262
  date: 2020-10-12_01-32-22
  done: false
  episode_len_mean: 861.3790436005626
  episode_reward_max: 280.8686868686867
  episode_reward_mean: 226.13687507991295
  episode_reward_min: 85.8686868686868
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: b4a49dfbd4174160b09786899fce316e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.9797004610300064
        entropy_coeff: 0.0001
        kl: 0.015101720268527666
        model: {}
        policy_loss: -0.017913284595124424
        total_loss: 12.506019830703735
        vf_explained_var: 0.9763869643211365
        vf_loss: 12.52176562945048
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.273170731707314
    gpu_util_percent0: 0.366829268292683
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7780487804878056
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55021
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1552414804541321
    mean_env_wait_ms: 1.1708813596675083
    mean_inference_ms: 4.856612537070194
    mean_raw_obs_processing_ms: 0.4121939454785611
  time_since_restore: 276.4255657196045
  time_this_iter_s: 34.431774377822876
  time_total_s: 276.4255657196045
  timers:
    learn_throughput: 5965.356
    learn_time_ms: 27121.935
    sample_throughput: 22019.329
    sample_time_ms: 7347.726
    update_time_ms: 33.759
  timestamp: 1602466342
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 1d9bd_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1d9bd_00000 | RUNNING  | 172.17.0.4:55021 |      8 |          276.426 | 1294336 |  226.137 |              280.869 |              85.8687 |            861.379 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1d9bd_00000:
  custom_metrics:
    time_step_max: 4489
    time_step_mean: 3554.2414681262076
    time_step_min: 3262
  date: 2020-10-12_01-32-56
  done: false
  episode_len_mean: 857.8627450980392
  episode_reward_max: 280.8686868686867
  episode_reward_mean: 227.8633967761101
  episode_reward_min: 85.8686868686868
  episodes_this_iter: 159
  episodes_total: 1581
  experiment_id: b4a49dfbd4174160b09786899fce316e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.943953072031339
        entropy_coeff: 0.0001
        kl: 0.012753567658364773
        model: {}
        policy_loss: -0.019110337365418673
        total_loss: 13.325849930445353
        vf_explained_var: 0.9745603203773499
        vf_loss: 13.34314195315043
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.514999999999997
    gpu_util_percent0: 0.38
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7875
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55021
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1546648812346305
    mean_env_wait_ms: 1.1723076642530192
    mean_inference_ms: 4.820766685683321
    mean_raw_obs_processing_ms: 0.4101385483390485
  time_since_restore: 310.5327892303467
  time_this_iter_s: 34.10722351074219
  time_total_s: 310.5327892303467
  timers:
    learn_throughput: 5964.955
    learn_time_ms: 27123.759
    sample_throughput: 22171.358
    sample_time_ms: 7297.343
    update_time_ms: 32.4
  timestamp: 1602466376
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 1d9bd_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1d9bd_00000 | RUNNING  | 172.17.0.4:55021 |      9 |          310.533 | 1456128 |  227.863 |              280.869 |              85.8687 |            857.863 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1d9bd_00000:
  custom_metrics:
    time_step_max: 4489
    time_step_mean: 3535.940949227373
    time_step_min: 3188
  date: 2020-10-12_01-33-31
  done: false
  episode_len_mean: 852.2407608695652
  episode_reward_max: 291.32323232323233
  episode_reward_mean: 230.66405906895028
  episode_reward_min: 85.8686868686868
  episodes_this_iter: 259
  episodes_total: 1840
  experiment_id: b4a49dfbd4174160b09786899fce316e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.897337461511294
        entropy_coeff: 0.0001
        kl: 0.014614415199806293
        model: {}
        policy_loss: -0.019379634798193972
        total_loss: 14.784548362096151
        vf_explained_var: 0.9793860912322998
        vf_loss: 14.801826159159342
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.77
    gpu_util_percent0: 0.3195
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7775000000000007
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55021
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15386177245020902
    mean_env_wait_ms: 1.1746000424483953
    mean_inference_ms: 4.771369750358935
    mean_raw_obs_processing_ms: 0.40731921063037063
  time_since_restore: 344.8380653858185
  time_this_iter_s: 34.3052761554718
  time_total_s: 344.8380653858185
  timers:
    learn_throughput: 5963.862
    learn_time_ms: 27128.729
    sample_throughput: 22247.736
    sample_time_ms: 7272.291
    update_time_ms: 32.808
  timestamp: 1602466411
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 1d9bd_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1d9bd_00000 | RUNNING  | 172.17.0.4:55021 |     10 |          344.838 | 1617920 |  230.664 |              291.323 |              85.8687 |            852.241 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1d9bd_00000:
  custom_metrics:
    time_step_max: 4489
    time_step_mean: 3522.6722606120434
    time_step_min: 3188
  date: 2020-10-12_01-34-05
  done: false
  episode_len_mean: 847.1129503407984
  episode_reward_max: 291.32323232323233
  episode_reward_mean: 232.76218366724686
  episode_reward_min: 85.8686868686868
  episodes_this_iter: 214
  episodes_total: 2054
  experiment_id: b4a49dfbd4174160b09786899fce316e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.8914641439914703
        entropy_coeff: 0.0001
        kl: 0.01258210581727326
        model: {}
        policy_loss: -0.017406457831384614
        total_loss: 11.222355922063192
        vf_explained_var: 0.9795909523963928
        vf_loss: 11.237964073816935
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.2425
    gpu_util_percent0: 0.3465
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7775000000000007
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55021
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1533264341106217
    mean_env_wait_ms: 1.176477483715812
    mean_inference_ms: 4.738485581048138
    mean_raw_obs_processing_ms: 0.405422038081145
  time_since_restore: 378.7457506656647
  time_this_iter_s: 33.90768527984619
  time_total_s: 378.7457506656647
  timers:
    learn_throughput: 5966.159
    learn_time_ms: 27118.283
    sample_throughput: 22933.672
    sample_time_ms: 7054.78
    update_time_ms: 32.413
  timestamp: 1602466445
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 1d9bd_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1d9bd_00000 | RUNNING  | 172.17.0.4:55021 |     11 |          378.746 | 1779712 |  232.762 |              291.323 |              85.8687 |            847.113 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1d9bd_00000:
  custom_metrics:
    time_step_max: 4489
    time_step_mean: 3513.5668498168498
    time_step_min: 3174
  date: 2020-10-12_01-34-39
  done: false
  episode_len_mean: 843.8024412296564
  episode_reward_max: 291.32323232323233
  episode_reward_mean: 233.98796737720778
  episode_reward_min: 85.8686868686868
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: b4a49dfbd4174160b09786899fce316e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.8762886077165604
        entropy_coeff: 0.0001
        kl: 0.013215228371943036
        model: {}
        policy_loss: -0.017654948329436593
        total_loss: 10.567802985509237
        vf_explained_var: 0.9782084822654724
        vf_loss: 10.583563407262167
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.615384615384617
    gpu_util_percent0: 0.3835897435897436
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.784615384615386
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55021
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1529704388219338
    mean_env_wait_ms: 1.1777514954137727
    mean_inference_ms: 4.716641527270698
    mean_raw_obs_processing_ms: 0.40413254694706946
  time_since_restore: 412.80868458747864
  time_this_iter_s: 34.062933921813965
  time_total_s: 412.80868458747864
  timers:
    learn_throughput: 5966.023
    learn_time_ms: 27118.903
    sample_throughput: 23193.536
    sample_time_ms: 6975.737
    update_time_ms: 30.746
  timestamp: 1602466479
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 1d9bd_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1d9bd_00000 | RUNNING  | 172.17.0.4:55021 |     12 |          412.809 | 1941504 |  233.988 |              291.323 |              85.8687 |            843.802 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1d9bd_00000:
  custom_metrics:
    time_step_max: 4489
    time_step_mean: 3505.390731292517
    time_step_min: 3174
  date: 2020-10-12_01-35-13
  done: false
  episode_len_mean: 841.1647058823529
  episode_reward_max: 291.32323232323233
  episode_reward_mean: 235.20704948646113
  episode_reward_min: 85.8686868686868
  episodes_this_iter: 168
  episodes_total: 2380
  experiment_id: b4a49dfbd4174160b09786899fce316e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.8319534013668696
        entropy_coeff: 0.0001
        kl: 0.01303012118053933
        model: {}
        policy_loss: -0.01946251195234557
        total_loss: 11.030685186386108
        vf_explained_var: 0.980231761932373
        vf_loss: 11.04827650388082
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.435
    gpu_util_percent0: 0.37474999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.785
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55021
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1526259635989907
    mean_env_wait_ms: 1.1790634598800207
    mean_inference_ms: 4.695348283094881
    mean_raw_obs_processing_ms: 0.4028585177470695
  time_since_restore: 446.8995246887207
  time_this_iter_s: 34.090840101242065
  time_total_s: 446.8995246887207
  timers:
    learn_throughput: 5963.185
    learn_time_ms: 27131.808
    sample_throughput: 23312.322
    sample_time_ms: 6940.193
    update_time_ms: 30.74
  timestamp: 1602466513
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 1d9bd_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1d9bd_00000 | RUNNING  | 172.17.0.4:55021 |     13 |            446.9 | 2103296 |  235.207 |              291.323 |              85.8687 |            841.165 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1d9bd_00000:
  custom_metrics:
    time_step_max: 4489
    time_step_mean: 3492.669943289225
    time_step_min: 3174
  date: 2020-10-12_01-35-47
  done: false
  episode_len_mean: 836.6472128694351
  episode_reward_max: 291.32323232323233
  episode_reward_mean: 237.19672595766863
  episode_reward_min: 85.8686868686868
  episodes_this_iter: 293
  episodes_total: 2673
  experiment_id: b4a49dfbd4174160b09786899fce316e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.8084462781747183
        entropy_coeff: 0.0001
        kl: 0.01124430944522222
        model: {}
        policy_loss: -0.015038244465055564
        total_loss: 13.181054989496866
        vf_explained_var: 0.9818102717399597
        vf_loss: 13.19448701540629
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.39
    gpu_util_percent0: 0.33099999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55021
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15211353625452917
    mean_env_wait_ms: 1.1813518728099626
    mean_inference_ms: 4.66349810498669
    mean_raw_obs_processing_ms: 0.4010014747681621
  time_since_restore: 481.07728600502014
  time_this_iter_s: 34.17776131629944
  time_total_s: 481.07728600502014
  timers:
    learn_throughput: 5955.417
    learn_time_ms: 27167.2
    sample_throughput: 23396.203
    sample_time_ms: 6915.31
    update_time_ms: 30.49
  timestamp: 1602466547
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 1d9bd_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1d9bd_00000 | RUNNING  | 172.17.0.4:55021 |     14 |          481.077 | 2265088 |  237.197 |              291.323 |              85.8687 |            836.647 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1d9bd_00000:
  custom_metrics:
    time_step_max: 4489
    time_step_mean: 3485.6839488636365
    time_step_min: 3174
  date: 2020-10-12_01-36-22
  done: false
  episode_len_mean: 834.3357946554149
  episode_reward_max: 291.32323232323233
  episode_reward_mean: 238.34620466266028
  episode_reward_min: 85.8686868686868
  episodes_this_iter: 171
  episodes_total: 2844
  experiment_id: b4a49dfbd4174160b09786899fce316e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.8010631302992502
        entropy_coeff: 0.0001
        kl: 0.012518176808953285
        model: {}
        policy_loss: -0.018707693903706968
        total_loss: 8.942731618881226
        vf_explained_var: 0.9823443293571472
        vf_loss: 8.959641695022583
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.075
    gpu_util_percent0: 0.383
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7900000000000005
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55021
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15185314597510427
    mean_env_wait_ms: 1.1825408359468663
    mean_inference_ms: 4.647046429367519
    mean_raw_obs_processing_ms: 0.4000254608540247
  time_since_restore: 515.1851415634155
  time_this_iter_s: 34.107855558395386
  time_total_s: 515.1851415634155
  timers:
    learn_throughput: 5953.253
    learn_time_ms: 27177.076
    sample_throughput: 23474.232
    sample_time_ms: 6892.323
    update_time_ms: 30.427
  timestamp: 1602466582
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 1d9bd_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1d9bd_00000 | RUNNING  | 172.17.0.4:55021 |     15 |          515.185 | 2426880 |  238.346 |              291.323 |              85.8687 |            834.336 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1d9bd_00000:
  custom_metrics:
    time_step_max: 4489
    time_step_mean: 3479.1876260928043
    time_step_min: 3174
  date: 2020-10-12_01-36-56
  done: false
  episode_len_mean: 832.4526982011992
  episode_reward_max: 291.32323232323233
  episode_reward_mean: 239.30043943768123
  episode_reward_min: 85.8686868686868
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: b4a49dfbd4174160b09786899fce316e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.7735292911529541
        entropy_coeff: 0.0001
        kl: 0.012144294877847036
        model: {}
        policy_loss: -0.016990692898010213
        total_loss: 8.895003398259481
        vf_explained_var: 0.9821467995643616
        vf_loss: 8.910249948501587
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.7875
    gpu_util_percent0: 0.39725
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.785000000000001
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55021
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15162668532169365
    mean_env_wait_ms: 1.1835583164620869
    mean_inference_ms: 4.633093081868211
    mean_raw_obs_processing_ms: 0.3991876227452474
  time_since_restore: 549.8299560546875
  time_this_iter_s: 34.64481449127197
  time_total_s: 549.8299560546875
  timers:
    learn_throughput: 5943.252
    learn_time_ms: 27222.808
    sample_throughput: 23431.917
    sample_time_ms: 6904.77
    update_time_ms: 30.582
  timestamp: 1602466616
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 1d9bd_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1d9bd_00000 | RUNNING  | 172.17.0.4:55021 |     16 |           549.83 | 2588672 |    239.3 |              291.323 |              85.8687 |            832.453 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1d9bd_00000:
  custom_metrics:
    time_step_max: 4489
    time_step_mean: 3470.03799439427
    time_step_min: 3094
  date: 2020-10-12_01-37-31
  done: false
  episode_len_mean: 829.8619944427293
  episode_reward_max: 297.2323232323231
  episode_reward_mean: 240.65986820972918
  episode_reward_min: 85.8686868686868
  episodes_this_iter: 237
  episodes_total: 3239
  experiment_id: b4a49dfbd4174160b09786899fce316e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.7196178485949835
        entropy_coeff: 0.0001
        kl: 0.011688839023311933
        model: {}
        policy_loss: -0.01667096884921193
        total_loss: 11.033457120259603
        vf_explained_var: 0.9830520153045654
        vf_loss: 11.048446814219156
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.387804878048783
    gpu_util_percent0: 0.4039024390243902
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7780487804878056
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55021
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15131174978178027
    mean_env_wait_ms: 1.185046456829057
    mean_inference_ms: 4.613751248845352
    mean_raw_obs_processing_ms: 0.3980273027545235
  time_since_restore: 584.0841252803802
  time_this_iter_s: 34.25416922569275
  time_total_s: 584.0841252803802
  timers:
    learn_throughput: 5940.804
    learn_time_ms: 27234.024
    sample_throughput: 23498.019
    sample_time_ms: 6885.346
    update_time_ms: 31.929
  timestamp: 1602466651
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 1d9bd_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1d9bd_00000 | RUNNING  | 172.17.0.4:55021 |     17 |          584.084 | 2750464 |   240.66 |              297.232 |              85.8687 |            829.862 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1d9bd_00000:
  custom_metrics:
    time_step_max: 4489
    time_step_mean: 3461.6219901363506
    time_step_min: 3094
  date: 2020-10-12_01-38-05
  done: true
  episode_len_mean: 827.5804316546762
  episode_reward_max: 297.2323232323231
  episode_reward_mean: 241.96164522927106
  episode_reward_min: 85.8686868686868
  episodes_this_iter: 236
  episodes_total: 3475
  experiment_id: b4a49dfbd4174160b09786899fce316e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.7148176282644272
        entropy_coeff: 0.0001
        kl: 0.011864593640590707
        model: {}
        policy_loss: -0.017638342804275453
        total_loss: 9.20005997021993
        vf_explained_var: 0.9841329455375671
        vf_loss: 9.21599038441976
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.705000000000002
    gpu_util_percent0: 0.327
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55021
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1510443739711432
    mean_env_wait_ms: 1.186397317841518
    mean_inference_ms: 4.597124483967758
    mean_raw_obs_processing_ms: 0.39704956449802714
  time_since_restore: 618.0433926582336
  time_this_iter_s: 33.959267377853394
  time_total_s: 618.0433926582336
  timers:
    learn_throughput: 5942.812
    learn_time_ms: 27224.82
    sample_throughput: 23635.031
    sample_time_ms: 6845.432
    update_time_ms: 33.292
  timestamp: 1602466685
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 1d9bd_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1d9bd_00000 | TERMINATED |       |     18 |          618.043 | 2912256 |  241.962 |              297.232 |              85.8687 |             827.58 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1d9bd_00000 | TERMINATED |       |     18 |          618.043 | 2912256 |  241.962 |              297.232 |              85.8687 |             827.58 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


