2020-10-12 14:39:33,595	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_bf489_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=40953)[0m 2020-10-12 14:39:36,378	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=40904)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40904)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40931)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40931)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40921)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40921)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40957)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40957)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40949)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40949)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40961)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40961)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40935)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40935)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40918)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40918)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40963)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40963)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40941)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40941)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40924)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40924)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40920)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40920)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40951)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40951)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40945)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40945)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40938)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40938)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40944)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40944)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40919)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40919)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40928)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40928)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40915)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40915)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40917)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40917)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40947)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40947)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40838)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40838)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40898)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40898)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40855)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40855)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40858)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40858)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40932)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40932)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40853)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40853)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40851)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40851)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40842)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40842)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40972)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40972)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40892)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40892)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40934)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40934)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40912)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40912)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40839)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40839)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40867)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40867)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40872)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40872)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40891)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40891)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40850)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40850)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40927)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40927)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40960)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40960)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40874)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40874)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40913)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40913)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40846)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40846)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40909)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40909)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40954)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40954)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40967)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40967)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40862)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40862)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40857)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40857)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40905)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40905)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40925)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40925)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40847)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40847)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40866)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40866)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40911)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40911)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40854)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40854)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40837)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40837)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40878)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40878)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40869)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40869)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40943)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40943)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40922)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40922)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40916)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40916)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40914)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40914)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40900)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40900)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40940)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40940)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40876)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40876)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40936)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40936)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40841)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40841)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40840)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40840)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40848)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40848)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40907)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40907)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40844)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40844)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40930)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40930)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40870)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40870)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40856)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40856)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40849)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40849)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40956)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40956)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40910)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40910)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40843)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40843)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40859)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40859)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40908)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40908)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_bf489_00000:
  custom_metrics:
    time_step_max: 3669
    time_step_mean: 3363.603448275862
    time_step_min: 3125
  date: 2020-10-12_14-40-10
  done: false
  episode_len_mean: 881.5316455696203
  episode_reward_max: 283.8080808080806
  episode_reward_mean: 244.05069684183616
  episode_reward_min: 164.4141414141411
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: c5b56dd326bb4e65ac344f34ee55c698
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1715679466724396
        entropy_coeff: 0.0005000000000000001
        kl: 0.003930501930881292
        model: {}
        policy_loss: -0.00778718293683293
        total_loss: 516.1756820678711
        vf_explained_var: 0.4896630346775055
        vf_loss: 516.1832809448242
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.235294117647058
    gpu_util_percent0: 0.28676470588235287
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5647058823529414
    vram_util_percent0: 0.08636872262844136
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40953
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16664141672339913
    mean_env_wait_ms: 1.128168503566081
    mean_inference_ms: 5.951269370017503
    mean_raw_obs_processing_ms: 0.4477471324829968
  time_since_restore: 28.65974712371826
  time_this_iter_s: 28.65974712371826
  time_total_s: 28.65974712371826
  timers:
    learn_throughput: 8541.371
    learn_time_ms: 18942.158
    sample_throughput: 16858.265
    sample_time_ms: 9597.191
    update_time_ms: 79.087
  timestamp: 1602513610
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: bf489_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bf489_00000 | RUNNING  | 172.17.0.4:40953 |      1 |          28.6597 | 161792 |  244.051 |              283.808 |              164.414 |            881.532 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bf489_00000:
  custom_metrics:
    time_step_max: 3869
    time_step_mean: 3377.0
    time_step_min: 3125
  date: 2020-10-12_14-40-37
  done: false
  episode_len_mean: 881.126582278481
  episode_reward_max: 283.8080808080806
  episode_reward_mean: 242.05942334739814
  episode_reward_min: 164.4141414141411
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: c5b56dd326bb4e65ac344f34ee55c698
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1408922374248505
        entropy_coeff: 0.0005000000000000001
        kl: 0.006987970671616495
        model: {}
        policy_loss: -0.009066562740675485
        total_loss: 136.38060887654623
        vf_explained_var: 0.7857485413551331
        vf_loss: 136.38954798380533
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.335483870967746
    gpu_util_percent0: 0.26387096774193547
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.748387096774193
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40953
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16316464785791918
    mean_env_wait_ms: 1.126964135328122
    mean_inference_ms: 5.695918943430108
    mean_raw_obs_processing_ms: 0.4388138687329729
  time_since_restore: 55.38010263442993
  time_this_iter_s: 26.72035551071167
  time_total_s: 55.38010263442993
  timers:
    learn_throughput: 8591.164
    learn_time_ms: 18832.373
    sample_throughput: 18483.927
    sample_time_ms: 8753.118
    update_time_ms: 59.988
  timestamp: 1602513637
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: bf489_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bf489_00000 | RUNNING  | 172.17.0.4:40953 |      2 |          55.3801 | 323584 |  242.059 |              283.808 |              164.414 |            881.127 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bf489_00000:
  custom_metrics:
    time_step_max: 3871
    time_step_mean: 3384.8194444444443
    time_step_min: 3104
  date: 2020-10-12_14-41-03
  done: false
  episode_len_mean: 875.0569620253165
  episode_reward_max: 284.86868686868706
  episode_reward_mean: 241.46439074287184
  episode_reward_min: 164.4141414141411
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: c5b56dd326bb4e65ac344f34ee55c698
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1264353493849437
        entropy_coeff: 0.0005000000000000001
        kl: 0.009802788573627671
        model: {}
        policy_loss: -0.012675396748818457
        total_loss: 60.41511758168539
        vf_explained_var: 0.8837491869926453
        vf_loss: 60.427374521891274
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.59666666666667
    gpu_util_percent0: 0.33233333333333337
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40953
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16083150790610726
    mean_env_wait_ms: 1.1281844120340474
    mean_inference_ms: 5.496997823688215
    mean_raw_obs_processing_ms: 0.43160565381093513
  time_since_restore: 81.45542168617249
  time_this_iter_s: 26.075319051742554
  time_total_s: 81.45542168617249
  timers:
    learn_throughput: 8604.292
    learn_time_ms: 18803.639
    sample_throughput: 19611.768
    sample_time_ms: 8249.741
    update_time_ms: 53.528
  timestamp: 1602513663
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: bf489_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bf489_00000 | RUNNING  | 172.17.0.4:40953 |      3 |          81.4554 | 485376 |  241.464 |              284.869 |              164.414 |            875.057 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bf489_00000:
  custom_metrics:
    time_step_max: 3927
    time_step_mean: 3387.8050847457625
    time_step_min: 3104
  date: 2020-10-12_14-41-29
  done: false
  episode_len_mean: 871.5268987341772
  episode_reward_max: 284.86868686868706
  episode_reward_mean: 241.93859480884805
  episode_reward_min: 160.17171717171726
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: c5b56dd326bb4e65ac344f34ee55c698
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1075291832288106
        entropy_coeff: 0.0005000000000000001
        kl: 0.00853245899391671
        model: {}
        policy_loss: -0.011526559355843347
        total_loss: 44.10186163584391
        vf_explained_var: 0.9141210913658142
        vf_loss: 44.1130895614624
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.39677419354839
    gpu_util_percent0: 0.2906451612903226
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770967741935483
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40953
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15908904258328807
    mean_env_wait_ms: 1.1296197262286234
    mean_inference_ms: 5.349804248521752
    mean_raw_obs_processing_ms: 0.4258690137691947
  time_since_restore: 107.45699334144592
  time_this_iter_s: 26.001571655273438
  time_total_s: 107.45699334144592
  timers:
    learn_throughput: 8599.087
    learn_time_ms: 18815.02
    sample_throughput: 20343.345
    sample_time_ms: 7953.068
    update_time_ms: 50.549
  timestamp: 1602513689
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: bf489_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bf489_00000 | RUNNING  | 172.17.0.4:40953 |      4 |          107.457 | 647168 |  241.939 |              284.869 |              160.172 |            871.527 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bf489_00000:
  custom_metrics:
    time_step_max: 3927
    time_step_mean: 3381.8594164456235
    time_step_min: 3104
  date: 2020-10-12_14-41-55
  done: false
  episode_len_mean: 866.8391959798995
  episode_reward_max: 284.86868686868706
  episode_reward_mean: 242.8055301761333
  episode_reward_min: 160.17171717171726
  episodes_this_iter: 164
  episodes_total: 796
  experiment_id: c5b56dd326bb4e65ac344f34ee55c698
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0599133570988972
        entropy_coeff: 0.0005000000000000001
        kl: 0.00805330699464927
        model: {}
        policy_loss: -0.009734194648141662
        total_loss: 32.486494382222496
        vf_explained_var: 0.9489476084709167
        vf_loss: 32.49595355987549
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.85666666666667
    gpu_util_percent0: 0.322
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7599999999999993
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40953
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15774888043708285
    mean_env_wait_ms: 1.1320697465153844
    mean_inference_ms: 5.233963245133509
    mean_raw_obs_processing_ms: 0.4210750263015557
  time_since_restore: 133.43829941749573
  time_this_iter_s: 25.981306076049805
  time_total_s: 133.43829941749573
  timers:
    learn_throughput: 8595.306
    learn_time_ms: 18823.298
    sample_throughput: 20821.151
    sample_time_ms: 7770.56
    update_time_ms: 47.038
  timestamp: 1602513715
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: bf489_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bf489_00000 | RUNNING  | 172.17.0.4:40953 |      5 |          133.438 | 808960 |  242.806 |              284.869 |              160.172 |            866.839 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bf489_00000:
  custom_metrics:
    time_step_max: 3927
    time_step_mean: 3367.4323308270677
    time_step_min: 3078
  date: 2020-10-12_14-42-21
  done: false
  episode_len_mean: 856.883363471971
  episode_reward_max: 288.8080808080812
  episode_reward_mean: 245.21240433265757
  episode_reward_min: 160.17171717171726
  episodes_this_iter: 310
  episodes_total: 1106
  experiment_id: c5b56dd326bb4e65ac344f34ee55c698
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.071306178967158
        entropy_coeff: 0.0005000000000000001
        kl: 0.008238797464097539
        model: {}
        policy_loss: -0.011969462172904363
        total_loss: 28.96843910217285
        vf_explained_var: 0.9578704833984375
        vf_loss: 28.980120023091633
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.646666666666665
    gpu_util_percent0: 0.4083333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7599999999999993
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40953
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15593886556055578
    mean_env_wait_ms: 1.1362283266103848
    mean_inference_ms: 5.083690548765182
    mean_raw_obs_processing_ms: 0.4149847820727615
  time_since_restore: 159.39461660385132
  time_this_iter_s: 25.95631718635559
  time_total_s: 159.39461660385132
  timers:
    learn_throughput: 8599.923
    learn_time_ms: 18813.191
    sample_throughput: 21123.743
    sample_time_ms: 7659.249
    update_time_ms: 46.322
  timestamp: 1602513741
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: bf489_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bf489_00000 | RUNNING  | 172.17.0.4:40953 |      6 |          159.395 | 970752 |  245.212 |              288.808 |              160.172 |            856.883 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bf489_00000:
  custom_metrics:
    time_step_max: 3927
    time_step_mean: 3362.1800327332244
    time_step_min: 3078
  date: 2020-10-12_14-42-47
  done: false
  episode_len_mean: 852.179588607595
  episode_reward_max: 293.65656565656565
  episode_reward_mean: 246.19576300984542
  episode_reward_min: 160.17171717171726
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: c5b56dd326bb4e65ac344f34ee55c698
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0482013523578644
        entropy_coeff: 0.0005000000000000001
        kl: 0.007311464326145749
        model: {}
        policy_loss: -0.011051583365770057
        total_loss: 19.482070922851562
        vf_explained_var: 0.9613587260246277
        vf_loss: 19.492915948232014
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.290000000000003
    gpu_util_percent0: 0.35066666666666657
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7866666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40953
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1552791724627304
    mean_env_wait_ms: 1.1379453853825476
    mean_inference_ms: 5.02807286409167
    mean_raw_obs_processing_ms: 0.4126178615781305
  time_since_restore: 185.17217564582825
  time_this_iter_s: 25.77755904197693
  time_total_s: 185.17217564582825
  timers:
    learn_throughput: 8601.047
    learn_time_ms: 18810.734
    sample_throughput: 21421.773
    sample_time_ms: 7552.689
    update_time_ms: 42.665
  timestamp: 1602513767
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: bf489_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bf489_00000 | RUNNING  | 172.17.0.4:40953 |      7 |          185.172 | 1132544 |  246.196 |              293.657 |              160.172 |             852.18 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bf489_00000:
  custom_metrics:
    time_step_max: 3927
    time_step_mean: 3353.78115942029
    time_step_min: 3064
  date: 2020-10-12_14-43-13
  done: false
  episode_len_mean: 847.381153305204
  episode_reward_max: 296.6868686868687
  episode_reward_mean: 247.39319353876326
  episode_reward_min: 160.17171717171726
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: c5b56dd326bb4e65ac344f34ee55c698
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0248040159543355
        entropy_coeff: 0.0005000000000000001
        kl: 0.007192811734663944
        model: {}
        policy_loss: -0.012482399101524303
        total_loss: 16.573991378148396
        vf_explained_var: 0.9641326069831848
        vf_loss: 16.586267232894897
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.099999999999998
    gpu_util_percent0: 0.4748387096774193
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7612903225806447
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40953
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15470957461924317
    mean_env_wait_ms: 1.1397137552611756
    mean_inference_ms: 4.979775802225855
    mean_raw_obs_processing_ms: 0.4104494721231356
  time_since_restore: 211.19404697418213
  time_this_iter_s: 26.021871328353882
  time_total_s: 211.19404697418213
  timers:
    learn_throughput: 8601.827
    learn_time_ms: 18809.028
    sample_throughput: 21601.064
    sample_time_ms: 7490.001
    update_time_ms: 42.629
  timestamp: 1602513793
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: bf489_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bf489_00000 | RUNNING  | 172.17.0.4:40953 |      8 |          211.194 | 1294336 |  247.393 |              296.687 |              160.172 |            847.381 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bf489_00000:
  custom_metrics:
    time_step_max: 3927
    time_step_mean: 3344.8988764044943
    time_step_min: 3064
  date: 2020-10-12_14-43-39
  done: false
  episode_len_mean: 840.897201946472
  episode_reward_max: 296.6868686868687
  episode_reward_mean: 248.74430435744316
  episode_reward_min: 160.17171717171726
  episodes_this_iter: 222
  episodes_total: 1644
  experiment_id: c5b56dd326bb4e65ac344f34ee55c698
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9738969107468923
        entropy_coeff: 0.0005000000000000001
        kl: 0.006379361497238278
        model: {}
        policy_loss: -0.012259047235905504
        total_loss: 22.226102352142334
        vf_explained_var: 0.9665055871009827
        vf_loss: 22.23821036020915
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.876666666666665
    gpu_util_percent0: 0.3576666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769999999999999
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40953
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15404538885268687
    mean_env_wait_ms: 1.1426165156146462
    mean_inference_ms: 4.922753499383801
    mean_raw_obs_processing_ms: 0.40786065018348705
  time_since_restore: 237.02224707603455
  time_this_iter_s: 25.828200101852417
  time_total_s: 237.02224707603455
  timers:
    learn_throughput: 8601.026
    learn_time_ms: 18810.78
    sample_throughput: 21786.265
    sample_time_ms: 7426.33
    update_time_ms: 41.93
  timestamp: 1602513819
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: bf489_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bf489_00000 | RUNNING  | 172.17.0.4:40953 |      9 |          237.022 | 1456128 |  248.744 |              296.687 |              160.172 |            840.897 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bf489_00000:
  custom_metrics:
    time_step_max: 3927
    time_step_mean: 3333.3327939590076
    time_step_min: 3036
  date: 2020-10-12_14-44-05
  done: false
  episode_len_mean: 834.3728902953586
  episode_reward_max: 296.6868686868687
  episode_reward_mean: 250.30573136427577
  episode_reward_min: 160.17171717171726
  episodes_this_iter: 252
  episodes_total: 1896
  experiment_id: c5b56dd326bb4e65ac344f34ee55c698
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.968529686331749
        entropy_coeff: 0.0005000000000000001
        kl: 0.006252618157304823
        model: {}
        policy_loss: -0.010011641182548678
        total_loss: 15.227359533309937
        vf_explained_var: 0.97138911485672
        vf_loss: 15.2372305393219
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.60666666666667
    gpu_util_percent0: 0.373
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.77
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40953
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15341123729149214
    mean_env_wait_ms: 1.1455774761150415
    mean_inference_ms: 4.869972609780811
    mean_raw_obs_processing_ms: 0.4054250554823376
  time_since_restore: 262.87982177734375
  time_this_iter_s: 25.857574701309204
  time_total_s: 262.87982177734375
  timers:
    learn_throughput: 8600.968
    learn_time_ms: 18810.906
    sample_throughput: 21924.396
    sample_time_ms: 7379.542
    update_time_ms: 41.362
  timestamp: 1602513845
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: bf489_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bf489_00000 | RUNNING  | 172.17.0.4:40953 |     10 |           262.88 | 1617920 |  250.306 |              296.687 |              160.172 |            834.373 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bf489_00000:
  custom_metrics:
    time_step_max: 3927
    time_step_mean: 3328.4209741550694
    time_step_min: 3036
  date: 2020-10-12_14-44-31
  done: false
  episode_len_mean: 830.8437195715677
  episode_reward_max: 296.6868686868687
  episode_reward_mean: 251.11142092787668
  episode_reward_min: 160.17171717171726
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: c5b56dd326bb4e65ac344f34ee55c698
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9550741414229075
        entropy_coeff: 0.0005000000000000001
        kl: 0.006006665799456338
        model: {}
        policy_loss: -0.012216550302885784
        total_loss: 14.387996912002563
        vf_explained_var: 0.9684069752693176
        vf_loss: 14.400090297063192
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.49666666666667
    gpu_util_percent0: 0.2826666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40953
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15307219251075102
    mean_env_wait_ms: 1.147268686870087
    mean_inference_ms: 4.841779883094084
    mean_raw_obs_processing_ms: 0.4041027642838796
  time_since_restore: 288.7878568172455
  time_this_iter_s: 25.908035039901733
  time_total_s: 288.7878568172455
  timers:
    learn_throughput: 8603.938
    learn_time_ms: 18804.414
    sample_throughput: 22738.597
    sample_time_ms: 7115.303
    update_time_ms: 35.878
  timestamp: 1602513871
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: bf489_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bf489_00000 | RUNNING  | 172.17.0.4:40953 |     11 |          288.788 | 1779712 |  251.111 |              296.687 |              160.172 |            830.844 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bf489_00000:
  custom_metrics:
    time_step_max: 3927
    time_step_mean: 3323.5875862068965
    time_step_min: 3036
  date: 2020-10-12_14-44-57
  done: false
  episode_len_mean: 827.5119530897609
  episode_reward_max: 296.6868686868687
  episode_reward_mean: 251.97233498722005
  episode_reward_min: 160.17171717171726
  episodes_this_iter: 163
  episodes_total: 2217
  experiment_id: c5b56dd326bb4e65ac344f34ee55c698
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9188966850439707
        entropy_coeff: 0.0005000000000000001
        kl: 0.00623135210480541
        model: {}
        policy_loss: -0.012058262596838176
        total_loss: 13.930777152379354
        vf_explained_var: 0.9721924662590027
        vf_loss: 13.942671616872152
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.700000000000003
    gpu_util_percent0: 0.36366666666666664
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.77
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40953
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1527665937032668
    mean_env_wait_ms: 1.1490609828824796
    mean_inference_ms: 4.815447559779265
    mean_raw_obs_processing_ms: 0.402839753428242
  time_since_restore: 314.65122389793396
  time_this_iter_s: 25.863367080688477
  time_total_s: 314.65122389793396
  timers:
    learn_throughput: 8597.322
    learn_time_ms: 18818.883
    sample_throughput: 23063.696
    sample_time_ms: 7015.007
    update_time_ms: 35.553
  timestamp: 1602513897
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: bf489_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bf489_00000 | RUNNING  | 172.17.0.4:40953 |     12 |          314.651 | 1941504 |  251.972 |              296.687 |              160.172 |            827.512 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bf489_00000:
  custom_metrics:
    time_step_max: 3927
    time_step_mean: 3314.2779565567175
    time_step_min: 3036
  date: 2020-10-12_14-45-22
  done: false
  episode_len_mean: 821.9600474683544
  episode_reward_max: 296.6868686868687
  episode_reward_mean: 253.37343370412998
  episode_reward_min: 160.17171717171726
  episodes_this_iter: 311
  episodes_total: 2528
  experiment_id: c5b56dd326bb4e65ac344f34ee55c698
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8911013106505076
        entropy_coeff: 0.0005000000000000001
        kl: 0.00614805705845356
        model: {}
        policy_loss: -0.01046816335777597
        total_loss: 14.937302589416504
        vf_explained_var: 0.9774847030639648
        vf_loss: 14.947601795196533
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.68
    gpu_util_percent0: 0.26466666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40953
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1522435223834264
    mean_env_wait_ms: 1.1523257788627044
    mean_inference_ms: 4.772562757607494
    mean_raw_obs_processing_ms: 0.40082845855292926
  time_since_restore: 340.39173579216003
  time_this_iter_s: 25.740511894226074
  time_total_s: 340.39173579216003
  timers:
    learn_throughput: 8602.314
    learn_time_ms: 18807.962
    sample_throughput: 23142.481
    sample_time_ms: 6991.126
    update_time_ms: 35.817
  timestamp: 1602513922
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: bf489_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bf489_00000 | RUNNING  | 172.17.0.4:40953 |     13 |          340.392 | 2103296 |  253.373 |              296.687 |              160.172 |             821.96 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bf489_00000:
  custom_metrics:
    time_step_max: 3927
    time_step_mean: 3309.3282904689863
    time_step_min: 3034
  date: 2020-10-12_14-45-48
  done: false
  episode_len_mean: 819.2516753536858
  episode_reward_max: 299.5656565656566
  episode_reward_mean: 254.2009709906211
  episode_reward_min: 160.17171717171726
  episodes_this_iter: 158
  episodes_total: 2686
  experiment_id: c5b56dd326bb4e65ac344f34ee55c698
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8883989155292511
        entropy_coeff: 0.0005000000000000001
        kl: 0.005655435457204779
        model: {}
        policy_loss: -0.011879076599143445
        total_loss: 9.973519086837769
        vf_explained_var: 0.9757456183433533
        vf_loss: 9.98527709643046
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.696666666666665
    gpu_util_percent0: 0.42100000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40953
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1520172009628042
    mean_env_wait_ms: 1.1538239165028061
    mean_inference_ms: 4.753733134464473
    mean_raw_obs_processing_ms: 0.3999361812270338
  time_since_restore: 366.28425335884094
  time_this_iter_s: 25.892517566680908
  time_total_s: 366.28425335884094
  timers:
    learn_throughput: 8610.507
    learn_time_ms: 18790.066
    sample_throughput: 23122.268
    sample_time_ms: 6997.237
    update_time_ms: 36.101
  timestamp: 1602513948
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: bf489_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bf489_00000 | RUNNING  | 172.17.0.4:40953 |     14 |          366.284 | 2265088 |  254.201 |              299.566 |              160.172 |            819.252 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bf489_00000:
  custom_metrics:
    time_step_max: 3927
    time_step_mean: 3304.058110516934
    time_step_min: 3034
  date: 2020-10-12_14-46-15
  done: false
  episode_len_mean: 816.7463997190025
  episode_reward_max: 299.5656565656566
  episode_reward_mean: 255.00758906238366
  episode_reward_min: 160.17171717171726
  episodes_this_iter: 161
  episodes_total: 2847
  experiment_id: c5b56dd326bb4e65ac344f34ee55c698
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8732159187396368
        entropy_coeff: 0.0005000000000000001
        kl: 0.006058271353443463
        model: {}
        policy_loss: -0.012418695783708245
        total_loss: 9.868411302566528
        vf_explained_var: 0.9765015244483948
        vf_loss: 9.88066061337789
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.87741935483871
    gpu_util_percent0: 0.4
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40953
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15180881116568526
    mean_env_wait_ms: 1.1553448737951901
    mean_inference_ms: 4.73596822263734
    mean_raw_obs_processing_ms: 0.3990704292599801
  time_since_restore: 392.36000990867615
  time_this_iter_s: 26.075756549835205
  time_total_s: 392.36000990867615
  timers:
    learn_throughput: 8616.89
    learn_time_ms: 18776.147
    sample_throughput: 23077.559
    sample_time_ms: 7010.793
    update_time_ms: 36.67
  timestamp: 1602513975
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: bf489_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bf489_00000 | RUNNING  | 172.17.0.4:40953 |     15 |           392.36 | 2426880 |  255.008 |              299.566 |              160.172 |            816.746 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bf489_00000:
  custom_metrics:
    time_step_max: 3927
    time_step_mean: 3294.7485567671583
    time_step_min: 3016
  date: 2020-10-12_14-46-41
  done: false
  episode_len_mean: 812.3917721518987
  episode_reward_max: 299.5656565656566
  episode_reward_mean: 256.1996228103824
  episode_reward_min: 160.17171717171726
  episodes_this_iter: 313
  episodes_total: 3160
  experiment_id: c5b56dd326bb4e65ac344f34ee55c698
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8344785422086716
        entropy_coeff: 0.0005000000000000001
        kl: 0.00587861891835928
        model: {}
        policy_loss: -0.010444189373326177
        total_loss: 13.899945179621378
        vf_explained_var: 0.9787079691886902
        vf_loss: 13.910218795140585
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.84137931034483
    gpu_util_percent0: 0.41689655172413786
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7655172413793094
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40953
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15143501523062883
    mean_env_wait_ms: 1.1582143616298461
    mean_inference_ms: 4.705405899514696
    mean_raw_obs_processing_ms: 0.3975963789553817
  time_since_restore: 418.07779574394226
  time_this_iter_s: 25.717785835266113
  time_total_s: 418.07779574394226
  timers:
    learn_throughput: 8619.75
    learn_time_ms: 18769.918
    sample_throughput: 23139.814
    sample_time_ms: 6991.932
    update_time_ms: 36.375
  timestamp: 1602514001
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: bf489_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bf489_00000 | RUNNING  | 172.17.0.4:40953 |     16 |          418.078 | 2588672 |    256.2 |              299.566 |              160.172 |            812.392 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bf489_00000:
  custom_metrics:
    time_step_max: 3927
    time_step_mean: 3290.7713675213677
    time_step_min: 3010
  date: 2020-10-12_14-47-06
  done: false
  episode_len_mean: 810.3351416515974
  episode_reward_max: 299.5656565656566
  episode_reward_mean: 256.7730377920252
  episode_reward_min: 160.17171717171726
  episodes_this_iter: 158
  episodes_total: 3318
  experiment_id: c5b56dd326bb4e65ac344f34ee55c698
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8384240468343099
        entropy_coeff: 0.0005000000000000001
        kl: 0.0053978989987323684
        model: {}
        policy_loss: -0.011896416496407861
        total_loss: 9.386300961176554
        vf_explained_var: 0.9776299595832825
        vf_loss: 9.398076931635538
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.71
    gpu_util_percent0: 0.3186666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7766666666666664
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40953
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15126959163817574
    mean_env_wait_ms: 1.159519759099853
    mean_inference_ms: 4.691670169755335
    mean_raw_obs_processing_ms: 0.3969278621604349
  time_since_restore: 443.6678807735443
  time_this_iter_s: 25.59008502960205
  time_total_s: 443.6678807735443
  timers:
    learn_throughput: 8625.615
    learn_time_ms: 18757.156
    sample_throughput: 23169.403
    sample_time_ms: 6983.002
    update_time_ms: 38.167
  timestamp: 1602514026
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: bf489_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bf489_00000 | RUNNING  | 172.17.0.4:40953 |     17 |          443.668 | 2750464 |  256.773 |              299.566 |              160.172 |            810.335 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bf489_00000:
  custom_metrics:
    time_step_max: 3927
    time_step_mean: 3287.6860634274076
    time_step_min: 2984
  date: 2020-10-12_14-47-32
  done: false
  episode_len_mean: 808.4596148318483
  episode_reward_max: 303.05050505050514
  episode_reward_mean: 257.21201088203105
  episode_reward_min: 160.17171717171726
  episodes_this_iter: 161
  episodes_total: 3479
  experiment_id: c5b56dd326bb4e65ac344f34ee55c698
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8263530830542246
        entropy_coeff: 0.0005000000000000001
        kl: 0.00601558949953566
        model: {}
        policy_loss: -0.013046822976320982
        total_loss: 10.768564303716024
        vf_explained_var: 0.9754762649536133
        vf_loss: 10.78142261505127
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.703333333333333
    gpu_util_percent0: 0.46199999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40953
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15111356166660822
    mean_env_wait_ms: 1.1608325785678522
    mean_inference_ms: 4.678497022161008
    mean_raw_obs_processing_ms: 0.3962746827159407
  time_since_restore: 469.33216285705566
  time_this_iter_s: 25.664282083511353
  time_total_s: 469.33216285705566
  timers:
    learn_throughput: 8630.383
    learn_time_ms: 18746.792
    sample_throughput: 23227.87
    sample_time_ms: 6965.426
    update_time_ms: 37.448
  timestamp: 1602514052
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: bf489_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bf489_00000 | RUNNING  | 172.17.0.4:40953 |     18 |          469.332 | 2912256 |  257.212 |              303.051 |              160.172 |             808.46 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bf489_00000:
  custom_metrics:
    time_step_max: 3927
    time_step_mean: 3281.0016
    time_step_min: 2954
  date: 2020-10-12_14-47-59
  done: false
  episode_len_mean: 805.3974156118144
  episode_reward_max: 307.59595959595924
  episode_reward_mean: 258.3012322593019
  episode_reward_min: 160.17171717171726
  episodes_this_iter: 313
  episodes_total: 3792
  experiment_id: c5b56dd326bb4e65ac344f34ee55c698
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7947459469238917
        entropy_coeff: 0.0005000000000000001
        kl: 0.005477127657892804
        model: {}
        policy_loss: -0.012167421659493508
        total_loss: 14.687130689620972
        vf_explained_var: 0.977111279964447
        vf_loss: 14.699147860209147
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.69354838709678
    gpu_util_percent0: 0.3816129032258065
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.761290322580645
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40953
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15082792456299374
    mean_env_wait_ms: 1.1632874263479156
    mean_inference_ms: 4.655434993106941
    mean_raw_obs_processing_ms: 0.3951434405574617
  time_since_restore: 495.549329996109
  time_this_iter_s: 26.217167139053345
  time_total_s: 495.549329996109
  timers:
    learn_throughput: 8623.747
    learn_time_ms: 18761.219
    sample_throughput: 23152.32
    sample_time_ms: 6988.155
    update_time_ms: 37.565
  timestamp: 1602514079
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: bf489_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bf489_00000 | RUNNING  | 172.17.0.4:40953 |     19 |          495.549 | 3074048 |  258.301 |              307.596 |              160.172 |            805.397 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bf489_00000:
  custom_metrics:
    time_step_max: 3927
    time_step_mean: 3277.4357727737975
    time_step_min: 2954
  date: 2020-10-12_14-48-25
  done: false
  episode_len_mean: 804.0949367088608
  episode_reward_max: 307.59595959595924
  episode_reward_mean: 258.89404168264934
  episode_reward_min: 160.17171717171726
  episodes_this_iter: 158
  episodes_total: 3950
  experiment_id: c5b56dd326bb4e65ac344f34ee55c698
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8061949710051218
        entropy_coeff: 0.0005000000000000001
        kl: 0.006130845169536769
        model: {}
        policy_loss: -0.010873976105358452
        total_loss: 8.992526610692343
        vf_explained_var: 0.9773077964782715
        vf_loss: 9.003190676371256
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.463333333333335
    gpu_util_percent0: 0.25433333333333336
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40953
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15069864175168593
    mean_env_wait_ms: 1.1644066548233711
    mean_inference_ms: 4.64489546333125
    mean_raw_obs_processing_ms: 0.3946273208239206
  time_since_restore: 521.4407720565796
  time_this_iter_s: 25.89144206047058
  time_total_s: 521.4407720565796
  timers:
    learn_throughput: 8619.871
    learn_time_ms: 18769.655
    sample_throughput: 23173.905
    sample_time_ms: 6981.646
    update_time_ms: 37.955
  timestamp: 1602514105
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: bf489_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bf489_00000 | RUNNING  | 172.17.0.4:40953 |     20 |          521.441 | 3235840 |  258.894 |              307.596 |              160.172 |            804.095 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bf489_00000:
  custom_metrics:
    time_step_max: 3927
    time_step_mean: 3274.6622418879056
    time_step_min: 2954
  date: 2020-10-12_14-48-51
  done: false
  episode_len_mean: 803.0717761557178
  episode_reward_max: 307.59595959595924
  episode_reward_mean: 259.3341812283419
  episode_reward_min: 160.17171717171726
  episodes_this_iter: 160
  episodes_total: 4110
  experiment_id: c5b56dd326bb4e65ac344f34ee55c698
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.804583822687467
        entropy_coeff: 0.0005000000000000001
        kl: 0.006675932789221406
        model: {}
        policy_loss: -0.011738290796832493
        total_loss: 10.735313495000204
        vf_explained_var: 0.9747953414916992
        vf_loss: 10.746786197026571
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.322580645161295
    gpu_util_percent0: 0.44451612903225807
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7774193548387096
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40953
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1505761411640842
    mean_env_wait_ms: 1.1654985656650654
    mean_inference_ms: 4.634782773833999
    mean_raw_obs_processing_ms: 0.3941271841898013
  time_since_restore: 547.5300598144531
  time_this_iter_s: 26.089287757873535
  time_total_s: 547.5300598144531
  timers:
    learn_throughput: 8618.164
    learn_time_ms: 18773.373
    sample_throughput: 23140.218
    sample_time_ms: 6991.81
    update_time_ms: 41.372
  timestamp: 1602514131
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: bf489_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bf489_00000 | RUNNING  | 172.17.0.4:40953 |     21 |           547.53 | 3397632 |  259.334 |              307.596 |              160.172 |            803.072 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bf489_00000:
  custom_metrics:
    time_step_max: 3927
    time_step_mean: 3269.2985825331502
    time_step_min: 2954
  date: 2020-10-12_14-49-17
  done: false
  episode_len_mean: 801.3052536231884
  episode_reward_max: 307.59595959595924
  episode_reward_mean: 260.13030440272297
  episode_reward_min: 160.17171717171726
  episodes_this_iter: 306
  episodes_total: 4416
  experiment_id: c5b56dd326bb4e65ac344f34ee55c698
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7650169382492701
        entropy_coeff: 0.0005000000000000001
        kl: 0.0053621438176681595
        model: {}
        policy_loss: -0.01004139548361612
        total_loss: 15.226029952367147
        vf_explained_var: 0.9767293930053711
        vf_loss: 15.235918045043945
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.29666666666667
    gpu_util_percent0: 0.4299999999999999
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769999999999999
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40953
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15035481456364003
    mean_env_wait_ms: 1.167485533734289
    mean_inference_ms: 4.616999060036005
    mean_raw_obs_processing_ms: 0.3932513589437651
  time_since_restore: 573.3557074069977
  time_this_iter_s: 25.825647592544556
  time_total_s: 573.3557074069977
  timers:
    learn_throughput: 8619.354
    learn_time_ms: 18770.78
    sample_throughput: 23147.507
    sample_time_ms: 6989.608
    update_time_ms: 41.507
  timestamp: 1602514157
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: bf489_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bf489_00000 | RUNNING  | 172.17.0.4:40953 |     22 |          573.356 | 3559424 |   260.13 |              307.596 |              160.172 |            801.305 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bf489_00000:
  custom_metrics:
    time_step_max: 3927
    time_step_mean: 3266.2654185022025
    time_step_min: 2954
  date: 2020-10-12_14-49-43
  done: false
  episode_len_mean: 800.4751200349192
  episode_reward_max: 307.59595959595924
  episode_reward_mean: 260.6454417593659
  episode_reward_min: 160.17171717171726
  episodes_this_iter: 166
  episodes_total: 4582
  experiment_id: c5b56dd326bb4e65ac344f34ee55c698
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.758562500278155
        entropy_coeff: 0.0005000000000000001
        kl: 0.005646925768814981
        model: {}
        policy_loss: -0.011008052000155052
        total_loss: 7.616831421852112
        vf_explained_var: 0.9816978573799133
        vf_loss: 7.6276540358861284
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.469999999999995
    gpu_util_percent0: 0.35433333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40953
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15024661191369185
    mean_env_wait_ms: 1.168460775037004
    mean_inference_ms: 4.608160295608316
    mean_raw_obs_processing_ms: 0.3928199775697928
  time_since_restore: 599.0932841300964
  time_this_iter_s: 25.737576723098755
  time_total_s: 599.0932841300964
  timers:
    learn_throughput: 8616.716
    learn_time_ms: 18776.528
    sample_throughput: 23163.465
    sample_time_ms: 6984.793
    update_time_ms: 39.283
  timestamp: 1602514183
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: bf489_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bf489_00000 | RUNNING  | 172.17.0.4:40953 |     23 |          599.093 | 3721216 |  260.645 |              307.596 |              160.172 |            800.475 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bf489_00000:
  custom_metrics:
    time_step_max: 3927
    time_step_mean: 3264.125744680851
    time_step_min: 2954
  date: 2020-10-12_14-50-09
  done: true
  episode_len_mean: 799.7191058625052
  episode_reward_max: 307.59595959595924
  episode_reward_mean: 261.01878975329004
  episode_reward_min: 160.17171717171726
  episodes_this_iter: 160
  episodes_total: 4742
  experiment_id: c5b56dd326bb4e65ac344f34ee55c698
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7632499734560648
        entropy_coeff: 0.0005000000000000001
        kl: 0.006014090691072245
        model: {}
        policy_loss: -0.012040382775012404
        total_loss: 8.783557653427124
        vf_explained_var: 0.9784457087516785
        vf_loss: 8.79537852605184
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.746666666666673
    gpu_util_percent0: 0.252
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.79
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40953
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15014955524243317
    mean_env_wait_ms: 1.1693686575729807
    mean_inference_ms: 4.600035248562612
    mean_raw_obs_processing_ms: 0.392419892805789
  time_since_restore: 625.0172574520111
  time_this_iter_s: 25.923973321914673
  time_total_s: 625.0172574520111
  timers:
    learn_throughput: 8609.319
    learn_time_ms: 18792.658
    sample_throughput: 23210.374
    sample_time_ms: 6970.676
    update_time_ms: 39.054
  timestamp: 1602514209
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: bf489_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bf489_00000 | TERMINATED |       |     24 |          625.017 | 3883008 |  261.019 |              307.596 |              160.172 |            799.719 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bf489_00000 | TERMINATED |       |     24 |          625.017 | 3883008 |  261.019 |              307.596 |              160.172 |            799.719 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


