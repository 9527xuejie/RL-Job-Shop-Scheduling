2020-10-11 20:39:28,572	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_dc7e0_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=15842)[0m 2020-10-11 20:39:31,348	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=15826)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15826)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15799)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15799)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15838)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15838)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15744)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15744)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15865)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15865)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15866)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15866)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15792)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15792)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15820)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15820)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15816)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15816)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15832)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15832)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15812)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15812)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15830)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15830)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15813)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15813)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15775)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15775)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15825)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15825)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15860)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15860)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15868)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15868)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15876)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15876)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15877)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15877)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15800)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15800)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15765)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15765)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15818)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15818)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15739)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15739)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15766)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15766)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15737)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15737)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15819)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15819)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15853)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15853)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15810)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15810)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15758)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15758)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15869)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15869)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15808)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15808)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15755)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15755)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15828)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15828)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15811)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15811)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15757)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15757)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15741)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15741)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15858)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15858)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15847)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15847)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15753)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15753)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15859)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15859)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15795)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15795)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15846)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15846)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15762)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15762)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15749)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15749)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15738)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15738)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15872)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15872)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15802)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15802)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15746)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15746)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15852)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15852)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15833)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15833)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15748)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15748)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15840)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15840)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15740)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15740)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15751)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15751)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15862)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15862)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15774)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15774)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15760)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15760)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15743)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15743)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15805)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15805)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15767)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15767)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15814)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15814)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15807)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15807)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15817)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15817)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15844)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15844)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15835)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15835)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15736)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15736)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15750)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15750)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15854)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15854)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15849)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15849)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15759)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15759)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15834)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15834)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15773)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15773)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15809)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15809)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15806)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15806)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15769)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15769)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15752)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15752)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15747)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15747)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15764)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15764)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15827)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15827)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_dc7e0_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_20-40-12
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1813993354638417
        entropy_coeff: 0.0005000000000000001
        kl: 0.007591694826260209
        model: {}
        policy_loss: -0.012553695759076314
        total_loss: 500.41192626953125
        vf_explained_var: 0.5819632411003113
        vf_loss: 500.42430623372394
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.811363636363637
    gpu_util_percent0: 0.31227272727272726
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5909090909090895
    vram_util_percent0: 0.08942201616029101
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15842
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16739492248554
    mean_env_wait_ms: 1.1652346855698266
    mean_inference_ms: 5.5060321204858855
    mean_raw_obs_processing_ms: 0.44000907090020136
  time_since_restore: 35.872936725616455
  time_this_iter_s: 35.872936725616455
  time_total_s: 35.872936725616455
  timers:
    learn_throughput: 6001.037
    learn_time_ms: 26960.675
    sample_throughput: 18322.175
    sample_time_ms: 8830.393
    update_time_ms: 41.968
  timestamp: 1602448812
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: dc7e0_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      1 |          35.8729 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dc7e0_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3613.684027777778
    time_step_min: 3358
  date: 2020-10-11_20-40-47
  done: false
  episode_len_mean: 888.5917721518987
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 217.0985487789283
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.149230072895686
        entropy_coeff: 0.0005000000000000001
        kl: 0.00951601347575585
        model: {}
        policy_loss: -0.01619932148605585
        total_loss: 120.9416898091634
        vf_explained_var: 0.8221778273582458
        vf_loss: 120.95751126607259
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.199999999999996
    gpu_util_percent0: 0.32047619047619047
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.76904761904762
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15842
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16326572534453276
    mean_env_wait_ms: 1.1632587587181373
    mean_inference_ms: 5.312069869064258
    mean_raw_obs_processing_ms: 0.43039064260126914
  time_since_restore: 70.36755323410034
  time_this_iter_s: 34.49461650848389
  time_total_s: 70.36755323410034
  timers:
    learn_throughput: 6017.136
    learn_time_ms: 26888.542
    sample_throughput: 19703.911
    sample_time_ms: 8211.162
    update_time_ms: 40.266
  timestamp: 1602448847
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: dc7e0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      2 |          70.3676 | 323584 |  217.099 |              258.596 |              106.778 |            888.592 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dc7e0_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3616.4686098654706
    time_step_min: 3337
  date: 2020-10-11_20-41-21
  done: false
  episode_len_mean: 885.3459915611814
  episode_reward_max: 260.41414141414157
  episode_reward_mean: 217.68079529471913
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.137440989414851
        entropy_coeff: 0.0005000000000000001
        kl: 0.010796306344370047
        model: {}
        policy_loss: -0.017557858838699758
        total_loss: 47.99287382761637
        vf_explained_var: 0.9169993996620178
        vf_loss: 48.00991948445638
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.892857142857146
    gpu_util_percent0: 0.34785714285714286
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7809523809523813
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15842
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16056212834421194
    mean_env_wait_ms: 1.1634296276589942
    mean_inference_ms: 5.15785089440761
    mean_raw_obs_processing_ms: 0.4230651018633661
  time_since_restore: 104.36089730262756
  time_this_iter_s: 33.99334406852722
  time_total_s: 104.36089730262756
  timers:
    learn_throughput: 6029.227
    learn_time_ms: 26834.618
    sample_throughput: 20609.33
    sample_time_ms: 7850.425
    update_time_ms: 56.456
  timestamp: 1602448881
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: dc7e0_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      3 |          104.361 | 485376 |  217.681 |              260.414 |              106.778 |            885.346 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dc7e0_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3614.6423841059604
    time_step_min: 3337
  date: 2020-10-11_20-41-55
  done: false
  episode_len_mean: 881.8196202531645
  episode_reward_max: 260.41414141414157
  episode_reward_mean: 218.72613796189725
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1155910591284435
        entropy_coeff: 0.0005000000000000001
        kl: 0.009656987541044751
        model: {}
        policy_loss: -0.01651762195736713
        total_loss: 28.95356051127116
        vf_explained_var: 0.9477614760398865
        vf_loss: 28.969671090443928
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.343902439024394
    gpu_util_percent0: 0.35048780487804876
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7829268292682934
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15842
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1586801646218421
    mean_env_wait_ms: 1.164152942958408
    mean_inference_ms: 5.046484781278792
    mean_raw_obs_processing_ms: 0.41745109450024254
  time_since_restore: 138.51990175247192
  time_this_iter_s: 34.15900444984436
  time_total_s: 138.51990175247192
  timers:
    learn_throughput: 6020.605
    learn_time_ms: 26873.045
    sample_throughput: 21117.842
    sample_time_ms: 7661.389
    update_time_ms: 48.665
  timestamp: 1602448915
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: dc7e0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      4 |           138.52 | 647168 |  218.726 |              260.414 |              106.778 |             881.82 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dc7e0_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3605.250656167979
    time_step_min: 3304
  date: 2020-10-11_20-42-29
  done: false
  episode_len_mean: 877.9139240506329
  episode_reward_max: 265.41414141414134
  episode_reward_mean: 220.00543408771236
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0832295417785645
        entropy_coeff: 0.0005000000000000001
        kl: 0.009306296007707715
        model: {}
        policy_loss: -0.018154682746777933
        total_loss: 23.046836853027344
        vf_explained_var: 0.9613752365112305
        vf_loss: 23.06460205713908
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.524390243902438
    gpu_util_percent0: 0.31585365853658537
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7829268292682934
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15842
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15728991577564908
    mean_env_wait_ms: 1.165519039293983
    mean_inference_ms: 4.9625030190174435
    mean_raw_obs_processing_ms: 0.41304544879908506
  time_since_restore: 172.49350261688232
  time_this_iter_s: 33.9736008644104
  time_total_s: 172.49350261688232
  timers:
    learn_throughput: 6022.129
    learn_time_ms: 26866.247
    sample_throughput: 21465.213
    sample_time_ms: 7537.405
    update_time_ms: 47.824
  timestamp: 1602448949
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: dc7e0_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      5 |          172.494 | 808960 |  220.005 |              265.414 |              106.778 |            877.914 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dc7e0_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3589.0765639589167
    time_step_min: 3289
  date: 2020-10-11_20-43-03
  done: false
  episode_len_mean: 868.1392174704276
  episode_reward_max: 267.6868686868687
  episode_reward_mean: 222.3442707328056
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 309
  episodes_total: 1099
  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0729438364505768
        entropy_coeff: 0.0005000000000000001
        kl: 0.008983297661567727
        model: {}
        policy_loss: -0.014856907461459437
        total_loss: 27.952880541483562
        vf_explained_var: 0.967507541179657
        vf_loss: 27.96737511952718
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.916666666666668
    gpu_util_percent0: 0.32166666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7857142857142865
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15842
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15544227505819425
    mean_env_wait_ms: 1.1697635491006715
    mean_inference_ms: 4.850780353416123
    mean_raw_obs_processing_ms: 0.4076391069538378
  time_since_restore: 206.787859916687
  time_this_iter_s: 34.29435729980469
  time_total_s: 206.787859916687
  timers:
    learn_throughput: 6012.676
    learn_time_ms: 26908.487
    sample_throughput: 21686.82
    sample_time_ms: 7460.384
    update_time_ms: 46.403
  timestamp: 1602448983
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: dc7e0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      6 |          206.788 | 970752 |  222.344 |              267.687 |              106.778 |            868.139 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dc7e0_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3580.65857605178
    time_step_min: 3206
  date: 2020-10-11_20-43-37
  done: false
  episode_len_mean: 864.2848101265823
  episode_reward_max: 280.2626262626266
  episode_reward_mean: 223.69569108809597
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 165
  episodes_total: 1264
  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.058151125907898
        entropy_coeff: 0.0005000000000000001
        kl: 0.009279307521258792
        model: {}
        policy_loss: -0.01645077992967951
        total_loss: 15.616268157958984
        vf_explained_var: 0.9726335406303406
        vf_loss: 15.632320404052734
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.31219512195122
    gpu_util_percent0: 0.39048780487804874
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.790243902439025
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15842
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1547533973210653
    mean_env_wait_ms: 1.1714575614665215
    mean_inference_ms: 4.8082734759399735
    mean_raw_obs_processing_ms: 0.4055719972688042
  time_since_restore: 240.5369439125061
  time_this_iter_s: 33.74908399581909
  time_total_s: 240.5369439125061
  timers:
    learn_throughput: 6015.051
    learn_time_ms: 26897.858
    sample_throughput: 21950.814
    sample_time_ms: 7370.661
    update_time_ms: 43.835
  timestamp: 1602449017
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: dc7e0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      7 |          240.537 | 1132544 |  223.696 |              280.263 |              106.778 |            864.285 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dc7e0_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3572.3407460545195
    time_step_min: 3206
  date: 2020-10-11_20-44-11
  done: false
  episode_len_mean: 860.7060478199719
  episode_reward_max: 283.7474747474749
  episode_reward_mean: 224.74979755359487
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0435506701469421
        entropy_coeff: 0.0005000000000000001
        kl: 0.00859822037940224
        model: {}
        policy_loss: -0.017028980733205874
        total_loss: 14.67722193400065
        vf_explained_var: 0.973932683467865
        vf_loss: 14.693913221359253
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.33658536585366
    gpu_util_percent0: 0.3939024390243903
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.790243902439025
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15842
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15419709361525985
    mean_env_wait_ms: 1.173051547586474
    mean_inference_ms: 4.773140764750721
    mean_raw_obs_processing_ms: 0.4038527557885323
  time_since_restore: 274.5138940811157
  time_this_iter_s: 33.97695016860962
  time_total_s: 274.5138940811157
  timers:
    learn_throughput: 6015.4
    learn_time_ms: 26896.299
    sample_throughput: 22088.803
    sample_time_ms: 7324.616
    update_time_ms: 42.976
  timestamp: 1602449051
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: dc7e0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      8 |          274.514 | 1294336 |   224.75 |              283.747 |              106.778 |            860.706 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dc7e0_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3564.5992268041236
    time_step_min: 3206
  date: 2020-10-11_20-44-45
  done: false
  episode_len_mean: 857.1246835443038
  episode_reward_max: 283.7474747474749
  episode_reward_mean: 226.1820739035928
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0148475964864094
        entropy_coeff: 0.0005000000000000001
        kl: 0.008687774262701472
        model: {}
        policy_loss: -0.019221531343646348
        total_loss: 13.16464869181315
        vf_explained_var: 0.974395751953125
        vf_loss: 13.18350887298584
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.164285714285715
    gpu_util_percent0: 0.3242857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7809523809523817
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15842
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15371439312164148
    mean_env_wait_ms: 1.1745967344936128
    mean_inference_ms: 4.742392873103581
    mean_raw_obs_processing_ms: 0.40227968154243166
  time_since_restore: 308.6301050186157
  time_this_iter_s: 34.1162109375
  time_total_s: 308.6301050186157
  timers:
    learn_throughput: 6008.991
    learn_time_ms: 26924.987
    sample_throughput: 22237.247
    sample_time_ms: 7275.721
    update_time_ms: 40.494
  timestamp: 1602449085
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: dc7e0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      9 |           308.63 | 1456128 |  226.182 |              283.747 |              106.778 |            857.125 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dc7e0_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3552.531868131868
    time_step_min: 3206
  date: 2020-10-11_20-45-20
  done: false
  episode_len_mean: 852.1964285714286
  episode_reward_max: 283.7474747474749
  episode_reward_mean: 228.07582316673216
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 268
  episodes_total: 1848
  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9734643250703812
        entropy_coeff: 0.0005000000000000001
        kl: 0.00841127677510182
        model: {}
        policy_loss: -0.015553771576378495
        total_loss: 19.610436121622723
        vf_explained_var: 0.9750833511352539
        vf_loss: 19.625635147094727
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.104878048780492
    gpu_util_percent0: 0.3853658536585366
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7731707317073173
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15842
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1530331197150846
    mean_env_wait_ms: 1.1772620710886672
    mean_inference_ms: 4.6989199095298195
    mean_raw_obs_processing_ms: 0.40005810250385193
  time_since_restore: 342.688401222229
  time_this_iter_s: 34.05829620361328
  time_total_s: 342.688401222229
  timers:
    learn_throughput: 6005.184
    learn_time_ms: 26942.055
    sample_throughput: 22362.798
    sample_time_ms: 7234.873
    update_time_ms: 40.393
  timestamp: 1602449120
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: dc7e0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     10 |          342.688 | 1617920 |  228.076 |              283.747 |              106.778 |            852.196 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dc7e0_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3542.3598223099702
    time_step_min: 3206
  date: 2020-10-11_20-45-53
  done: false
  episode_len_mean: 849.3028237585199
  episode_reward_max: 283.7474747474749
  episode_reward_mean: 229.4285552703273
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 206
  episodes_total: 2054
  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9663667529821396
        entropy_coeff: 0.0005000000000000001
        kl: 0.00833925325423479
        model: {}
        policy_loss: -0.01736273110145703
        total_loss: 12.502357721328735
        vf_explained_var: 0.9791706204414368
        vf_loss: 12.51936944325765
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.58048780487805
    gpu_util_percent0: 0.3982926829268293
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7804878048780495
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15842
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1526132408098708
    mean_env_wait_ms: 1.1789611773593984
    mean_inference_ms: 4.671734404012167
    mean_raw_obs_processing_ms: 0.39871998319890184
  time_since_restore: 376.51920080184937
  time_this_iter_s: 33.83079957962036
  time_total_s: 376.51920080184937
  timers:
    learn_throughput: 6006.948
    learn_time_ms: 26934.144
    sample_throughput: 22990.875
    sample_time_ms: 7037.227
    update_time_ms: 40.215
  timestamp: 1602449153
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: dc7e0_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     11 |          376.519 | 1779712 |  229.429 |              283.747 |              106.778 |            849.303 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dc7e0_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3534.694597069597
    time_step_min: 3206
  date: 2020-10-11_20-46-27
  done: false
  episode_len_mean: 847.131555153707
  episode_reward_max: 283.7474747474749
  episode_reward_mean: 230.50298189855144
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9568162461121877
        entropy_coeff: 0.0005000000000000001
        kl: 0.00814399627658228
        model: {}
        policy_loss: -0.015694946744285215
        total_loss: 12.548736731211344
        vf_explained_var: 0.9766435623168945
        vf_loss: 12.564095417658487
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.81707317073171
    gpu_util_percent0: 0.3797560975609756
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.792682926829269
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15842
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1523239438594431
    mean_env_wait_ms: 1.1801704441448417
    mean_inference_ms: 4.653173903698042
    mean_raw_obs_processing_ms: 0.3977863822432723
  time_since_restore: 410.4603908061981
  time_this_iter_s: 33.941190004348755
  time_total_s: 410.4603908061981
  timers:
    learn_throughput: 6004.841
    learn_time_ms: 26943.593
    sample_throughput: 23202.406
    sample_time_ms: 6973.07
    update_time_ms: 38.84
  timestamp: 1602449187
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: dc7e0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     12 |           410.46 | 1941504 |  230.503 |              283.747 |              106.778 |            847.132 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dc7e0_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3528.8706233988046
    time_step_min: 3206
  date: 2020-10-11_20-47-02
  done: false
  episode_len_mean: 845.0793248945148
  episode_reward_max: 283.7474747474749
  episode_reward_mean: 231.55561948599922
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9341403146584829
        entropy_coeff: 0.0005000000000000001
        kl: 0.008328795510654649
        model: {}
        policy_loss: -0.015285106880279878
        total_loss: 11.184300502141317
        vf_explained_var: 0.9784317016601562
        vf_loss: 11.199219783147177
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.056097560975612
    gpu_util_percent0: 0.3531707317073171
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7829268292682925
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15842
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15206707844660014
    mean_env_wait_ms: 1.1812995165783673
    mean_inference_ms: 4.636268107417298
    mean_raw_obs_processing_ms: 0.39691338971294254
  time_since_restore: 444.4848208427429
  time_this_iter_s: 34.0244300365448
  time_total_s: 444.4848208427429
  timers:
    learn_throughput: 5995.984
    learn_time_ms: 26983.393
    sample_throughput: 23304.966
    sample_time_ms: 6942.383
    update_time_ms: 32.03
  timestamp: 1602449222
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: dc7e0_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     13 |          444.485 | 2103296 |  231.556 |              283.747 |              106.778 |            845.079 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dc7e0_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3517.263601532567
    time_step_min: 3206
  date: 2020-10-11_20-47-35
  done: false
  episode_len_mean: 841.8491281273692
  episode_reward_max: 283.7474747474749
  episode_reward_mean: 233.18196368537525
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 268
  episodes_total: 2638
  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9020447830359141
        entropy_coeff: 0.0005000000000000001
        kl: 0.008081968214052418
        model: {}
        policy_loss: -0.015293826969961325
        total_loss: 12.724741299947103
        vf_explained_var: 0.9831693172454834
        vf_loss: 12.739677826563517
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.178048780487803
    gpu_util_percent0: 0.34682926829268296
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775609756097561
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15842
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15168397874215378
    mean_env_wait_ms: 1.1831688977197714
    mean_inference_ms: 4.610931204965214
    mean_raw_obs_processing_ms: 0.39561206070844984
  time_since_restore: 478.23622155189514
  time_this_iter_s: 33.75140070915222
  time_total_s: 478.23622155189514
  timers:
    learn_throughput: 5998.158
    learn_time_ms: 26973.613
    sample_throughput: 23414.5
    sample_time_ms: 6909.906
    update_time_ms: 33.132
  timestamp: 1602449255
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: dc7e0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     14 |          478.236 | 2265088 |  233.182 |              283.747 |              106.778 |            841.849 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dc7e0_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3509.4779829545455
    time_step_min: 3206
  date: 2020-10-11_20-48-09
  done: false
  episode_len_mean: 839.5295358649789
  episode_reward_max: 283.7474747474749
  episode_reward_mean: 234.39397135916116
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 206
  episodes_total: 2844
  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8862918565670649
        entropy_coeff: 0.0005000000000000001
        kl: 0.007904120022431016
        model: {}
        policy_loss: -0.014935656054755478
        total_loss: 9.06860645612081
        vf_explained_var: 0.984200656414032
        vf_loss: 9.083194653193155
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.682926829268297
    gpu_util_percent0: 0.38243902439024396
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7878048780487807
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15842
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15143390810491775
    mean_env_wait_ms: 1.1844643908633714
    mean_inference_ms: 4.594233582997575
    mean_raw_obs_processing_ms: 0.3947809594728215
  time_since_restore: 512.1841127872467
  time_this_iter_s: 33.94789123535156
  time_total_s: 512.1841127872467
  timers:
    learn_throughput: 5994.585
    learn_time_ms: 26989.692
    sample_throughput: 23481.767
    sample_time_ms: 6890.112
    update_time_ms: 32.925
  timestamp: 1602449289
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: dc7e0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     15 |          512.184 | 2426880 |  234.394 |              283.747 |              106.778 |             839.53 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dc7e0_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3504.0221923335575
    time_step_min: 3206
  date: 2020-10-11_20-48-44
  done: false
  episode_len_mean: 837.8334443704197
  episode_reward_max: 283.7474747474749
  episode_reward_mean: 235.28937610616484
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8804336041212082
        entropy_coeff: 0.0005000000000000001
        kl: 0.00791139566960434
        model: {}
        policy_loss: -0.017682172047595184
        total_loss: 8.313085556030273
        vf_explained_var: 0.9836888313293457
        vf_loss: 8.330416997273764
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.829268292682926
    gpu_util_percent0: 0.4309756097560975
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7853658536585377
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15842
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15125642659333643
    mean_env_wait_ms: 1.1853858835587299
    mean_inference_ms: 4.5824743389127525
    mean_raw_obs_processing_ms: 0.39418437084622066
  time_since_restore: 546.3757491111755
  time_this_iter_s: 34.19163632392883
  time_total_s: 546.3757491111755
  timers:
    learn_throughput: 5991.373
    learn_time_ms: 27004.162
    sample_throughput: 23569.806
    sample_time_ms: 6864.376
    update_time_ms: 32.942
  timestamp: 1602449324
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: dc7e0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     16 |          546.376 | 2588672 |  235.289 |              283.747 |              106.778 |            837.833 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dc7e0_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3498.312918660287
    time_step_min: 3206
  date: 2020-10-11_20-49-18
  done: false
  episode_len_mean: 836.1346822636738
  episode_reward_max: 283.7474747474749
  episode_reward_mean: 236.18048330283543
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 161
  episodes_total: 3163
  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8537542670965195
        entropy_coeff: 0.0005000000000000001
        kl: 0.008198376706180474
        model: {}
        policy_loss: -0.015993841225281358
        total_loss: 9.6584951877594
        vf_explained_var: 0.9823360443115234
        vf_loss: 9.67409602801005
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.716666666666665
    gpu_util_percent0: 0.3614285714285715
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7809523809523813
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15842
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15108549071824215
    mean_env_wait_ms: 1.186299740621708
    mean_inference_ms: 4.571266181106936
    mean_raw_obs_processing_ms: 0.3935990755523057
  time_since_restore: 580.5327708721161
  time_this_iter_s: 34.15702176094055
  time_total_s: 580.5327708721161
  timers:
    learn_throughput: 5980.848
    learn_time_ms: 27051.68
    sample_throughput: 23599.526
    sample_time_ms: 6855.731
    update_time_ms: 34.302
  timestamp: 1602449358
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: dc7e0_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     17 |          580.533 | 2750464 |   236.18 |              283.747 |              106.778 |            836.135 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dc7e0_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3488.101369064958
    time_step_min: 3158
  date: 2020-10-11_20-49-52
  done: true
  episode_len_mean: 833.3886160069344
  episode_reward_max: 287.53535353535375
  episode_reward_mean: 237.6940920327224
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 298
  episodes_total: 3461
  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8270254284143448
        entropy_coeff: 0.0005000000000000001
        kl: 0.007853905437514186
        model: {}
        policy_loss: -0.014354762931664785
        total_loss: 12.10600503285726
        vf_explained_var: 0.9836263060569763
        vf_loss: 12.119987805684408
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.90487804878049
    gpu_util_percent0: 0.37609756097560976
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7829268292682934
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 15842
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15081126315046797
    mean_env_wait_ms: 1.1879326543189301
    mean_inference_ms: 4.552816786571983
    mean_raw_obs_processing_ms: 0.39263685907469736
  time_since_restore: 614.4084322452545
  time_this_iter_s: 33.87566137313843
  time_total_s: 614.4084322452545
  timers:
    learn_throughput: 5980.24
    learn_time_ms: 27054.431
    sample_throughput: 23642.693
    sample_time_ms: 6843.214
    update_time_ms: 32.784
  timestamp: 1602449392
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: dc7e0_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dc7e0_00000 | TERMINATED |       |     18 |          614.408 | 2912256 |  237.694 |              287.535 |              106.778 |            833.389 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dc7e0_00000 | TERMINATED |       |     18 |          614.408 | 2912256 |  237.694 |              287.535 |              106.778 |            833.389 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


