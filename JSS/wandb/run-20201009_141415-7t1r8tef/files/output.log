2020-10-09 14:14:18,905	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_b9357_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=22763)[0m 2020-10-09 14:14:21,938	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=22716)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22716)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22717)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22717)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22637)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22637)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22724)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22724)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22655)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22655)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22668)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22668)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22727)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22727)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22644)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22644)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22697)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22697)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22720)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22720)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22623)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22623)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22738)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22738)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22740)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22740)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22707)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22707)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22710)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22710)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22625)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22625)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22714)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22714)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22748)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22748)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22703)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22703)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22759)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22759)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22722)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22722)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22731)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22731)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22705)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22705)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22718)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22718)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22723)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22723)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22745)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22745)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22729)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22729)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22713)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22713)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22715)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22715)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22736)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22736)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22754)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22754)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22643)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22643)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22659)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22659)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22698)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22698)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22638)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22638)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22700)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22700)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22640)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22640)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22646)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22646)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22737)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22737)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22751)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22751)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22712)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22712)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22695)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22695)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22661)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22661)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22627)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22627)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22742)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22742)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22699)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22699)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22624)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22624)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22708)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22708)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22764)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22764)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22734)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22734)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22721)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22721)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22666)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22666)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22749)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22749)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22739)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22739)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22709)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22709)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22711)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22711)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22701)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22701)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22642)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22642)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22639)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22639)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22706)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22706)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22633)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22633)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22636)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22636)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22629)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22629)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22704)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22704)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22761)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22761)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22650)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22650)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22665)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22665)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22730)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22730)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22652)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22652)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22628)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22628)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22670)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22670)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22664)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22664)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22732)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22732)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22641)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22641)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22725)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22725)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22626)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22626)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22702)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22702)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22630)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22630)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22656)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22656)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_b9357_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-09_14-14-57
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 22118ab98007455c9a569653a8a5057f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.185721375725486
        entropy_coeff: 0.0
        kl: 0.003703018311749805
        model: {}
        policy_loss: -0.006415682442655618
        total_loss: 504.9379799582741
        vf_explained_var: 0.5547387599945068
        vf_loss: 504.9436562278054
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.982857142857142
    gpu_util_percent0: 0.3380000000000001
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.6085714285714285
    vram_util_percent0: 0.09333973668181605
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22763
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1624563793666424
    mean_env_wait_ms: 1.172360534762188
    mean_inference_ms: 4.953541556932779
    mean_raw_obs_processing_ms: 0.4301955678574131
  time_since_restore: 30.01008439064026
  time_this_iter_s: 30.01008439064026
  time_total_s: 30.01008439064026
  timers:
    learn_throughput: 7313.349
    learn_time_ms: 22122.833
    sample_throughput: 20729.44
    sample_time_ms: 7804.938
    update_time_ms: 44.173
  timestamp: 1602252897
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: b9357_00000
  
== Status ==
Memory usage on this node: 27.9/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9357_00000 | RUNNING  | 172.17.0.4:22763 |      1 |          30.0101 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9357_00000:
  custom_metrics:
    time_step_max: 4214
    time_step_mean: 3598.9930555555557
    time_step_min: 3340
  date: 2020-10-09_14-15-27
  done: false
  episode_len_mean: 889.3227848101266
  episode_reward_max: 259.95959595959556
  episode_reward_mean: 219.009269914333
  episode_reward_min: 127.53535353535293
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 22118ab98007455c9a569653a8a5057f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.1551292917945168
        entropy_coeff: 0.0
        kl: 0.00970912038941275
        model: {}
        policy_loss: -0.008042187506692822
        total_loss: 122.30779682506214
        vf_explained_var: 0.8153958916664124
        vf_loss: 122.31486719304866
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.86857142857143
    gpu_util_percent0: 0.3945714285714285
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7771428571428585
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22763
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16109263920736538
    mean_env_wait_ms: 1.1691101222565894
    mean_inference_ms: 4.944249535645804
    mean_raw_obs_processing_ms: 0.4297904055567008
  time_since_restore: 59.927109241485596
  time_this_iter_s: 29.917024850845337
  time_total_s: 59.927109241485596
  timers:
    learn_throughput: 7333.085
    learn_time_ms: 22063.293
    sample_throughput: 20694.953
    sample_time_ms: 7817.945
    update_time_ms: 39.533
  timestamp: 1602252927
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: b9357_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9357_00000 | RUNNING  | 172.17.0.4:22763 |      2 |          59.9271 | 323584 |  219.009 |               259.96 |              127.535 |            889.323 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9357_00000:
  custom_metrics:
    time_step_max: 4214
    time_step_mean: 3599.1928251121076
    time_step_min: 3320
  date: 2020-10-09_14-15-56
  done: false
  episode_len_mean: 883.1097046413502
  episode_reward_max: 266.1717171717168
  episode_reward_mean: 220.63438179260945
  episode_reward_min: 127.53535353535293
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 22118ab98007455c9a569653a8a5057f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.148613983934576
        entropy_coeff: 0.0
        kl: 0.008726517669856548
        model: {}
        policy_loss: -0.009318642646328291
        total_loss: 57.69076156616211
        vf_explained_var: 0.8949190378189087
        vf_loss: 57.6992055719549
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.170588235294115
    gpu_util_percent0: 0.3694117647058824
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8000000000000007
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22763
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15947840907609986
    mean_env_wait_ms: 1.1685868339163172
    mean_inference_ms: 4.887105200891112
    mean_raw_obs_processing_ms: 0.4254985642336507
  time_since_restore: 89.30883145332336
  time_this_iter_s: 29.38172221183777
  time_total_s: 89.30883145332336
  timers:
    learn_throughput: 7331.146
    learn_time_ms: 22069.127
    sample_throughput: 21244.145
    sample_time_ms: 7615.839
    update_time_ms: 39.019
  timestamp: 1602252956
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: b9357_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9357_00000 | RUNNING  | 172.17.0.4:22763 |      3 |          89.3088 | 485376 |  220.634 |              266.172 |              127.535 |             883.11 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9357_00000:
  custom_metrics:
    time_step_max: 4214
    time_step_mean: 3597.1903973509934
    time_step_min: 3320
  date: 2020-10-09_14-16-26
  done: false
  episode_len_mean: 878.625
  episode_reward_max: 266.1717171717168
  episode_reward_mean: 220.4966116864849
  episode_reward_min: 126.6262626262627
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 22118ab98007455c9a569653a8a5057f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.1225847656076604
        entropy_coeff: 0.0
        kl: 0.0077413090674037285
        model: {}
        policy_loss: -0.007794778201390396
        total_loss: 42.26507984508168
        vf_explained_var: 0.9280005097389221
        vf_loss: 42.27210062200373
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.36285714285714
    gpu_util_percent0: 0.3431428571428572
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.805714285714286
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22763
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15811117498690236
    mean_env_wait_ms: 1.1686265799943498
    mean_inference_ms: 4.83167858042823
    mean_raw_obs_processing_ms: 0.4211193409296684
  time_since_restore: 118.71339893341064
  time_this_iter_s: 29.40456748008728
  time_total_s: 118.71339893341064
  timers:
    learn_throughput: 7330.104
    learn_time_ms: 22072.265
    sample_throughput: 21556.567
    sample_time_ms: 7505.462
    update_time_ms: 37.408
  timestamp: 1602252986
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: b9357_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9357_00000 | RUNNING  | 172.17.0.4:22763 |      4 |          118.713 | 647168 |  220.497 |              266.172 |              126.626 |            878.625 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9357_00000:
  custom_metrics:
    time_step_max: 4214
    time_step_mean: 3594.4036697247707
    time_step_min: 3279
  date: 2020-10-09_14-16-55
  done: false
  episode_len_mean: 872.9898862199747
  episode_reward_max: 269.2020202020199
  episode_reward_mean: 221.81187347559006
  episode_reward_min: 126.6262626262627
  episodes_this_iter: 159
  episodes_total: 791
  experiment_id: 22118ab98007455c9a569653a8a5057f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0894083218141035
        entropy_coeff: 0.0
        kl: 0.007603533777662299
        model: {}
        policy_loss: -0.0016074297230013392
        total_loss: 30.77157870205966
        vf_explained_var: 0.9528976678848267
        vf_loss: 30.772425044666637
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.508823529411767
    gpu_util_percent0: 0.3732352941176471
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7911764705882356
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22763
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15694227229917396
    mean_env_wait_ms: 1.169823256987093
    mean_inference_ms: 4.783095099759012
    mean_raw_obs_processing_ms: 0.41712866138200366
  time_since_restore: 147.85186004638672
  time_this_iter_s: 29.138461112976074
  time_total_s: 147.85186004638672
  timers:
    learn_throughput: 7331.286
    learn_time_ms: 22068.706
    sample_throughput: 21886.596
    sample_time_ms: 7392.287
    update_time_ms: 47.585
  timestamp: 1602253015
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: b9357_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9357_00000 | RUNNING  | 172.17.0.4:22763 |      5 |          147.852 | 808960 |  221.812 |              269.202 |              126.626 |             872.99 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9357_00000:
  custom_metrics:
    time_step_max: 4214
    time_step_mean: 3573.703153988868
    time_step_min: 3212
  date: 2020-10-09_14-17-24
  done: false
  episode_len_mean: 862.1636528028934
  episode_reward_max: 281.02020202020157
  episode_reward_mean: 224.88890715472974
  episode_reward_min: 126.6262626262627
  episodes_this_iter: 315
  episodes_total: 1106
  experiment_id: 22118ab98007455c9a569653a8a5057f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0830840847708962
        entropy_coeff: 0.0
        kl: 0.007620807948776267
        model: {}
        policy_loss: -0.012368944646037893
        total_loss: 32.01120740717108
        vf_explained_var: 0.9594013094902039
        vf_loss: 32.02281310341575
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.500000000000004
    gpu_util_percent0: 0.3458823529411765
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7911764705882356
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22763
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1553503908291614
    mean_env_wait_ms: 1.1736229092825277
    mean_inference_ms: 4.714262226203266
    mean_raw_obs_processing_ms: 0.4119476531706438
  time_since_restore: 177.19147276878357
  time_this_iter_s: 29.33961272239685
  time_total_s: 177.19147276878357
  timers:
    learn_throughput: 7327.013
    learn_time_ms: 22081.578
    sample_throughput: 22034.84
    sample_time_ms: 7342.554
    update_time_ms: 47.848
  timestamp: 1602253044
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: b9357_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9357_00000 | RUNNING  | 172.17.0.4:22763 |      6 |          177.191 | 970752 |  224.889 |               281.02 |              126.626 |            862.164 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9357_00000:
  custom_metrics:
    time_step_max: 4214
    time_step_mean: 3564.7241100323627
    time_step_min: 3212
  date: 2020-10-09_14-17-54
  done: false
  episode_len_mean: 857.1930379746835
  episode_reward_max: 283.4444444444442
  episode_reward_mean: 226.16979925840667
  episode_reward_min: 126.6262626262627
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 22118ab98007455c9a569653a8a5057f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0694612806493586
        entropy_coeff: 0.0
        kl: 0.007540336090394042
        model: {}
        policy_loss: -0.018460005860437046
        total_loss: 22.289595517245207
        vf_explained_var: 0.9615520238876343
        vf_loss: 22.307301434603605
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.685294117647057
    gpu_util_percent0: 0.33470588235294113
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22763
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15475731659325376
    mean_env_wait_ms: 1.1752911931280985
    mean_inference_ms: 4.688049874202399
    mean_raw_obs_processing_ms: 0.4100123619237476
  time_since_restore: 206.5634686946869
  time_this_iter_s: 29.37199592590332
  time_total_s: 206.5634686946869
  timers:
    learn_throughput: 7324.567
    learn_time_ms: 22088.95
    sample_throughput: 22114.363
    sample_time_ms: 7316.15
    update_time_ms: 45.744
  timestamp: 1602253074
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: b9357_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9357_00000 | RUNNING  | 172.17.0.4:22763 |      7 |          206.563 | 1132544 |   226.17 |              283.444 |              126.626 |            857.193 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9357_00000:
  custom_metrics:
    time_step_max: 4214
    time_step_mean: 3558.9913916786227
    time_step_min: 3212
  date: 2020-10-09_14-18-23
  done: false
  episode_len_mean: 854.1673699015471
  episode_reward_max: 283.4444444444442
  episode_reward_mean: 226.95465200528474
  episode_reward_min: 126.1717171717171
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 22118ab98007455c9a569653a8a5057f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0574940659783103
        entropy_coeff: 0.0
        kl: 0.006632144224237312
        model: {}
        policy_loss: -0.010896146509119055
        total_loss: 23.55630285089666
        vf_explained_var: 0.9598752856254578
        vf_loss: 23.566536123102363
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.05151515151515
    gpu_util_percent0: 0.37000000000000005
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7939393939393944
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22763
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1542331994385267
    mean_env_wait_ms: 1.1766584723986524
    mean_inference_ms: 4.664458682610933
    mean_raw_obs_processing_ms: 0.408233427506521
  time_since_restore: 235.36326146125793
  time_this_iter_s: 28.799792766571045
  time_total_s: 235.36326146125793
  timers:
    learn_throughput: 7333.574
    learn_time_ms: 22061.822
    sample_throughput: 22290.003
    sample_time_ms: 7258.501
    update_time_ms: 42.384
  timestamp: 1602253103
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: b9357_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9357_00000 | RUNNING  | 172.17.0.4:22763 |      8 |          235.363 | 1294336 |  226.955 |              283.444 |              126.172 |            854.167 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9357_00000:
  custom_metrics:
    time_step_max: 4214
    time_step_mean: 3550.1333762886597
    time_step_min: 3212
  date: 2020-10-09_14-18-52
  done: false
  episode_len_mean: 851.5025316455697
  episode_reward_max: 283.4444444444442
  episode_reward_mean: 228.60612453650415
  episode_reward_min: 126.1717171717171
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 22118ab98007455c9a569653a8a5057f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.027727105400779
        entropy_coeff: 0.0
        kl: 0.006365660493346778
        model: {}
        policy_loss: -0.004469933537290093
        total_loss: 18.954552910544656
        vf_explained_var: 0.966886579990387
        vf_loss: 18.95838668129661
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.78529411764706
    gpu_util_percent0: 0.34147058823529414
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8617647058823534
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22763
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15377271476359128
    mean_env_wait_ms: 1.1778856216494382
    mean_inference_ms: 4.64324482378201
    mean_raw_obs_processing_ms: 0.4065697134142558
  time_since_restore: 264.4570791721344
  time_this_iter_s: 29.093817710876465
  time_total_s: 264.4570791721344
  timers:
    learn_throughput: 7332.485
    learn_time_ms: 22065.098
    sample_throughput: 22411.437
    sample_time_ms: 7219.171
    update_time_ms: 42.656
  timestamp: 1602253132
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: b9357_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9357_00000 | RUNNING  | 172.17.0.4:22763 |      9 |          264.457 | 1456128 |  228.606 |              283.444 |              126.172 |            851.503 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9357_00000:
  custom_metrics:
    time_step_max: 4214
    time_step_mean: 3534.47591006424
    time_step_min: 3190
  date: 2020-10-09_14-19-21
  done: false
  episode_len_mean: 845.7737341772151
  episode_reward_max: 283.4444444444442
  episode_reward_mean: 230.8081127733025
  episode_reward_min: 126.1717171717171
  episodes_this_iter: 316
  episodes_total: 1896
  experiment_id: 22118ab98007455c9a569653a8a5057f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0160154429349033
        entropy_coeff: 0.0
        kl: 0.005873527293178168
        model: {}
        policy_loss: -0.006780969127166
        total_loss: 27.537723194469105
        vf_explained_var: 0.9669179320335388
        vf_loss: 27.54391687566584
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.66764705882353
    gpu_util_percent0: 0.3447058823529412
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7911764705882356
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22763
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1530200589503377
    mean_env_wait_ms: 1.1804360258080036
    mean_inference_ms: 4.608009403461588
    mean_raw_obs_processing_ms: 0.4039321463825551
  time_since_restore: 293.7101082801819
  time_this_iter_s: 29.253029108047485
  time_total_s: 293.7101082801819
  timers:
    learn_throughput: 7329.564
    learn_time_ms: 22073.891
    sample_throughput: 22478.04
    sample_time_ms: 7197.781
    update_time_ms: 42.072
  timestamp: 1602253161
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: b9357_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9357_00000 | RUNNING  | 172.17.0.4:22763 |     10 |           293.71 | 1617920 |  230.808 |              283.444 |              126.172 |            845.774 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9357_00000:
  custom_metrics:
    time_step_max: 4214
    time_step_mean: 3527.0607107601186
    time_step_min: 3190
  date: 2020-10-09_14-19-50
  done: false
  episode_len_mean: 843.047711781889
  episode_reward_max: 283.4444444444442
  episode_reward_mean: 231.78552319691548
  episode_reward_min: 126.1717171717171
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 22118ab98007455c9a569653a8a5057f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9969234303994612
        entropy_coeff: 0.0
        kl: 0.007128168574788354
        model: {}
        policy_loss: -0.007989988683468917
        total_loss: 16.994939283891156
        vf_explained_var: 0.9705255627632141
        vf_loss: 17.00221651250666
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.403030303030306
    gpu_util_percent0: 0.4481818181818181
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.803030303030303
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22763
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15270388778442656
    mean_env_wait_ms: 1.1815489841493845
    mean_inference_ms: 4.59322119576652
    mean_raw_obs_processing_ms: 0.4028054566350206
  time_since_restore: 322.79928970336914
  time_this_iter_s: 29.089181423187256
  time_total_s: 322.79928970336914
  timers:
    learn_throughput: 7325.386
    learn_time_ms: 22086.48
    sample_throughput: 22812.118
    sample_time_ms: 7092.371
    update_time_ms: 41.173
  timestamp: 1602253190
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: b9357_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9357_00000 | RUNNING  | 172.17.0.4:22763 |     11 |          322.799 | 1779712 |  231.786 |              283.444 |              126.172 |            843.048 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9357_00000:
  custom_metrics:
    time_step_max: 4214
    time_step_mean: 3518.08195970696
    time_step_min: 3190
  date: 2020-10-09_14-20-20
  done: false
  episode_len_mean: 840.5420433996384
  episode_reward_max: 283.4444444444442
  episode_reward_mean: 233.1088781120425
  episode_reward_min: 126.1717171717171
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 22118ab98007455c9a569653a8a5057f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9838359301740472
        entropy_coeff: 0.0
        kl: 0.00570176893167875
        model: {}
        policy_loss: -0.006835197733545845
        total_loss: 13.414334123784846
        vf_explained_var: 0.9735238552093506
        vf_loss: 13.420599330555309
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.33823529411765
    gpu_util_percent0: 0.35058823529411764
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8029411764705885
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22763
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15241612317971776
    mean_env_wait_ms: 1.1825691200298833
    mean_inference_ms: 4.579574639839592
    mean_raw_obs_processing_ms: 0.4017394422578009
  time_since_restore: 351.92632007598877
  time_this_iter_s: 29.12703037261963
  time_total_s: 351.92632007598877
  timers:
    learn_throughput: 7316.634
    learn_time_ms: 22112.901
    sample_throughput: 23157.851
    sample_time_ms: 6986.486
    update_time_ms: 41.166
  timestamp: 1602253220
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: b9357_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9357_00000 | RUNNING  | 172.17.0.4:22763 |     12 |          351.926 | 1941504 |  233.109 |              283.444 |              126.172 |            840.542 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9357_00000:
  custom_metrics:
    time_step_max: 4214
    time_step_mean: 3508.505722763883
    time_step_min: 3147
  date: 2020-10-09_14-20-49
  done: false
  episode_len_mean: 837.8240469208212
  episode_reward_max: 289.2020202020204
  episode_reward_mean: 234.64158552428333
  episode_reward_min: 126.1717171717171
  episodes_this_iter: 175
  episodes_total: 2387
  experiment_id: 22118ab98007455c9a569653a8a5057f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9407419724897905
        entropy_coeff: 0.0
        kl: 0.007120964540676637
        model: {}
        policy_loss: -0.007723826174200935
        total_loss: 15.08078332380815
        vf_explained_var: 0.9750441908836365
        vf_loss: 15.08779525756836
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.066666666666666
    gpu_util_percent0: 0.3657575757575758
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.812121212121212
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22763
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15212557644766267
    mean_env_wait_ms: 1.1837306850561935
    mean_inference_ms: 4.565806629366887
    mean_raw_obs_processing_ms: 0.40063330019086435
  time_since_restore: 380.8783047199249
  time_this_iter_s: 28.951984643936157
  time_total_s: 380.8783047199249
  timers:
    learn_throughput: 7317.101
    learn_time_ms: 22111.49
    sample_throughput: 23297.835
    sample_time_ms: 6944.508
    update_time_ms: 40.996
  timestamp: 1602253249
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: b9357_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9357_00000 | RUNNING  | 172.17.0.4:22763 |     13 |          380.878 | 2103296 |  234.642 |              289.202 |              126.172 |            837.824 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9357_00000:
  custom_metrics:
    time_step_max: 4214
    time_step_mean: 3495.49510910459
    time_step_min: 3147
  date: 2020-10-09_14-21-18
  done: false
  episode_len_mean: 834.4676098287416
  episode_reward_max: 289.2020202020204
  episode_reward_mean: 236.60697067472927
  episode_reward_min: 126.1717171717171
  episodes_this_iter: 299
  episodes_total: 2686
  experiment_id: 22118ab98007455c9a569653a8a5057f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9318342967466875
        entropy_coeff: 0.0
        kl: 0.006606650073081255
        model: {}
        policy_loss: -0.00825766590423882
        total_loss: 14.82509656385942
        vf_explained_var: 0.9790762066841125
        vf_loss: 14.832693966952236
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.38823529411765
    gpu_util_percent0: 0.37058823529411766
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7882352941176465
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22763
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15169299152868265
    mean_env_wait_ms: 1.1854382465744282
    mean_inference_ms: 4.544997395440975
    mean_raw_obs_processing_ms: 0.3990097451313615
  time_since_restore: 409.86106419563293
  time_this_iter_s: 28.982759475708008
  time_total_s: 409.86106419563293
  timers:
    learn_throughput: 7315.867
    learn_time_ms: 22115.219
    sample_throughput: 23432.77
    sample_time_ms: 6904.519
    update_time_ms: 40.906
  timestamp: 1602253278
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: b9357_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9357_00000 | RUNNING  | 172.17.0.4:22763 |     14 |          409.861 | 2265088 |  236.607 |              289.202 |              126.172 |            834.468 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9357_00000:
  custom_metrics:
    time_step_max: 4214
    time_step_mean: 3489.6693892045455
    time_step_min: 3147
  date: 2020-10-09_14-21-47
  done: false
  episode_len_mean: 833.342123769339
  episode_reward_max: 289.2020202020204
  episode_reward_mean: 237.4318927673357
  episode_reward_min: 126.1717171717171
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 22118ab98007455c9a569653a8a5057f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.919576184316115
        entropy_coeff: 0.0
        kl: 0.006340132645246657
        model: {}
        policy_loss: -0.0069929671643132515
        total_loss: 10.807782780040394
        vf_explained_var: 0.9804653525352478
        vf_loss: 10.814141967079856
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.3969696969697
    gpu_util_percent0: 0.3948484848484849
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8030303030303028
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22763
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1514922086907751
    mean_env_wait_ms: 1.1862293918427635
    mean_inference_ms: 4.535330680723764
    mean_raw_obs_processing_ms: 0.3982531163560047
  time_since_restore: 438.77122020721436
  time_this_iter_s: 28.91015601158142
  time_total_s: 438.77122020721436
  timers:
    learn_throughput: 7317.148
    learn_time_ms: 22111.347
    sample_throughput: 23480.057
    sample_time_ms: 6890.613
    update_time_ms: 35.565
  timestamp: 1602253307
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: b9357_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9357_00000 | RUNNING  | 172.17.0.4:22763 |     15 |          438.771 | 2426880 |  237.432 |              289.202 |              126.172 |            833.342 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9357_00000:
  custom_metrics:
    time_step_max: 4214
    time_step_mean: 3483.829186281103
    time_step_min: 3147
  date: 2020-10-09_14-22-16
  done: false
  episode_len_mean: 832.0306462358428
  episode_reward_max: 289.2020202020204
  episode_reward_mean: 238.34935632137484
  episode_reward_min: 126.1717171717171
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: 22118ab98007455c9a569653a8a5057f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9057004831053994
        entropy_coeff: 0.0
        kl: 0.005995341957631436
        model: {}
        policy_loss: -0.004709603529508141
        total_loss: 11.041045969182795
        vf_explained_var: 0.9778314232826233
        vf_loss: 11.045156305486506
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.52058823529412
    gpu_util_percent0: 0.35470588235294115
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8617647058823534
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22763
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15130529543034305
    mean_env_wait_ms: 1.1869703128025078
    mean_inference_ms: 4.526282122434646
    mean_raw_obs_processing_ms: 0.3975322944236152
  time_since_restore: 467.9032828807831
  time_this_iter_s: 29.132062673568726
  time_total_s: 467.9032828807831
  timers:
    learn_throughput: 7312.795
    learn_time_ms: 22124.511
    sample_throughput: 23591.21
    sample_time_ms: 6858.148
    update_time_ms: 33.424
  timestamp: 1602253336
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: b9357_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9357_00000 | RUNNING  | 172.17.0.4:22763 |     16 |          467.903 | 2588672 |  238.349 |              289.202 |              126.172 |            832.031 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9357_00000:
  custom_metrics:
    time_step_max: 4214
    time_step_mean: 3474.901588290252
    time_step_min: 3128
  date: 2020-10-09_14-22-45
  done: false
  episode_len_mean: 829.9567767829577
  episode_reward_max: 292.08080808080797
  episode_reward_mean: 239.5999638247244
  episode_reward_min: 126.1717171717171
  episodes_this_iter: 237
  episodes_total: 3239
  experiment_id: 22118ab98007455c9a569653a8a5057f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8690042116425254
        entropy_coeff: 0.0
        kl: 0.0077272760681807995
        model: {}
        policy_loss: -0.00246855537195436
        total_loss: 18.110904173417524
        vf_explained_var: 0.9745468497276306
        vf_loss: 18.112600499933418
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.1
    gpu_util_percent0: 0.363030303030303
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.806060606060606
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22763
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1510368432122863
    mean_env_wait_ms: 1.1880260098437843
    mean_inference_ms: 4.513636554321224
    mean_raw_obs_processing_ms: 0.39652146884574957
  time_since_restore: 496.8723781108856
  time_this_iter_s: 28.96909523010254
  time_total_s: 496.8723781108856
  timers:
    learn_throughput: 7315.715
    learn_time_ms: 22115.679
    sample_throughput: 23699.211
    sample_time_ms: 6826.894
    update_time_ms: 32.248
  timestamp: 1602253365
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: b9357_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9357_00000 | RUNNING  | 172.17.0.4:22763 |     17 |          496.872 | 2750464 |    239.6 |              292.081 |              126.172 |            829.957 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9357_00000:
  custom_metrics:
    time_step_max: 4214
    time_step_mean: 3467.027842227378
    time_step_min: 3128
  date: 2020-10-09_14-23-14
  done: false
  episode_len_mean: 828.460586881473
  episode_reward_max: 292.08080808080797
  episode_reward_mean: 240.7234049354301
  episode_reward_min: 126.1717171717171
  episodes_this_iter: 237
  episodes_total: 3476
  experiment_id: 22118ab98007455c9a569653a8a5057f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8669653968377546
        entropy_coeff: 0.0
        kl: 0.005602358967404474
        model: {}
        policy_loss: -0.003124676433137872
        total_loss: 13.099708383733576
        vf_explained_var: 0.979870617389679
        vf_loss: 13.102272553877397
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.378125
    gpu_util_percent0: 0.38656250000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.809375
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22763
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15082093017014955
    mean_env_wait_ms: 1.1889907581189911
    mean_inference_ms: 4.502707421191493
    mean_raw_obs_processing_ms: 0.3956797813639115
  time_since_restore: 525.0284481048584
  time_this_iter_s: 28.15606999397278
  time_total_s: 525.0284481048584
  timers:
    learn_throughput: 7335.027
    learn_time_ms: 22057.452
    sample_throughput: 23723.837
    sample_time_ms: 6819.807
    update_time_ms: 32.122
  timestamp: 1602253394
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: b9357_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9357_00000 | RUNNING  | 172.17.0.4:22763 |     18 |          525.028 | 2912256 |  240.723 |              292.081 |              126.172 |            828.461 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9357_00000:
  custom_metrics:
    time_step_max: 4214
    time_step_mean: 3461.869107043816
    time_step_min: 3128
  date: 2020-10-09_14-23-43
  done: false
  episode_len_mean: 827.5803522289489
  episode_reward_max: 292.08080808080797
  episode_reward_mean: 241.54204121567895
  episode_reward_min: 126.1717171717171
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: 22118ab98007455c9a569653a8a5057f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8620001727884467
        entropy_coeff: 0.0
        kl: 0.0071292511949485
        model: {}
        policy_loss: -0.013342279252934863
        total_loss: 11.896947253834117
        vf_explained_var: 0.9770678877830505
        vf_loss: 11.909576416015625
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.950000000000003
    gpu_util_percent0: 0.375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8058823529411767
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22763
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15067953848021337
    mean_env_wait_ms: 1.1895327775904463
    mean_inference_ms: 4.495825013409
    mean_raw_obs_processing_ms: 0.39513580428971196
  time_since_restore: 554.0033528804779
  time_this_iter_s: 28.974904775619507
  time_total_s: 554.0033528804779
  timers:
    learn_throughput: 7337.954
    learn_time_ms: 22048.654
    sample_throughput: 23732.73
    sample_time_ms: 6817.252
    update_time_ms: 31.111
  timestamp: 1602253423
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: b9357_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9357_00000 | RUNNING  | 172.17.0.4:22763 |     19 |          554.003 | 3074048 |  241.542 |              292.081 |              126.172 |             827.58 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9357_00000:
  custom_metrics:
    time_step_max: 4214
    time_step_mean: 3457.127523910733
    time_step_min: 3128
  date: 2020-10-09_14-24-12
  done: false
  episode_len_mean: 826.4944620253165
  episode_reward_max: 292.08080808080797
  episode_reward_mean: 242.33493159442511
  episode_reward_min: 126.1717171717171
  episodes_this_iter: 158
  episodes_total: 3792
  experiment_id: 22118ab98007455c9a569653a8a5057f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8354949409311468
        entropy_coeff: 0.0
        kl: 0.00606557841158726
        model: {}
        policy_loss: -0.005951231917027722
        total_loss: 11.650629997253418
        vf_explained_var: 0.9779437780380249
        vf_loss: 11.655974561517889
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.23939393939394
    gpu_util_percent0: 0.353030303030303
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.866666666666667
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22763
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15054635711292005
    mean_env_wait_ms: 1.1900539794206717
    mean_inference_ms: 4.489316289957131
    mean_raw_obs_processing_ms: 0.39461677915421645
  time_since_restore: 582.9954314231873
  time_this_iter_s: 28.99207854270935
  time_total_s: 582.9954314231873
  timers:
    learn_throughput: 7338.274
    learn_time_ms: 22047.69
    sample_throughput: 23823.128
    sample_time_ms: 6791.384
    update_time_ms: 31.368
  timestamp: 1602253452
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: b9357_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9357_00000 | RUNNING  | 172.17.0.4:22763 |     20 |          582.995 | 3235840 |  242.335 |              292.081 |              126.172 |            826.494 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9357_00000:
  custom_metrics:
    time_step_max: 4214
    time_step_mean: 3446.902463054187
    time_step_min: 3106
  date: 2020-10-09_14-24-41
  done: true
  episode_len_mean: 824.0682485322897
  episode_reward_max: 295.4141414141416
  episode_reward_mean: 243.84402488683298
  episode_reward_min: 126.1717171717171
  episodes_this_iter: 296
  episodes_total: 4088
  experiment_id: 22118ab98007455c9a569653a8a5057f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8096613992344249
        entropy_coeff: 0.0
        kl: 0.00650248977101662
        model: {}
        policy_loss: -0.005041922992942008
        total_loss: 14.56360964341597
        vf_explained_var: 0.9796381592750549
        vf_loss: 14.568001053550027
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.927272727272726
    gpu_util_percent0: 0.35484848484848486
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.790909090909091
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22763
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15031457823955963
    mean_env_wait_ms: 1.1910279595007005
    mean_inference_ms: 4.47802774260912
    mean_raw_obs_processing_ms: 0.3937272367184632
  time_since_restore: 611.9313938617706
  time_this_iter_s: 28.935962438583374
  time_total_s: 611.9313938617706
  timers:
    learn_throughput: 7343.558
    learn_time_ms: 22031.827
    sample_throughput: 23820.081
    sample_time_ms: 6792.252
    update_time_ms: 30.062
  timestamp: 1602253481
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: b9357_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9357_00000 | TERMINATED |       |     21 |          611.931 | 3397632 |  243.844 |              295.414 |              126.172 |            824.068 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9357_00000 | TERMINATED |       |     21 |          611.931 | 3397632 |  243.844 |              295.414 |              126.172 |            824.068 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


