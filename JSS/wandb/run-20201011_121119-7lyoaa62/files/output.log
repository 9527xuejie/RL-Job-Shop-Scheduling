2020-10-11 12:11:23,028	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_e1b55_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=510)[0m 2020-10-11 12:11:25,870	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=472)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=472)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=495)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=495)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=463)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=463)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=468)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=468)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=504)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=504)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=494)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=494)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=467)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=467)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=480)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=480)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=406)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=406)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=496)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=496)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=489)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=489)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=508)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=508)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=512)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=512)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=449)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=449)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=487)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=487)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=470)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=470)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=479)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=479)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=459)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=459)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=500)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=500)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=401)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=401)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=474)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=474)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=450)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=450)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=411)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=411)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=384)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=384)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=396)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=396)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=382)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=382)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=446)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=446)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=402)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=402)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=460)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=460)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=478)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=478)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=505)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=505)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=388)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=388)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=455)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=455)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=399)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=399)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=469)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=469)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=448)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=448)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=442)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=442)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=381)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=381)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=461)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=461)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=483)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=483)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=397)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=397)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=515)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=515)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=452)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=452)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=454)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=454)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=445)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=445)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=498)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=498)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=383)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=383)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=387)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=387)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=391)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=391)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=421)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=421)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=400)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=400)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=394)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=394)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=416)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=416)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=438)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=438)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=413)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=413)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=476)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=476)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=395)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=395)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=407)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=407)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=465)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=465)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=386)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=386)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=418)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=418)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=466)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=466)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=392)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=392)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=380)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=380)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=493)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=493)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=390)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=390)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=456)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=456)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=423)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=423)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=457)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=457)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=485)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=485)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=439)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=439)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=502)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=502)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=385)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=385)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=464)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=464)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=458)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=458)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=453)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=453)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=403)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=403)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=415)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=415)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=471)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=471)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_e1b55_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_12-12-02
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: c250966b40c941a8b817c5cf3b6adc16
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.1799351811408996
        entropy_coeff: 0.0001
        kl: 0.009163967613130809
        model: {}
        policy_loss: -0.022389407735317945
        total_loss: 496.3965576171875
        vf_explained_var: 0.5992882251739502
        vf_loss: 496.4172332763672
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.14594594594595
    gpu_util_percent0: 0.30027027027027026
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5783783783783787
    vram_util_percent0: 0.0910777126749577
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 510
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1679822080258272
    mean_env_wait_ms: 1.162418404932779
    mean_inference_ms: 5.700814278635871
    mean_raw_obs_processing_ms: 0.4437571199045537
  time_since_restore: 31.394636631011963
  time_this_iter_s: 31.394636631011963
  time_total_s: 31.394636631011963
  timers:
    learn_throughput: 7341.032
    learn_time_ms: 22039.407
    sample_throughput: 17446.892
    sample_time_ms: 9273.4
    update_time_ms: 44.714
  timestamp: 1602418322
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: e1b55_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e1b55_00000 | RUNNING  | 172.17.0.4:510 |      1 |          31.3946 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e1b55_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3619.3819444444443
    time_step_min: 3337
  date: 2020-10-11_12-12-32
  done: false
  episode_len_mean: 890.1487341772151
  episode_reward_max: 264.05050505050457
  episode_reward_mean: 215.84471295230765
  episode_reward_min: 123.29292929292909
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: c250966b40c941a8b817c5cf3b6adc16
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.1439732432365417
        entropy_coeff: 0.0001
        kl: 0.009825420193374157
        model: {}
        policy_loss: -0.02416425133123994
        total_loss: 113.76054382324219
        vf_explained_var: 0.8353287577629089
        vf_loss: 113.78285751342773
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.98
    gpu_util_percent0: 0.4382857142857142
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.757142857142857
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 510
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16367234044100826
    mean_env_wait_ms: 1.1614622836684774
    mean_inference_ms: 5.452430792345185
    mean_raw_obs_processing_ms: 0.43385845902003306
  time_since_restore: 61.19264316558838
  time_this_iter_s: 29.798006534576416
  time_total_s: 61.19264316558838
  timers:
    learn_throughput: 7340.848
    learn_time_ms: 22039.959
    sample_throughput: 19186.528
    sample_time_ms: 8432.584
    update_time_ms: 44.279
  timestamp: 1602418352
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: e1b55_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e1b55_00000 | RUNNING  | 172.17.0.4:510 |      2 |          61.1926 | 323584 |  215.845 |              264.051 |              123.293 |            890.149 |
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e1b55_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3620.060538116592
    time_step_min: 3267
  date: 2020-10-11_12-13-01
  done: false
  episode_len_mean: 888.1371308016878
  episode_reward_max: 271.0202020202022
  episode_reward_mean: 216.85609257128226
  episode_reward_min: 123.29292929292909
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: c250966b40c941a8b817c5cf3b6adc16
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.129786241054535
        entropy_coeff: 0.0001
        kl: 0.012502900883555412
        model: {}
        policy_loss: -0.027493705973029137
        total_loss: 40.715406799316405
        vf_explained_var: 0.9306110143661499
        vf_loss: 40.740512466430665
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.203030303030303
    gpu_util_percent0: 0.40303030303030307
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.772727272727273
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 510
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16085429541690682
    mean_env_wait_ms: 1.160565213731138
    mean_inference_ms: 5.270025847664796
    mean_raw_obs_processing_ms: 0.4262026248606476
  time_since_restore: 90.20444917678833
  time_this_iter_s: 29.01180601119995
  time_total_s: 90.20444917678833
  timers:
    learn_throughput: 7351.328
    learn_time_ms: 22008.54
    sample_throughput: 20357.315
    sample_time_ms: 7947.61
    update_time_ms: 43.124
  timestamp: 1602418381
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: e1b55_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e1b55_00000 | RUNNING  | 172.17.0.4:510 |      3 |          90.2044 | 485376 |  216.856 |               271.02 |              123.293 |            888.137 |
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e1b55_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3620.110927152318
    time_step_min: 3267
  date: 2020-10-11_12-13-30
  done: false
  episode_len_mean: 883.6360759493671
  episode_reward_max: 271.0202020202022
  episode_reward_mean: 217.768380002557
  episode_reward_min: 123.29292929292909
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: c250966b40c941a8b817c5cf3b6adc16
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.1123188853263855
        entropy_coeff: 0.0001
        kl: 0.01132758306339383
        model: {}
        policy_loss: -0.027013924717903138
        total_loss: 24.61378002166748
        vf_explained_var: 0.9568639993667603
        vf_loss: 24.63863925933838
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.923529411764704
    gpu_util_percent0: 0.2891176470588236
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7794117647058822
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 510
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15892552283541864
    mean_env_wait_ms: 1.1610794858792932
    mean_inference_ms: 5.139430633210851
    mean_raw_obs_processing_ms: 0.4203416798100646
  time_since_restore: 119.27471971511841
  time_this_iter_s: 29.070270538330078
  time_total_s: 119.27471971511841
  timers:
    learn_throughput: 7345.231
    learn_time_ms: 22026.809
    sample_throughput: 21039.717
    sample_time_ms: 7689.837
    update_time_ms: 39.245
  timestamp: 1602418410
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: e1b55_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e1b55_00000 | RUNNING  | 172.17.0.4:510 |      4 |          119.275 | 647168 |  217.768 |               271.02 |              123.293 |            883.636 |
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e1b55_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3610.8963254593177
    time_step_min: 3235
  date: 2020-10-11_12-13-59
  done: false
  episode_len_mean: 878.4658227848101
  episode_reward_max: 275.86868686868644
  episode_reward_mean: 219.52595576013277
  episode_reward_min: 123.29292929292909
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: c250966b40c941a8b817c5cf3b6adc16
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.0746033430099486
        entropy_coeff: 0.0001
        kl: 0.011191165167838335
        model: {}
        policy_loss: -0.026542939711362123
        total_loss: 21.762293434143068
        vf_explained_var: 0.962584376335144
        vf_loss: 21.78670597076416
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.258823529411764
    gpu_util_percent0: 0.2908823529411765
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7735294117647062
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 510
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15751004791719678
    mean_env_wait_ms: 1.162608804752902
    mean_inference_ms: 5.041700931902052
    mean_raw_obs_processing_ms: 0.4157685299455087
  time_since_restore: 148.3650016784668
  time_this_iter_s: 29.09028196334839
  time_total_s: 148.3650016784668
  timers:
    learn_throughput: 7341.323
    learn_time_ms: 22038.535
    sample_throughput: 21472.059
    sample_time_ms: 7535.002
    update_time_ms: 39.56
  timestamp: 1602418439
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: e1b55_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e1b55_00000 | RUNNING  | 172.17.0.4:510 |      5 |          148.365 | 808960 |  219.526 |              275.869 |              123.293 |            878.466 |
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e1b55_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3591.214953271028
    time_step_min: 3235
  date: 2020-10-11_12-14-28
  done: false
  episode_len_mean: 868.8761384335155
  episode_reward_max: 275.86868686868644
  episode_reward_mean: 221.32350830711468
  episode_reward_min: 123.29292929292909
  episodes_this_iter: 308
  episodes_total: 1098
  experiment_id: c250966b40c941a8b817c5cf3b6adc16
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.0639512419700623
        entropy_coeff: 0.0001
        kl: 0.01023023622110486
        model: {}
        policy_loss: -0.023170785047113895
        total_loss: 33.178314208984375
        vf_explained_var: 0.962297260761261
        vf_loss: 33.19954414367676
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.476470588235298
    gpu_util_percent0: 0.2858823529411764
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7735294117647062
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 510
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15563270311277544
    mean_env_wait_ms: 1.1670285621091558
    mean_inference_ms: 4.913503513873004
    mean_raw_obs_processing_ms: 0.4099257670780637
  time_since_restore: 177.42977237701416
  time_this_iter_s: 29.064770698547363
  time_total_s: 177.42977237701416
  timers:
    learn_throughput: 7335.958
    learn_time_ms: 22054.653
    sample_throughput: 21802.059
    sample_time_ms: 7420.95
    update_time_ms: 37.295
  timestamp: 1602418468
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: e1b55_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e1b55_00000 | RUNNING  | 172.17.0.4:510 |      6 |           177.43 | 970752 |  221.324 |              275.869 |              123.293 |            868.876 |
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e1b55_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3584.6197411003236
    time_step_min: 3235
  date: 2020-10-11_12-14-57
  done: false
  episode_len_mean: 864.5648734177215
  episode_reward_max: 275.86868686868644
  episode_reward_mean: 222.2078698376165
  episode_reward_min: 123.29292929292909
  episodes_this_iter: 166
  episodes_total: 1264
  experiment_id: c250966b40c941a8b817c5cf3b6adc16
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.0617385506629944
        entropy_coeff: 0.0001
        kl: 0.010510526318103074
        model: {}
        policy_loss: -0.027222130820155142
        total_loss: 18.651087951660156
        vf_explained_var: 0.9689925312995911
        vf_loss: 18.67631378173828
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.93235294117647
    gpu_util_percent0: 0.3185294117647059
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7823529411764714
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 510
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15492767378817393
    mean_env_wait_ms: 1.169044442550522
    mean_inference_ms: 4.863580796081313
    mean_raw_obs_processing_ms: 0.4077493738649601
  time_since_restore: 206.3780391216278
  time_this_iter_s: 28.948266744613647
  time_total_s: 206.3780391216278
  timers:
    learn_throughput: 7336.056
    learn_time_ms: 22054.357
    sample_throughput: 22054.631
    sample_time_ms: 7335.965
    update_time_ms: 34.729
  timestamp: 1602418497
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: e1b55_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e1b55_00000 | RUNNING  | 172.17.0.4:510 |      7 |          206.378 | 1132544 |  222.208 |              275.869 |              123.293 |            864.565 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e1b55_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3577.8285509325683
    time_step_min: 3235
  date: 2020-10-11_12-15-27
  done: false
  episode_len_mean: 861.2011251758087
  episode_reward_max: 275.86868686868644
  episode_reward_mean: 223.43794484933707
  episode_reward_min: 123.29292929292909
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: c250966b40c941a8b817c5cf3b6adc16
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.0402146220207213
        entropy_coeff: 0.0001
        kl: 0.010617439169436693
        model: {}
        policy_loss: -0.027036925312131643
        total_loss: 15.829029273986816
        vf_explained_var: 0.9718809127807617
        vf_loss: 15.854046535491943
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.279411764705884
    gpu_util_percent0: 0.4411764705882352
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7823529411764705
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 510
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1543493473864875
    mean_env_wait_ms: 1.170737747314997
    mean_inference_ms: 4.823397065786101
    mean_raw_obs_processing_ms: 0.40592090010719883
  time_since_restore: 235.5049843788147
  time_this_iter_s: 29.12694525718689
  time_total_s: 235.5049843788147
  timers:
    learn_throughput: 7331.24
    learn_time_ms: 22068.844
    sample_throughput: 22229.673
    sample_time_ms: 7278.2
    update_time_ms: 34.499
  timestamp: 1602418527
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: e1b55_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e1b55_00000 | RUNNING  | 172.17.0.4:510 |      8 |          235.505 | 1294336 |  223.438 |              275.869 |              123.293 |            861.201 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e1b55_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3570.4342783505153
    time_step_min: 3235
  date: 2020-10-11_12-15-56
  done: false
  episode_len_mean: 858.4740506329114
  episode_reward_max: 275.86868686868644
  episode_reward_mean: 224.85459020585589
  episode_reward_min: 123.29292929292909
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: c250966b40c941a8b817c5cf3b6adc16
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.0093730211257934
        entropy_coeff: 0.0001
        kl: 0.010841601807624102
        model: {}
        policy_loss: -0.027265441603958607
        total_loss: 14.261428451538086
        vf_explained_var: 0.9726153612136841
        vf_loss: 14.286626434326172
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.533333333333335
    gpu_util_percent0: 0.4693939393939394
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775757575757576
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 510
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1538494948629305
    mean_env_wait_ms: 1.172229110596236
    mean_inference_ms: 4.788636211563227
    mean_raw_obs_processing_ms: 0.4042645109847279
  time_since_restore: 264.5096507072449
  time_this_iter_s: 29.004666328430176
  time_total_s: 264.5096507072449
  timers:
    learn_throughput: 7333.593
    learn_time_ms: 22061.765
    sample_throughput: 22354.326
    sample_time_ms: 7237.615
    update_time_ms: 34.922
  timestamp: 1602418556
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: e1b55_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e1b55_00000 | RUNNING  | 172.17.0.4:510 |      9 |           264.51 | 1456128 |  224.855 |              275.869 |              123.293 |            858.474 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e1b55_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3560.244656917885
    time_step_min: 3216
  date: 2020-10-11_12-16-25
  done: false
  episode_len_mean: 854.9457364341085
  episode_reward_max: 278.7474747474746
  episode_reward_mean: 226.52256787140496
  episode_reward_min: 123.29292929292909
  episodes_this_iter: 226
  episodes_total: 1806
  experiment_id: c250966b40c941a8b817c5cf3b6adc16
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.9729682087898255
        entropy_coeff: 0.0001
        kl: 0.010905965976417065
        model: {}
        policy_loss: -0.026900710165500642
        total_loss: 18.113222503662108
        vf_explained_var: 0.9759072065353394
        vf_loss: 18.13803939819336
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.594285714285718
    gpu_util_percent0: 0.4794285714285715
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.76
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 510
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15323772269857375
    mean_env_wait_ms: 1.1742466016171444
    mean_inference_ms: 4.74699494065339
    mean_raw_obs_processing_ms: 0.4022309116333748
  time_since_restore: 293.8302948474884
  time_this_iter_s: 29.32064414024353
  time_total_s: 293.8302948474884
  timers:
    learn_throughput: 7329.065
    learn_time_ms: 22075.395
    sample_throughput: 22439.366
    sample_time_ms: 7210.186
    update_time_ms: 35.324
  timestamp: 1602418585
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: e1b55_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e1b55_00000 | RUNNING  | 172.17.0.4:510 |     10 |           293.83 | 1617920 |  226.523 |              278.747 |              123.293 |            854.946 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e1b55_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3550.732477788746
    time_step_min: 3179
  date: 2020-10-11_12-16-55
  done: false
  episode_len_mean: 851.8067185978579
  episode_reward_max: 284.3535353535355
  episode_reward_mean: 228.33563974703202
  episode_reward_min: 123.29292929292909
  episodes_this_iter: 248
  episodes_total: 2054
  experiment_id: c250966b40c941a8b817c5cf3b6adc16
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.9790506660938263
        entropy_coeff: 0.0001
        kl: 0.010462676919996739
        model: {}
        policy_loss: -0.027094032801687717
        total_loss: 11.846628952026368
        vf_explained_var: 0.980627179145813
        vf_loss: 11.871728515625
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.24705882352941
    gpu_util_percent0: 0.28058823529411764
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7735294117647062
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 510
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1527215959315573
    mean_env_wait_ms: 1.1762715519277132
    mean_inference_ms: 4.709132041681868
    mean_raw_obs_processing_ms: 0.4004866668306601
  time_since_restore: 323.26061820983887
  time_this_iter_s: 29.430323362350464
  time_total_s: 323.26061820983887
  timers:
    learn_throughput: 7323.569
    learn_time_ms: 22091.962
    sample_throughput: 23126.858
    sample_time_ms: 6995.849
    update_time_ms: 34.435
  timestamp: 1602418615
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: e1b55_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e1b55_00000 | RUNNING  | 172.17.0.4:510 |     11 |          323.261 | 1779712 |  228.336 |              284.354 |              123.293 |            851.807 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e1b55_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3543.260073260073
    time_step_min: 3179
  date: 2020-10-11_12-17-24
  done: false
  episode_len_mean: 849.9009945750452
  episode_reward_max: 284.3535353535355
  episode_reward_mean: 229.4821040422305
  episode_reward_min: 123.29292929292909
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: c250966b40c941a8b817c5cf3b6adc16
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.9582612335681915
        entropy_coeff: 0.0001
        kl: 0.010559653770178557
        model: {}
        policy_loss: -0.029059689678251743
        total_loss: 10.191654586791993
        vf_explained_var: 0.9809468984603882
        vf_loss: 10.218698215484618
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.735294117647054
    gpu_util_percent0: 0.4026470588235294
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7764705882352945
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 510
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15242835813165906
    mean_env_wait_ms: 1.1773471362631778
    mean_inference_ms: 4.688526726450156
    mean_raw_obs_processing_ms: 0.39950670518125836
  time_since_restore: 352.385134935379
  time_this_iter_s: 29.12451672554016
  time_total_s: 352.385134935379
  timers:
    learn_throughput: 7322.924
    learn_time_ms: 22093.906
    sample_throughput: 23331.283
    sample_time_ms: 6934.552
    update_time_ms: 33.335
  timestamp: 1602418644
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: e1b55_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e1b55_00000 | RUNNING  | 172.17.0.4:510 |     12 |          352.385 | 1941504 |  229.482 |              284.354 |              123.293 |            849.901 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e1b55_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3536.6707941929976
    time_step_min: 3179
  date: 2020-10-11_12-17-54
  done: false
  episode_len_mean: 847.9143459915612
  episode_reward_max: 284.3535353535355
  episode_reward_mean: 230.57831479350457
  episode_reward_min: 123.29292929292909
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: c250966b40c941a8b817c5cf3b6adc16
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.9371744573116303
        entropy_coeff: 0.0001
        kl: 0.010782759636640549
        model: {}
        policy_loss: -0.028221168369054795
        total_loss: 10.440719318389892
        vf_explained_var: 0.9791200757026672
        vf_loss: 10.466877841949463
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.173529411764704
    gpu_util_percent0: 0.3423529411764706
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.785294117647059
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 510
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15216420280635234
    mean_env_wait_ms: 1.1783382276307572
    mean_inference_ms: 4.669877274610566
    mean_raw_obs_processing_ms: 0.3986037376434196
  time_since_restore: 381.86093950271606
  time_this_iter_s: 29.475804567337036
  time_total_s: 381.86093950271606
  timers:
    learn_throughput: 7310.193
    learn_time_ms: 22132.385
    sample_throughput: 23307.75
    sample_time_ms: 6941.554
    update_time_ms: 33.158
  timestamp: 1602418674
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: e1b55_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e1b55_00000 | RUNNING  | 172.17.0.4:510 |     13 |          381.861 | 2103296 |  230.578 |              284.354 |              123.293 |            847.914 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e1b55_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3524.6280155642025
    time_step_min: 3128
  date: 2020-10-11_12-18-23
  done: false
  episode_len_mean: 844.8633564280216
  episode_reward_max: 292.08080808080797
  episode_reward_mean: 232.35806097930796
  episode_reward_min: 123.29292929292909
  episodes_this_iter: 228
  episodes_total: 2598
  experiment_id: c250966b40c941a8b817c5cf3b6adc16
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.9008014798164368
        entropy_coeff: 0.0001
        kl: 0.010148439556360245
        model: {}
        policy_loss: -0.027319308556616306
        total_loss: 13.326163578033448
        vf_explained_var: 0.9803694486618042
        vf_loss: 13.351543521881103
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.008823529411767
    gpu_util_percent0: 0.39058823529411757
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.764705882352941
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 510
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1518148677660887
    mean_env_wait_ms: 1.1797631688079575
    mean_inference_ms: 4.645975340496925
    mean_raw_obs_processing_ms: 0.3974243563022586
  time_since_restore: 410.80020236968994
  time_this_iter_s: 28.939262866973877
  time_total_s: 410.80020236968994
  timers:
    learn_throughput: 7311.88
    learn_time_ms: 22127.278
    sample_throughput: 23338.623
    sample_time_ms: 6932.371
    update_time_ms: 32.635
  timestamp: 1602418703
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: e1b55_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e1b55_00000 | RUNNING  | 172.17.0.4:510 |     14 |            410.8 | 2265088 |  232.358 |              292.081 |              123.293 |            844.863 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e1b55_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3514.091619318182
    time_step_min: 3128
  date: 2020-10-11_12-18-52
  done: false
  episode_len_mean: 842.0214486638537
  episode_reward_max: 292.08080808080797
  episode_reward_mean: 233.96052295102922
  episode_reward_min: 123.29292929292909
  episodes_this_iter: 246
  episodes_total: 2844
  experiment_id: c250966b40c941a8b817c5cf3b6adc16
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.9052600383758544
        entropy_coeff: 0.0001
        kl: 0.010046969633549452
        model: {}
        policy_loss: -0.027153751999139785
        total_loss: 12.247693824768067
        vf_explained_var: 0.9801948666572571
        vf_loss: 12.272928619384766
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.590909090909093
    gpu_util_percent0: 0.33848484848484856
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775757575757576
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 510
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15151563913947416
    mean_env_wait_ms: 1.1812208924178553
    mean_inference_ms: 4.62354125167519
    mean_raw_obs_processing_ms: 0.3963828107099102
  time_since_restore: 439.6986725330353
  time_this_iter_s: 28.898470163345337
  time_total_s: 439.6986725330353
  timers:
    learn_throughput: 7314.328
    learn_time_ms: 22119.872
    sample_throughput: 23380.899
    sample_time_ms: 6919.837
    update_time_ms: 32.613
  timestamp: 1602418732
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: e1b55_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e1b55_00000 | RUNNING  | 172.17.0.4:510 |     15 |          439.699 | 2426880 |  233.961 |              292.081 |              123.293 |            842.021 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e1b55_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3507.4828513786147
    time_step_min: 3128
  date: 2020-10-11_12-19-21
  done: false
  episode_len_mean: 840.2544970019986
  episode_reward_max: 292.08080808080797
  episode_reward_mean: 234.84664095989868
  episode_reward_min: 123.29292929292909
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: c250966b40c941a8b817c5cf3b6adc16
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.8862417817115784
        entropy_coeff: 0.0001
        kl: 0.010789969470351934
        model: {}
        policy_loss: -0.029117788560688494
        total_loss: 8.937541198730468
        vf_explained_var: 0.9824325442314148
        vf_loss: 8.964589691162109
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.188235294117646
    gpu_util_percent0: 0.29205882352941176
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7882352941176474
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 510
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15133561511769925
    mean_env_wait_ms: 1.1820757884017679
    mean_inference_ms: 4.610615060441024
    mean_raw_obs_processing_ms: 0.39575726263401056
  time_since_restore: 468.94075179100037
  time_this_iter_s: 29.242079257965088
  time_total_s: 468.94075179100037
  timers:
    learn_throughput: 7308.713
    learn_time_ms: 22136.867
    sample_throughput: 23382.882
    sample_time_ms: 6919.25
    update_time_ms: 33.698
  timestamp: 1602418761
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: e1b55_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e1b55_00000 | RUNNING  | 172.17.0.4:510 |     16 |          468.941 | 2588672 |  234.847 |              292.081 |              123.293 |            840.254 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e1b55_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3501.5003190810467
    time_step_min: 3128
  date: 2020-10-11_12-19-50
  done: false
  episode_len_mean: 838.4266287160025
  episode_reward_max: 292.08080808080797
  episode_reward_mean: 235.74755141548303
  episode_reward_min: 123.29292929292909
  episodes_this_iter: 160
  episodes_total: 3162
  experiment_id: c250966b40c941a8b817c5cf3b6adc16
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.8657396495342254
        entropy_coeff: 0.0001
        kl: 0.011070250254124402
        model: {}
        policy_loss: -0.028276787791401147
        total_loss: 10.049534893035888
        vf_explained_var: 0.9804965853691101
        vf_loss: 10.075684452056885
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.36176470588235
    gpu_util_percent0: 0.32882352941176474
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7823529411764705
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 510
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1511664255007151
    mean_env_wait_ms: 1.1829170464069347
    mean_inference_ms: 4.598429658414409
    mean_raw_obs_processing_ms: 0.39515088419701305
  time_since_restore: 498.1757345199585
  time_this_iter_s: 29.23498272895813
  time_total_s: 498.1757345199585
  timers:
    learn_throughput: 7300.388
    learn_time_ms: 22162.109
    sample_throughput: 23386.165
    sample_time_ms: 6918.278
    update_time_ms: 35.42
  timestamp: 1602418790
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: e1b55_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e1b55_00000 | RUNNING  | 172.17.0.4:510 |     17 |          498.176 | 2750464 |  235.748 |              292.081 |              123.293 |            838.427 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e1b55_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3491.9932630345634
    time_step_min: 3128
  date: 2020-10-11_12-20-19
  done: false
  episode_len_mean: 835.4416037187682
  episode_reward_max: 294.50505050505046
  episode_reward_mean: 237.2999371988331
  episode_reward_min: 123.29292929292909
  episodes_this_iter: 280
  episodes_total: 3442
  experiment_id: c250966b40c941a8b817c5cf3b6adc16
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.850167042016983
        entropy_coeff: 0.0001
        kl: 0.009641105681657791
        model: {}
        policy_loss: -0.02628334555774927
        total_loss: 11.60653371810913
        vf_explained_var: 0.9836215972900391
        vf_loss: 11.630974102020264
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.857575757575756
    gpu_util_percent0: 0.29757575757575766
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.778787878787879
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 510
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15090394555178677
    mean_env_wait_ms: 1.1843483740148832
    mean_inference_ms: 4.579302863223333
    mean_raw_obs_processing_ms: 0.3942199731801606
  time_since_restore: 527.053160905838
  time_this_iter_s: 28.877426385879517
  time_total_s: 527.053160905838
  timers:
    learn_throughput: 7306.796
    learn_time_ms: 22142.673
    sample_throughput: 23410.838
    sample_time_ms: 6910.987
    update_time_ms: 36.008
  timestamp: 1602418819
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: e1b55_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e1b55_00000 | RUNNING  | 172.17.0.4:510 |     18 |          527.053 | 2912256 |    237.3 |              294.505 |              123.293 |            835.442 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e1b55_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3485.991403216861
    time_step_min: 3128
  date: 2020-10-11_12-20-48
  done: false
  episode_len_mean: 833.4988992845349
  episode_reward_max: 294.50505050505046
  episode_reward_mean: 238.26757948221893
  episode_reward_min: 123.29292929292909
  episodes_this_iter: 192
  episodes_total: 3634
  experiment_id: c250966b40c941a8b817c5cf3b6adc16
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.8378308773040771
        entropy_coeff: 0.0001
        kl: 0.00989818163216114
        model: {}
        policy_loss: -0.028901598416268826
        total_loss: 8.472923755645752
        vf_explained_var: 0.9842227697372437
        vf_loss: 8.499929428100586
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.921212121212122
    gpu_util_percent0: 0.34272727272727277
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7818181818181817
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 510
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15074321413734731
    mean_env_wait_ms: 1.1852995862605709
    mean_inference_ms: 4.5675159255942575
    mean_raw_obs_processing_ms: 0.3936504200461163
  time_since_restore: 555.8512172698975
  time_this_iter_s: 28.79805636405945
  time_total_s: 555.8512172698975
  timers:
    learn_throughput: 7307.613
    learn_time_ms: 22140.198
    sample_throughput: 23469.565
    sample_time_ms: 6893.694
    update_time_ms: 33.999
  timestamp: 1602418848
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: e1b55_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e1b55_00000 | RUNNING  | 172.17.0.4:510 |     19 |          555.851 | 3074048 |  238.268 |              294.505 |              123.293 |            833.499 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e1b55_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3480.2417640807653
    time_step_min: 3081
  date: 2020-10-11_12-21-17
  done: false
  episode_len_mean: 831.9760021097046
  episode_reward_max: 299.20202020202044
  episode_reward_mean: 239.06057409538414
  episode_reward_min: 123.29292929292909
  episodes_this_iter: 158
  episodes_total: 3792
  experiment_id: c250966b40c941a8b817c5cf3b6adc16
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.8236041486263275
        entropy_coeff: 0.0001
        kl: 0.010369488876312971
        model: {}
        policy_loss: -0.029850305616855623
        total_loss: 7.332795476913452
        vf_explained_var: 0.984580397605896
        vf_loss: 7.360654354095459
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.249999999999996
    gpu_util_percent0: 0.34911764705882353
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7882352941176474
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 510
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1506187839309709
    mean_env_wait_ms: 1.1860228322965913
    mean_inference_ms: 4.558491806508125
    mean_raw_obs_processing_ms: 0.39320335955402513
  time_since_restore: 584.7108430862427
  time_this_iter_s: 28.859625816345215
  time_total_s: 584.7108430862427
  timers:
    learn_throughput: 7318.825
    learn_time_ms: 22106.281
    sample_throughput: 23501.081
    sample_time_ms: 6884.449
    update_time_ms: 34.57
  timestamp: 1602418877
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: e1b55_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e1b55_00000 | RUNNING  | 172.17.0.4:510 |     20 |          584.711 | 3235840 |  239.061 |              299.202 |              123.293 |            831.976 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e1b55_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3474.275391611925
    time_step_min: 3081
  date: 2020-10-11_12-21-46
  done: true
  episode_len_mean: 830.3497240341194
  episode_reward_max: 299.20202020202044
  episode_reward_mean: 239.94427719239553
  episode_reward_min: 123.29292929292909
  episodes_this_iter: 194
  episodes_total: 3986
  experiment_id: c250966b40c941a8b817c5cf3b6adc16
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.8011045694351197
        entropy_coeff: 0.0001
        kl: 0.010443141032010318
        model: {}
        policy_loss: -0.02891784328967333
        total_loss: 8.905732440948487
        vf_explained_var: 0.9849239587783813
        vf_loss: 8.9326416015625
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.60882352941176
    gpu_util_percent0: 0.31911764705882356
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7764705882352945
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 510
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.150471120825814
    mean_env_wait_ms: 1.1868961738676962
    mean_inference_ms: 4.548088167178412
    mean_raw_obs_processing_ms: 0.3926724724194426
  time_since_restore: 613.6703548431396
  time_this_iter_s: 28.959511756896973
  time_total_s: 613.6703548431396
  timers:
    learn_throughput: 7325.289
    learn_time_ms: 22086.773
    sample_throughput: 23621.488
    sample_time_ms: 6849.357
    update_time_ms: 41.058
  timestamp: 1602418906
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: e1b55_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e1b55_00000 | TERMINATED |       |     21 |           613.67 | 3397632 |  239.944 |              299.202 |              123.293 |             830.35 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e1b55_00000 | TERMINATED |       |     21 |           613.67 | 3397632 |  239.944 |              299.202 |              123.293 |             830.35 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


