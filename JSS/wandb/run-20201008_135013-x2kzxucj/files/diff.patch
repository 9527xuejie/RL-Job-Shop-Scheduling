diff --git a/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb b/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
index 71f6e33..5f8ce7c 100644
--- a/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
+++ b/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
@@ -2,7 +2,7 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 1,
+   "execution_count": 4,
    "metadata": {},
    "outputs": [
     {
@@ -72,15 +72,15 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 2,
+   "execution_count": 5,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Create sweep with ID: mq1j5yvs\n",
-      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/mq1j5yvs\n"
+      "Create sweep with ID: xzzphp80\n",
+      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/xzzphp80\n"
      ]
     }
    ],
@@ -90,7 +90,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": 6,
    "metadata": {},
    "outputs": [
     {
@@ -98,207 +98,207 @@
      "output_type": "stream",
      "text": [
       "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n",
-      "2020-10-08 11:45:48,119 - wandb.wandb_agent - INFO - Running runs: []\n",
-      "2020-10-08 11:45:48,430 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 11:45:48,431 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "2020-10-08 13:03:19,073 - wandb.wandb_agent - INFO - Running runs: []\n",
+      "2020-10-08 13:03:19,445 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-08 13:03:19,446 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
       "\tclip_param: 0.2\n",
       "\tlambda: 0.95\n",
       "\tlr: 0.0001\n",
       "\tnum_envs_per_worker: 2\n",
       "\tnum_sgd_iter: 20\n",
       "\tsgd_minibatch_size: 4096\n",
-      "2020-10-08 11:45:48,434 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=4096\n",
+      "2020-10-08 13:03:19,449 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=4096\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.5 is available!  To upgrade, please run:\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.4\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33musual-sweep-1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mnorthern-sweep-1\u001b[0m\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/mq1j5yvs\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/82d8n3my\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_114550-82d8n3my\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/xzzphp80\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/64siszl4\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_130321-64siszl4\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-08 11:45:52,454\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8268\u001b[39m\u001b[22m\n",
-      "2020-10-08 11:45:53,470 - wandb.wandb_agent - INFO - Running runs: ['82d8n3my']\n",
+      "2020-10-08 13:03:23,547\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8269\u001b[39m\u001b[22m\n",
+      "2020-10-08 13:03:24,482 - wandb.wandb_agent - INFO - Running runs: ['64siszl4']\n",
       "== Status ==\n",
-      "Memory usage on this node: 17.1/754.6 GiB\n",
+      "Memory usage on this node: 37.0/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
       "| Trial name              | status   | loc   |\n",
       "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  |       |\n",
+      "| PPO_jss_env_a66ba_00000 | RUNNING  |       |\n",
       "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=80010)\u001b[0m 2020-10-08 11:45:55,254\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=79990)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79990)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80020)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80020)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79986)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79986)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79996)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79996)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79992)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79992)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79974)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79974)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80017)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80017)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79966)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79966)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79993)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79993)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79977)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79977)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80000)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80000)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79965)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79965)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79975)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79975)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79970)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79970)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80002)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80002)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80012)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80012)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79960)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79960)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79941)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79941)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80004)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80004)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79976)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79976)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79957)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79957)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80006)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80006)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79888)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79888)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79902)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79902)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79901)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79901)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79891)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79891)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79962)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79962)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79879)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79879)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79972)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79972)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79898)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79898)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79985)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79985)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79978)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79978)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79880)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79880)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79895)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79895)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79908)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79908)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79967)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79967)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79875)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79875)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79953)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79953)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79907)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79907)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79968)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79968)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79910)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79910)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79887)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79887)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79878)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79878)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79959)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79959)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79886)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79886)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79958)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79958)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79981)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79981)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79955)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79955)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79948)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79948)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79877)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79877)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79973)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79973)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79917)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79917)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79890)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79890)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79997)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79997)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79964)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79964)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79956)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79956)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79914)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79914)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79942)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79942)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79989)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79989)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79889)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79889)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79900)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79900)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79916)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79916)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79984)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79984)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79885)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79885)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79896)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79896)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79893)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79893)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79876)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79876)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79894)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79894)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79944)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79944)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79904)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79904)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79943)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79943)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79971)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79971)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79969)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79969)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79987)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79987)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79961)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79961)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79952)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79952)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79913)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79913)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79892)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79892)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79963)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79963)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "\u001b[2m\u001b[36m(pid=48420)\u001b[0m 2020-10-08 13:03:26,448\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=48400)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48400)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48456)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48456)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48432)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48432)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48331)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48331)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48342)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48342)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48415)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48415)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48409)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48409)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48430)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48430)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48324)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48324)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48381)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48381)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48315)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48315)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48440)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48440)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48407)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48407)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48399)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48399)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48437)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48437)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48350)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48350)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48444)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48444)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48384)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48384)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48398)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48398)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48428)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48428)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48388)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48388)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48328)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48328)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48435)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48435)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48322)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48322)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48391)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48391)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48422)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48422)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48325)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48325)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48411)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48411)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48421)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48421)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48321)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48321)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48346)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48346)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48404)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48404)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48451)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48451)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48439)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48439)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48338)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48338)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48397)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48397)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48462)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48462)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48412)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48412)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48394)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48394)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48323)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48323)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48327)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48327)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48377)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48377)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48396)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48396)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48406)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48406)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48446)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48446)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48332)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48332)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48344)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48344)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48329)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48329)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48447)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48447)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48395)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48395)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48382)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48382)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48403)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48403)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48341)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48341)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48376)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48376)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48353)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48353)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48335)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48335)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48333)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48333)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48351)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48351)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48417)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48417)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48357)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48357)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48314)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48314)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48373)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48373)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48326)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48326)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48410)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48410)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48352)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48352)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48330)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48330)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48347)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48347)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48393)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48393)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48390)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48390)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48316)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48316)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48402)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48402)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48429)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48429)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48405)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48405)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48383)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48383)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48336)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48336)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48401)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48401)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48379)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48379)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48334)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48334)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48408)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48408)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_a66ba_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_11-46-31\n",
+      "  date: 2020-10-08_13-04-02\n",
       "  done: false\n",
       "  episode_len_mean: 877.1708860759494\n",
       "  episode_reward_max: 273.13131313131294\n",
@@ -306,7 +306,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 158\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -330,59 +330,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.499999999999993\n",
-      "    gpu_util_percent0: 0.2733333333333334\n",
+      "    cpu_util_percent: 32.04857142857142\n",
+      "    gpu_util_percent0: 0.2725714285714285\n",
       "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0002777777777777778\n",
-      "    ram_util_percent: 4.261111111111112\n",
-      "    vram_util_percent0: 0.06302157355781494\n",
+      "    gpu_util_percent2: 0.00028571428571428574\n",
+      "    ram_util_percent: 6.868571428571428\n",
+      "    vram_util_percent0: 0.1419669212388137\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 48420\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16875616228481102\n",
-      "    mean_env_wait_ms: 1.5739218855242776\n",
-      "    mean_inference_ms: 5.591068856691865\n",
-      "    mean_raw_obs_processing_ms: 0.4506270552020118\n",
-      "  time_since_restore: 30.11682629585266\n",
-      "  time_this_iter_s: 30.11682629585266\n",
-      "  time_total_s: 30.11682629585266\n",
+      "    mean_action_processing_ms: 0.17684283761486444\n",
+      "    mean_env_wait_ms: 1.6125988643748705\n",
+      "    mean_inference_ms: 6.031567699271022\n",
+      "    mean_raw_obs_processing_ms: 0.48085302804568264\n",
+      "  time_since_restore: 30.11922836303711\n",
+      "  time_this_iter_s: 30.11922836303711\n",
+      "  time_total_s: 30.11922836303711\n",
       "  timers:\n",
-      "    learn_throughput: 7796.6\n",
-      "    learn_time_ms: 20751.61\n",
-      "    sample_throughput: 17419.067\n",
-      "    sample_time_ms: 9288.213\n",
-      "    update_time_ms: 44.874\n",
-      "  timestamp: 1602157591\n",
+      "    learn_throughput: 8088.741\n",
+      "    learn_time_ms: 20002.124\n",
+      "    sample_throughput: 16103.928\n",
+      "    sample_time_ms: 10046.741\n",
+      "    update_time_ms: 38.232\n",
+      "  timestamp: 1602162242\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 161792\n",
       "  training_iteration: 1\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: a66ba_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 32.9/754.6 GiB\n",
+      "Memory usage on this node: 52.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      1 |          30.1168 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
+      "| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |      1 |          30.1192 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_a66ba_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_11-46-59\n",
+      "  date: 2020-10-08_13-04-30\n",
       "  done: false\n",
       "  episode_len_mean: 869.3417721518987\n",
       "  episode_reward_max: 273.13131313131294\n",
@@ -390,7 +390,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 316\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -414,59 +414,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 26.066666666666663\n",
-      "    gpu_util_percent0: 0.29\n",
+      "    cpu_util_percent: 29.21212121212121\n",
+      "    gpu_util_percent0: 0.2715151515151515\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.451515151515152\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 7.069696969696969\n",
+      "    vram_util_percent0: 0.14890127910790424\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 48420\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1640005638893568\n",
-      "    mean_env_wait_ms: 1.5775274092583902\n",
-      "    mean_inference_ms: 5.302413775269009\n",
-      "    mean_raw_obs_processing_ms: 0.43677931133826275\n",
-      "  time_since_restore: 58.54918050765991\n",
-      "  time_this_iter_s: 28.43235421180725\n",
-      "  time_total_s: 58.54918050765991\n",
+      "    mean_action_processing_ms: 0.17175043990631078\n",
+      "    mean_env_wait_ms: 1.612560008483974\n",
+      "    mean_inference_ms: 5.697708034370405\n",
+      "    mean_raw_obs_processing_ms: 0.4654917298335798\n",
+      "  time_since_restore: 58.14509844779968\n",
+      "  time_this_iter_s: 28.025870084762573\n",
+      "  time_total_s: 58.14509844779968\n",
       "  timers:\n",
-      "    learn_throughput: 7837.771\n",
-      "    learn_time_ms: 20642.602\n",
-      "    sample_throughput: 18926.883\n",
-      "    sample_time_ms: 8548.264\n",
-      "    update_time_ms: 42.329\n",
-      "  timestamp: 1602157619\n",
+      "    learn_throughput: 8179.868\n",
+      "    learn_time_ms: 19779.291\n",
+      "    sample_throughput: 17556.662\n",
+      "    sample_time_ms: 9215.419\n",
+      "    update_time_ms: 38.524\n",
+      "  timestamp: 1602162270\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 323584\n",
       "  training_iteration: 2\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: a66ba_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
+      "Memory usage on this node: 53.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      2 |          58.5492 | 323584 |    224.9 |              273.131 |              115.788 |            869.342 |\n",
+      "| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |      2 |          58.1451 | 323584 |    224.9 |              273.131 |              115.788 |            869.342 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_a66ba_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3247.0\n",
-      "  date: 2020-10-08_11-47-27\n",
+      "  date: 2020-10-08_13-04-58\n",
       "  done: false\n",
       "  episode_len_mean: 864.6983122362869\n",
       "  episode_reward_max: 278.99999999999983\n",
@@ -474,7 +474,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 474\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -498,59 +498,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.75151515151515\n",
-      "    gpu_util_percent0: 0.2918181818181818\n",
+      "    cpu_util_percent: 28.842424242424244\n",
+      "    gpu_util_percent0: 0.26878787878787874\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.466666666666667\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 7.087878787878787\n",
+      "    vram_util_percent0: 0.14890127910790424\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 48420\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1610433593452084\n",
-      "    mean_env_wait_ms: 1.5791339042559354\n",
-      "    mean_inference_ms: 5.141168556600388\n",
-      "    mean_raw_obs_processing_ms: 0.4272760547189869\n",
-      "  time_since_restore: 86.52022004127502\n",
-      "  time_this_iter_s: 27.971039533615112\n",
-      "  time_total_s: 86.52022004127502\n",
+      "    mean_action_processing_ms: 0.16835567750479274\n",
+      "    mean_env_wait_ms: 1.6123591488447364\n",
+      "    mean_inference_ms: 5.500225972412794\n",
+      "    mean_raw_obs_processing_ms: 0.45395802121858475\n",
+      "  time_since_restore: 85.81576776504517\n",
+      "  time_this_iter_s: 27.670669317245483\n",
+      "  time_total_s: 85.81576776504517\n",
       "  timers:\n",
-      "    learn_throughput: 7892.613\n",
-      "    learn_time_ms: 20499.168\n",
-      "    sample_throughput: 19596.92\n",
-      "    sample_time_ms: 8255.991\n",
-      "    update_time_ms: 42.426\n",
-      "  timestamp: 1602157647\n",
+      "    learn_throughput: 8196.573\n",
+      "    learn_time_ms: 19738.98\n",
+      "    sample_throughput: 18409.652\n",
+      "    sample_time_ms: 8788.433\n",
+      "    update_time_ms: 34.699\n",
+      "  timestamp: 1602162298\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 485376\n",
       "  training_iteration: 3\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: a66ba_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
+      "Memory usage on this node: 53.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      3 |          86.5202 | 485376 |  225.522 |                  279 |              115.788 |            864.698 |\n",
+      "| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |      3 |          85.8158 | 485376 |  225.522 |                  279 |              115.788 |            864.698 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_a66ba_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3247.0\n",
-      "  date: 2020-10-08_11-47-55\n",
+      "  date: 2020-10-08_13-05-25\n",
       "  done: false\n",
       "  episode_len_mean: 860.242088607595\n",
       "  episode_reward_max: 278.99999999999983\n",
@@ -558,7 +558,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 632\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -582,59 +582,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.815625\n",
-      "    gpu_util_percent0: 0.26625\n",
+      "    cpu_util_percent: 28.568749999999998\n",
+      "    gpu_util_percent0: 0.30874999999999997\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.46875\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 7.074999999999999\n",
+      "    vram_util_percent0: 0.14890127910790424\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 48420\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1590423832293999\n",
-      "    mean_env_wait_ms: 1.5820174193292231\n",
-      "    mean_inference_ms: 5.0251596991819705\n",
-      "    mean_raw_obs_processing_ms: 0.42029578233494164\n",
-      "  time_since_restore: 114.42771482467651\n",
-      "  time_this_iter_s: 27.90749478340149\n",
-      "  time_total_s: 114.42771482467651\n",
+      "    mean_action_processing_ms: 0.16590883993937328\n",
+      "    mean_env_wait_ms: 1.614039687505855\n",
+      "    mean_inference_ms: 5.354406275754719\n",
+      "    mean_raw_obs_processing_ms: 0.44568708821756753\n",
+      "  time_since_restore: 113.32211327552795\n",
+      "  time_this_iter_s: 27.506345510482788\n",
+      "  time_total_s: 113.32211327552795\n",
       "  timers:\n",
-      "    learn_throughput: 7915.515\n",
-      "    learn_time_ms: 20439.858\n",
-      "    sample_throughput: 20021.505\n",
-      "    sample_time_ms: 8080.911\n",
-      "    update_time_ms: 41.717\n",
-      "  timestamp: 1602157675\n",
+      "    learn_throughput: 8195.223\n",
+      "    learn_time_ms: 19742.233\n",
+      "    sample_throughput: 19008.098\n",
+      "    sample_time_ms: 8511.741\n",
+      "    update_time_ms: 31.179\n",
+      "  timestamp: 1602162325\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 647168\n",
       "  training_iteration: 4\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: a66ba_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 53.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      4 |          114.428 | 647168 |  225.506 |                  279 |              115.788 |            860.242 |\n",
+      "| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |      4 |          113.322 | 647168 |  225.506 |                  279 |              115.788 |            860.242 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_a66ba_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3235.0\n",
-      "  date: 2020-10-08_11-48-23\n",
+      "  date: 2020-10-08_13-05-53\n",
       "  done: false\n",
       "  episode_len_mean: 853.6054421768707\n",
       "  episode_reward_max: 278.99999999999983\n",
@@ -642,7 +642,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 250\n",
       "  episodes_total: 882\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -666,59 +666,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.309374999999996\n",
-      "    gpu_util_percent0: 0.2690625\n",
+      "    cpu_util_percent: 28.196969696969695\n",
+      "    gpu_util_percent0: 0.28151515151515155\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.4593750000000005\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 7.078787878787878\n",
+      "    vram_util_percent0: 0.14890127910790424\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 48420\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1569472608169185\n",
-      "    mean_env_wait_ms: 1.5876407685008682\n",
-      "    mean_inference_ms: 4.901463646021808\n",
-      "    mean_raw_obs_processing_ms: 0.4132403078994484\n",
-      "  time_since_restore: 142.0127465724945\n",
-      "  time_this_iter_s: 27.585031747817993\n",
-      "  time_total_s: 142.0127465724945\n",
+      "    mean_action_processing_ms: 0.16322613586806162\n",
+      "    mean_env_wait_ms: 1.618564715142128\n",
+      "    mean_inference_ms: 5.1965775987407\n",
+      "    mean_raw_obs_processing_ms: 0.43688733469373264\n",
+      "  time_since_restore: 140.94446516036987\n",
+      "  time_this_iter_s: 27.62235188484192\n",
+      "  time_total_s: 140.94446516036987\n",
       "  timers:\n",
-      "    learn_throughput: 7949.618\n",
-      "    learn_time_ms: 20352.173\n",
-      "    sample_throughput: 20316.996\n",
-      "    sample_time_ms: 7963.382\n",
-      "    update_time_ms: 40.79\n",
-      "  timestamp: 1602157703\n",
+      "    learn_throughput: 8201.83\n",
+      "    learn_time_ms: 19726.329\n",
+      "    sample_throughput: 19300.882\n",
+      "    sample_time_ms: 8382.622\n",
+      "    update_time_ms: 33.788\n",
+      "  timestamp: 1602162353\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 808960\n",
       "  training_iteration: 5\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: a66ba_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
+      "Memory usage on this node: 53.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      5 |          142.013 | 808960 |  226.644 |                  279 |              115.788 |            853.605 |\n",
+      "| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |      5 |          140.944 | 808960 |  226.644 |                  279 |              115.788 |            853.605 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_a66ba_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3235.0\n",
-      "  date: 2020-10-08_11-48-50\n",
+      "  date: 2020-10-08_13-06-21\n",
       "  done: false\n",
       "  episode_len_mean: 847.8264014466546\n",
       "  episode_reward_max: 278.99999999999983\n",
@@ -726,7 +726,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 224\n",
       "  episodes_total: 1106\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -750,59 +750,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.978125\n",
-      "    gpu_util_percent0: 0.294375\n",
+      "    cpu_util_percent: 27.91818181818182\n",
+      "    gpu_util_percent0: 0.2675757575757575\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.4625\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 7.093939393939394\n",
+      "    vram_util_percent0: 0.14890127910790424\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 48420\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1557195397072005\n",
-      "    mean_env_wait_ms: 1.5919018099970674\n",
-      "    mean_inference_ms: 4.826965344047954\n",
-      "    mean_raw_obs_processing_ms: 0.4091659356791254\n",
-      "  time_since_restore: 168.97307991981506\n",
-      "  time_this_iter_s: 26.960333347320557\n",
-      "  time_total_s: 168.97307991981506\n",
+      "    mean_action_processing_ms: 0.16170303457671983\n",
+      "    mean_env_wait_ms: 1.6223100669775932\n",
+      "    mean_inference_ms: 5.1020076494140145\n",
+      "    mean_raw_obs_processing_ms: 0.4318509637184022\n",
+      "  time_since_restore: 168.99340772628784\n",
+      "  time_this_iter_s: 28.04894256591797\n",
+      "  time_total_s: 168.99340772628784\n",
       "  timers:\n",
-      "    learn_throughput: 8004.051\n",
-      "    learn_time_ms: 20213.764\n",
-      "    sample_throughput: 20586.195\n",
-      "    sample_time_ms: 7859.248\n",
-      "    update_time_ms: 40.239\n",
-      "  timestamp: 1602157730\n",
+      "    learn_throughput: 8189.649\n",
+      "    learn_time_ms: 19755.669\n",
+      "    sample_throughput: 19458.479\n",
+      "    sample_time_ms: 8314.73\n",
+      "    update_time_ms: 44.893\n",
+      "  timestamp: 1602162381\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 970752\n",
       "  training_iteration: 6\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: a66ba_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 53.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      6 |          168.973 | 970752 |  227.106 |                  279 |              115.788 |            847.826 |\n",
+      "| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |      6 |          168.993 | 970752 |  227.106 |                  279 |              115.788 |            847.826 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_a66ba_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-49-17\n",
+      "  date: 2020-10-08_13-06-49\n",
       "  done: false\n",
       "  episode_len_mean: 844.1083860759494\n",
       "  episode_reward_max: 282.4848484848477\n",
@@ -810,7 +810,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 1264\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -834,59 +834,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.95\n",
-      "    gpu_util_percent0: 0.28812499999999996\n",
+      "    cpu_util_percent: 28.393749999999997\n",
+      "    gpu_util_percent0: 0.2890625\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.475\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 7.09375\n",
+      "    vram_util_percent0: 0.14890127910790424\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 48420\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15503429170730368\n",
-      "    mean_env_wait_ms: 1.594563087955357\n",
-      "    mean_inference_ms: 4.785002724236677\n",
-      "    mean_raw_obs_processing_ms: 0.4068913211080966\n",
-      "  time_since_restore: 195.9782907962799\n",
-      "  time_this_iter_s: 27.005210876464844\n",
-      "  time_total_s: 195.9782907962799\n",
+      "    mean_action_processing_ms: 0.16083207028712804\n",
+      "    mean_env_wait_ms: 1.6246649103902648\n",
+      "    mean_inference_ms: 5.047979912651508\n",
+      "    mean_raw_obs_processing_ms: 0.4289438974397711\n",
+      "  time_since_restore: 196.5391137599945\n",
+      "  time_this_iter_s: 27.545706033706665\n",
+      "  time_total_s: 196.5391137599945\n",
       "  timers:\n",
-      "    learn_throughput: 8045.813\n",
-      "    learn_time_ms: 20108.844\n",
-      "    sample_throughput: 20766.024\n",
-      "    sample_time_ms: 7791.188\n",
-      "    update_time_ms: 38.206\n",
-      "  timestamp: 1602157757\n",
+      "    learn_throughput: 8192.368\n",
+      "    learn_time_ms: 19749.112\n",
+      "    sample_throughput: 19649.458\n",
+      "    sample_time_ms: 8233.917\n",
+      "    update_time_ms: 43.465\n",
+      "  timestamp: 1602162409\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1132544\n",
       "  training_iteration: 7\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: a66ba_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
+      "Memory usage on this node: 53.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      7 |          195.978 | 1132544 |   227.63 |              282.485 |              115.788 |            844.108 |\n",
+      "| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |      7 |          196.539 | 1132544 |   227.63 |              282.485 |              115.788 |            844.108 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_a66ba_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-49-44\n",
+      "  date: 2020-10-08_13-07-17\n",
       "  done: false\n",
       "  episode_len_mean: 840.8741209563995\n",
       "  episode_reward_max: 282.4848484848477\n",
@@ -894,7 +894,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 1422\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -918,59 +918,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.5625\n",
-      "    gpu_util_percent0: 0.2934375\n",
+      "    cpu_util_percent: 28.34375\n",
+      "    gpu_util_percent0: 0.26187499999999997\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.471875\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 7.090624999999999\n",
+      "    vram_util_percent0: 0.14890127910790424\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 48420\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15445205035357232\n",
-      "    mean_env_wait_ms: 1.5970754276033823\n",
-      "    mean_inference_ms: 4.748860951121171\n",
-      "    mean_raw_obs_processing_ms: 0.40491847437517203\n",
-      "  time_since_restore: 223.42373943328857\n",
-      "  time_this_iter_s: 27.445448637008667\n",
-      "  time_total_s: 223.42373943328857\n",
+      "    mean_action_processing_ms: 0.1600692160166658\n",
+      "    mean_env_wait_ms: 1.6269229831056464\n",
+      "    mean_inference_ms: 5.001360241831795\n",
+      "    mean_raw_obs_processing_ms: 0.42636690475877\n",
+      "  time_since_restore: 224.0884222984314\n",
+      "  time_this_iter_s: 27.54930853843689\n",
+      "  time_total_s: 224.0884222984314\n",
       "  timers:\n",
-      "    learn_throughput: 8055.885\n",
-      "    learn_time_ms: 20083.703\n",
-      "    sample_throughput: 20900.724\n",
-      "    sample_time_ms: 7740.976\n",
-      "    update_time_ms: 44.602\n",
-      "  timestamp: 1602157784\n",
+      "    learn_throughput: 8190.648\n",
+      "    learn_time_ms: 19753.259\n",
+      "    sample_throughput: 19817.121\n",
+      "    sample_time_ms: 8164.253\n",
+      "    update_time_ms: 42.962\n",
+      "  timestamp: 1602162437\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1294336\n",
       "  training_iteration: 8\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: a66ba_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 53.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      8 |          223.424 | 1294336 |  227.879 |              282.485 |              115.788 |            840.874 |\n",
+      "| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |      8 |          224.088 | 1294336 |  227.879 |              282.485 |              115.788 |            840.874 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_a66ba_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-50-12\n",
+      "  date: 2020-10-08_13-07-44\n",
       "  done: false\n",
       "  episode_len_mean: 835.0944055944055\n",
       "  episode_reward_max: 282.4848484848477\n",
@@ -978,7 +978,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 294\n",
       "  episodes_total: 1716\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1002,59 +1002,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 26.15625\n",
-      "    gpu_util_percent0: 0.2734375\n",
+      "    cpu_util_percent: 27.893749999999997\n",
+      "    gpu_util_percent0: 0.27468750000000003\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.465625\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 7.081250000000001\n",
+      "    vram_util_percent0: 0.14890127910790424\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 48420\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15359854017386879\n",
-      "    mean_env_wait_ms: 1.601715352177999\n",
-      "    mean_inference_ms: 4.694742071474369\n",
-      "    mean_raw_obs_processing_ms: 0.4019907511305347\n",
-      "  time_since_restore: 250.65174460411072\n",
-      "  time_this_iter_s: 27.228005170822144\n",
-      "  time_total_s: 250.65174460411072\n",
+      "    mean_action_processing_ms: 0.15893424360220432\n",
+      "    mean_env_wait_ms: 1.6312548911336793\n",
+      "    mean_inference_ms: 4.931393440296031\n",
+      "    mean_raw_obs_processing_ms: 0.42259131362554386\n",
+      "  time_since_restore: 251.39063906669617\n",
+      "  time_this_iter_s: 27.30221676826477\n",
+      "  time_total_s: 251.39063906669617\n",
       "  timers:\n",
-      "    learn_throughput: 8078.417\n",
-      "    learn_time_ms: 20027.685\n",
-      "    sample_throughput: 20977.883\n",
-      "    sample_time_ms: 7712.504\n",
-      "    update_time_ms: 43.814\n",
-      "  timestamp: 1602157812\n",
+      "    learn_throughput: 8195.137\n",
+      "    learn_time_ms: 19742.439\n",
+      "    sample_throughput: 19980.359\n",
+      "    sample_time_ms: 8097.552\n",
+      "    update_time_ms: 41.219\n",
+      "  timestamp: 1602162464\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1456128\n",
       "  training_iteration: 9\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: a66ba_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
+      "Memory usage on this node: 53.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      9 |          250.652 | 1456128 |  228.169 |              282.485 |              115.788 |            835.094 |\n",
+      "| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |      9 |          251.391 | 1456128 |  228.169 |              282.485 |              115.788 |            835.094 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_a66ba_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-50-39\n",
+      "  date: 2020-10-08_13-08-12\n",
       "  done: false\n",
       "  episode_len_mean: 832.079641350211\n",
       "  episode_reward_max: 282.4848484848477\n",
@@ -1062,7 +1062,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 180\n",
       "  episodes_total: 1896\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1086,59 +1086,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.484375\n",
-      "    gpu_util_percent0: 0.288125\n",
+      "    cpu_util_percent: 28.2125\n",
+      "    gpu_util_percent0: 0.2575\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.471875\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 7.090624999999999\n",
+      "    vram_util_percent0: 0.14890127910790424\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 48420\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15317220656345867\n",
-      "    mean_env_wait_ms: 1.604245414768565\n",
-      "    mean_inference_ms: 4.668108436640403\n",
-      "    mean_raw_obs_processing_ms: 0.40059241178385674\n",
-      "  time_since_restore: 278.01485896110535\n",
-      "  time_this_iter_s: 27.36311435699463\n",
-      "  time_total_s: 278.01485896110535\n",
+      "    mean_action_processing_ms: 0.15839508313317022\n",
+      "    mean_env_wait_ms: 1.6336331012374383\n",
+      "    mean_inference_ms: 4.8972865076615\n",
+      "    mean_raw_obs_processing_ms: 0.42074921067835536\n",
+      "  time_since_restore: 279.0602397918701\n",
+      "  time_this_iter_s: 27.66960072517395\n",
+      "  time_total_s: 279.0602397918701\n",
       "  timers:\n",
-      "    learn_throughput: 8090.085\n",
-      "    learn_time_ms: 19998.802\n",
-      "    sample_throughput: 21045.891\n",
-      "    sample_time_ms: 7687.581\n",
-      "    update_time_ms: 43.4\n",
-      "  timestamp: 1602157839\n",
+      "    learn_throughput: 8190.217\n",
+      "    learn_time_ms: 19754.3\n",
+      "    sample_throughput: 20073.856\n",
+      "    sample_time_ms: 8059.837\n",
+      "    update_time_ms: 40.691\n",
+      "  timestamp: 1602162492\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1617920\n",
       "  training_iteration: 10\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: a66ba_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 53.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     10 |          278.015 | 1617920 |  228.597 |              282.485 |              115.788 |             832.08 |\n",
+      "| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |     10 |           279.06 | 1617920 |  228.597 |              282.485 |              115.788 |             832.08 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_a66ba_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-51-07\n",
+      "  date: 2020-10-08_13-08-39\n",
       "  done: false\n",
       "  episode_len_mean: 830.1703992210321\n",
       "  episode_reward_max: 282.4848484848477\n",
@@ -1146,7 +1146,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 2054\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1170,59 +1170,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 26.23548387096774\n",
-      "    gpu_util_percent0: 0.26903225806451614\n",
+      "    cpu_util_percent: 27.9375\n",
+      "    gpu_util_percent0: 0.28125\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.47741935483871\n",
-      "    vram_util_percent0: 0.06928501147917349\n",
+      "    ram_util_percent: 7.090624999999999\n",
+      "    vram_util_percent0: 0.14890127910790424\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 48420\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15283766436808183\n",
-      "    mean_env_wait_ms: 1.6062695046004585\n",
-      "    mean_inference_ms: 4.647350806058767\n",
-      "    mean_raw_obs_processing_ms: 0.39949114295740445\n",
-      "  time_since_restore: 305.27174377441406\n",
-      "  time_this_iter_s: 27.256884813308716\n",
-      "  time_total_s: 305.27174377441406\n",
+      "    mean_action_processing_ms: 0.1579654496622953\n",
+      "    mean_env_wait_ms: 1.6355676311935072\n",
+      "    mean_inference_ms: 4.870419542024985\n",
+      "    mean_raw_obs_processing_ms: 0.41930659432398215\n",
+      "  time_since_restore: 306.65611481666565\n",
+      "  time_this_iter_s: 27.595875024795532\n",
+      "  time_total_s: 306.65611481666565\n",
       "  timers:\n",
-      "    learn_throughput: 8137.51\n",
-      "    learn_time_ms: 19882.248\n",
-      "    sample_throughput: 21520.396\n",
-      "    sample_time_ms: 7518.077\n",
-      "    update_time_ms: 41.114\n",
-      "  timestamp: 1602157867\n",
+      "    learn_throughput: 8194.743\n",
+      "    learn_time_ms: 19743.388\n",
+      "    sample_throughput: 20698.258\n",
+      "    sample_time_ms: 7816.697\n",
+      "    update_time_ms: 40.274\n",
+      "  timestamp: 1602162519\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1779712\n",
       "  training_iteration: 11\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: a66ba_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 53.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     11 |          305.272 | 1779712 |  229.068 |              282.485 |              115.788 |             830.17 |\n",
+      "| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |     11 |          306.656 | 1779712 |  229.068 |              282.485 |              115.788 |             830.17 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_a66ba_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-51-34\n",
+      "  date: 2020-10-08_13-09-07\n",
       "  done: false\n",
       "  episode_len_mean: 828.50904159132\n",
       "  episode_reward_max: 287.9191919191919\n",
@@ -1230,7 +1230,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 2212\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1254,59 +1254,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.678787878787883\n",
-      "    gpu_util_percent0: 0.2809090909090909\n",
+      "    cpu_util_percent: 28.03125\n",
+      "    gpu_util_percent0: 0.2884375\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.466666666666667\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 7.096874999999999\n",
+      "    vram_util_percent0: 0.14890127910790424\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 48420\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15253638840628728\n",
-      "    mean_env_wait_ms: 1.6081161690939731\n",
-      "    mean_inference_ms: 4.628595571108588\n",
-      "    mean_raw_obs_processing_ms: 0.39846808184493565\n",
-      "  time_since_restore: 332.607017993927\n",
-      "  time_this_iter_s: 27.33527421951294\n",
-      "  time_total_s: 332.607017993927\n",
+      "    mean_action_processing_ms: 0.15758185014791637\n",
+      "    mean_env_wait_ms: 1.6374025587863599\n",
+      "    mean_inference_ms: 4.8461770891818805\n",
+      "    mean_raw_obs_processing_ms: 0.41798002916463206\n",
+      "  time_since_restore: 333.9199523925781\n",
+      "  time_this_iter_s: 27.263837575912476\n",
+      "  time_total_s: 333.9199523925781\n",
       "  timers:\n",
-      "    learn_throughput: 8176.778\n",
-      "    learn_time_ms: 19786.766\n",
-      "    sample_throughput: 21563.454\n",
-      "    sample_time_ms: 7503.065\n",
-      "    update_time_ms: 41.647\n",
-      "  timestamp: 1602157894\n",
+      "    learn_throughput: 8203.151\n",
+      "    learn_time_ms: 19723.152\n",
+      "    sample_throughput: 20847.854\n",
+      "    sample_time_ms: 7760.607\n",
+      "    update_time_ms: 39.779\n",
+      "  timestamp: 1602162547\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1941504\n",
       "  training_iteration: 12\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: a66ba_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.6/754.6 GiB\n",
+      "Memory usage on this node: 53.5/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     12 |          332.607 | 1941504 |  229.548 |              287.919 |              115.788 |            828.509 |\n",
+      "| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |     12 |           333.92 | 1941504 |  229.548 |              287.919 |              115.788 |            828.509 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_a66ba_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-52-01\n",
+      "  date: 2020-10-08_13-09-35\n",
       "  done: false\n",
       "  episode_len_mean: 825.9173259493671\n",
       "  episode_reward_max: 289.9797979797982\n",
@@ -1314,7 +1314,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 316\n",
       "  episodes_total: 2528\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1338,59 +1338,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.699999999999996\n",
-      "    gpu_util_percent0: 0.2815625\n",
+      "    cpu_util_percent: 28.278787878787877\n",
+      "    gpu_util_percent0: 0.26242424242424245\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.465625\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 7.078787878787878\n",
+      "    vram_util_percent0: 0.14890127910790424\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 48420\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15202521348457168\n",
-      "    mean_env_wait_ms: 1.6115012963552209\n",
-      "    mean_inference_ms: 4.596639178335069\n",
-      "    mean_raw_obs_processing_ms: 0.3967428044141634\n",
-      "  time_since_restore: 359.82592964172363\n",
-      "  time_this_iter_s: 27.21891164779663\n",
-      "  time_total_s: 359.82592964172363\n",
+      "    mean_action_processing_ms: 0.15692756531146781\n",
+      "    mean_env_wait_ms: 1.6407068507668097\n",
+      "    mean_inference_ms: 4.804748256271755\n",
+      "    mean_raw_obs_processing_ms: 0.4157399628394673\n",
+      "  time_since_restore: 361.73055267333984\n",
+      "  time_this_iter_s: 27.81060028076172\n",
+      "  time_total_s: 361.73055267333984\n",
       "  timers:\n",
-      "    learn_throughput: 8195.68\n",
-      "    learn_time_ms: 19741.132\n",
-      "    sample_throughput: 21654.113\n",
-      "    sample_time_ms: 7471.652\n",
-      "    update_time_ms: 42.032\n",
-      "  timestamp: 1602157921\n",
+      "    learn_throughput: 8193.451\n",
+      "    learn_time_ms: 19746.504\n",
+      "    sample_throughput: 20873.804\n",
+      "    sample_time_ms: 7750.959\n",
+      "    update_time_ms: 39.512\n",
+      "  timestamp: 1602162575\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2103296\n",
       "  training_iteration: 13\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: a66ba_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 53.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     13 |          359.826 | 2103296 |  230.738 |               289.98 |              115.788 |            825.917 |\n",
+      "| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |     13 |          361.731 | 2103296 |  230.738 |               289.98 |              115.788 |            825.917 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_a66ba_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-52-29\n",
+      "  date: 2020-10-08_13-10-02\n",
       "  done: false\n",
       "  episode_len_mean: 824.9274013402829\n",
       "  episode_reward_max: 289.9797979797982\n",
@@ -1398,7 +1398,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 2686\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1422,59 +1422,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.40625\n",
-      "    gpu_util_percent0: 0.2846875\n",
+      "    cpu_util_percent: 27.628124999999997\n",
+      "    gpu_util_percent0: 0.270625\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.4781249999999995\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 7.090624999999999\n",
+      "    vram_util_percent0: 0.14890127910790424\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 48420\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15180800096963903\n",
-      "    mean_env_wait_ms: 1.613010827888792\n",
-      "    mean_inference_ms: 4.582932598838708\n",
-      "    mean_raw_obs_processing_ms: 0.39601789200760174\n",
-      "  time_since_restore: 387.4496352672577\n",
-      "  time_this_iter_s: 27.623705625534058\n",
-      "  time_total_s: 387.4496352672577\n",
+      "    mean_action_processing_ms: 0.15664376348269557\n",
+      "    mean_env_wait_ms: 1.642168947228257\n",
+      "    mean_inference_ms: 4.7868873460739\n",
+      "    mean_raw_obs_processing_ms: 0.41477525757369893\n",
+      "  time_since_restore: 389.24887132644653\n",
+      "  time_this_iter_s: 27.51831865310669\n",
+      "  time_total_s: 389.24887132644653\n",
       "  timers:\n",
-      "    learn_throughput: 8204.033\n",
-      "    learn_time_ms: 19721.031\n",
-      "    sample_throughput: 21680.325\n",
-      "    sample_time_ms: 7462.619\n",
-      "    update_time_ms: 41.93\n",
-      "  timestamp: 1602157949\n",
+      "    learn_throughput: 8192.237\n",
+      "    learn_time_ms: 19749.428\n",
+      "    sample_throughput: 20883.748\n",
+      "    sample_time_ms: 7747.268\n",
+      "    update_time_ms: 40.855\n",
+      "  timestamp: 1602162602\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2265088\n",
       "  training_iteration: 14\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: a66ba_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 53.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     14 |           387.45 | 2265088 |  231.187 |               289.98 |              115.788 |            824.927 |\n",
+      "| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |     14 |          389.249 | 2265088 |  231.187 |               289.98 |              115.788 |            824.927 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_a66ba_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-52-57\n",
+      "  date: 2020-10-08_13-10-30\n",
       "  done: false\n",
       "  episode_len_mean: 824.0777074542897\n",
       "  episode_reward_max: 289.9797979797982\n",
@@ -1482,7 +1482,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 2844\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1506,59 +1506,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.83125\n",
-      "    gpu_util_percent0: 0.285625\n",
+      "    cpu_util_percent: 27.75625\n",
+      "    gpu_util_percent0: 0.2996875\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.475\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 7.1\n",
+      "    vram_util_percent0: 0.14890127910790424\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 48420\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15161473875055903\n",
-      "    mean_env_wait_ms: 1.6144244916591914\n",
-      "    mean_inference_ms: 4.570359858195114\n",
-      "    mean_raw_obs_processing_ms: 0.3953474948059144\n",
-      "  time_since_restore: 414.69566917419434\n",
-      "  time_this_iter_s: 27.246033906936646\n",
-      "  time_total_s: 414.69566917419434\n",
+      "    mean_action_processing_ms: 0.15638277949636234\n",
+      "    mean_env_wait_ms: 1.6435161713443915\n",
+      "    mean_inference_ms: 4.770368733513049\n",
+      "    mean_raw_obs_processing_ms: 0.41387653588677614\n",
+      "  time_since_restore: 416.92683267593384\n",
+      "  time_this_iter_s: 27.677961349487305\n",
+      "  time_total_s: 416.92683267593384\n",
       "  timers:\n",
-      "    learn_throughput: 8216.436\n",
-      "    learn_time_ms: 19691.264\n",
-      "    sample_throughput: 21698.645\n",
-      "    sample_time_ms: 7456.318\n",
-      "    update_time_ms: 43.356\n",
-      "  timestamp: 1602157977\n",
+      "    learn_throughput: 8187.713\n",
+      "    learn_time_ms: 19760.342\n",
+      "    sample_throughput: 20895.148\n",
+      "    sample_time_ms: 7743.041\n",
+      "    update_time_ms: 38.352\n",
+      "  timestamp: 1602162630\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2426880\n",
       "  training_iteration: 15\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: a66ba_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 53.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     15 |          414.696 | 2426880 |  231.633 |               289.98 |              115.788 |            824.078 |\n",
+      "| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |     15 |          416.927 | 2426880 |  231.633 |               289.98 |              115.788 |            824.078 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_a66ba_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-53-24\n",
+      "  date: 2020-10-08_13-10-58\n",
       "  done: false\n",
       "  episode_len_mean: 822.9910447761195\n",
       "  episode_reward_max: 289.9797979797982\n",
@@ -1566,7 +1566,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 171\n",
       "  episodes_total: 3015\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1590,59 +1590,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.764516129032256\n",
-      "    gpu_util_percent0: 0.297741935483871\n",
+      "    cpu_util_percent: 27.765625\n",
+      "    gpu_util_percent0: 0.264375\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.470967741935484\n",
-      "    vram_util_percent0: 0.06928501147917349\n",
+      "    ram_util_percent: 7.093749999999999\n",
+      "    vram_util_percent0: 0.14890127910790424\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 48420\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15141989112198903\n",
-      "    mean_env_wait_ms: 1.6159236661106888\n",
-      "    mean_inference_ms: 4.557815570915645\n",
-      "    mean_raw_obs_processing_ms: 0.39467050753293315\n",
-      "  time_since_restore: 441.87632274627686\n",
-      "  time_this_iter_s: 27.18065357208252\n",
-      "  time_total_s: 441.87632274627686\n",
+      "    mean_action_processing_ms: 0.1561274407042432\n",
+      "    mean_env_wait_ms: 1.6449275619289732\n",
+      "    mean_inference_ms: 4.7538760001880425\n",
+      "    mean_raw_obs_processing_ms: 0.41298375172845214\n",
+      "  time_since_restore: 444.42542719841003\n",
+      "  time_this_iter_s: 27.498594522476196\n",
+      "  time_total_s: 444.42542719841003\n",
       "  timers:\n",
-      "    learn_throughput: 8211.786\n",
-      "    learn_time_ms: 19702.413\n",
-      "    sample_throughput: 21667.308\n",
-      "    sample_time_ms: 7467.102\n",
-      "    update_time_ms: 43.552\n",
-      "  timestamp: 1602158004\n",
+      "    learn_throughput: 8205.125\n",
+      "    learn_time_ms: 19718.408\n",
+      "    sample_throughput: 20914.127\n",
+      "    sample_time_ms: 7736.015\n",
+      "    update_time_ms: 32.523\n",
+      "  timestamp: 1602162658\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2588672\n",
       "  training_iteration: 16\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: a66ba_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 53.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     16 |          441.876 | 2588672 |  232.337 |               289.98 |              115.788 |            822.991 |\n",
+      "| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |     16 |          444.425 | 2588672 |  232.337 |               289.98 |              115.788 |            822.991 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_a66ba_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-53-51\n",
+      "  date: 2020-10-08_13-11-25\n",
       "  done: false\n",
       "  episode_len_mean: 821.0216998191681\n",
       "  episode_reward_max: 289.9797979797982\n",
@@ -1650,7 +1650,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 303\n",
       "  episodes_total: 3318\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1674,59 +1674,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.715625000000003\n",
-      "    gpu_util_percent0: 0.301875\n",
+      "    cpu_util_percent: 28.384848484848487\n",
+      "    gpu_util_percent0: 0.2733333333333334\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.4593750000000005\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 7.084848484848485\n",
+      "    vram_util_percent0: 0.14890127910790424\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 48420\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15111617742851072\n",
-      "    mean_env_wait_ms: 1.6183026472863848\n",
-      "    mean_inference_ms: 4.5380869771344665\n",
-      "    mean_raw_obs_processing_ms: 0.3936242667088673\n",
-      "  time_since_restore: 469.05478024482727\n",
-      "  time_this_iter_s: 27.178457498550415\n",
-      "  time_total_s: 469.05478024482727\n",
+      "    mean_action_processing_ms: 0.1557249214530076\n",
+      "    mean_env_wait_ms: 1.6472950848938899\n",
+      "    mean_inference_ms: 4.72807427169106\n",
+      "    mean_raw_obs_processing_ms: 0.41163200120001464\n",
+      "  time_since_restore: 471.9680824279785\n",
+      "  time_this_iter_s: 27.54265522956848\n",
+      "  time_total_s: 471.9680824279785\n",
       "  timers:\n",
-      "    learn_throughput: 8204.084\n",
-      "    learn_time_ms: 19720.91\n",
-      "    sample_throughput: 21655.953\n",
-      "    sample_time_ms: 7471.017\n",
-      "    update_time_ms: 43.943\n",
-      "  timestamp: 1602158031\n",
+      "    learn_throughput: 8203.679\n",
+      "    learn_time_ms: 19721.884\n",
+      "    sample_throughput: 20932.974\n",
+      "    sample_time_ms: 7729.05\n",
+      "    update_time_ms: 33.068\n",
+      "  timestamp: 1602162685\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2750464\n",
       "  training_iteration: 17\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: a66ba_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 53.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     17 |          469.055 | 2750464 |  233.155 |               289.98 |              115.788 |            821.022 |\n",
+      "| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |     17 |          471.968 | 2750464 |  233.155 |               289.98 |              115.788 |            821.022 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_a66ba_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-54-19\n",
+      "  date: 2020-10-08_13-11-53\n",
       "  done: false\n",
       "  episode_len_mean: 820.0376869965478\n",
       "  episode_reward_max: 289.9797979797982\n",
@@ -1734,7 +1734,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 3476\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1758,59 +1758,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.784375\n",
-      "    gpu_util_percent0: 0.2903125\n",
+      "    cpu_util_percent: 28.625\n",
+      "    gpu_util_percent0: 0.2828125\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.481249999999999\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 7.090624999999999\n",
+      "    vram_util_percent0: 0.14890127910790424\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 48420\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15097538572791852\n",
-      "    mean_env_wait_ms: 1.6194704277376637\n",
-      "    mean_inference_ms: 4.52891423862918\n",
-      "    mean_raw_obs_processing_ms: 0.3931393304580003\n",
-      "  time_since_restore: 496.22354912757874\n",
-      "  time_this_iter_s: 27.168768882751465\n",
-      "  time_total_s: 496.22354912757874\n",
+      "    mean_action_processing_ms: 0.15553702279016246\n",
+      "    mean_env_wait_ms: 1.6484300169434907\n",
+      "    mean_inference_ms: 4.716036479297133\n",
+      "    mean_raw_obs_processing_ms: 0.4110046184978835\n",
+      "  time_since_restore: 499.3933494091034\n",
+      "  time_this_iter_s: 27.425266981124878\n",
+      "  time_total_s: 499.3933494091034\n",
       "  timers:\n",
-      "    learn_throughput: 8215.377\n",
-      "    learn_time_ms: 19693.8\n",
-      "    sample_throughput: 21639.305\n",
-      "    sample_time_ms: 7476.765\n",
-      "    update_time_ms: 37.093\n",
-      "  timestamp: 1602158059\n",
+      "    learn_throughput: 8210.879\n",
+      "    learn_time_ms: 19704.59\n",
+      "    sample_throughput: 20925.136\n",
+      "    sample_time_ms: 7731.945\n",
+      "    update_time_ms: 33.368\n",
+      "  timestamp: 1602162713\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2912256\n",
       "  training_iteration: 18\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: a66ba_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 53.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     18 |          496.224 | 2912256 |  233.582 |               289.98 |              115.788 |            820.038 |\n",
+      "| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |     18 |          499.393 | 2912256 |  233.582 |               289.98 |              115.788 |            820.038 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_a66ba_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-54-45\n",
+      "  date: 2020-10-08_13-12-21\n",
       "  done: false\n",
       "  episode_len_mean: 819.1164006604292\n",
       "  episode_reward_max: 289.9797979797982\n",
@@ -1818,7 +1818,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 3634\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1842,59 +1842,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 26.36774193548387\n",
-      "    gpu_util_percent0: 0.30548387096774193\n",
+      "    cpu_util_percent: 27.003030303030304\n",
+      "    gpu_util_percent0: 0.27454545454545454\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.480645161290322\n",
-      "    vram_util_percent0: 0.06928501147917349\n",
+      "    ram_util_percent: 7.109090909090909\n",
+      "    vram_util_percent0: 0.14890127910790424\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 48420\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15084453438607362\n",
-      "    mean_env_wait_ms: 1.6205942190593885\n",
-      "    mean_inference_ms: 4.520349568470547\n",
-      "    mean_raw_obs_processing_ms: 0.3926786361932948\n",
-      "  time_since_restore: 522.9063003063202\n",
-      "  time_this_iter_s: 26.682751178741455\n",
-      "  time_total_s: 522.9063003063202\n",
+      "    mean_action_processing_ms: 0.15536040332395953\n",
+      "    mean_env_wait_ms: 1.6495075288779244\n",
+      "    mean_inference_ms: 4.704714417712872\n",
+      "    mean_raw_obs_processing_ms: 0.4104060889788023\n",
+      "  time_since_restore: 527.4742221832275\n",
+      "  time_this_iter_s: 28.080872774124146\n",
+      "  time_total_s: 527.4742221832275\n",
       "  timers:\n",
-      "    learn_throughput: 8235.447\n",
-      "    learn_time_ms: 19645.806\n",
-      "    sample_throughput: 21635.851\n",
-      "    sample_time_ms: 7477.959\n",
-      "    update_time_ms: 35.387\n",
-      "  timestamp: 1602158085\n",
+      "    learn_throughput: 8198.495\n",
+      "    learn_time_ms: 19734.355\n",
+      "    sample_throughput: 20800.761\n",
+      "    sample_time_ms: 7778.177\n",
+      "    update_time_ms: 34.299\n",
+      "  timestamp: 1602162741\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3074048\n",
       "  training_iteration: 19\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: a66ba_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.6/754.6 GiB\n",
+      "Memory usage on this node: 53.5/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     19 |          522.906 | 3074048 |  234.031 |               289.98 |              115.788 |            819.116 |\n",
+      "| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |     19 |          527.474 | 3074048 |  234.031 |               289.98 |              115.788 |            819.116 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_a66ba_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-55-13\n",
+      "  date: 2020-10-08_13-12-49\n",
       "  done: false\n",
       "  episode_len_mean: 817.554763117677\n",
       "  episode_reward_max: 289.9797979797982\n",
@@ -1902,7 +1902,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 292\n",
       "  episodes_total: 3926\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1926,59 +1926,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.421875\n",
-      "    gpu_util_percent0: 0.2903125\n",
+      "    cpu_util_percent: 27.609375\n",
+      "    gpu_util_percent0: 0.2859375\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.471875000000001\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 7.081249999999999\n",
+      "    vram_util_percent0: 0.14890127910790424\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 48420\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15062615343426108\n",
-      "    mean_env_wait_ms: 1.6226010223295135\n",
-      "    mean_inference_ms: 4.5059904498713115\n",
-      "    mean_raw_obs_processing_ms: 0.3919086060605794\n",
-      "  time_since_restore: 550.2158420085907\n",
-      "  time_this_iter_s: 27.309541702270508\n",
-      "  time_total_s: 550.2158420085907\n",
+      "    mean_action_processing_ms: 0.1550703221428815\n",
+      "    mean_env_wait_ms: 1.651463438051546\n",
+      "    mean_inference_ms: 4.6855771363783765\n",
+      "    mean_raw_obs_processing_ms: 0.4094023764924248\n",
+      "  time_since_restore: 555.0455634593964\n",
+      "  time_this_iter_s: 27.571341276168823\n",
+      "  time_total_s: 555.0455634593964\n",
       "  timers:\n",
-      "    learn_throughput: 8238.594\n",
-      "    learn_time_ms: 19638.301\n",
-      "    sample_throughput: 21617.958\n",
-      "    sample_time_ms: 7484.148\n",
-      "    update_time_ms: 35.351\n",
-      "  timestamp: 1602158113\n",
+      "    learn_throughput: 8208.213\n",
+      "    learn_time_ms: 19710.989\n",
+      "    sample_throughput: 20771.059\n",
+      "    sample_time_ms: 7789.299\n",
+      "    update_time_ms: 35.589\n",
+      "  timestamp: 1602162769\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3235840\n",
       "  training_iteration: 20\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: a66ba_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 53.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     20 |          550.216 | 3235840 |  234.815 |               289.98 |              115.788 |            817.555 |\n",
+      "| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |     20 |          555.046 | 3235840 |  234.815 |               289.98 |              115.788 |            817.555 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_a66ba_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-55-40\n",
+      "  date: 2020-10-08_13-13-17\n",
       "  done: false\n",
       "  episode_len_mean: 816.6701557935735\n",
       "  episode_reward_max: 289.9797979797982\n",
@@ -1986,7 +1986,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 182\n",
       "  episodes_total: 4108\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2010,59 +2010,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.924999999999997\n",
-      "    gpu_util_percent0: 0.301875\n",
+      "    cpu_util_percent: 27.512121212121215\n",
+      "    gpu_util_percent0: 0.26939393939393935\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.481249999999999\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 7.093939393939394\n",
+      "    vram_util_percent0: 0.14890127910790424\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 48420\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15050530919609634\n",
-      "    mean_env_wait_ms: 1.623724292281501\n",
-      "    mean_inference_ms: 4.497921157414929\n",
-      "    mean_raw_obs_processing_ms: 0.3914896591205486\n",
-      "  time_since_restore: 577.2629189491272\n",
-      "  time_this_iter_s: 27.0470769405365\n",
-      "  time_total_s: 577.2629189491272\n",
+      "    mean_action_processing_ms: 0.1548976772280636\n",
+      "    mean_env_wait_ms: 1.6525637514629699\n",
+      "    mean_inference_ms: 4.674894397263583\n",
+      "    mean_raw_obs_processing_ms: 0.40883941125309264\n",
+      "  time_since_restore: 582.9639811515808\n",
+      "  time_this_iter_s: 27.91841769218445\n",
+      "  time_total_s: 582.9639811515808\n",
       "  timers:\n",
-      "    learn_throughput: 8242.44\n",
-      "    learn_time_ms: 19629.139\n",
-      "    sample_throughput: 21663.425\n",
-      "    sample_time_ms: 7468.441\n",
-      "    update_time_ms: 36.165\n",
-      "  timestamp: 1602158140\n",
+      "    learn_throughput: 8208.833\n",
+      "    learn_time_ms: 19709.502\n",
+      "    sample_throughput: 20682.718\n",
+      "    sample_time_ms: 7822.57\n",
+      "    update_time_ms: 34.663\n",
+      "  timestamp: 1602162797\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3397632\n",
       "  training_iteration: 21\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: a66ba_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 53.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     21 |          577.263 | 3397632 |  235.228 |               289.98 |              115.788 |             816.67 |\n",
+      "| PPO_jss_env_a66ba_00000 | RUNNING  | 172.17.0.4:48420 |     21 |          582.964 | 3397632 |  235.228 |               289.98 |              115.788 |             816.67 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_a66ba_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-56-08\n",
+      "  date: 2020-10-08_13-13-45\n",
       "  done: true\n",
       "  episode_len_mean: 815.9498359118612\n",
       "  episode_reward_max: 289.9797979797982\n",
@@ -2070,7 +2070,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 4266\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: e4560d3dcc4a4d75b37d8b4bf7eef4d1\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2094,297 +2094,286 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.875\n",
-      "    gpu_util_percent0: 0.2996875\n",
+      "    cpu_util_percent: 28.2\n",
+      "    gpu_util_percent0: 0.26666666666666666\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.4875\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 7.093939393939394\n",
+      "    vram_util_percent0: 0.14890127910790424\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 48420\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15040791303314213\n",
-      "    mean_env_wait_ms: 1.6246785514214\n",
-      "    mean_inference_ms: 4.4913398893005585\n",
-      "    mean_raw_obs_processing_ms: 0.39114072918445014\n",
-      "  time_since_restore: 604.5293033123016\n",
-      "  time_this_iter_s: 27.26638436317444\n",
-      "  time_total_s: 604.5293033123016\n",
+      "    mean_action_processing_ms: 0.1547595503397134\n",
+      "    mean_env_wait_ms: 1.653500753996499\n",
+      "    mean_inference_ms: 4.666083329815146\n",
+      "    mean_raw_obs_processing_ms: 0.4083720965414222\n",
+      "  time_since_restore: 610.8142249584198\n",
+      "  time_this_iter_s: 27.85024380683899\n",
+      "  time_total_s: 610.8142249584198\n",
       "  timers:\n",
-      "    learn_throughput: 8243.137\n",
-      "    learn_time_ms: 19627.479\n",
-      "    sample_throughput: 21703.935\n",
-      "    sample_time_ms: 7454.501\n",
-      "    update_time_ms: 41.057\n",
-      "  timestamp: 1602158168\n",
+      "    learn_throughput: 8188.645\n",
+      "    learn_time_ms: 19758.093\n",
+      "    sample_throughput: 20657.849\n",
+      "    sample_time_ms: 7831.987\n",
+      "    update_time_ms: 33.895\n",
+      "  timestamp: 1602162825\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3559424\n",
       "  training_iteration: 22\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: a66ba_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 53.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 TERMINATED)\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | TERMINATED |       |     22 |          604.529 | 3559424 |   235.54 |               289.98 |              115.788 |             815.95 |\n",
+      "| PPO_jss_env_a66ba_00000 | TERMINATED |       |     22 |          610.814 | 3559424 |   235.54 |               289.98 |              115.788 |             815.95 |\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
+      "Memory usage on this node: 53.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 TERMINATED)\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | TERMINATED |       |     22 |          604.529 | 3559424 |   235.54 |               289.98 |              115.788 |             815.95 |\n",
+      "| PPO_jss_env_a66ba_00000 | TERMINATED |       |     22 |          610.814 | 3559424 |   235.54 |               289.98 |              115.788 |             815.95 |\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
       "Traceback (most recent call last):\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 2895, in get_loc\n",
-      "    return self._engine.get_loc(casted_key)\n",
-      "  File \"pandas/_libs/index.pyx\", line 70, in pandas._libs.index.IndexEngine.get_loc\n",
-      "  File \"pandas/_libs/index.pyx\", line 101, in pandas._libs.index.IndexEngine.get_loc\n",
-      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1675, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
-      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1683, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
-      "KeyError: 'custom_metrics'\n",
-      "\n",
-      "The above exception was the direct cause of the following exception:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"train.py\", line 66, in <module>\n",
+      "  File \"train.py\", line 68, in <module>\n",
       "    train_func()\n",
-      "  File \"train.py\", line 55, in train_func\n",
-      "    my_custom_metric = result['custom_metrics']\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 2902, in __getitem__\n",
-      "    indexer = self.columns.get_loc(key)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 2897, in get_loc\n",
-      "    raise KeyError(key) from err\n",
-      "KeyError: 'custom_metrics'\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 79778\n",
+      "  File \"train.py\", line 53, in train_func\n",
+      "    result = analysis.dataframe().to_dict('index')[0]\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py\", line 89, in dataframe\n",
+      "    metric = self._validate_metric(metric)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py\", line 64, in _validate_metric\n",
+      "    raise ValueError(\n",
+      "ValueError: No `metric` has been passed and  `default_metric` has not been set. Please specify the `metric` parameter.\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 48214\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201008_114550-82d8n3my/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201008_114550-82d8n3my/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201008_130321-64siszl4/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201008_130321-64siszl4/logs/debug-internal.log\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33musual-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/82d8n3my\u001b[0m\n",
-      "2020-10-08 11:56:16,232 - wandb.wandb_agent - INFO - Cleaning up finished run: 82d8n3my\n",
-      "2020-10-08 11:56:16,524 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 11:56:16,524 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mnorthern-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/64siszl4\u001b[0m\n",
+      "2020-10-08 13:13:52,903 - wandb.wandb_agent - INFO - Cleaning up finished run: 64siszl4\n",
+      "2020-10-08 13:13:53,265 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-08 13:13:53,265 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
       "\tclip_param: 0.2\n",
       "\tlambda: 0.95\n",
       "\tlr: 0.0001\n",
       "\tnum_envs_per_worker: 2\n",
       "\tnum_sgd_iter: 20\n",
       "\tsgd_minibatch_size: 8192\n",
-      "2020-10-08 11:56:16,529 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=8192\n",
+      "2020-10-08 13:13:53,269 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=8192\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.5 is available!  To upgrade, please run:\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.4\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msandy-sweep-2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbalmy-sweep-2\u001b[0m\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/mq1j5yvs\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/uaw0r211\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_115618-uaw0r211\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/xzzphp80\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/wzm01kce\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_131355-wzm01kce\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-08 11:56:20,530\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8268\u001b[39m\u001b[22m\n",
-      "2020-10-08 11:56:21,566 - wandb.wandb_agent - INFO - Running runs: ['uaw0r211']\n",
+      "2020-10-08 13:13:57,407\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8269\u001b[39m\u001b[22m\n",
+      "2020-10-08 13:13:58,302 - wandb.wandb_agent - INFO - Running runs: ['wzm01kce']\n",
       "== Status ==\n",
-      "Memory usage on this node: 17.1/754.6 GiB\n",
+      "Memory usage on this node: 37.0/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
       "| Trial name              | status   | loc   |\n",
       "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_4898a_00000 | RUNNING  |       |\n",
+      "| PPO_jss_env_20482_00000 | RUNNING  |       |\n",
       "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=22161)\u001b[0m 2020-10-08 11:56:23,493\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=22120)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22120)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22113)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22113)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22156)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22156)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22145)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22145)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22167)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22167)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22038)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22038)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22121)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22121)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22035)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22035)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22151)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22151)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22097)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22097)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22051)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22051)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22136)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22136)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22129)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22129)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22115)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22115)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22105)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22105)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22128)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22128)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22059)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22059)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22108)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22108)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22141)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22141)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22101)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22101)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22118)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22118)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22039)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22039)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22160)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22160)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22091)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22091)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22036)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22036)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22060)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22060)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22107)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22107)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22062)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22062)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22154)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22154)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22029)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22029)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22134)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22134)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22103)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22103)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22027)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22027)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22122)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22122)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22024)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22024)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22040)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22040)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22155)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22155)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22084)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22084)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22106)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22106)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22139)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22139)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22081)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22081)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22037)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22037)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22147)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22147)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22048)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22048)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22065)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22065)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22045)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22045)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22142)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22142)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22042)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22042)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22025)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22025)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22033)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22033)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22163)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22163)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22083)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22083)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22058)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22058)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22171)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22171)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22092)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22092)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22053)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22053)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22165)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22165)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22034)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22034)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22028)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22028)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22041)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22041)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22152)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22152)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22026)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22026)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22112)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22112)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22104)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22104)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22054)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22054)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22030)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22030)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22032)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22032)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22131)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22131)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22031)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22031)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22109)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22109)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22050)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22050)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22124)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22124)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22111)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22111)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22110)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22110)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22114)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22114)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22123)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22123)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22133)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22133)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22116)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22116)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22125)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22125)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_4898a_00000:\n",
+      "\u001b[2m\u001b[36m(pid=72926)\u001b[0m 2020-10-08 13:14:00,378\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=72917)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72917)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72923)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72923)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72877)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72877)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72902)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72902)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72910)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72910)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72884)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72884)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72897)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72897)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72932)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72932)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72889)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72889)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72894)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72894)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72919)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72919)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72909)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72909)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72936)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72936)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72924)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72924)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72879)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72879)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72921)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72921)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72882)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72882)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72914)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72914)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72898)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72898)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72892)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72892)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72825)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72825)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72803)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72803)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72818)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72818)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72891)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72891)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72835)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72835)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72808)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72808)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72794)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72794)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72868)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72868)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72795)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72795)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72885)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72885)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72890)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72890)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72912)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72912)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72883)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72883)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72893)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72893)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72827)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72827)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72878)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72878)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72896)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72896)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72798)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72798)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72796)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72796)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72801)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72801)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72805)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72805)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72809)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72809)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72793)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72793)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72866)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72866)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72832)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72832)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72810)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72810)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72887)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72887)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72864)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72864)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72874)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72874)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72806)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72806)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72834)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72834)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72802)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72802)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72807)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72807)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72880)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72880)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72870)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72870)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72799)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72799)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72881)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72881)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72867)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72867)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72804)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72804)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72863)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72863)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72901)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72901)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72907)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72907)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72939)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72939)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72800)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72800)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72905)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72905)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72828)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72828)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72821)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72821)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72875)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72875)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72812)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72812)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72931)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72931)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72888)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72888)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72872)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72872)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72823)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72823)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72876)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72876)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72797)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72797)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72811)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72811)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72873)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72873)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72831)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72831)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=72930)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=72930)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_20482_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_11-56-55\n",
+      "  date: 2020-10-08_13-14-32\n",
       "  done: false\n",
       "  episode_len_mean: 877.1708860759494\n",
       "  episode_reward_max: 273.13131313131294\n",
@@ -2392,7 +2381,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 158\n",
-      "  experiment_id: 8196fe3f2c5c4e22af63c11ec84b6459\n",
+      "  experiment_id: e019eb488f504d908d1b8cde01a67779\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2416,59 +2405,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 32.55\n",
-      "    gpu_util_percent0: 0.22966666666666669\n",
+      "    cpu_util_percent: 34.854838709677416\n",
+      "    gpu_util_percent0: 0.40387096774193554\n",
       "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.250000000000002\n",
-      "    vram_util_percent0: 0.06902809664370832\n",
+      "    gpu_util_percent2: 0.0003225806451612903\n",
+      "    ram_util_percent: 6.858064516129033\n",
+      "    vram_util_percent0: 0.14882192998233162\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 22161\n",
+      "  pid: 72926\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17109087125207587\n",
-      "    mean_env_wait_ms: 1.5727916416028063\n",
-      "    mean_inference_ms: 5.579640846923753\n",
-      "    mean_raw_obs_processing_ms: 0.4581124033961777\n",
-      "  time_since_restore: 25.996026754379272\n",
-      "  time_this_iter_s: 25.996026754379272\n",
-      "  time_total_s: 25.996026754379272\n",
+      "    mean_action_processing_ms: 0.17311963301891525\n",
+      "    mean_env_wait_ms: 1.619766967905344\n",
+      "    mean_inference_ms: 5.664909503532803\n",
+      "    mean_raw_obs_processing_ms: 0.4645348331301843\n",
+      "  time_since_restore: 26.242305755615234\n",
+      "  time_this_iter_s: 26.242305755615234\n",
+      "  time_total_s: 26.242305755615234\n",
       "  timers:\n",
-      "    learn_throughput: 9708.757\n",
-      "    learn_time_ms: 16664.542\n",
-      "    sample_throughput: 17496.047\n",
-      "    sample_time_ms: 9247.346\n",
-      "    update_time_ms: 51.617\n",
-      "  timestamp: 1602158215\n",
+      "    learn_throughput: 9691.785\n",
+      "    learn_time_ms: 16693.726\n",
+      "    sample_throughput: 17069.205\n",
+      "    sample_time_ms: 9478.59\n",
+      "    update_time_ms: 32.62\n",
+      "  timestamp: 1602162872\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 161792\n",
       "  training_iteration: 1\n",
-      "  trial_id: 4898a_00000\n",
+      "  trial_id: '20482_00000'\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 32.9/754.6 GiB\n",
+      "Memory usage on this node: 52.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_4898a_00000 | RUNNING  | 172.17.0.4:22161 |      1 |           25.996 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
+      "| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |      1 |          26.2423 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_4898a_00000:\n",
+      "Result for PPO_jss_env_20482_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3265.0\n",
-      "  date: 2020-10-08_11-57-19\n",
+      "  date: 2020-10-08_13-14-57\n",
       "  done: false\n",
       "  episode_len_mean: 873.4715189873418\n",
       "  episode_reward_max: 274.85858585858557\n",
@@ -2476,7 +2465,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 316\n",
-      "  experiment_id: 8196fe3f2c5c4e22af63c11ec84b6459\n",
+      "  experiment_id: e019eb488f504d908d1b8cde01a67779\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2500,50 +2489,2377 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.485714285714288\n",
-      "    gpu_util_percent0: 0.1157142857142857\n",
+      "    cpu_util_percent: 33.272413793103446\n",
+      "    gpu_util_percent0: 0.1520689655172414\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 7.065517241379309\n",
+      "    vram_util_percent0: 0.16005247622171206\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 72926\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1687145306260058\n",
+      "    mean_env_wait_ms: 1.6153583995147767\n",
+      "    mean_inference_ms: 5.397734435135553\n",
+      "    mean_raw_obs_processing_ms: 0.4536503960134253\n",
+      "  time_since_restore: 51.10045146942139\n",
+      "  time_this_iter_s: 24.858145713806152\n",
+      "  time_total_s: 51.10045146942139\n",
+      "  timers:\n",
+      "    learn_throughput: 9795.667\n",
+      "    learn_time_ms: 16516.69\n",
+      "    sample_throughput: 18051.956\n",
+      "    sample_time_ms: 8962.574\n",
+      "    update_time_ms: 26.347\n",
+      "  timestamp: 1602162897\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 323584\n",
+      "  training_iteration: 2\n",
+      "  trial_id: '20482_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 53.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |      2 |          51.1005 | 323584 |  227.369 |              274.859 |              115.788 |            873.472 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_20482_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3265.0\n",
+      "  date: 2020-10-08_13-15-22\n",
+      "  done: false\n",
+      "  episode_len_mean: 867.8713080168776\n",
+      "  episode_reward_max: 274.85858585858557\n",
+      "  episode_reward_mean: 228.246196138601\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 474\n",
+      "  experiment_id: e019eb488f504d908d1b8cde01a67779\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 1.1271256804466248\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.007389193354174495\n",
+      "        model: {}\n",
+      "        policy_loss: -0.018508310522884132\n",
+      "        total_loss: 6.457739639282226\n",
+      "        vf_explained_var: 0.9464155435562134\n",
+      "        vf_loss: 6.4747700691223145\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
+      "  iterations_since_restore: 3\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.04\n",
+      "    gpu_util_percent0: 0.4126666666666666\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 7.0699999999999985\n",
+      "    vram_util_percent0: 0.16005247622171206\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 72926\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1657725376814399\n",
+      "    mean_env_wait_ms: 1.6143474174526447\n",
+      "    mean_inference_ms: 5.2544808037270725\n",
+      "    mean_raw_obs_processing_ms: 0.4459664380596616\n",
+      "  time_since_restore: 75.95954275131226\n",
+      "  time_this_iter_s: 24.85909128189087\n",
+      "  time_total_s: 75.95954275131226\n",
+      "  timers:\n",
+      "    learn_throughput: 9815.193\n",
+      "    learn_time_ms: 16483.832\n",
+      "    sample_throughput: 18464.91\n",
+      "    sample_time_ms: 8762.133\n",
+      "    update_time_ms: 25.762\n",
+      "  timestamp: 1602162922\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 485376\n",
+      "  training_iteration: 3\n",
+      "  trial_id: '20482_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 53.1/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |      3 |          75.9595 | 485376 |  228.246 |              274.859 |              115.788 |            867.871 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_20482_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3230.0\n",
+      "  date: 2020-10-08_13-15-46\n",
+      "  done: false\n",
+      "  episode_len_mean: 862.3544303797469\n",
+      "  episode_reward_max: 278.70707070707056\n",
+      "  episode_reward_mean: 230.3964326812426\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 632\n",
+      "  experiment_id: e019eb488f504d908d1b8cde01a67779\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 1.0996861219406129\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.008276985818520188\n",
+      "        model: {}\n",
+      "        policy_loss: -0.020328705292195083\n",
+      "        total_loss: 5.005046558380127\n",
+      "        vf_explained_var: 0.9697187542915344\n",
+      "        vf_loss: 5.023719763755798\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
+      "  iterations_since_restore: 4\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.686206896551724\n",
+      "    gpu_util_percent0: 0.37241379310344824\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 7.058620689655171\n",
+      "    vram_util_percent0: 0.16005247622171206\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 72926\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16370989334392427\n",
+      "    mean_env_wait_ms: 1.6160268086005207\n",
+      "    mean_inference_ms: 5.150723377241317\n",
+      "    mean_raw_obs_processing_ms: 0.44028141144316024\n",
+      "  time_since_restore: 100.53206896781921\n",
+      "  time_this_iter_s: 24.572526216506958\n",
+      "  time_total_s: 100.53206896781921\n",
+      "  timers:\n",
+      "    learn_throughput: 9846.583\n",
+      "    learn_time_ms: 16431.283\n",
+      "    sample_throughput: 18801.772\n",
+      "    sample_time_ms: 8605.146\n",
+      "    update_time_ms: 29.099\n",
+      "  timestamp: 1602162946\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 647168\n",
+      "  training_iteration: 4\n",
+      "  trial_id: '20482_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 53.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |      4 |          100.532 | 647168 |  230.396 |              278.707 |              115.788 |            862.354 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_20482_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3223.0\n",
+      "  date: 2020-10-08_13-16-11\n",
+      "  done: false\n",
+      "  episode_len_mean: 852.6247216035634\n",
+      "  episode_reward_max: 278.70707070707056\n",
+      "  episode_reward_mean: 231.18069334773102\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 266\n",
+      "  episodes_total: 898\n",
+      "  experiment_id: e019eb488f504d908d1b8cde01a67779\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 1.0624429881572723\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.0077964670956134794\n",
+      "        model: {}\n",
+      "        policy_loss: -0.02084309732308611\n",
+      "        total_loss: 7.683893799781799\n",
+      "        vf_explained_var: 0.9791978597640991\n",
+      "        vf_loss: 7.703177666664123\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
+      "  iterations_since_restore: 5\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.542857142857144\n",
+      "    gpu_util_percent0: 0.03\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 7.121428571428571\n",
+      "    vram_util_percent0: 0.16005247622171206\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 72926\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16154215177554349\n",
+      "    mean_env_wait_ms: 1.622384708687623\n",
+      "    mean_inference_ms: 5.032478173228996\n",
+      "    mean_raw_obs_processing_ms: 0.43396318661457844\n",
+      "  time_since_restore: 124.77606844902039\n",
+      "  time_this_iter_s: 24.243999481201172\n",
+      "  time_total_s: 124.77606844902039\n",
+      "  timers:\n",
+      "    learn_throughput: 9848.951\n",
+      "    learn_time_ms: 16427.333\n",
+      "    sample_throughput: 19182.267\n",
+      "    sample_time_ms: 8434.457\n",
+      "    update_time_ms: 30.214\n",
+      "  timestamp: 1602162971\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 808960\n",
+      "  training_iteration: 5\n",
+      "  trial_id: '20482_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 53.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |      5 |          124.776 | 808960 |  231.181 |              278.707 |              115.788 |            852.625 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_20482_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3223.0\n",
+      "  date: 2020-10-08_13-16-35\n",
+      "  done: false\n",
+      "  episode_len_mean: 846.0479204339964\n",
+      "  episode_reward_max: 278.70707070707056\n",
+      "  episode_reward_mean: 231.96029919447625\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 208\n",
+      "  episodes_total: 1106\n",
+      "  experiment_id: e019eb488f504d908d1b8cde01a67779\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 1.0738083600997925\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.007217544643208384\n",
+      "        model: {}\n",
+      "        policy_loss: -0.02225890466943383\n",
+      "        total_loss: 4.545075726509094\n",
+      "        vf_explained_var: 0.9842392206192017\n",
+      "        vf_loss: 4.565891194343567\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
+      "  iterations_since_restore: 6\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.48275862068966\n",
+      "    gpu_util_percent0: 0.3993103448275862\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 7.072413793103447\n",
+      "    vram_util_percent0: 0.16005247622171206\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 72926\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1602743259590165\n",
+      "    mean_env_wait_ms: 1.6261454318768824\n",
+      "    mean_inference_ms: 4.968356024071804\n",
+      "    mean_raw_obs_processing_ms: 0.43045935101156774\n",
+      "  time_since_restore: 149.21555709838867\n",
+      "  time_this_iter_s: 24.439488649368286\n",
+      "  time_total_s: 149.21555709838867\n",
+      "  timers:\n",
+      "    learn_throughput: 9854.247\n",
+      "    learn_time_ms: 16418.504\n",
+      "    sample_throughput: 19357.003\n",
+      "    sample_time_ms: 8358.319\n",
+      "    update_time_ms: 31.743\n",
+      "  timestamp: 1602162995\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 970752\n",
+      "  training_iteration: 6\n",
+      "  trial_id: '20482_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 53.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |      6 |          149.216 | 970752 |   231.96 |              278.707 |              115.788 |            846.048 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_20482_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3170.0\n",
+      "  date: 2020-10-08_13-17-00\n",
+      "  done: false\n",
+      "  episode_len_mean: 841.3995253164557\n",
+      "  episode_reward_max: 284.4040404040406\n",
+      "  episode_reward_mean: 232.7926815624599\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1264\n",
+      "  experiment_id: e019eb488f504d908d1b8cde01a67779\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 1.0473353922367097\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.006994991353712976\n",
+      "        model: {}\n",
+      "        policy_loss: -0.022564191045239566\n",
+      "        total_loss: 4.000831997394561\n",
+      "        vf_explained_var: 0.9874190092086792\n",
+      "        vf_loss: 4.021997082233429\n",
+      "    num_steps_sampled: 1132544\n",
+      "    num_steps_trained: 1132544\n",
+      "  iterations_since_restore: 7\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.05\n",
+      "    gpu_util_percent0: 0.03607142857142857\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 7.1392857142857125\n",
+      "    vram_util_percent0: 0.16005247622171206\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 72926\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15954332548416084\n",
+      "    mean_env_wait_ms: 1.6290227853591808\n",
+      "    mean_inference_ms: 4.928510157079865\n",
+      "    mean_raw_obs_processing_ms: 0.4282714927763549\n",
+      "  time_since_restore: 173.52936792373657\n",
+      "  time_this_iter_s: 24.3138108253479\n",
+      "  time_total_s: 173.52936792373657\n",
+      "  timers:\n",
+      "    learn_throughput: 9848.427\n",
+      "    learn_time_ms: 16428.207\n",
+      "    sample_throughput: 19565.936\n",
+      "    sample_time_ms: 8269.065\n",
+      "    update_time_ms: 33.207\n",
+      "  timestamp: 1602163020\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1132544\n",
+      "  training_iteration: 7\n",
+      "  trial_id: '20482_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 53.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |      7 |          173.529 | 1132544 |  232.793 |              284.404 |              115.788 |              841.4 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_20482_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3170.0\n",
+      "  date: 2020-10-08_13-17-24\n",
+      "  done: false\n",
+      "  episode_len_mean: 837.3713080168776\n",
+      "  episode_reward_max: 284.4040404040406\n",
+      "  episode_reward_mean: 233.61432184006011\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1422\n",
+      "  experiment_id: e019eb488f504d908d1b8cde01a67779\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 1.01868434548378\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.007189809367991984\n",
+      "        model: {}\n",
+      "        policy_loss: -0.023347471375018358\n",
+      "        total_loss: 3.781139385700226\n",
+      "        vf_explained_var: 0.9891014099121094\n",
+      "        vf_loss: 3.803048861026764\n",
+      "    num_steps_sampled: 1294336\n",
+      "    num_steps_trained: 1294336\n",
+      "  iterations_since_restore: 8\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.237931034482756\n",
+      "    gpu_util_percent0: 0.3775862068965518\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 7.075862068965516\n",
+      "    vram_util_percent0: 0.16005247622171206\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 72926\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15891368528149816\n",
+      "    mean_env_wait_ms: 1.6319569838817485\n",
+      "    mean_inference_ms: 4.893836789565313\n",
+      "    mean_raw_obs_processing_ms: 0.42634126208708445\n",
+      "  time_since_restore: 197.79426956176758\n",
+      "  time_this_iter_s: 24.264901638031006\n",
+      "  time_total_s: 197.79426956176758\n",
+      "  timers:\n",
+      "    learn_throughput: 9856.304\n",
+      "    learn_time_ms: 16415.078\n",
+      "    sample_throughput: 19687.49\n",
+      "    sample_time_ms: 8218.011\n",
+      "    update_time_ms: 31.869\n",
+      "  timestamp: 1602163044\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1294336\n",
+      "  training_iteration: 8\n",
+      "  trial_id: '20482_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 53.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |      8 |          197.794 | 1294336 |  233.614 |              284.404 |              115.788 |            837.371 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_20482_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_13-17-49\n",
+      "  done: false\n",
+      "  episode_len_mean: 829.8141542002302\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 235.34277179156337\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 1738\n",
+      "  experiment_id: e019eb488f504d908d1b8cde01a67779\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.9904811769723892\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.006311689200811088\n",
+      "        model: {}\n",
+      "        policy_loss: -0.020997717510908842\n",
+      "        total_loss: 5.1504497051239015\n",
+      "        vf_explained_var: 0.9909344911575317\n",
+      "        vf_loss: 5.170185089111328\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
+      "  iterations_since_restore: 9\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.67931034482759\n",
+      "    gpu_util_percent0: 0.38068965517241377\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 7.055172413793103\n",
+      "    vram_util_percent0: 0.16005247622171206\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 72926\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.157959829699883\n",
+      "    mean_env_wait_ms: 1.6378718810700204\n",
+      "    mean_inference_ms: 4.838743156811552\n",
+      "    mean_raw_obs_processing_ms: 0.42330816479094296\n",
+      "  time_since_restore: 222.32361674308777\n",
+      "  time_this_iter_s: 24.52934718132019\n",
+      "  time_total_s: 222.32361674308777\n",
+      "  timers:\n",
+      "    learn_throughput: 9853.853\n",
+      "    learn_time_ms: 16419.161\n",
+      "    sample_throughput: 19753.396\n",
+      "    sample_time_ms: 8190.592\n",
+      "    update_time_ms: 32.175\n",
+      "  timestamp: 1602163069\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1456128\n",
+      "  training_iteration: 9\n",
+      "  trial_id: '20482_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 53.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |      9 |          222.324 | 1456128 |  235.343 |              290.242 |              115.788 |            829.814 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_20482_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_13-18-13\n",
+      "  done: false\n",
+      "  episode_len_mean: 826.4541139240506\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 235.7108905510803\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1896\n",
+      "  experiment_id: e019eb488f504d908d1b8cde01a67779\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.9730047971010208\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.006372990598902106\n",
+      "        model: {}\n",
+      "        policy_loss: -0.022790615819394587\n",
+      "        total_loss: 3.343014180660248\n",
+      "        vf_explained_var: 0.9915106892585754\n",
+      "        vf_loss: 3.3645302057266235\n",
+      "    num_steps_sampled: 1617920\n",
+      "    num_steps_trained: 1617920\n",
+      "  iterations_since_restore: 10\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.08214285714286\n",
+      "    gpu_util_percent0: 0.16285714285714287\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 7.103571428571428\n",
+      "    vram_util_percent0: 0.16005247622171206\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 72926\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15757910819338425\n",
+      "    mean_env_wait_ms: 1.6406169640202375\n",
+      "    mean_inference_ms: 4.816179947756191\n",
+      "    mean_raw_obs_processing_ms: 0.42204263109223905\n",
+      "  time_since_restore: 246.7284791469574\n",
+      "  time_this_iter_s: 24.40486240386963\n",
+      "  time_total_s: 246.7284791469574\n",
+      "  timers:\n",
+      "    learn_throughput: 9847.675\n",
+      "    learn_time_ms: 16429.462\n",
+      "    sample_throughput: 19849.195\n",
+      "    sample_time_ms: 8151.061\n",
+      "    update_time_ms: 32.321\n",
+      "  timestamp: 1602163093\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1617920\n",
+      "  training_iteration: 10\n",
+      "  trial_id: '20482_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 53.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |     10 |          246.728 | 1617920 |  235.711 |              290.242 |              115.788 |            826.454 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_20482_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_13-18-38\n",
+      "  done: false\n",
+      "  episode_len_mean: 823.6002921129503\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 236.65748035368276\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2054\n",
+      "  experiment_id: e019eb488f504d908d1b8cde01a67779\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.9577732890844345\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.006211055861786008\n",
+      "        model: {}\n",
+      "        policy_loss: -0.022765795403392984\n",
+      "        total_loss: 3.0192813992500307\n",
+      "        vf_explained_var: 0.9923363924026489\n",
+      "        vf_loss: 3.0408049702644346\n",
+      "    num_steps_sampled: 1779712\n",
+      "    num_steps_trained: 1779712\n",
+      "  iterations_since_restore: 11\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.77857142857143\n",
+      "    gpu_util_percent0: 0.16107142857142856\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 7.142857142857141\n",
+      "    vram_util_percent0: 0.16005247622171206\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 72926\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15723552203389532\n",
+      "    mean_env_wait_ms: 1.6431788542353838\n",
+      "    mean_inference_ms: 4.795565785178838\n",
+      "    mean_raw_obs_processing_ms: 0.4208698540707466\n",
+      "  time_since_restore: 271.224684715271\n",
+      "  time_this_iter_s: 24.4962055683136\n",
+      "  time_total_s: 271.224684715271\n",
+      "  timers:\n",
+      "    learn_throughput: 9852.058\n",
+      "    learn_time_ms: 16422.153\n",
+      "    sample_throughput: 20269.288\n",
+      "    sample_time_ms: 7982.126\n",
+      "    update_time_ms: 32.124\n",
+      "  timestamp: 1602163118\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1779712\n",
+      "  training_iteration: 11\n",
+      "  trial_id: '20482_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 53.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |     11 |          271.225 | 1779712 |  236.657 |              290.242 |              115.788 |              823.6 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_20482_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_13-19-02\n",
+      "  done: false\n",
+      "  episode_len_mean: 820.2957437472576\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 237.36838769440774\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 225\n",
+      "  episodes_total: 2279\n",
+      "  experiment_id: e019eb488f504d908d1b8cde01a67779\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.9244333893060684\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.006004941323772073\n",
+      "        model: {}\n",
+      "        policy_loss: -0.021168453525751828\n",
+      "        total_loss: 4.074023377895355\n",
+      "        vf_explained_var: 0.9932994842529297\n",
+      "        vf_loss: 4.093990921974182\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 12\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.49655172413793\n",
+      "    gpu_util_percent0: 0.37827586206896546\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 7.065517241379308\n",
+      "    vram_util_percent0: 0.16005247622171206\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 72926\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15679164845732013\n",
+      "    mean_env_wait_ms: 1.6467252365879843\n",
+      "    mean_inference_ms: 4.769134762898821\n",
+      "    mean_raw_obs_processing_ms: 0.4193369791609706\n",
+      "  time_since_restore: 295.67071437835693\n",
+      "  time_this_iter_s: 24.446029663085938\n",
+      "  time_total_s: 295.67071437835693\n",
+      "  timers:\n",
+      "    learn_throughput: 9849.111\n",
+      "    learn_time_ms: 16427.067\n",
+      "    sample_throughput: 20390.396\n",
+      "    sample_time_ms: 7934.716\n",
+      "    update_time_ms: 32.684\n",
+      "  timestamp: 1602163142\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 12\n",
+      "  trial_id: '20482_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 53.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |     12 |          295.671 | 1941504 |  237.368 |              290.242 |              115.788 |            820.296 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_20482_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_13-19-27\n",
+      "  done: false\n",
+      "  episode_len_mean: 817.5490506329114\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 238.05452068149842\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 249\n",
+      "  episodes_total: 2528\n",
+      "  experiment_id: e019eb488f504d908d1b8cde01a67779\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.9116032361984253\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.0059999656863510605\n",
+      "        model: {}\n",
+      "        policy_loss: -0.020421561488183214\n",
+      "        total_loss: 3.2677656054496764\n",
+      "        vf_explained_var: 0.9931272268295288\n",
+      "        vf_loss: 3.2869871616363526\n",
+      "    num_steps_sampled: 2103296\n",
+      "    num_steps_trained: 2103296\n",
+      "  iterations_since_restore: 13\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.06785714285714\n",
+      "    gpu_util_percent0: 0.38392857142857134\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 7.057142857142856\n",
+      "    vram_util_percent0: 0.16005247622171206\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 72926\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15638443382274794\n",
+      "    mean_env_wait_ms: 1.6501725119830468\n",
+      "    mean_inference_ms: 4.744610246890177\n",
+      "    mean_raw_obs_processing_ms: 0.4179913954280996\n",
+      "  time_since_restore: 320.09689450263977\n",
+      "  time_this_iter_s: 24.426180124282837\n",
+      "  time_total_s: 320.09689450263977\n",
+      "  timers:\n",
+      "    learn_throughput: 9847.161\n",
+      "    learn_time_ms: 16430.32\n",
+      "    sample_throughput: 20512.946\n",
+      "    sample_time_ms: 7887.312\n",
+      "    update_time_ms: 32.655\n",
+      "  timestamp: 1602163167\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2103296\n",
+      "  training_iteration: 13\n",
+      "  trial_id: '20482_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 53.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |     13 |          320.097 | 2103296 |  238.055 |              290.242 |              115.788 |            817.549 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_20482_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_13-19-51\n",
+      "  done: false\n",
+      "  episode_len_mean: 816.2442293373045\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 238.46138225140444\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2686\n",
+      "  experiment_id: e019eb488f504d908d1b8cde01a67779\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.9013321816921234\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.006421135948039591\n",
+      "        model: {}\n",
+      "        policy_loss: -0.021805241936817765\n",
+      "        total_loss: 2.9366058349609374\n",
+      "        vf_explained_var: 0.9931826591491699\n",
+      "        vf_loss: 2.9571268558502197\n",
+      "    num_steps_sampled: 2265088\n",
+      "    num_steps_trained: 2265088\n",
+      "  iterations_since_restore: 14\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.646428571428565\n",
+      "    gpu_util_percent0: 0.16392857142857142\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 7.099999999999999\n",
+      "    vram_util_percent0: 0.16005247622171206\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 72926\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15614529648189554\n",
+      "    mean_env_wait_ms: 1.6521389750754119\n",
+      "    mean_inference_ms: 4.73053241417009\n",
+      "    mean_raw_obs_processing_ms: 0.41720474865082524\n",
+      "  time_since_restore: 344.41752886772156\n",
+      "  time_this_iter_s: 24.320634365081787\n",
+      "  time_total_s: 344.41752886772156\n",
+      "  timers:\n",
+      "    learn_throughput: 9837.776\n",
+      "    learn_time_ms: 16445.994\n",
+      "    sample_throughput: 20599.986\n",
+      "    sample_time_ms: 7853.986\n",
+      "    update_time_ms: 30.91\n",
+      "  timestamp: 1602163191\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2265088\n",
+      "  training_iteration: 14\n",
+      "  trial_id: '20482_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 53.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |     14 |          344.418 | 2265088 |  238.461 |              290.242 |              115.788 |            816.244 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_20482_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_13-20-16\n",
+      "  done: false\n",
+      "  episode_len_mean: 814.502106741573\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 238.95662736919752\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 162\n",
+      "  episodes_total: 2848\n",
+      "  experiment_id: e019eb488f504d908d1b8cde01a67779\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.8737345904111862\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.005880716699175536\n",
+      "        model: {}\n",
+      "        policy_loss: -0.023541058914270253\n",
+      "        total_loss: 2.77874299287796\n",
+      "        vf_explained_var: 0.9943079948425293\n",
+      "        vf_loss: 2.801107919216156\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 15\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.07931034482758\n",
+      "    gpu_util_percent0: 0.35724137931034483\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 7.068965517241378\n",
+      "    vram_util_percent0: 0.16005247622171206\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 72926\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15591428798709747\n",
+      "    mean_env_wait_ms: 1.6541309900562287\n",
+      "    mean_inference_ms: 4.717179349715265\n",
+      "    mean_raw_obs_processing_ms: 0.41645872662204997\n",
+      "  time_since_restore: 368.9808130264282\n",
+      "  time_this_iter_s: 24.563284158706665\n",
+      "  time_total_s: 368.9808130264282\n",
+      "  timers:\n",
+      "    learn_throughput: 9834.907\n",
+      "    learn_time_ms: 16450.791\n",
+      "    sample_throughput: 20538.191\n",
+      "    sample_time_ms: 7877.617\n",
+      "    update_time_ms: 31.814\n",
+      "  timestamp: 1602163216\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 15\n",
+      "  trial_id: '20482_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 53.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |     15 |          368.981 | 2426880 |  238.957 |              290.242 |              115.788 |            814.502 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_20482_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_13-20-41\n",
+      "  done: false\n",
+      "  episode_len_mean: 811.5661392405063\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 239.56847270170044\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 312\n",
+      "  episodes_total: 3160\n",
+      "  experiment_id: e019eb488f504d908d1b8cde01a67779\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.836417630314827\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.005600748467259109\n",
+      "        model: {}\n",
+      "        policy_loss: -0.019153478858061134\n",
+      "        total_loss: 3.4916038155555724\n",
+      "        vf_explained_var: 0.9944165349006653\n",
+      "        vf_loss: 3.5096370816230773\n",
+      "    num_steps_sampled: 2588672\n",
+      "    num_steps_trained: 2588672\n",
+      "  iterations_since_restore: 16\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.385714285714286\n",
+      "    gpu_util_percent0: 0.012499999999999999\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 7.124999999999998\n",
+      "    vram_util_percent0: 0.16005247622171206\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 72926\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1555265162232438\n",
+      "    mean_env_wait_ms: 1.657691166928328\n",
+      "    mean_inference_ms: 4.694226265108467\n",
+      "    mean_raw_obs_processing_ms: 0.4151903011455144\n",
+      "  time_since_restore: 393.6567976474762\n",
+      "  time_this_iter_s: 24.675984621047974\n",
+      "  time_total_s: 393.6567976474762\n",
+      "  timers:\n",
+      "    learn_throughput: 9819.613\n",
+      "    learn_time_ms: 16476.413\n",
+      "    sample_throughput: 20548.693\n",
+      "    sample_time_ms: 7873.591\n",
+      "    update_time_ms: 32.324\n",
+      "  timestamp: 1602163241\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2588672\n",
+      "  training_iteration: 16\n",
+      "  trial_id: '20482_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 53.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |     16 |          393.657 | 2588672 |  239.568 |              290.242 |              115.788 |            811.566 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_20482_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_13-21-05\n",
+      "  done: false\n",
+      "  episode_len_mean: 810.3282097649186\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 239.7355501975754\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 3318\n",
+      "  experiment_id: e019eb488f504d908d1b8cde01a67779\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.8335719257593155\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.006123062083497643\n",
+      "        model: {}\n",
+      "        policy_loss: -0.020987965818494558\n",
+      "        total_loss: 2.507720983028412\n",
+      "        vf_explained_var: 0.9944343566894531\n",
+      "        vf_loss: 2.5274842858314512\n",
+      "    num_steps_sampled: 2750464\n",
+      "    num_steps_trained: 2750464\n",
+      "  iterations_since_restore: 17\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.658620689655166\n",
+      "    gpu_util_percent0: 0.01103448275862069\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 7.1275862068965505\n",
+      "    vram_util_percent0: 0.16005247622171206\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 72926\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15535230640052955\n",
+      "    mean_env_wait_ms: 1.659385700950701\n",
+      "    mean_inference_ms: 4.683905191630317\n",
+      "    mean_raw_obs_processing_ms: 0.41463069133714486\n",
+      "  time_since_restore: 418.1674716472626\n",
+      "  time_this_iter_s: 24.510673999786377\n",
+      "  time_total_s: 418.1674716472626\n",
+      "  timers:\n",
+      "    learn_throughput: 9812.797\n",
+      "    learn_time_ms: 16487.858\n",
+      "    sample_throughput: 20527.515\n",
+      "    sample_time_ms: 7881.714\n",
+      "    update_time_ms: 31.791\n",
+      "  timestamp: 1602163265\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2750464\n",
+      "  training_iteration: 17\n",
+      "  trial_id: '20482_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 53.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |     17 |          418.167 | 2750464 |  239.736 |              290.242 |              115.788 |            810.328 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_20482_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_13-21-30\n",
+      "  done: false\n",
+      "  episode_len_mean: 809.0097813578826\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 239.89810649649536\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 3476\n",
+      "  experiment_id: e019eb488f504d908d1b8cde01a67779\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.830751609802246\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.005981297581456602\n",
+      "        model: {}\n",
+      "        policy_loss: -0.023448871518485247\n",
+      "        total_loss: 2.440117084980011\n",
+      "        vf_explained_var: 0.994672954082489\n",
+      "        vf_loss: 2.462369680404663\n",
+      "    num_steps_sampled: 2912256\n",
+      "    num_steps_trained: 2912256\n",
+      "  iterations_since_restore: 18\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.66206896551724\n",
+      "    gpu_util_percent0: 0.43655172413793103\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 7.079310344827585\n",
+      "    vram_util_percent0: 0.16005247622171206\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 72926\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15518911270894606\n",
+      "    mean_env_wait_ms: 1.66104596928502\n",
+      "    mean_inference_ms: 4.674219672029851\n",
+      "    mean_raw_obs_processing_ms: 0.41409634295401404\n",
+      "  time_since_restore: 442.4850378036499\n",
+      "  time_this_iter_s: 24.31756615638733\n",
+      "  time_total_s: 442.4850378036499\n",
+      "  timers:\n",
+      "    learn_throughput: 9812.073\n",
+      "    learn_time_ms: 16489.075\n",
+      "    sample_throughput: 20521.455\n",
+      "    sample_time_ms: 7884.041\n",
+      "    update_time_ms: 33.291\n",
+      "  timestamp: 1602163290\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2912256\n",
+      "  training_iteration: 18\n",
+      "  trial_id: '20482_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 53.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |     18 |          442.485 | 2912256 |  239.898 |              290.242 |              115.788 |             809.01 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_20482_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_13-21-55\n",
+      "  done: false\n",
+      "  episode_len_mean: 806.8230485232068\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 240.2267639474917\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 3792\n",
+      "  experiment_id: e019eb488f504d908d1b8cde01a67779\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.7929262965917587\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.005467748525552452\n",
+      "        model: {}\n",
+      "        policy_loss: -0.018968340079300105\n",
+      "        total_loss: 3.431827688217163\n",
+      "        vf_explained_var: 0.9950782060623169\n",
+      "        vf_loss: 3.4497024059295653\n",
+      "    num_steps_sampled: 3074048\n",
+      "    num_steps_trained: 3074048\n",
+      "  iterations_since_restore: 19\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.84642857142857\n",
+      "    gpu_util_percent0: 0.20142857142857146\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 7.092857142857142\n",
+      "    vram_util_percent0: 0.16005247622171206\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 72926\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15489375855306428\n",
+      "    mean_env_wait_ms: 1.6642226976233971\n",
+      "    mean_inference_ms: 4.65674052024899\n",
+      "    mean_raw_obs_processing_ms: 0.41315027526725906\n",
+      "  time_since_restore: 466.97452116012573\n",
+      "  time_this_iter_s: 24.48948335647583\n",
+      "  time_total_s: 466.97452116012573\n",
+      "  timers:\n",
+      "    learn_throughput: 9814.608\n",
+      "    learn_time_ms: 16484.815\n",
+      "    sample_throughput: 20517.495\n",
+      "    sample_time_ms: 7885.563\n",
+      "    update_time_ms: 33.174\n",
+      "  timestamp: 1602163315\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3074048\n",
+      "  training_iteration: 19\n",
+      "  trial_id: '20482_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 53.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |     19 |          466.975 | 3074048 |  240.227 |              290.242 |              115.788 |            806.823 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_20482_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_13-22-19\n",
+      "  done: false\n",
+      "  episode_len_mean: 805.7225316455696\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 240.49984400971735\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 3950\n",
+      "  experiment_id: e019eb488f504d908d1b8cde01a67779\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.7794228792190552\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.005526655982248485\n",
+      "        model: {}\n",
+      "        policy_loss: -0.023039081250317395\n",
+      "        total_loss: 2.078591358661652\n",
+      "        vf_explained_var: 0.9953739047050476\n",
+      "        vf_loss: 2.1005250751972198\n",
+      "    num_steps_sampled: 3235840\n",
+      "    num_steps_trained: 3235840\n",
+      "  iterations_since_restore: 20\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.603448275862068\n",
+      "    gpu_util_percent0: 0.3510344827586207\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 7.075862068965516\n",
+      "    vram_util_percent0: 0.16005247622171206\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 72926\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15476163632995826\n",
+      "    mean_env_wait_ms: 1.6656993184585767\n",
+      "    mean_inference_ms: 4.6488134213727434\n",
+      "    mean_raw_obs_processing_ms: 0.41272395699835374\n",
+      "  time_since_restore: 491.4215154647827\n",
+      "  time_this_iter_s: 24.446994304656982\n",
+      "  time_total_s: 491.4215154647827\n",
+      "  timers:\n",
+      "    learn_throughput: 9817.173\n",
+      "    learn_time_ms: 16480.508\n",
+      "    sample_throughput: 20496.13\n",
+      "    sample_time_ms: 7893.783\n",
+      "    update_time_ms: 32.3\n",
+      "  timestamp: 1602163339\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3235840\n",
+      "  training_iteration: 20\n",
+      "  trial_id: '20482_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 53.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |     20 |          491.422 | 3235840 |    240.5 |              290.242 |              115.788 |            805.723 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_20482_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_13-22-44\n",
+      "  done: false\n",
+      "  episode_len_mean: 804.7280915287245\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 240.70876486382807\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 4108\n",
+      "  experiment_id: e019eb488f504d908d1b8cde01a67779\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.7865538984537125\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.005757506913505494\n",
+      "        model: {}\n",
+      "        policy_loss: -0.02310952057596296\n",
+      "        total_loss: 1.973700213432312\n",
+      "        vf_explained_var: 0.9953605532646179\n",
+      "        vf_loss: 1.9956582367420197\n",
+      "    num_steps_sampled: 3397632\n",
+      "    num_steps_trained: 3397632\n",
+      "  iterations_since_restore: 21\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.621428571428574\n",
+      "    gpu_util_percent0: 0.11714285714285715\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 7.107142857142855\n",
+      "    vram_util_percent0: 0.16005247622171206\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 72926\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15463826788744325\n",
+      "    mean_env_wait_ms: 1.6671296389951276\n",
+      "    mean_inference_ms: 4.641298983375448\n",
+      "    mean_raw_obs_processing_ms: 0.41231589636433646\n",
+      "  time_since_restore: 515.9117021560669\n",
+      "  time_this_iter_s: 24.49018669128418\n",
+      "  time_total_s: 515.9117021560669\n",
+      "  timers:\n",
+      "    learn_throughput: 9821.901\n",
+      "    learn_time_ms: 16472.574\n",
+      "    sample_throughput: 20477.444\n",
+      "    sample_time_ms: 7900.986\n",
+      "    update_time_ms: 31.054\n",
+      "  timestamp: 1602163364\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3397632\n",
+      "  training_iteration: 21\n",
+      "  trial_id: '20482_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 53.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |     21 |          515.912 | 3397632 |  240.709 |              290.242 |              115.788 |            804.728 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_20482_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_13-23-09\n",
+      "  done: false\n",
+      "  episode_len_mean: 803.1457812144644\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 241.09711855879692\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 289\n",
+      "  episodes_total: 4397\n",
+      "  experiment_id: e019eb488f504d908d1b8cde01a67779\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.755255714058876\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.005404739850200712\n",
+      "        model: {}\n",
+      "        policy_loss: -0.019464567000977696\n",
+      "        total_loss: 3.0453175783157347\n",
+      "        vf_explained_var: 0.9953736066818237\n",
+      "        vf_loss: 3.0637012124061584\n",
+      "    num_steps_sampled: 3559424\n",
+      "    num_steps_trained: 3559424\n",
+      "  iterations_since_restore: 22\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.451724137931027\n",
+      "    gpu_util_percent0: 0.3524137931034483\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 7.058620689655171\n",
+      "    vram_util_percent0: 0.16005247622171206\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 72926\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15443164992451375\n",
+      "    mean_env_wait_ms: 1.6696716376955234\n",
+      "    mean_inference_ms: 4.628641353057089\n",
+      "    mean_raw_obs_processing_ms: 0.4116237338549396\n",
+      "  time_since_restore: 540.5083248615265\n",
+      "  time_this_iter_s: 24.596622705459595\n",
+      "  time_total_s: 540.5083248615265\n",
+      "  timers:\n",
+      "    learn_throughput: 9807.284\n",
+      "    learn_time_ms: 16497.126\n",
+      "    sample_throughput: 20505.923\n",
+      "    sample_time_ms: 7890.013\n",
+      "    update_time_ms: 31.487\n",
+      "  timestamp: 1602163389\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3559424\n",
+      "  training_iteration: 22\n",
+      "  trial_id: '20482_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 53.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |     22 |          540.508 | 3559424 |  241.097 |              290.242 |              115.788 |            803.146 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_20482_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_13-23-34\n",
+      "  done: false\n",
+      "  episode_len_mean: 802.2247926669577\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 241.27666671075653\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 185\n",
+      "  episodes_total: 4582\n",
+      "  experiment_id: e019eb488f504d908d1b8cde01a67779\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.7225345104932785\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.005478021572344005\n",
+      "        model: {}\n",
+      "        policy_loss: -0.022186438925564288\n",
+      "        total_loss: 1.9642526030540466\n",
+      "        vf_explained_var: 0.9957612752914429\n",
+      "        vf_loss: 1.9853434622287751\n",
+      "    num_steps_sampled: 3721216\n",
+      "    num_steps_trained: 3721216\n",
+      "  iterations_since_restore: 23\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.3551724137931\n",
+      "    gpu_util_percent0: 0.24517241379310345\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 7.082758620689654\n",
+      "    vram_util_percent0: 0.16005247622171206\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 72926\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15430947095824407\n",
+      "    mean_env_wait_ms: 1.6711400307873732\n",
+      "    mean_inference_ms: 4.621209545345874\n",
+      "    mean_raw_obs_processing_ms: 0.41122162004541535\n",
+      "  time_since_restore: 565.12957072258\n",
+      "  time_this_iter_s: 24.621245861053467\n",
+      "  time_total_s: 565.12957072258\n",
+      "  timers:\n",
+      "    learn_throughput: 9811.099\n",
+      "    learn_time_ms: 16490.712\n",
+      "    sample_throughput: 20444.354\n",
+      "    sample_time_ms: 7913.774\n",
+      "    update_time_ms: 33.107\n",
+      "  timestamp: 1602163414\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3721216\n",
+      "  training_iteration: 23\n",
+      "  trial_id: '20482_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 53.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |     23 |           565.13 | 3721216 |  241.277 |              290.242 |              115.788 |            802.225 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_20482_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_13-23-59\n",
+      "  done: false\n",
+      "  episode_len_mean: 801.512447257384\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 241.5184460640156\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 4740\n",
+      "  experiment_id: e019eb488f504d908d1b8cde01a67779\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.7451686680316925\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.005771003756672144\n",
+      "        model: {}\n",
+      "        policy_loss: -0.024150656536221504\n",
+      "        total_loss: 1.7480961799621582\n",
+      "        vf_explained_var: 0.9958817362785339\n",
+      "        vf_loss: 1.7710926413536072\n",
+      "    num_steps_sampled: 3883008\n",
+      "    num_steps_trained: 3883008\n",
+      "  iterations_since_restore: 24\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.700000000000003\n",
+      "    gpu_util_percent0: 0.2286206896551724\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 7.141379310344825\n",
+      "    vram_util_percent0: 0.16005247622171206\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 72926\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15421167791618215\n",
+      "    mean_env_wait_ms: 1.672353659895845\n",
+      "    mean_inference_ms: 4.615171884779788\n",
+      "    mean_raw_obs_processing_ms: 0.41089512558313934\n",
+      "  time_since_restore: 589.8426554203033\n",
+      "  time_this_iter_s: 24.71308469772339\n",
+      "  time_total_s: 589.8426554203033\n",
+      "  timers:\n",
+      "    learn_throughput: 9799.662\n",
+      "    learn_time_ms: 16509.957\n",
+      "    sample_throughput: 20397.267\n",
+      "    sample_time_ms: 7932.043\n",
+      "    update_time_ms: 34.767\n",
+      "  timestamp: 1602163439\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3883008\n",
+      "  training_iteration: 24\n",
+      "  trial_id: '20482_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 53.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |     24 |          589.843 | 3883008 |  241.518 |              290.242 |              115.788 |            801.512 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_20482_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_13-24-23\n",
+      "  done: true\n",
+      "  episode_len_mean: 800.4764492753624\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 241.8013874656386\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 228\n",
+      "  episodes_total: 4968\n",
+      "  experiment_id: e019eb488f504d908d1b8cde01a67779\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.7212436735630036\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.00533560358453542\n",
+      "        model: {}\n",
+      "        policy_loss: -0.020342798670753837\n",
+      "        total_loss: 2.63335440158844\n",
+      "        vf_explained_var: 0.9957489967346191\n",
+      "        vf_loss: 2.65263010263443\n",
+      "    num_steps_sampled: 4044800\n",
+      "    num_steps_trained: 4044800\n",
+      "  iterations_since_restore: 25\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.57142857142857\n",
+      "    gpu_util_percent0: 0.010357142857142858\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 7.132142857142855\n",
+      "    vram_util_percent0: 0.16005247622171206\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 72926\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15407978857325982\n",
+      "    mean_env_wait_ms: 1.674048569824602\n",
+      "    mean_inference_ms: 4.606872457251446\n",
+      "    mean_raw_obs_processing_ms: 0.410437719877507\n",
+      "  time_since_restore: 614.4670424461365\n",
+      "  time_this_iter_s: 24.62438702583313\n",
+      "  time_total_s: 614.4670424461365\n",
+      "  timers:\n",
+      "    learn_throughput: 9788.599\n",
+      "    learn_time_ms: 16528.616\n",
+      "    sample_throughput: 20425.639\n",
+      "    sample_time_ms: 7921.025\n",
+      "    update_time_ms: 33.481\n",
+      "  timestamp: 1602163463\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4044800\n",
+      "  training_iteration: 25\n",
+      "  trial_id: '20482_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 53.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_20482_00000 | TERMINATED |       |     25 |          614.467 | 4044800 |  241.801 |              290.242 |              115.788 |            800.476 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "== Status ==\n",
+      "Memory usage on this node: 53.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_20482_00000 | TERMINATED |       |     25 |          614.467 | 4044800 |  241.801 |              290.242 |              115.788 |            800.476 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"train.py\", line 68, in <module>\n",
+      "    train_func()\n",
+      "  File \"train.py\", line 53, in train_func\n",
+      "    result = analysis.dataframe().to_dict('index')[0]\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py\", line 89, in dataframe\n",
+      "    metric = self._validate_metric(metric)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py\", line 64, in _validate_metric\n",
+      "    raise ValueError(\n",
+      "ValueError: No `metric` has been passed and  `default_metric` has not been set. Please specify the `metric` parameter.\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 72693\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201008_131355-wzm01kce/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201008_131355-wzm01kce/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mbalmy-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/wzm01kce\u001b[0m\n",
+      "2020-10-08 13:24:31,642 - wandb.wandb_agent - INFO - Cleaning up finished run: wzm01kce\n",
+      "2020-10-08 13:24:32,007 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-08 13:24:32,007 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tclip_param: 0.2\n",
+      "\tlambda: 0.95\n",
+      "\tlr: 0.0001\n",
+      "\tnum_envs_per_worker: 2\n",
+      "\tnum_sgd_iter: 20\n",
+      "\tsgd_minibatch_size: 16384\n",
+      "2020-10-08 13:24:32,011 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=16384\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.5 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.4\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33munique-sweep-3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/xzzphp80\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/5hkelzt0\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_132434-5hkelzt0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "\n",
+      "2020-10-08 13:24:36,199\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8269\u001b[39m\u001b[22m\n",
+      "2020-10-08 13:24:37,046 - wandb.wandb_agent - INFO - Running runs: ['5hkelzt0']\n",
+      "== Status ==\n",
+      "Memory usage on this node: 37.0/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_9d0e2_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "\n",
+      "\n",
+      "\u001b[2m\u001b[36m(pid=18841)\u001b[0m 2020-10-08 13:24:39,262\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=18789)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18789)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18826)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18826)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18821)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18821)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18815)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18815)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18743)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18743)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18848)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18848)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18825)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18825)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18796)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18796)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18818)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18818)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18788)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18788)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18793)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18793)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18846)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18846)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18795)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18795)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18811)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18811)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18838)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18838)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18708)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18708)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18725)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18725)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18822)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18822)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18783)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18783)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18790)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18790)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18718)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18718)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18710)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18710)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18723)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18723)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18715)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18715)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18785)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18785)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18721)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18721)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18716)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18716)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18778)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18778)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18709)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18709)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18735)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18735)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18794)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18794)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18711)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18711)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18750)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18750)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18724)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18724)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18733)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18733)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18792)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18792)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18831)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18831)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18828)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18828)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18817)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18817)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18746)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18746)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18717)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18717)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18748)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18748)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18773)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18773)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18712)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18712)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18782)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18782)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18741)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18741)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18786)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18786)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18770)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18770)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18714)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18714)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18813)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18813)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18720)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18720)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18731)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18731)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18727)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18727)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18787)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18787)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18774)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18774)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18820)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18820)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18771)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18771)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18834)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18834)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18730)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18730)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18736)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18736)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18827)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18827)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18810)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18810)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18722)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18722)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18713)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18713)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18857)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18857)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18776)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18776)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18854)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18854)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18850)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18850)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18784)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18784)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18791)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18791)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18719)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18719)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18729)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18729)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18805)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18805)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18797)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18797)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=18798)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=18798)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_9d0e2_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3279.0\n",
+      "  date: 2020-10-08_13-25-10\n",
+      "  done: false\n",
+      "  episode_len_mean: 877.1708860759494\n",
+      "  episode_reward_max: 273.13131313131294\n",
+      "  episode_reward_mean: 224.28870988364636\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 158\n",
+      "  experiment_id: 1045991bf15d42fca932be81762308aa\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 1.1623204231262207\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.0048057976178824905\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00972368239890784\n",
+      "        total_loss: 8.319466400146485\n",
+      "        vf_explained_var: 0.7498777508735657\n",
+      "        vf_loss: 8.328228569030761\n",
+      "    num_steps_sampled: 161792\n",
+      "    num_steps_trained: 161792\n",
+      "  iterations_since_restore: 1\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 35.68333333333332\n",
+      "    gpu_util_percent0: 0.313\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0003333333333333333\n",
+      "    ram_util_percent: 6.85\n",
+      "    vram_util_percent0: 0.16651907729310164\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 18841\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.17159329773872567\n",
+      "    mean_env_wait_ms: 1.613818687139819\n",
+      "    mean_inference_ms: 5.713953958613227\n",
+      "    mean_raw_obs_processing_ms: 0.4627183382435322\n",
+      "  time_since_restore: 25.17475461959839\n",
+      "  time_this_iter_s: 25.17475461959839\n",
+      "  time_total_s: 25.17475461959839\n",
+      "  timers:\n",
+      "    learn_throughput: 10388.932\n",
+      "    learn_time_ms: 15573.497\n",
+      "    sample_throughput: 16975.293\n",
+      "    sample_time_ms: 9531.028\n",
+      "    update_time_ms: 40.873\n",
+      "  timestamp: 1602163510\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 161792\n",
+      "  training_iteration: 1\n",
+      "  trial_id: 9d0e2_00000\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 52.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9d0e2_00000 | RUNNING  | 172.17.0.4:18841 |      1 |          25.1748 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_9d0e2_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3217.0\n",
+      "  date: 2020-10-08_13-25-33\n",
+      "  done: false\n",
+      "  episode_len_mean: 870.7974683544304\n",
+      "  episode_reward_max: 278.3535353535354\n",
+      "  episode_reward_mean: 226.3724267996418\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 316\n",
+      "  experiment_id: 1045991bf15d42fca932be81762308aa\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 1.138706338405609\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.006825200421735645\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01274334719637409\n",
+      "        total_loss: 7.690042400360108\n",
+      "        vf_explained_var: 0.8869457244873047\n",
+      "        vf_loss: 7.702103328704834\n",
+      "    num_steps_sampled: 323584\n",
+      "    num_steps_trained: 323584\n",
+      "  iterations_since_restore: 2\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.47037037037036\n",
+      "    gpu_util_percent0: 0.21925925925925924\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.446428571428571\n",
-      "    vram_util_percent0: 0.08043620859298131\n",
+      "    ram_util_percent: 7.0814814814814815\n",
+      "    vram_util_percent0: 0.18858642177763205\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 22161\n",
+      "  pid: 18841\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1665971035079177\n",
-      "    mean_env_wait_ms: 1.5718622755619396\n",
-      "    mean_inference_ms: 5.344314668249787\n",
-      "    mean_raw_obs_processing_ms: 0.44582337103132463\n",
-      "  time_since_restore: 50.581798791885376\n",
-      "  time_this_iter_s: 24.585772037506104\n",
-      "  time_total_s: 50.581798791885376\n",
+      "    mean_action_processing_ms: 0.16714291292253497\n",
+      "    mean_env_wait_ms: 1.612162934206623\n",
+      "    mean_inference_ms: 5.43285484948987\n",
+      "    mean_raw_obs_processing_ms: 0.4514940644032998\n",
+      "  time_since_restore: 48.71338224411011\n",
+      "  time_this_iter_s: 23.53862762451172\n",
+      "  time_total_s: 48.71338224411011\n",
       "  timers:\n",
-      "    learn_throughput: 9785.94\n",
-      "    learn_time_ms: 16533.108\n",
-      "    sample_throughput: 18656.081\n",
-      "    sample_time_ms: 8672.347\n",
-      "    update_time_ms: 45.172\n",
-      "  timestamp: 1602158239\n",
+      "    learn_throughput: 10481.456\n",
+      "    learn_time_ms: 15436.023\n",
+      "    sample_throughput: 18281.994\n",
+      "    sample_time_ms: 8849.8\n",
+      "    update_time_ms: 30.515\n",
+      "  timestamp: 1602163533\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 323584\n",
       "  training_iteration: 2\n",
-      "  trial_id: 4898a_00000\n",
+      "  trial_id: 9d0e2_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
+      "Memory usage on this node: 53.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_4898a_00000 | RUNNING  | 172.17.0.4:22161 |      2 |          50.5818 | 323584 |  227.369 |              274.859 |              115.788 |            873.472 |\n",
+      "| PPO_jss_env_9d0e2_00000 | RUNNING  | 172.17.0.4:18841 |      2 |          48.7134 | 323584 |  226.372 |              278.354 |              115.788 |            870.797 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n"
@@ -2551,7 +4867,7 @@
     }
    ],
    "source": [
-    "!wandb agent mq1j5yvs"
+    "!wandb agent xzzphp80"
    ]
   },
   {
diff --git a/JSS/.ipynb_checkpoints/train-checkpoint.py b/JSS/.ipynb_checkpoints/train-checkpoint.py
index 7209fb9..df479ca 100644
--- a/JSS/.ipynb_checkpoints/train-checkpoint.py
+++ b/JSS/.ipynb_checkpoints/train-checkpoint.py
@@ -45,20 +45,24 @@ def train_func():
     config.pop('layer_size', None)
     config.pop('layer_nb', None)
 
-    
     ray.init()
     stop = {
-        "time_total_s": 600,
+        "time_total_s": 140,
     }
-    analysis = tune.run(PPOTrainer, config=config, stop=stop)
-    result = analysis.results_df
-    my_custom_metric = result['custom_metrics']
-    wandb.log(my_custom_metric)
+    analysis = tune.run(PPOTrainer, config=config, stop=stop, name="ppo-jss")
+    print(analysis.dataframe(metric='custom_metrics/time_step_min', mode='min'))
+    print(analysis.dataframe(metric='custom_metrics/time_step_min', mode='min').tail(1))
+    result = analysis.dataframe(mode='max').to_dict('index')[0]
+    wandb.log({'time_step_min': result['custom_metrics/time_step_min']})
+    if result['custom_metrics/time_step_max'] != float('inf'):
+        wandb.log({'time_step_max': result['custom_metrics/time_step_max']})
+        wandb.log({'time_step_mean': result['custom_metrics/time_step_mean']})
     wandb.log({'episode_reward_max': result['episode_reward_max']})
     wandb.log({'episode_reward_min': result['episode_reward_min']})
     wandb.log({'episode_reward_mean': result['episode_reward_mean']})
     wandb.log({'episodes_total': result['episodes_total']})
     wandb.log({'training_iteration': result['training_iteration']})
+
     ray.shutdown()
 
 
diff --git a/JSS/Untitled.ipynb b/JSS/Untitled.ipynb
index 71f6e33..5a3716e 100644
--- a/JSS/Untitled.ipynb
+++ b/JSS/Untitled.ipynb
@@ -2,7 +2,7 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 1,
+   "execution_count": 10,
    "metadata": {},
    "outputs": [
     {
@@ -72,15 +72,15 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 2,
+   "execution_count": 11,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Create sweep with ID: mq1j5yvs\n",
-      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/mq1j5yvs\n"
+      "Create sweep with ID: 04pm0u5v\n",
+      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/04pm0u5v\n"
      ]
     }
    ],
@@ -90,7 +90,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": null,
    "metadata": {},
    "outputs": [
     {
@@ -98,207 +98,205 @@
      "output_type": "stream",
      "text": [
       "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n",
-      "2020-10-08 11:45:48,119 - wandb.wandb_agent - INFO - Running runs: []\n",
-      "2020-10-08 11:45:48,430 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 11:45:48,431 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "2020-10-08 13:47:12,524 - wandb.wandb_agent - INFO - Running runs: []\n",
+      "2020-10-08 13:47:12,843 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-08 13:47:12,843 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
       "\tclip_param: 0.2\n",
       "\tlambda: 0.95\n",
       "\tlr: 0.0001\n",
       "\tnum_envs_per_worker: 2\n",
-      "\tnum_sgd_iter: 20\n",
-      "\tsgd_minibatch_size: 4096\n",
-      "2020-10-08 11:45:48,434 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=4096\n",
+      "\tnum_sgd_iter: 30\n",
+      "\tsgd_minibatch_size: 32768\n",
+      "2020-10-08 13:47:12,847 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=30 --sgd_minibatch_size=32768\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.5 is available!  To upgrade, please run:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.4\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33musual-sweep-1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33musual-sweep-8\u001b[0m\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/mq1j5yvs\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/82d8n3my\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_114550-82d8n3my\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/04pm0u5v\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/er47ohr8\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_134714-er47ohr8\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-08 11:45:52,454\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8268\u001b[39m\u001b[22m\n",
-      "2020-10-08 11:45:53,470 - wandb.wandb_agent - INFO - Running runs: ['82d8n3my']\n",
+      "2020-10-08 13:47:17,092\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8270\u001b[39m\u001b[22m\n",
+      "2020-10-08 13:47:17,882 - wandb.wandb_agent - INFO - Running runs: ['er47ohr8']\n",
       "== Status ==\n",
-      "Memory usage on this node: 17.1/754.6 GiB\n",
+      "Memory usage on this node: 57.0/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
       "| Trial name              | status   | loc   |\n",
       "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  |       |\n",
+      "| PPO_jss_env_c8348_00000 | RUNNING  |       |\n",
       "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=80010)\u001b[0m 2020-10-08 11:45:55,254\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=79990)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79990)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80020)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80020)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79986)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79986)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79996)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79996)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79992)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79992)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79974)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79974)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80017)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80017)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79966)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79966)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79993)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79993)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79977)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79977)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80000)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80000)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79965)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79965)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79975)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79975)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79970)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79970)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80002)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80002)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80012)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80012)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79960)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79960)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79941)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79941)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80004)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80004)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79976)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79976)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79957)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79957)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80006)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80006)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79888)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79888)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79902)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79902)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79901)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79901)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79891)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79891)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79962)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79962)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79879)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79879)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79972)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79972)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79898)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79898)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79985)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79985)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79978)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79978)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79880)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79880)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79895)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79895)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79908)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79908)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79967)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79967)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79875)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79875)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79953)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79953)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79907)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79907)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79968)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79968)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79910)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79910)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79887)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79887)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79878)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79878)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79959)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79959)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79886)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79886)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79958)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79958)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79981)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79981)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79955)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79955)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79948)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79948)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79877)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79877)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79973)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79973)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79917)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79917)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79890)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79890)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79997)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79997)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79964)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79964)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79956)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79956)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79914)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79914)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79942)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79942)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79989)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79989)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79889)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79889)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79900)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79900)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79916)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79916)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79984)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79984)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79885)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79885)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79896)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79896)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79893)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79893)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79876)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79876)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79894)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79894)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79944)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79944)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79904)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79904)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79943)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79943)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79971)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79971)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79969)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79969)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79987)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79987)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79961)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79961)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79952)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79952)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79913)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79913)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79892)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79892)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79963)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79963)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "\u001b[2m\u001b[36m(pid=14054)\u001b[0m 2020-10-08 13:47:20,177\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=14077)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14077)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14024)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14024)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13993)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13993)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14065)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14065)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14058)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14058)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14068)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14068)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14035)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14035)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14041)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14041)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14031)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14031)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14038)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14038)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14009)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14009)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14011)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14011)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14082)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14082)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14055)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14055)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14051)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14051)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14026)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14026)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14023)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14023)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13945)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13945)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14014)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14014)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14027)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14027)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14005)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14005)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14045)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14045)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13950)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13950)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13958)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13958)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13947)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13947)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14049)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14049)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13941)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13941)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13936)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13936)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14019)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14019)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14012)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14012)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13929)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13929)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13927)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13927)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13990)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13990)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13943)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13943)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13964)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13964)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14020)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14020)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14039)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14039)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13951)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13951)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13933)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13933)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13966)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13966)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14043)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14043)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14034)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14034)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13988)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13988)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13959)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13959)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14006)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14006)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14022)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14022)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13963)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13963)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14044)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14044)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14030)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14030)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14017)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14017)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13937)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13937)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13992)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13992)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13961)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13961)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13956)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13956)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13940)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13940)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13930)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13930)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13931)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13931)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13954)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13954)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14001)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14001)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13928)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13928)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13939)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13939)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14042)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14042)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14007)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14007)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13934)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13934)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13948)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13948)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13935)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13935)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14015)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14015)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14010)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14010)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14003)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14003)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13932)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13932)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14028)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14028)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13942)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13942)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14047)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14047)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14013)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14013)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14059)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14059)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=13938)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=13938)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14070)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14070)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14016)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14016)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=14062)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=14062)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_c8348_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_11-46-31\n",
+      "  date: 2020-10-08_13-47-58\n",
       "  done: false\n",
       "  episode_len_mean: 877.1708860759494\n",
       "  episode_reward_max: 273.13131313131294\n",
@@ -306,7 +304,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 158\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: ba9234115e424d80a5eae5847cd45607\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -315,14 +313,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 1.1603952676057816\n",
+      "        entropy: 1.1622311115264892\n",
       "        entropy_coeff: 0.0\n",
-      "        kl: 0.006529558636248112\n",
+      "        kl: 0.004912613797932864\n",
       "        model: {}\n",
-      "        policy_loss: -0.01697929573711008\n",
-      "        total_loss: 6.624263763427734\n",
-      "        vf_explained_var: 0.8197423815727234\n",
-      "        vf_loss: 6.639937055110932\n",
+      "        policy_loss: -0.010443088319152593\n",
+      "        total_loss: 8.661703491210938\n",
+      "        vf_explained_var: 0.7370953559875488\n",
+      "        vf_loss: 8.671164321899415\n",
       "    num_steps_sampled: 161792\n",
       "    num_steps_trained: 161792\n",
       "  iterations_since_restore: 1\n",
@@ -330,83 +328,83 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.499999999999993\n",
-      "    gpu_util_percent0: 0.2733333333333334\n",
+      "    cpu_util_percent: 32.113157894736844\n",
+      "    gpu_util_percent0: 0.30657894736842106\n",
       "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0002777777777777778\n",
-      "    ram_util_percent: 4.261111111111112\n",
-      "    vram_util_percent0: 0.06302157355781494\n",
+      "    gpu_util_percent2: 0.0002631578947368421\n",
+      "    ram_util_percent: 9.523684210526318\n",
+      "    vram_util_percent0: 0.3184564395574046\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 14054\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16875616228481102\n",
-      "    mean_env_wait_ms: 1.5739218855242776\n",
-      "    mean_inference_ms: 5.591068856691865\n",
-      "    mean_raw_obs_processing_ms: 0.4506270552020118\n",
-      "  time_since_restore: 30.11682629585266\n",
-      "  time_this_iter_s: 30.11682629585266\n",
-      "  time_total_s: 30.11682629585266\n",
+      "    mean_action_processing_ms: 0.17734564392240598\n",
+      "    mean_env_wait_ms: 1.6587112258341108\n",
+      "    mean_inference_ms: 5.807721899703315\n",
+      "    mean_raw_obs_processing_ms: 0.4866245507678709\n",
+      "  time_since_restore: 32.13078451156616\n",
+      "  time_this_iter_s: 32.13078451156616\n",
+      "  time_total_s: 32.13078451156616\n",
       "  timers:\n",
-      "    learn_throughput: 7796.6\n",
-      "    learn_time_ms: 20751.61\n",
-      "    sample_throughput: 17419.067\n",
-      "    sample_time_ms: 9288.213\n",
-      "    update_time_ms: 44.874\n",
-      "  timestamp: 1602157591\n",
+      "    learn_throughput: 7286.826\n",
+      "    learn_time_ms: 22203.359\n",
+      "    sample_throughput: 16415.812\n",
+      "    sample_time_ms: 9855.863\n",
+      "    update_time_ms: 29.929\n",
+      "  timestamp: 1602164878\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 161792\n",
       "  training_iteration: 1\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: c8348_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 32.9/754.6 GiB\n",
+      "Memory usage on this node: 72.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      1 |          30.1168 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
+      "| PPO_jss_env_c8348_00000 | RUNNING  | 172.17.0.4:14054 |      1 |          32.1308 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_c8348_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_11-46-59\n",
+      "    time_step_min: 3244.0\n",
+      "  date: 2020-10-08_13-48-28\n",
       "  done: false\n",
-      "  episode_len_mean: 869.3417721518987\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.90004475131036\n",
+      "  episode_len_mean: 870.0316455696203\n",
+      "  episode_reward_max: 273.91919191919146\n",
+      "  episode_reward_mean: 227.07144227080917\n",
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 316\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: ba9234115e424d80a5eae5847cd45607\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
+      "        cur_kl_coeff: 0.1\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 1.1352683365345002\n",
+      "        entropy: 1.1356603145599364\n",
       "        entropy_coeff: 0.0\n",
-      "        kl: 0.007792104431428015\n",
+      "        kl: 0.006972228828817606\n",
       "        model: {}\n",
-      "        policy_loss: -0.020531148964073508\n",
-      "        total_loss: 5.638339829444885\n",
-      "        vf_explained_var: 0.9249752759933472\n",
-      "        vf_loss: 5.657312452793121\n",
+      "        policy_loss: -0.013742314092814923\n",
+      "        total_loss: 8.958678436279296\n",
+      "        vf_explained_var: 0.8662806749343872\n",
+      "        vf_loss: 8.971723365783692\n",
       "    num_steps_sampled: 323584\n",
       "    num_steps_trained: 323584\n",
       "  iterations_since_restore: 2\n",
@@ -414,83 +412,83 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 26.066666666666663\n",
-      "    gpu_util_percent0: 0.29\n",
+      "    cpu_util_percent: 30.28055555555556\n",
+      "    gpu_util_percent0: 0.32666666666666666\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.451515151515152\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.750000000000002\n",
+      "    vram_util_percent0: 0.355608396195474\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 14054\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1640005638893568\n",
-      "    mean_env_wait_ms: 1.5775274092583902\n",
-      "    mean_inference_ms: 5.302413775269009\n",
-      "    mean_raw_obs_processing_ms: 0.43677931133826275\n",
-      "  time_since_restore: 58.54918050765991\n",
-      "  time_this_iter_s: 28.43235421180725\n",
-      "  time_total_s: 58.54918050765991\n",
+      "    mean_action_processing_ms: 0.17241433175504492\n",
+      "    mean_env_wait_ms: 1.6520422963835932\n",
+      "    mean_inference_ms: 5.541245121450117\n",
+      "    mean_raw_obs_processing_ms: 0.47330953648097646\n",
+      "  time_since_restore: 62.52746343612671\n",
+      "  time_this_iter_s: 30.396678924560547\n",
+      "  time_total_s: 62.52746343612671\n",
       "  timers:\n",
-      "    learn_throughput: 7837.771\n",
-      "    learn_time_ms: 20642.602\n",
-      "    sample_throughput: 18926.883\n",
-      "    sample_time_ms: 8548.264\n",
-      "    update_time_ms: 42.329\n",
-      "  timestamp: 1602157619\n",
+      "    learn_throughput: 7352.74\n",
+      "    learn_time_ms: 22004.314\n",
+      "    sample_throughput: 17605.829\n",
+      "    sample_time_ms: 9189.684\n",
+      "    update_time_ms: 24.073\n",
+      "  timestamp: 1602164908\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 323584\n",
       "  training_iteration: 2\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: c8348_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
+      "Memory usage on this node: 73.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      2 |          58.5492 | 323584 |    224.9 |              273.131 |              115.788 |            869.342 |\n",
+      "| PPO_jss_env_c8348_00000 | RUNNING  | 172.17.0.4:14054 |      2 |          62.5275 | 323584 |  227.071 |              273.919 |              115.788 |            870.032 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_c8348_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
-      "    time_step_min: 3247.0\n",
-      "  date: 2020-10-08_11-47-27\n",
+      "    time_step_min: 3244.0\n",
+      "  date: 2020-10-08_13-48-59\n",
       "  done: false\n",
-      "  episode_len_mean: 864.6983122362869\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 225.52218386395583\n",
+      "  episode_len_mean: 863.409282700422\n",
+      "  episode_reward_max: 273.91919191919146\n",
+      "  episode_reward_mean: 227.2880705792096\n",
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 474\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: ba9234115e424d80a5eae5847cd45607\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
+      "        cur_kl_coeff: 0.1\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 1.1208289206027984\n",
+      "        entropy: 1.1236045122146607\n",
       "        entropy_coeff: 0.0\n",
-      "        kl: 0.008471710339654237\n",
+      "        kl: 0.007770490366965532\n",
       "        model: {}\n",
-      "        policy_loss: -0.024524397612549365\n",
-      "        total_loss: 4.379646378755569\n",
-      "        vf_explained_var: 0.9663649797439575\n",
-      "        vf_loss: 4.4024763882160185\n",
+      "        policy_loss: -0.015292425081133843\n",
+      "        total_loss: 10.330543327331544\n",
+      "        vf_explained_var: 0.9152754545211792\n",
+      "        vf_loss: 10.345059013366699\n",
       "    num_steps_sampled: 485376\n",
       "    num_steps_trained: 485376\n",
       "  iterations_since_restore: 3\n",
@@ -498,83 +496,83 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.75151515151515\n",
-      "    gpu_util_percent0: 0.2918181818181818\n",
+      "    cpu_util_percent: 30.150000000000002\n",
+      "    gpu_util_percent0: 0.29027777777777775\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.466666666666667\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.76388888888889\n",
+      "    vram_util_percent0: 0.355608396195474\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 14054\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1610433593452084\n",
-      "    mean_env_wait_ms: 1.5791339042559354\n",
-      "    mean_inference_ms: 5.141168556600388\n",
-      "    mean_raw_obs_processing_ms: 0.4272760547189869\n",
-      "  time_since_restore: 86.52022004127502\n",
-      "  time_this_iter_s: 27.971039533615112\n",
-      "  time_total_s: 86.52022004127502\n",
+      "    mean_action_processing_ms: 0.16939468369145722\n",
+      "    mean_env_wait_ms: 1.6503138663148351\n",
+      "    mean_inference_ms: 5.393610889329284\n",
+      "    mean_raw_obs_processing_ms: 0.4629918972999444\n",
+      "  time_since_restore: 93.12351202964783\n",
+      "  time_this_iter_s: 30.596048593521118\n",
+      "  time_total_s: 93.12351202964783\n",
       "  timers:\n",
-      "    learn_throughput: 7892.613\n",
-      "    learn_time_ms: 20499.168\n",
-      "    sample_throughput: 19596.92\n",
-      "    sample_time_ms: 8255.991\n",
-      "    update_time_ms: 42.426\n",
-      "  timestamp: 1602157647\n",
+      "    learn_throughput: 7355.251\n",
+      "    learn_time_ms: 21996.801\n",
+      "    sample_throughput: 18044.164\n",
+      "    sample_time_ms: 8966.445\n",
+      "    update_time_ms: 29.449\n",
+      "  timestamp: 1602164939\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 485376\n",
       "  training_iteration: 3\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: c8348_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
+      "Memory usage on this node: 73.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      3 |          86.5202 | 485376 |  225.522 |                  279 |              115.788 |            864.698 |\n",
+      "| PPO_jss_env_c8348_00000 | RUNNING  | 172.17.0.4:14054 |      3 |          93.1235 | 485376 |  227.288 |              273.919 |              115.788 |            863.409 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_c8348_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
-      "    time_step_min: 3247.0\n",
-      "  date: 2020-10-08_11-47-55\n",
+      "    time_step_min: 3241.0\n",
+      "  date: 2020-10-08_13-49-29\n",
       "  done: false\n",
-      "  episode_len_mean: 860.242088607595\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 225.50586561820717\n",
+      "  episode_len_mean: 857.1898734177215\n",
+      "  episode_reward_max: 273.91919191919146\n",
+      "  episode_reward_mean: 227.75882240122726\n",
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 632\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: ba9234115e424d80a5eae5847cd45607\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
+      "        cur_kl_coeff: 0.1\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 1.0932798445224763\n",
+      "        entropy: 1.0905964374542236\n",
       "        entropy_coeff: 0.0\n",
-      "        kl: 0.009407231188379227\n",
+      "        kl: 0.007997870352119208\n",
       "        model: {}\n",
-      "        policy_loss: -0.026628604688448833\n",
-      "        total_loss: 4.111228054761886\n",
-      "        vf_explained_var: 0.9783345460891724\n",
-      "        vf_loss: 4.135975193977356\n",
+      "        policy_loss: -0.01639746017754078\n",
+      "        total_loss: 10.277668762207032\n",
+      "        vf_explained_var: 0.9415737390518188\n",
+      "        vf_loss: 10.293266487121581\n",
       "    num_steps_sampled: 647168\n",
       "    num_steps_trained: 647168\n",
       "  iterations_since_restore: 4\n",
@@ -582,1968 +580,50 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.815625\n",
-      "    gpu_util_percent0: 0.26625\n",
+      "    cpu_util_percent: 29.591666666666665\n",
+      "    gpu_util_percent0: 0.36722222222222217\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.46875\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.766666666666667\n",
+      "    vram_util_percent0: 0.355608396195474\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 14054\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1590423832293999\n",
-      "    mean_env_wait_ms: 1.5820174193292231\n",
-      "    mean_inference_ms: 5.0251596991819705\n",
-      "    mean_raw_obs_processing_ms: 0.42029578233494164\n",
-      "  time_since_restore: 114.42771482467651\n",
-      "  time_this_iter_s: 27.90749478340149\n",
-      "  time_total_s: 114.42771482467651\n",
+      "    mean_action_processing_ms: 0.16719149041947604\n",
+      "    mean_env_wait_ms: 1.651926341157787\n",
+      "    mean_inference_ms: 5.282176846221136\n",
+      "    mean_raw_obs_processing_ms: 0.4559839899849967\n",
+      "  time_since_restore: 123.36390590667725\n",
+      "  time_this_iter_s: 30.24039387702942\n",
+      "  time_total_s: 123.36390590667725\n",
       "  timers:\n",
-      "    learn_throughput: 7915.515\n",
-      "    learn_time_ms: 20439.858\n",
-      "    sample_throughput: 20021.505\n",
-      "    sample_time_ms: 8080.911\n",
-      "    update_time_ms: 41.717\n",
-      "  timestamp: 1602157675\n",
+      "    learn_throughput: 7365.467\n",
+      "    learn_time_ms: 21966.292\n",
+      "    sample_throughput: 18398.674\n",
+      "    sample_time_ms: 8793.677\n",
+      "    update_time_ms: 32.116\n",
+      "  timestamp: 1602164969\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 647168\n",
       "  training_iteration: 4\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      4 |          114.428 | 647168 |  225.506 |                  279 |              115.788 |            860.242 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3235.0\n",
-      "  date: 2020-10-08_11-48-23\n",
-      "  done: false\n",
-      "  episode_len_mean: 853.6054421768707\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 226.6438076914266\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 250\n",
-      "  episodes_total: 882\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0601136475801467\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008663335489109159\n",
-      "        model: {}\n",
-      "        policy_loss: -0.029689956549555065\n",
-      "        total_loss: 5.979247343540192\n",
-      "        vf_explained_var: 0.9847942590713501\n",
-      "        vf_loss: 6.007204520702362\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
-      "  iterations_since_restore: 5\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.309374999999996\n",
-      "    gpu_util_percent0: 0.2690625\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.4593750000000005\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1569472608169185\n",
-      "    mean_env_wait_ms: 1.5876407685008682\n",
-      "    mean_inference_ms: 4.901463646021808\n",
-      "    mean_raw_obs_processing_ms: 0.4132403078994484\n",
-      "  time_since_restore: 142.0127465724945\n",
-      "  time_this_iter_s: 27.585031747817993\n",
-      "  time_total_s: 142.0127465724945\n",
-      "  timers:\n",
-      "    learn_throughput: 7949.618\n",
-      "    learn_time_ms: 20352.173\n",
-      "    sample_throughput: 20316.996\n",
-      "    sample_time_ms: 7963.382\n",
-      "    update_time_ms: 40.79\n",
-      "  timestamp: 1602157703\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
-      "  training_iteration: 5\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      5 |          142.013 | 808960 |  226.644 |                  279 |              115.788 |            853.605 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3235.0\n",
-      "  date: 2020-10-08_11-48-50\n",
-      "  done: false\n",
-      "  episode_len_mean: 847.8264014466546\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 227.10596927685518\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 224\n",
-      "  episodes_total: 1106\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0766338467597962\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008614842919632793\n",
-      "        model: {}\n",
-      "        policy_loss: -0.030333096848335118\n",
-      "        total_loss: 4.108908116817474\n",
-      "        vf_explained_var: 0.987047553062439\n",
-      "        vf_loss: 4.137518179416657\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
-      "  iterations_since_restore: 6\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.978125\n",
-      "    gpu_util_percent0: 0.294375\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.4625\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1557195397072005\n",
-      "    mean_env_wait_ms: 1.5919018099970674\n",
-      "    mean_inference_ms: 4.826965344047954\n",
-      "    mean_raw_obs_processing_ms: 0.4091659356791254\n",
-      "  time_since_restore: 168.97307991981506\n",
-      "  time_this_iter_s: 26.960333347320557\n",
-      "  time_total_s: 168.97307991981506\n",
-      "  timers:\n",
-      "    learn_throughput: 8004.051\n",
-      "    learn_time_ms: 20213.764\n",
-      "    sample_throughput: 20586.195\n",
-      "    sample_time_ms: 7859.248\n",
-      "    update_time_ms: 40.239\n",
-      "  timestamp: 1602157730\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
-      "  training_iteration: 6\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      6 |          168.973 | 970752 |  227.106 |                  279 |              115.788 |            847.826 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-49-17\n",
-      "  done: false\n",
-      "  episode_len_mean: 844.1083860759494\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 227.6303302007414\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0495809823274613\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008355090976692736\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03242016874719411\n",
-      "        total_loss: 3.189230865240097\n",
-      "        vf_explained_var: 0.9909769296646118\n",
-      "        vf_loss: 3.2199800491333006\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
-      "  iterations_since_restore: 7\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.95\n",
-      "    gpu_util_percent0: 0.28812499999999996\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.475\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15503429170730368\n",
-      "    mean_env_wait_ms: 1.594563087955357\n",
-      "    mean_inference_ms: 4.785002724236677\n",
-      "    mean_raw_obs_processing_ms: 0.4068913211080966\n",
-      "  time_since_restore: 195.9782907962799\n",
-      "  time_this_iter_s: 27.005210876464844\n",
-      "  time_total_s: 195.9782907962799\n",
-      "  timers:\n",
-      "    learn_throughput: 8045.813\n",
-      "    learn_time_ms: 20108.844\n",
-      "    sample_throughput: 20766.024\n",
-      "    sample_time_ms: 7791.188\n",
-      "    update_time_ms: 38.206\n",
-      "  timestamp: 1602157757\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
-      "  training_iteration: 7\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      7 |          195.978 | 1132544 |   227.63 |              282.485 |              115.788 |            844.108 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-49-44\n",
-      "  done: false\n",
-      "  episode_len_mean: 840.8741209563995\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 227.87909332424087\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0188148379325868\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008204545732587576\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03408731806557626\n",
-      "        total_loss: 3.0473277091979982\n",
-      "        vf_explained_var: 0.9921058416366577\n",
-      "        vf_loss: 3.079774135351181\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
-      "  iterations_since_restore: 8\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.5625\n",
-      "    gpu_util_percent0: 0.2934375\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.471875\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15445205035357232\n",
-      "    mean_env_wait_ms: 1.5970754276033823\n",
-      "    mean_inference_ms: 4.748860951121171\n",
-      "    mean_raw_obs_processing_ms: 0.40491847437517203\n",
-      "  time_since_restore: 223.42373943328857\n",
-      "  time_this_iter_s: 27.445448637008667\n",
-      "  time_total_s: 223.42373943328857\n",
-      "  timers:\n",
-      "    learn_throughput: 8055.885\n",
-      "    learn_time_ms: 20083.703\n",
-      "    sample_throughput: 20900.724\n",
-      "    sample_time_ms: 7740.976\n",
-      "    update_time_ms: 44.602\n",
-      "  timestamp: 1602157784\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
-      "  training_iteration: 8\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      8 |          223.424 | 1294336 |  227.879 |              282.485 |              115.788 |            840.874 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-50-12\n",
-      "  done: false\n",
-      "  episode_len_mean: 835.0944055944055\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 228.1691507146051\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 294\n",
-      "  episodes_total: 1716\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9918270707130432\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007521937682759017\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03050975254736841\n",
-      "        total_loss: 5.504689037799835\n",
-      "        vf_explained_var: 0.9918516874313354\n",
-      "        vf_loss: 5.53369448184967\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
-      "  iterations_since_restore: 9\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 26.15625\n",
-      "    gpu_util_percent0: 0.2734375\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.465625\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15359854017386879\n",
-      "    mean_env_wait_ms: 1.601715352177999\n",
-      "    mean_inference_ms: 4.694742071474369\n",
-      "    mean_raw_obs_processing_ms: 0.4019907511305347\n",
-      "  time_since_restore: 250.65174460411072\n",
-      "  time_this_iter_s: 27.228005170822144\n",
-      "  time_total_s: 250.65174460411072\n",
-      "  timers:\n",
-      "    learn_throughput: 8078.417\n",
-      "    learn_time_ms: 20027.685\n",
-      "    sample_throughput: 20977.883\n",
-      "    sample_time_ms: 7712.504\n",
-      "    update_time_ms: 43.814\n",
-      "  timestamp: 1602157812\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
-      "  training_iteration: 9\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      9 |          250.652 | 1456128 |  228.169 |              282.485 |              115.788 |            835.094 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-50-39\n",
-      "  done: false\n",
-      "  episode_len_mean: 832.079641350211\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 228.59731279035063\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 180\n",
-      "  episodes_total: 1896\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9763310596346855\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007896899722982197\n",
-      "        model: {}\n",
-      "        policy_loss: -0.033220290520694105\n",
-      "        total_loss: 2.953149896860123\n",
-      "        vf_explained_var: 0.993627667427063\n",
-      "        vf_loss: 2.98479083776474\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
-      "  iterations_since_restore: 10\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.484375\n",
-      "    gpu_util_percent0: 0.288125\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.471875\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15317220656345867\n",
-      "    mean_env_wait_ms: 1.604245414768565\n",
-      "    mean_inference_ms: 4.668108436640403\n",
-      "    mean_raw_obs_processing_ms: 0.40059241178385674\n",
-      "  time_since_restore: 278.01485896110535\n",
-      "  time_this_iter_s: 27.36311435699463\n",
-      "  time_total_s: 278.01485896110535\n",
-      "  timers:\n",
-      "    learn_throughput: 8090.085\n",
-      "    learn_time_ms: 19998.802\n",
-      "    sample_throughput: 21045.891\n",
-      "    sample_time_ms: 7687.581\n",
-      "    update_time_ms: 43.4\n",
-      "  timestamp: 1602157839\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
-      "  training_iteration: 10\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     10 |          278.015 | 1617920 |  228.597 |              282.485 |              115.788 |             832.08 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-51-07\n",
-      "  done: false\n",
-      "  episode_len_mean: 830.1703992210321\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 229.0675253017024\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9670185938477516\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007682974718045443\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03496774770319462\n",
-      "        total_loss: 2.589013671875\n",
-      "        vf_explained_var: 0.9946534037590027\n",
-      "        vf_loss: 2.622444784641266\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
-      "  iterations_since_restore: 11\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 26.23548387096774\n",
-      "    gpu_util_percent0: 0.26903225806451614\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.47741935483871\n",
-      "    vram_util_percent0: 0.06928501147917349\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15283766436808183\n",
-      "    mean_env_wait_ms: 1.6062695046004585\n",
-      "    mean_inference_ms: 4.647350806058767\n",
-      "    mean_raw_obs_processing_ms: 0.39949114295740445\n",
-      "  time_since_restore: 305.27174377441406\n",
-      "  time_this_iter_s: 27.256884813308716\n",
-      "  time_total_s: 305.27174377441406\n",
-      "  timers:\n",
-      "    learn_throughput: 8137.51\n",
-      "    learn_time_ms: 19882.248\n",
-      "    sample_throughput: 21520.396\n",
-      "    sample_time_ms: 7518.077\n",
-      "    update_time_ms: 41.114\n",
-      "  timestamp: 1602157867\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
-      "  training_iteration: 11\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     11 |          305.272 | 1779712 |  229.068 |              282.485 |              115.788 |             830.17 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-51-34\n",
-      "  done: false\n",
-      "  episode_len_mean: 828.50904159132\n",
-      "  episode_reward_max: 287.9191919191919\n",
-      "  episode_reward_mean: 229.5476966774434\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2212\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.940390695631504\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007805287896189839\n",
-      "        model: {}\n",
-      "        policy_loss: -0.035866627853829415\n",
-      "        total_loss: 2.6927455008029937\n",
-      "        vf_explained_var: 0.9949959516525269\n",
-      "        vf_loss: 2.7270510613918306\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
-      "  iterations_since_restore: 12\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.678787878787883\n",
-      "    gpu_util_percent0: 0.2809090909090909\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.466666666666667\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15253638840628728\n",
-      "    mean_env_wait_ms: 1.6081161690939731\n",
-      "    mean_inference_ms: 4.628595571108588\n",
-      "    mean_raw_obs_processing_ms: 0.39846808184493565\n",
-      "  time_since_restore: 332.607017993927\n",
-      "  time_this_iter_s: 27.33527421951294\n",
-      "  time_total_s: 332.607017993927\n",
-      "  timers:\n",
-      "    learn_throughput: 8176.778\n",
-      "    learn_time_ms: 19786.766\n",
-      "    sample_throughput: 21563.454\n",
-      "    sample_time_ms: 7503.065\n",
-      "    update_time_ms: 41.647\n",
-      "  timestamp: 1602157894\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
-      "  training_iteration: 12\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.6/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     12 |          332.607 | 1941504 |  229.548 |              287.919 |              115.788 |            828.509 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-52-01\n",
-      "  done: false\n",
-      "  episode_len_mean: 825.9173259493671\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 230.737545550441\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 316\n",
-      "  episodes_total: 2528\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9119029730558396\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007374470541253686\n",
-      "        model: {}\n",
-      "        policy_loss: -0.031025875953491776\n",
-      "        total_loss: 3.626113736629486\n",
-      "        vf_explained_var: 0.9953392744064331\n",
-      "        vf_loss: 3.655664700269699\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
-      "  iterations_since_restore: 13\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.699999999999996\n",
-      "    gpu_util_percent0: 0.2815625\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.465625\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15202521348457168\n",
-      "    mean_env_wait_ms: 1.6115012963552209\n",
-      "    mean_inference_ms: 4.596639178335069\n",
-      "    mean_raw_obs_processing_ms: 0.3967428044141634\n",
-      "  time_since_restore: 359.82592964172363\n",
-      "  time_this_iter_s: 27.21891164779663\n",
-      "  time_total_s: 359.82592964172363\n",
-      "  timers:\n",
-      "    learn_throughput: 8195.68\n",
-      "    learn_time_ms: 19741.132\n",
-      "    sample_throughput: 21654.113\n",
-      "    sample_time_ms: 7471.652\n",
-      "    update_time_ms: 42.032\n",
-      "  timestamp: 1602157921\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
-      "  training_iteration: 13\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     13 |          359.826 | 2103296 |  230.738 |               289.98 |              115.788 |            825.917 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-52-29\n",
-      "  done: false\n",
-      "  episode_len_mean: 824.9274013402829\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 231.18682355949656\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2686\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8989204004406929\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0074366391287185255\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03388760575326159\n",
-      "        total_loss: 2.3619153201580048\n",
-      "        vf_explained_var: 0.9957093000411987\n",
-      "        vf_loss: 2.394315606355667\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
-      "  iterations_since_restore: 14\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.40625\n",
-      "    gpu_util_percent0: 0.2846875\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.4781249999999995\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15180800096963903\n",
-      "    mean_env_wait_ms: 1.613010827888792\n",
-      "    mean_inference_ms: 4.582932598838708\n",
-      "    mean_raw_obs_processing_ms: 0.39601789200760174\n",
-      "  time_since_restore: 387.4496352672577\n",
-      "  time_this_iter_s: 27.623705625534058\n",
-      "  time_total_s: 387.4496352672577\n",
-      "  timers:\n",
-      "    learn_throughput: 8204.033\n",
-      "    learn_time_ms: 19721.031\n",
-      "    sample_throughput: 21680.325\n",
-      "    sample_time_ms: 7462.619\n",
-      "    update_time_ms: 41.93\n",
-      "  timestamp: 1602157949\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
-      "  training_iteration: 14\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     14 |           387.45 | 2265088 |  231.187 |               289.98 |              115.788 |            824.927 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-52-57\n",
-      "  done: false\n",
-      "  episode_len_mean: 824.0777074542897\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 231.63322749293204\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2844\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.895898899435997\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007697970513254404\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03602396983187646\n",
-      "        total_loss: 1.9372931450605393\n",
-      "        vf_explained_var: 0.9962417483329773\n",
-      "        vf_loss: 1.9717775255441665\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
-      "  iterations_since_restore: 15\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.83125\n",
-      "    gpu_util_percent0: 0.285625\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.475\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15161473875055903\n",
-      "    mean_env_wait_ms: 1.6144244916591914\n",
-      "    mean_inference_ms: 4.570359858195114\n",
-      "    mean_raw_obs_processing_ms: 0.3953474948059144\n",
-      "  time_since_restore: 414.69566917419434\n",
-      "  time_this_iter_s: 27.246033906936646\n",
-      "  time_total_s: 414.69566917419434\n",
-      "  timers:\n",
-      "    learn_throughput: 8216.436\n",
-      "    learn_time_ms: 19691.264\n",
-      "    sample_throughput: 21698.645\n",
-      "    sample_time_ms: 7456.318\n",
-      "    update_time_ms: 43.356\n",
-      "  timestamp: 1602157977\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
-      "  training_iteration: 15\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     15 |          414.696 | 2426880 |  231.633 |               289.98 |              115.788 |            824.078 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-53-24\n",
-      "  done: false\n",
-      "  episode_len_mean: 822.9910447761195\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 232.33685444829712\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 171\n",
-      "  episodes_total: 3015\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8683042243123055\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007607861259020865\n",
-      "        model: {}\n",
-      "        policy_loss: -0.036039730068296194\n",
-      "        total_loss: 2.116857588291168\n",
-      "        vf_explained_var: 0.9965157508850098\n",
-      "        vf_loss: 2.1513757526874544\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
-      "  iterations_since_restore: 16\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.764516129032256\n",
-      "    gpu_util_percent0: 0.297741935483871\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.470967741935484\n",
-      "    vram_util_percent0: 0.06928501147917349\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15141989112198903\n",
-      "    mean_env_wait_ms: 1.6159236661106888\n",
-      "    mean_inference_ms: 4.557815570915645\n",
-      "    mean_raw_obs_processing_ms: 0.39467050753293315\n",
-      "  time_since_restore: 441.87632274627686\n",
-      "  time_this_iter_s: 27.18065357208252\n",
-      "  time_total_s: 441.87632274627686\n",
-      "  timers:\n",
-      "    learn_throughput: 8211.786\n",
-      "    learn_time_ms: 19702.413\n",
-      "    sample_throughput: 21667.308\n",
-      "    sample_time_ms: 7467.102\n",
-      "    update_time_ms: 43.552\n",
-      "  timestamp: 1602158004\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
-      "  training_iteration: 16\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     16 |          441.876 | 2588672 |  232.337 |               289.98 |              115.788 |            822.991 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-53-51\n",
-      "  done: false\n",
-      "  episode_len_mean: 821.0216998191681\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 233.1551683197252\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 303\n",
-      "  episodes_total: 3318\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8348902150988579\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.00740289380773902\n",
-      "        model: {}\n",
-      "        policy_loss: -0.029998348827939482\n",
-      "        total_loss: 2.5100847482681274\n",
-      "        vf_explained_var: 0.9960853457450867\n",
-      "        vf_loss: 2.538602519035339\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
-      "  iterations_since_restore: 17\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.715625000000003\n",
-      "    gpu_util_percent0: 0.301875\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.4593750000000005\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15111617742851072\n",
-      "    mean_env_wait_ms: 1.6183026472863848\n",
-      "    mean_inference_ms: 4.5380869771344665\n",
-      "    mean_raw_obs_processing_ms: 0.3936242667088673\n",
-      "  time_since_restore: 469.05478024482727\n",
-      "  time_this_iter_s: 27.178457498550415\n",
-      "  time_total_s: 469.05478024482727\n",
-      "  timers:\n",
-      "    learn_throughput: 8204.084\n",
-      "    learn_time_ms: 19720.91\n",
-      "    sample_throughput: 21655.953\n",
-      "    sample_time_ms: 7471.017\n",
-      "    update_time_ms: 43.943\n",
-      "  timestamp: 1602158031\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
-      "  training_iteration: 17\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     17 |          469.055 | 2750464 |  233.155 |               289.98 |              115.788 |            821.022 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-54-19\n",
-      "  done: false\n",
-      "  episode_len_mean: 820.0376869965478\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 233.58232206995146\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3476\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8338133722543717\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007797137019224465\n",
-      "        model: {}\n",
-      "        policy_loss: -0.0366627115290612\n",
-      "        total_loss: 1.7475906014442444\n",
-      "        vf_explained_var: 0.9965535998344421\n",
-      "        vf_loss: 1.7826938778162003\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
-      "  iterations_since_restore: 18\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.784375\n",
-      "    gpu_util_percent0: 0.2903125\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.481249999999999\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15097538572791852\n",
-      "    mean_env_wait_ms: 1.6194704277376637\n",
-      "    mean_inference_ms: 4.52891423862918\n",
-      "    mean_raw_obs_processing_ms: 0.3931393304580003\n",
-      "  time_since_restore: 496.22354912757874\n",
-      "  time_this_iter_s: 27.168768882751465\n",
-      "  time_total_s: 496.22354912757874\n",
-      "  timers:\n",
-      "    learn_throughput: 8215.377\n",
-      "    learn_time_ms: 19693.8\n",
-      "    sample_throughput: 21639.305\n",
-      "    sample_time_ms: 7476.765\n",
-      "    update_time_ms: 37.093\n",
-      "  timestamp: 1602158059\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
-      "  training_iteration: 18\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     18 |          496.224 | 2912256 |  233.582 |               289.98 |              115.788 |            820.038 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-54-45\n",
-      "  done: false\n",
-      "  episode_len_mean: 819.1164006604292\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 234.0312925623877\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3634\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8341425269842148\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007575143571011722\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03457739797886461\n",
-      "        total_loss: 1.834545186161995\n",
-      "        vf_explained_var: 0.9961616396903992\n",
-      "        vf_loss: 1.8676075398921967\n",
-      "    num_steps_sampled: 3074048\n",
-      "    num_steps_trained: 3074048\n",
-      "  iterations_since_restore: 19\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 26.36774193548387\n",
-      "    gpu_util_percent0: 0.30548387096774193\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.480645161290322\n",
-      "    vram_util_percent0: 0.06928501147917349\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15084453438607362\n",
-      "    mean_env_wait_ms: 1.6205942190593885\n",
-      "    mean_inference_ms: 4.520349568470547\n",
-      "    mean_raw_obs_processing_ms: 0.3926786361932948\n",
-      "  time_since_restore: 522.9063003063202\n",
-      "  time_this_iter_s: 26.682751178741455\n",
-      "  time_total_s: 522.9063003063202\n",
-      "  timers:\n",
-      "    learn_throughput: 8235.447\n",
-      "    learn_time_ms: 19645.806\n",
-      "    sample_throughput: 21635.851\n",
-      "    sample_time_ms: 7477.959\n",
-      "    update_time_ms: 35.387\n",
-      "  timestamp: 1602158085\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3074048\n",
-      "  training_iteration: 19\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.6/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     19 |          522.906 | 3074048 |  234.031 |               289.98 |              115.788 |            819.116 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-55-13\n",
-      "  done: false\n",
-      "  episode_len_mean: 817.554763117677\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 234.8146184205786\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 292\n",
-      "  episodes_total: 3926\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7916461393237114\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007353159273043275\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03166137257358059\n",
-      "        total_loss: 2.4200849175453185\n",
-      "        vf_explained_var: 0.9965318441390991\n",
-      "        vf_loss: 2.450275695323944\n",
-      "    num_steps_sampled: 3235840\n",
-      "    num_steps_trained: 3235840\n",
-      "  iterations_since_restore: 20\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.421875\n",
-      "    gpu_util_percent0: 0.2903125\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.471875000000001\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15062615343426108\n",
-      "    mean_env_wait_ms: 1.6226010223295135\n",
-      "    mean_inference_ms: 4.5059904498713115\n",
-      "    mean_raw_obs_processing_ms: 0.3919086060605794\n",
-      "  time_since_restore: 550.2158420085907\n",
-      "  time_this_iter_s: 27.309541702270508\n",
-      "  time_total_s: 550.2158420085907\n",
-      "  timers:\n",
-      "    learn_throughput: 8238.594\n",
-      "    learn_time_ms: 19638.301\n",
-      "    sample_throughput: 21617.958\n",
-      "    sample_time_ms: 7484.148\n",
-      "    update_time_ms: 35.351\n",
-      "  timestamp: 1602158113\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3235840\n",
-      "  training_iteration: 20\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     20 |          550.216 | 3235840 |  234.815 |               289.98 |              115.788 |            817.555 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-55-40\n",
-      "  done: false\n",
-      "  episode_len_mean: 816.6701557935735\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 235.22827594346575\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 182\n",
-      "  episodes_total: 4108\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7638061985373497\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007330618624109775\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03147139406064525\n",
-      "        total_loss: 1.8828283458948136\n",
-      "        vf_explained_var: 0.9963488578796387\n",
-      "        vf_loss: 1.912833634018898\n",
-      "    num_steps_sampled: 3397632\n",
-      "    num_steps_trained: 3397632\n",
-      "  iterations_since_restore: 21\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.924999999999997\n",
-      "    gpu_util_percent0: 0.301875\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.481249999999999\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15050530919609634\n",
-      "    mean_env_wait_ms: 1.623724292281501\n",
-      "    mean_inference_ms: 4.497921157414929\n",
-      "    mean_raw_obs_processing_ms: 0.3914896591205486\n",
-      "  time_since_restore: 577.2629189491272\n",
-      "  time_this_iter_s: 27.0470769405365\n",
-      "  time_total_s: 577.2629189491272\n",
-      "  timers:\n",
-      "    learn_throughput: 8242.44\n",
-      "    learn_time_ms: 19629.139\n",
-      "    sample_throughput: 21663.425\n",
-      "    sample_time_ms: 7468.441\n",
-      "    update_time_ms: 36.165\n",
-      "  timestamp: 1602158140\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3397632\n",
-      "  training_iteration: 21\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     21 |          577.263 | 3397632 |  235.228 |               289.98 |              115.788 |             816.67 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-56-08\n",
-      "  done: true\n",
-      "  episode_len_mean: 815.9498359118612\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 235.53961319713775\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4266\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7843831703066826\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007404250220861286\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03531548953615129\n",
-      "        total_loss: 1.534095871448517\n",
-      "        vf_explained_var: 0.996734619140625\n",
-      "        vf_loss: 1.5679305166006088\n",
-      "    num_steps_sampled: 3559424\n",
-      "    num_steps_trained: 3559424\n",
-      "  iterations_since_restore: 22\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.875\n",
-      "    gpu_util_percent0: 0.2996875\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.4875\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15040791303314213\n",
-      "    mean_env_wait_ms: 1.6246785514214\n",
-      "    mean_inference_ms: 4.4913398893005585\n",
-      "    mean_raw_obs_processing_ms: 0.39114072918445014\n",
-      "  time_since_restore: 604.5293033123016\n",
-      "  time_this_iter_s: 27.26638436317444\n",
-      "  time_total_s: 604.5293033123016\n",
-      "  timers:\n",
-      "    learn_throughput: 8243.137\n",
-      "    learn_time_ms: 19627.479\n",
-      "    sample_throughput: 21703.935\n",
-      "    sample_time_ms: 7454.501\n",
-      "    update_time_ms: 41.057\n",
-      "  timestamp: 1602158168\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3559424\n",
-      "  training_iteration: 22\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | TERMINATED |       |     22 |          604.529 | 3559424 |   235.54 |               289.98 |              115.788 |             815.95 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | TERMINATED |       |     22 |          604.529 | 3559424 |   235.54 |               289.98 |              115.788 |             815.95 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 2895, in get_loc\n",
-      "    return self._engine.get_loc(casted_key)\n",
-      "  File \"pandas/_libs/index.pyx\", line 70, in pandas._libs.index.IndexEngine.get_loc\n",
-      "  File \"pandas/_libs/index.pyx\", line 101, in pandas._libs.index.IndexEngine.get_loc\n",
-      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1675, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
-      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1683, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
-      "KeyError: 'custom_metrics'\n",
-      "\n",
-      "The above exception was the direct cause of the following exception:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"train.py\", line 66, in <module>\n",
-      "    train_func()\n",
-      "  File \"train.py\", line 55, in train_func\n",
-      "    my_custom_metric = result['custom_metrics']\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 2902, in __getitem__\n",
-      "    indexer = self.columns.get_loc(key)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 2897, in get_loc\n",
-      "    raise KeyError(key) from err\n",
-      "KeyError: 'custom_metrics'\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 79778\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201008_114550-82d8n3my/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201008_114550-82d8n3my/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33musual-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/82d8n3my\u001b[0m\n",
-      "2020-10-08 11:56:16,232 - wandb.wandb_agent - INFO - Cleaning up finished run: 82d8n3my\n",
-      "2020-10-08 11:56:16,524 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 11:56:16,524 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.2\n",
-      "\tlambda: 0.95\n",
-      "\tlr: 0.0001\n",
-      "\tnum_envs_per_worker: 2\n",
-      "\tnum_sgd_iter: 20\n",
-      "\tsgd_minibatch_size: 8192\n",
-      "2020-10-08 11:56:16,529 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=8192\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.5 is available!  To upgrade, please run:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.4\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msandy-sweep-2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/mq1j5yvs\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/uaw0r211\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_115618-uaw0r211\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-08 11:56:20,530\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8268\u001b[39m\u001b[22m\n",
-      "2020-10-08 11:56:21,566 - wandb.wandb_agent - INFO - Running runs: ['uaw0r211']\n",
-      "== Status ==\n",
-      "Memory usage on this node: 17.1/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_4898a_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
-      "\n",
-      "\n",
-      "\u001b[2m\u001b[36m(pid=22161)\u001b[0m 2020-10-08 11:56:23,493\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=22120)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22120)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22113)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22113)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22156)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22156)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22145)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22145)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22167)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22167)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22038)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22038)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22121)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22121)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22035)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22035)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22151)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22151)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22097)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22097)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22051)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22051)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22136)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22136)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22129)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22129)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22115)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22115)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22105)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22105)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22128)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22128)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22059)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22059)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22108)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22108)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22141)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22141)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22101)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22101)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22118)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22118)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22039)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22039)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22160)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22160)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22091)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22091)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22036)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22036)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22060)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22060)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22107)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22107)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22062)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22062)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22154)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22154)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22029)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22029)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22134)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22134)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22103)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22103)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22027)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22027)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22122)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22122)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22024)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22024)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22040)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22040)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22155)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22155)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22084)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22084)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22106)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22106)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22139)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22139)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22081)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22081)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22037)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22037)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22147)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22147)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22048)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22048)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22065)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22065)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22045)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22045)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22142)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22142)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22042)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22042)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22025)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22025)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22033)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22033)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22163)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22163)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22083)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22083)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22058)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22058)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22171)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22171)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22092)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22092)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22053)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22053)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22165)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22165)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22034)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22034)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22028)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22028)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22041)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22041)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22152)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22152)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22026)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22026)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22112)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22112)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22104)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22104)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22054)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22054)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22030)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22030)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22032)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22032)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22131)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22131)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22031)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22031)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22109)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22109)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22050)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22050)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22124)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22124)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22111)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22111)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22110)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22110)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22114)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22114)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22123)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22123)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22133)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22133)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22116)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22116)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22125)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22125)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_4898a_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_11-56-55\n",
-      "  done: false\n",
-      "  episode_len_mean: 877.1708860759494\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.28870988364636\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 8196fe3f2c5c4e22af63c11ec84b6459\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1611746549606323\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005718740075826645\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013096390827558934\n",
-      "        total_loss: 7.403090405464172\n",
-      "        vf_explained_var: 0.7892305254936218\n",
-      "        vf_loss: 7.415043115615845\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 32.55\n",
-      "    gpu_util_percent0: 0.22966666666666669\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.250000000000002\n",
-      "    vram_util_percent0: 0.06902809664370832\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 22161\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17109087125207587\n",
-      "    mean_env_wait_ms: 1.5727916416028063\n",
-      "    mean_inference_ms: 5.579640846923753\n",
-      "    mean_raw_obs_processing_ms: 0.4581124033961777\n",
-      "  time_since_restore: 25.996026754379272\n",
-      "  time_this_iter_s: 25.996026754379272\n",
-      "  time_total_s: 25.996026754379272\n",
-      "  timers:\n",
-      "    learn_throughput: 9708.757\n",
-      "    learn_time_ms: 16664.542\n",
-      "    sample_throughput: 17496.047\n",
-      "    sample_time_ms: 9247.346\n",
-      "    update_time_ms: 51.617\n",
-      "  timestamp: 1602158215\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: 4898a_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 32.9/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_4898a_00000 | RUNNING  | 172.17.0.4:22161 |      1 |           25.996 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_4898a_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3265.0\n",
-      "  date: 2020-10-08_11-57-19\n",
-      "  done: false\n",
-      "  episode_len_mean: 873.4715189873418\n",
-      "  episode_reward_max: 274.85858585858557\n",
-      "  episode_reward_mean: 227.3690384861269\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 8196fe3f2c5c4e22af63c11ec84b6459\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.132627922296524\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006706285546533764\n",
-      "        model: {}\n",
-      "        policy_loss: -0.016248987091239543\n",
-      "        total_loss: 5.631959009170532\n",
-      "        vf_explained_var: 0.9176143407821655\n",
-      "        vf_loss: 5.646866726875305\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 30.485714285714288\n",
-      "    gpu_util_percent0: 0.1157142857142857\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.446428571428571\n",
-      "    vram_util_percent0: 0.08043620859298131\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 22161\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1665971035079177\n",
-      "    mean_env_wait_ms: 1.5718622755619396\n",
-      "    mean_inference_ms: 5.344314668249787\n",
-      "    mean_raw_obs_processing_ms: 0.44582337103132463\n",
-      "  time_since_restore: 50.581798791885376\n",
-      "  time_this_iter_s: 24.585772037506104\n",
-      "  time_total_s: 50.581798791885376\n",
-      "  timers:\n",
-      "    learn_throughput: 9785.94\n",
-      "    learn_time_ms: 16533.108\n",
-      "    sample_throughput: 18656.081\n",
-      "    sample_time_ms: 8672.347\n",
-      "    update_time_ms: 45.172\n",
-      "  timestamp: 1602158239\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: 4898a_00000\n",
+      "  trial_id: c8348_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_4898a_00000 | RUNNING  | 172.17.0.4:22161 |      2 |          50.5818 | 323584 |  227.369 |              274.859 |              115.788 |            873.472 |\n",
+      "| PPO_jss_env_c8348_00000 | RUNNING  | 172.17.0.4:14054 |      4 |          123.364 | 647168 |  227.759 |              273.919 |              115.788 |             857.19 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n"
@@ -2551,7 +631,7 @@
     }
    ],
    "source": [
-    "!wandb agent mq1j5yvs"
+    "!wandb agent 04pm0u5v"
    ]
   },
   {
diff --git a/JSS/train.py b/JSS/train.py
index f228f49..df479ca 100644
--- a/JSS/train.py
+++ b/JSS/train.py
@@ -47,10 +47,12 @@ def train_func():
 
     ray.init()
     stop = {
-        "time_total_s": 600,
+        "time_total_s": 140,
     }
     analysis = tune.run(PPOTrainer, config=config, stop=stop, name="ppo-jss")
-    result = analysis.dataframe().to_dict('index')[0]
+    print(analysis.dataframe(metric='custom_metrics/time_step_min', mode='min'))
+    print(analysis.dataframe(metric='custom_metrics/time_step_min', mode='min').tail(1))
+    result = analysis.dataframe(mode='max').to_dict('index')[0]
     wandb.log({'time_step_min': result['custom_metrics/time_step_min']})
     if result['custom_metrics/time_step_max'] != float('inf'):
         wandb.log({'time_step_max': result['custom_metrics/time_step_max']})
