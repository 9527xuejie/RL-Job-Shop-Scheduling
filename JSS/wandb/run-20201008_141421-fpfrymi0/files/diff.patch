diff --git a/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb b/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
index 71f6e33..6d794ec 100644
--- a/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
+++ b/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
@@ -79,8 +79,8 @@
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Create sweep with ID: mq1j5yvs\n",
-      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/mq1j5yvs\n"
+      "Create sweep with ID: rfs7la4y\n",
+      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\n"
      ]
     }
    ],
@@ -90,2468 +90,19 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": null,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n",
-      "2020-10-08 11:45:48,119 - wandb.wandb_agent - INFO - Running runs: []\n",
-      "2020-10-08 11:45:48,430 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 11:45:48,431 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.2\n",
-      "\tlambda: 0.95\n",
-      "\tlr: 0.0001\n",
-      "\tnum_envs_per_worker: 2\n",
-      "\tnum_sgd_iter: 20\n",
-      "\tsgd_minibatch_size: 4096\n",
-      "2020-10-08 11:45:48,434 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=4096\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.5 is available!  To upgrade, please run:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.4\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33musual-sweep-1\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/mq1j5yvs\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/82d8n3my\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_114550-82d8n3my\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-08 11:45:52,454\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8268\u001b[39m\u001b[22m\n",
-      "2020-10-08 11:45:53,470 - wandb.wandb_agent - INFO - Running runs: ['82d8n3my']\n",
-      "== Status ==\n",
-      "Memory usage on this node: 17.1/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
-      "\n",
-      "\n",
-      "\u001b[2m\u001b[36m(pid=80010)\u001b[0m 2020-10-08 11:45:55,254\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=79990)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79990)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80020)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80020)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79986)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79986)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79996)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79996)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79992)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79992)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79974)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79974)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80017)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80017)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79966)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79966)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79993)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79993)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79977)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79977)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80000)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80000)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79965)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79965)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79975)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79975)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79970)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79970)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80002)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80002)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80012)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80012)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79960)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79960)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79941)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79941)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80004)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80004)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79976)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79976)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79957)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79957)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80006)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80006)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79888)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79888)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79902)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79902)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79901)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79901)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79891)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79891)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79962)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79962)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79879)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79879)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79972)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79972)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79898)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79898)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79985)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79985)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79978)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79978)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79880)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79880)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79895)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79895)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79908)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79908)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79967)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79967)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79875)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79875)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79953)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79953)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79907)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79907)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79968)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79968)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79910)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79910)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79887)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79887)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79878)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79878)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79959)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79959)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79886)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79886)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79958)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79958)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79981)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79981)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79955)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79955)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79948)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79948)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79877)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79877)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79973)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79973)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79917)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79917)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79890)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79890)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79997)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79997)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79964)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79964)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79956)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79956)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79914)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79914)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79942)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79942)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79989)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79989)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79889)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79889)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79900)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79900)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79916)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79916)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79984)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79984)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79885)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79885)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79896)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79896)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79893)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79893)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79876)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79876)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79894)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79894)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79944)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79944)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79904)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79904)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79943)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79943)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79971)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79971)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79969)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79969)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79987)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79987)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79961)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79961)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79952)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79952)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79913)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79913)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79892)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79892)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79963)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79963)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_11-46-31\n",
-      "  done: false\n",
-      "  episode_len_mean: 877.1708860759494\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.28870988364636\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1603952676057816\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006529558636248112\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01697929573711008\n",
-      "        total_loss: 6.624263763427734\n",
-      "        vf_explained_var: 0.8197423815727234\n",
-      "        vf_loss: 6.639937055110932\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 29.499999999999993\n",
-      "    gpu_util_percent0: 0.2733333333333334\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0002777777777777778\n",
-      "    ram_util_percent: 4.261111111111112\n",
-      "    vram_util_percent0: 0.06302157355781494\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16875616228481102\n",
-      "    mean_env_wait_ms: 1.5739218855242776\n",
-      "    mean_inference_ms: 5.591068856691865\n",
-      "    mean_raw_obs_processing_ms: 0.4506270552020118\n",
-      "  time_since_restore: 30.11682629585266\n",
-      "  time_this_iter_s: 30.11682629585266\n",
-      "  time_total_s: 30.11682629585266\n",
-      "  timers:\n",
-      "    learn_throughput: 7796.6\n",
-      "    learn_time_ms: 20751.61\n",
-      "    sample_throughput: 17419.067\n",
-      "    sample_time_ms: 9288.213\n",
-      "    update_time_ms: 44.874\n",
-      "  timestamp: 1602157591\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 32.9/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      1 |          30.1168 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_11-46-59\n",
-      "  done: false\n",
-      "  episode_len_mean: 869.3417721518987\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.90004475131036\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1352683365345002\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007792104431428015\n",
-      "        model: {}\n",
-      "        policy_loss: -0.020531148964073508\n",
-      "        total_loss: 5.638339829444885\n",
-      "        vf_explained_var: 0.9249752759933472\n",
-      "        vf_loss: 5.657312452793121\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 26.066666666666663\n",
-      "    gpu_util_percent0: 0.29\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.451515151515152\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1640005638893568\n",
-      "    mean_env_wait_ms: 1.5775274092583902\n",
-      "    mean_inference_ms: 5.302413775269009\n",
-      "    mean_raw_obs_processing_ms: 0.43677931133826275\n",
-      "  time_since_restore: 58.54918050765991\n",
-      "  time_this_iter_s: 28.43235421180725\n",
-      "  time_total_s: 58.54918050765991\n",
-      "  timers:\n",
-      "    learn_throughput: 7837.771\n",
-      "    learn_time_ms: 20642.602\n",
-      "    sample_throughput: 18926.883\n",
-      "    sample_time_ms: 8548.264\n",
-      "    update_time_ms: 42.329\n",
-      "  timestamp: 1602157619\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      2 |          58.5492 | 323584 |    224.9 |              273.131 |              115.788 |            869.342 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3247.0\n",
-      "  date: 2020-10-08_11-47-27\n",
-      "  done: false\n",
-      "  episode_len_mean: 864.6983122362869\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 225.52218386395583\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1208289206027984\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008471710339654237\n",
-      "        model: {}\n",
-      "        policy_loss: -0.024524397612549365\n",
-      "        total_loss: 4.379646378755569\n",
-      "        vf_explained_var: 0.9663649797439575\n",
-      "        vf_loss: 4.4024763882160185\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.75151515151515\n",
-      "    gpu_util_percent0: 0.2918181818181818\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.466666666666667\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1610433593452084\n",
-      "    mean_env_wait_ms: 1.5791339042559354\n",
-      "    mean_inference_ms: 5.141168556600388\n",
-      "    mean_raw_obs_processing_ms: 0.4272760547189869\n",
-      "  time_since_restore: 86.52022004127502\n",
-      "  time_this_iter_s: 27.971039533615112\n",
-      "  time_total_s: 86.52022004127502\n",
-      "  timers:\n",
-      "    learn_throughput: 7892.613\n",
-      "    learn_time_ms: 20499.168\n",
-      "    sample_throughput: 19596.92\n",
-      "    sample_time_ms: 8255.991\n",
-      "    update_time_ms: 42.426\n",
-      "  timestamp: 1602157647\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      3 |          86.5202 | 485376 |  225.522 |                  279 |              115.788 |            864.698 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3247.0\n",
-      "  date: 2020-10-08_11-47-55\n",
-      "  done: false\n",
-      "  episode_len_mean: 860.242088607595\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 225.50586561820717\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0932798445224763\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.009407231188379227\n",
-      "        model: {}\n",
-      "        policy_loss: -0.026628604688448833\n",
-      "        total_loss: 4.111228054761886\n",
-      "        vf_explained_var: 0.9783345460891724\n",
-      "        vf_loss: 4.135975193977356\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
-      "  iterations_since_restore: 4\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.815625\n",
-      "    gpu_util_percent0: 0.26625\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.46875\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1590423832293999\n",
-      "    mean_env_wait_ms: 1.5820174193292231\n",
-      "    mean_inference_ms: 5.0251596991819705\n",
-      "    mean_raw_obs_processing_ms: 0.42029578233494164\n",
-      "  time_since_restore: 114.42771482467651\n",
-      "  time_this_iter_s: 27.90749478340149\n",
-      "  time_total_s: 114.42771482467651\n",
-      "  timers:\n",
-      "    learn_throughput: 7915.515\n",
-      "    learn_time_ms: 20439.858\n",
-      "    sample_throughput: 20021.505\n",
-      "    sample_time_ms: 8080.911\n",
-      "    update_time_ms: 41.717\n",
-      "  timestamp: 1602157675\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
-      "  training_iteration: 4\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      4 |          114.428 | 647168 |  225.506 |                  279 |              115.788 |            860.242 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3235.0\n",
-      "  date: 2020-10-08_11-48-23\n",
-      "  done: false\n",
-      "  episode_len_mean: 853.6054421768707\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 226.6438076914266\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 250\n",
-      "  episodes_total: 882\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0601136475801467\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008663335489109159\n",
-      "        model: {}\n",
-      "        policy_loss: -0.029689956549555065\n",
-      "        total_loss: 5.979247343540192\n",
-      "        vf_explained_var: 0.9847942590713501\n",
-      "        vf_loss: 6.007204520702362\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
-      "  iterations_since_restore: 5\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.309374999999996\n",
-      "    gpu_util_percent0: 0.2690625\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.4593750000000005\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1569472608169185\n",
-      "    mean_env_wait_ms: 1.5876407685008682\n",
-      "    mean_inference_ms: 4.901463646021808\n",
-      "    mean_raw_obs_processing_ms: 0.4132403078994484\n",
-      "  time_since_restore: 142.0127465724945\n",
-      "  time_this_iter_s: 27.585031747817993\n",
-      "  time_total_s: 142.0127465724945\n",
-      "  timers:\n",
-      "    learn_throughput: 7949.618\n",
-      "    learn_time_ms: 20352.173\n",
-      "    sample_throughput: 20316.996\n",
-      "    sample_time_ms: 7963.382\n",
-      "    update_time_ms: 40.79\n",
-      "  timestamp: 1602157703\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
-      "  training_iteration: 5\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      5 |          142.013 | 808960 |  226.644 |                  279 |              115.788 |            853.605 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3235.0\n",
-      "  date: 2020-10-08_11-48-50\n",
-      "  done: false\n",
-      "  episode_len_mean: 847.8264014466546\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 227.10596927685518\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 224\n",
-      "  episodes_total: 1106\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0766338467597962\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008614842919632793\n",
-      "        model: {}\n",
-      "        policy_loss: -0.030333096848335118\n",
-      "        total_loss: 4.108908116817474\n",
-      "        vf_explained_var: 0.987047553062439\n",
-      "        vf_loss: 4.137518179416657\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
-      "  iterations_since_restore: 6\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.978125\n",
-      "    gpu_util_percent0: 0.294375\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.4625\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1557195397072005\n",
-      "    mean_env_wait_ms: 1.5919018099970674\n",
-      "    mean_inference_ms: 4.826965344047954\n",
-      "    mean_raw_obs_processing_ms: 0.4091659356791254\n",
-      "  time_since_restore: 168.97307991981506\n",
-      "  time_this_iter_s: 26.960333347320557\n",
-      "  time_total_s: 168.97307991981506\n",
-      "  timers:\n",
-      "    learn_throughput: 8004.051\n",
-      "    learn_time_ms: 20213.764\n",
-      "    sample_throughput: 20586.195\n",
-      "    sample_time_ms: 7859.248\n",
-      "    update_time_ms: 40.239\n",
-      "  timestamp: 1602157730\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
-      "  training_iteration: 6\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      6 |          168.973 | 970752 |  227.106 |                  279 |              115.788 |            847.826 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-49-17\n",
-      "  done: false\n",
-      "  episode_len_mean: 844.1083860759494\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 227.6303302007414\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0495809823274613\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008355090976692736\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03242016874719411\n",
-      "        total_loss: 3.189230865240097\n",
-      "        vf_explained_var: 0.9909769296646118\n",
-      "        vf_loss: 3.2199800491333006\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
-      "  iterations_since_restore: 7\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.95\n",
-      "    gpu_util_percent0: 0.28812499999999996\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.475\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15503429170730368\n",
-      "    mean_env_wait_ms: 1.594563087955357\n",
-      "    mean_inference_ms: 4.785002724236677\n",
-      "    mean_raw_obs_processing_ms: 0.4068913211080966\n",
-      "  time_since_restore: 195.9782907962799\n",
-      "  time_this_iter_s: 27.005210876464844\n",
-      "  time_total_s: 195.9782907962799\n",
-      "  timers:\n",
-      "    learn_throughput: 8045.813\n",
-      "    learn_time_ms: 20108.844\n",
-      "    sample_throughput: 20766.024\n",
-      "    sample_time_ms: 7791.188\n",
-      "    update_time_ms: 38.206\n",
-      "  timestamp: 1602157757\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
-      "  training_iteration: 7\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      7 |          195.978 | 1132544 |   227.63 |              282.485 |              115.788 |            844.108 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-49-44\n",
-      "  done: false\n",
-      "  episode_len_mean: 840.8741209563995\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 227.87909332424087\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0188148379325868\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008204545732587576\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03408731806557626\n",
-      "        total_loss: 3.0473277091979982\n",
-      "        vf_explained_var: 0.9921058416366577\n",
-      "        vf_loss: 3.079774135351181\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
-      "  iterations_since_restore: 8\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.5625\n",
-      "    gpu_util_percent0: 0.2934375\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.471875\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15445205035357232\n",
-      "    mean_env_wait_ms: 1.5970754276033823\n",
-      "    mean_inference_ms: 4.748860951121171\n",
-      "    mean_raw_obs_processing_ms: 0.40491847437517203\n",
-      "  time_since_restore: 223.42373943328857\n",
-      "  time_this_iter_s: 27.445448637008667\n",
-      "  time_total_s: 223.42373943328857\n",
-      "  timers:\n",
-      "    learn_throughput: 8055.885\n",
-      "    learn_time_ms: 20083.703\n",
-      "    sample_throughput: 20900.724\n",
-      "    sample_time_ms: 7740.976\n",
-      "    update_time_ms: 44.602\n",
-      "  timestamp: 1602157784\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
-      "  training_iteration: 8\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      8 |          223.424 | 1294336 |  227.879 |              282.485 |              115.788 |            840.874 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-50-12\n",
-      "  done: false\n",
-      "  episode_len_mean: 835.0944055944055\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 228.1691507146051\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 294\n",
-      "  episodes_total: 1716\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9918270707130432\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007521937682759017\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03050975254736841\n",
-      "        total_loss: 5.504689037799835\n",
-      "        vf_explained_var: 0.9918516874313354\n",
-      "        vf_loss: 5.53369448184967\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
-      "  iterations_since_restore: 9\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 26.15625\n",
-      "    gpu_util_percent0: 0.2734375\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.465625\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15359854017386879\n",
-      "    mean_env_wait_ms: 1.601715352177999\n",
-      "    mean_inference_ms: 4.694742071474369\n",
-      "    mean_raw_obs_processing_ms: 0.4019907511305347\n",
-      "  time_since_restore: 250.65174460411072\n",
-      "  time_this_iter_s: 27.228005170822144\n",
-      "  time_total_s: 250.65174460411072\n",
-      "  timers:\n",
-      "    learn_throughput: 8078.417\n",
-      "    learn_time_ms: 20027.685\n",
-      "    sample_throughput: 20977.883\n",
-      "    sample_time_ms: 7712.504\n",
-      "    update_time_ms: 43.814\n",
-      "  timestamp: 1602157812\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
-      "  training_iteration: 9\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      9 |          250.652 | 1456128 |  228.169 |              282.485 |              115.788 |            835.094 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-50-39\n",
-      "  done: false\n",
-      "  episode_len_mean: 832.079641350211\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 228.59731279035063\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 180\n",
-      "  episodes_total: 1896\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9763310596346855\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007896899722982197\n",
-      "        model: {}\n",
-      "        policy_loss: -0.033220290520694105\n",
-      "        total_loss: 2.953149896860123\n",
-      "        vf_explained_var: 0.993627667427063\n",
-      "        vf_loss: 2.98479083776474\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
-      "  iterations_since_restore: 10\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.484375\n",
-      "    gpu_util_percent0: 0.288125\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.471875\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15317220656345867\n",
-      "    mean_env_wait_ms: 1.604245414768565\n",
-      "    mean_inference_ms: 4.668108436640403\n",
-      "    mean_raw_obs_processing_ms: 0.40059241178385674\n",
-      "  time_since_restore: 278.01485896110535\n",
-      "  time_this_iter_s: 27.36311435699463\n",
-      "  time_total_s: 278.01485896110535\n",
-      "  timers:\n",
-      "    learn_throughput: 8090.085\n",
-      "    learn_time_ms: 19998.802\n",
-      "    sample_throughput: 21045.891\n",
-      "    sample_time_ms: 7687.581\n",
-      "    update_time_ms: 43.4\n",
-      "  timestamp: 1602157839\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
-      "  training_iteration: 10\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     10 |          278.015 | 1617920 |  228.597 |              282.485 |              115.788 |             832.08 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-51-07\n",
-      "  done: false\n",
-      "  episode_len_mean: 830.1703992210321\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 229.0675253017024\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9670185938477516\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007682974718045443\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03496774770319462\n",
-      "        total_loss: 2.589013671875\n",
-      "        vf_explained_var: 0.9946534037590027\n",
-      "        vf_loss: 2.622444784641266\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
-      "  iterations_since_restore: 11\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 26.23548387096774\n",
-      "    gpu_util_percent0: 0.26903225806451614\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.47741935483871\n",
-      "    vram_util_percent0: 0.06928501147917349\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15283766436808183\n",
-      "    mean_env_wait_ms: 1.6062695046004585\n",
-      "    mean_inference_ms: 4.647350806058767\n",
-      "    mean_raw_obs_processing_ms: 0.39949114295740445\n",
-      "  time_since_restore: 305.27174377441406\n",
-      "  time_this_iter_s: 27.256884813308716\n",
-      "  time_total_s: 305.27174377441406\n",
-      "  timers:\n",
-      "    learn_throughput: 8137.51\n",
-      "    learn_time_ms: 19882.248\n",
-      "    sample_throughput: 21520.396\n",
-      "    sample_time_ms: 7518.077\n",
-      "    update_time_ms: 41.114\n",
-      "  timestamp: 1602157867\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
-      "  training_iteration: 11\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     11 |          305.272 | 1779712 |  229.068 |              282.485 |              115.788 |             830.17 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-51-34\n",
-      "  done: false\n",
-      "  episode_len_mean: 828.50904159132\n",
-      "  episode_reward_max: 287.9191919191919\n",
-      "  episode_reward_mean: 229.5476966774434\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2212\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.940390695631504\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007805287896189839\n",
-      "        model: {}\n",
-      "        policy_loss: -0.035866627853829415\n",
-      "        total_loss: 2.6927455008029937\n",
-      "        vf_explained_var: 0.9949959516525269\n",
-      "        vf_loss: 2.7270510613918306\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
-      "  iterations_since_restore: 12\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.678787878787883\n",
-      "    gpu_util_percent0: 0.2809090909090909\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.466666666666667\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15253638840628728\n",
-      "    mean_env_wait_ms: 1.6081161690939731\n",
-      "    mean_inference_ms: 4.628595571108588\n",
-      "    mean_raw_obs_processing_ms: 0.39846808184493565\n",
-      "  time_since_restore: 332.607017993927\n",
-      "  time_this_iter_s: 27.33527421951294\n",
-      "  time_total_s: 332.607017993927\n",
-      "  timers:\n",
-      "    learn_throughput: 8176.778\n",
-      "    learn_time_ms: 19786.766\n",
-      "    sample_throughput: 21563.454\n",
-      "    sample_time_ms: 7503.065\n",
-      "    update_time_ms: 41.647\n",
-      "  timestamp: 1602157894\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
-      "  training_iteration: 12\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.6/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     12 |          332.607 | 1941504 |  229.548 |              287.919 |              115.788 |            828.509 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-52-01\n",
-      "  done: false\n",
-      "  episode_len_mean: 825.9173259493671\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 230.737545550441\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 316\n",
-      "  episodes_total: 2528\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9119029730558396\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007374470541253686\n",
-      "        model: {}\n",
-      "        policy_loss: -0.031025875953491776\n",
-      "        total_loss: 3.626113736629486\n",
-      "        vf_explained_var: 0.9953392744064331\n",
-      "        vf_loss: 3.655664700269699\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
-      "  iterations_since_restore: 13\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.699999999999996\n",
-      "    gpu_util_percent0: 0.2815625\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.465625\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15202521348457168\n",
-      "    mean_env_wait_ms: 1.6115012963552209\n",
-      "    mean_inference_ms: 4.596639178335069\n",
-      "    mean_raw_obs_processing_ms: 0.3967428044141634\n",
-      "  time_since_restore: 359.82592964172363\n",
-      "  time_this_iter_s: 27.21891164779663\n",
-      "  time_total_s: 359.82592964172363\n",
-      "  timers:\n",
-      "    learn_throughput: 8195.68\n",
-      "    learn_time_ms: 19741.132\n",
-      "    sample_throughput: 21654.113\n",
-      "    sample_time_ms: 7471.652\n",
-      "    update_time_ms: 42.032\n",
-      "  timestamp: 1602157921\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
-      "  training_iteration: 13\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     13 |          359.826 | 2103296 |  230.738 |               289.98 |              115.788 |            825.917 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-52-29\n",
-      "  done: false\n",
-      "  episode_len_mean: 824.9274013402829\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 231.18682355949656\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2686\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8989204004406929\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0074366391287185255\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03388760575326159\n",
-      "        total_loss: 2.3619153201580048\n",
-      "        vf_explained_var: 0.9957093000411987\n",
-      "        vf_loss: 2.394315606355667\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
-      "  iterations_since_restore: 14\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.40625\n",
-      "    gpu_util_percent0: 0.2846875\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.4781249999999995\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15180800096963903\n",
-      "    mean_env_wait_ms: 1.613010827888792\n",
-      "    mean_inference_ms: 4.582932598838708\n",
-      "    mean_raw_obs_processing_ms: 0.39601789200760174\n",
-      "  time_since_restore: 387.4496352672577\n",
-      "  time_this_iter_s: 27.623705625534058\n",
-      "  time_total_s: 387.4496352672577\n",
-      "  timers:\n",
-      "    learn_throughput: 8204.033\n",
-      "    learn_time_ms: 19721.031\n",
-      "    sample_throughput: 21680.325\n",
-      "    sample_time_ms: 7462.619\n",
-      "    update_time_ms: 41.93\n",
-      "  timestamp: 1602157949\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
-      "  training_iteration: 14\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     14 |           387.45 | 2265088 |  231.187 |               289.98 |              115.788 |            824.927 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-52-57\n",
-      "  done: false\n",
-      "  episode_len_mean: 824.0777074542897\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 231.63322749293204\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2844\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.895898899435997\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007697970513254404\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03602396983187646\n",
-      "        total_loss: 1.9372931450605393\n",
-      "        vf_explained_var: 0.9962417483329773\n",
-      "        vf_loss: 1.9717775255441665\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
-      "  iterations_since_restore: 15\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.83125\n",
-      "    gpu_util_percent0: 0.285625\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.475\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15161473875055903\n",
-      "    mean_env_wait_ms: 1.6144244916591914\n",
-      "    mean_inference_ms: 4.570359858195114\n",
-      "    mean_raw_obs_processing_ms: 0.3953474948059144\n",
-      "  time_since_restore: 414.69566917419434\n",
-      "  time_this_iter_s: 27.246033906936646\n",
-      "  time_total_s: 414.69566917419434\n",
-      "  timers:\n",
-      "    learn_throughput: 8216.436\n",
-      "    learn_time_ms: 19691.264\n",
-      "    sample_throughput: 21698.645\n",
-      "    sample_time_ms: 7456.318\n",
-      "    update_time_ms: 43.356\n",
-      "  timestamp: 1602157977\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
-      "  training_iteration: 15\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     15 |          414.696 | 2426880 |  231.633 |               289.98 |              115.788 |            824.078 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-53-24\n",
-      "  done: false\n",
-      "  episode_len_mean: 822.9910447761195\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 232.33685444829712\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 171\n",
-      "  episodes_total: 3015\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8683042243123055\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007607861259020865\n",
-      "        model: {}\n",
-      "        policy_loss: -0.036039730068296194\n",
-      "        total_loss: 2.116857588291168\n",
-      "        vf_explained_var: 0.9965157508850098\n",
-      "        vf_loss: 2.1513757526874544\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
-      "  iterations_since_restore: 16\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.764516129032256\n",
-      "    gpu_util_percent0: 0.297741935483871\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.470967741935484\n",
-      "    vram_util_percent0: 0.06928501147917349\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15141989112198903\n",
-      "    mean_env_wait_ms: 1.6159236661106888\n",
-      "    mean_inference_ms: 4.557815570915645\n",
-      "    mean_raw_obs_processing_ms: 0.39467050753293315\n",
-      "  time_since_restore: 441.87632274627686\n",
-      "  time_this_iter_s: 27.18065357208252\n",
-      "  time_total_s: 441.87632274627686\n",
-      "  timers:\n",
-      "    learn_throughput: 8211.786\n",
-      "    learn_time_ms: 19702.413\n",
-      "    sample_throughput: 21667.308\n",
-      "    sample_time_ms: 7467.102\n",
-      "    update_time_ms: 43.552\n",
-      "  timestamp: 1602158004\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
-      "  training_iteration: 16\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     16 |          441.876 | 2588672 |  232.337 |               289.98 |              115.788 |            822.991 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-53-51\n",
-      "  done: false\n",
-      "  episode_len_mean: 821.0216998191681\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 233.1551683197252\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 303\n",
-      "  episodes_total: 3318\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8348902150988579\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.00740289380773902\n",
-      "        model: {}\n",
-      "        policy_loss: -0.029998348827939482\n",
-      "        total_loss: 2.5100847482681274\n",
-      "        vf_explained_var: 0.9960853457450867\n",
-      "        vf_loss: 2.538602519035339\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
-      "  iterations_since_restore: 17\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.715625000000003\n",
-      "    gpu_util_percent0: 0.301875\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.4593750000000005\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15111617742851072\n",
-      "    mean_env_wait_ms: 1.6183026472863848\n",
-      "    mean_inference_ms: 4.5380869771344665\n",
-      "    mean_raw_obs_processing_ms: 0.3936242667088673\n",
-      "  time_since_restore: 469.05478024482727\n",
-      "  time_this_iter_s: 27.178457498550415\n",
-      "  time_total_s: 469.05478024482727\n",
-      "  timers:\n",
-      "    learn_throughput: 8204.084\n",
-      "    learn_time_ms: 19720.91\n",
-      "    sample_throughput: 21655.953\n",
-      "    sample_time_ms: 7471.017\n",
-      "    update_time_ms: 43.943\n",
-      "  timestamp: 1602158031\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
-      "  training_iteration: 17\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     17 |          469.055 | 2750464 |  233.155 |               289.98 |              115.788 |            821.022 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-54-19\n",
-      "  done: false\n",
-      "  episode_len_mean: 820.0376869965478\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 233.58232206995146\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3476\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8338133722543717\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007797137019224465\n",
-      "        model: {}\n",
-      "        policy_loss: -0.0366627115290612\n",
-      "        total_loss: 1.7475906014442444\n",
-      "        vf_explained_var: 0.9965535998344421\n",
-      "        vf_loss: 1.7826938778162003\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
-      "  iterations_since_restore: 18\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.784375\n",
-      "    gpu_util_percent0: 0.2903125\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.481249999999999\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15097538572791852\n",
-      "    mean_env_wait_ms: 1.6194704277376637\n",
-      "    mean_inference_ms: 4.52891423862918\n",
-      "    mean_raw_obs_processing_ms: 0.3931393304580003\n",
-      "  time_since_restore: 496.22354912757874\n",
-      "  time_this_iter_s: 27.168768882751465\n",
-      "  time_total_s: 496.22354912757874\n",
-      "  timers:\n",
-      "    learn_throughput: 8215.377\n",
-      "    learn_time_ms: 19693.8\n",
-      "    sample_throughput: 21639.305\n",
-      "    sample_time_ms: 7476.765\n",
-      "    update_time_ms: 37.093\n",
-      "  timestamp: 1602158059\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
-      "  training_iteration: 18\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     18 |          496.224 | 2912256 |  233.582 |               289.98 |              115.788 |            820.038 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-54-45\n",
-      "  done: false\n",
-      "  episode_len_mean: 819.1164006604292\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 234.0312925623877\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3634\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8341425269842148\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007575143571011722\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03457739797886461\n",
-      "        total_loss: 1.834545186161995\n",
-      "        vf_explained_var: 0.9961616396903992\n",
-      "        vf_loss: 1.8676075398921967\n",
-      "    num_steps_sampled: 3074048\n",
-      "    num_steps_trained: 3074048\n",
-      "  iterations_since_restore: 19\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 26.36774193548387\n",
-      "    gpu_util_percent0: 0.30548387096774193\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.480645161290322\n",
-      "    vram_util_percent0: 0.06928501147917349\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15084453438607362\n",
-      "    mean_env_wait_ms: 1.6205942190593885\n",
-      "    mean_inference_ms: 4.520349568470547\n",
-      "    mean_raw_obs_processing_ms: 0.3926786361932948\n",
-      "  time_since_restore: 522.9063003063202\n",
-      "  time_this_iter_s: 26.682751178741455\n",
-      "  time_total_s: 522.9063003063202\n",
-      "  timers:\n",
-      "    learn_throughput: 8235.447\n",
-      "    learn_time_ms: 19645.806\n",
-      "    sample_throughput: 21635.851\n",
-      "    sample_time_ms: 7477.959\n",
-      "    update_time_ms: 35.387\n",
-      "  timestamp: 1602158085\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3074048\n",
-      "  training_iteration: 19\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.6/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     19 |          522.906 | 3074048 |  234.031 |               289.98 |              115.788 |            819.116 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-55-13\n",
-      "  done: false\n",
-      "  episode_len_mean: 817.554763117677\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 234.8146184205786\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 292\n",
-      "  episodes_total: 3926\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7916461393237114\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007353159273043275\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03166137257358059\n",
-      "        total_loss: 2.4200849175453185\n",
-      "        vf_explained_var: 0.9965318441390991\n",
-      "        vf_loss: 2.450275695323944\n",
-      "    num_steps_sampled: 3235840\n",
-      "    num_steps_trained: 3235840\n",
-      "  iterations_since_restore: 20\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.421875\n",
-      "    gpu_util_percent0: 0.2903125\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.471875000000001\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15062615343426108\n",
-      "    mean_env_wait_ms: 1.6226010223295135\n",
-      "    mean_inference_ms: 4.5059904498713115\n",
-      "    mean_raw_obs_processing_ms: 0.3919086060605794\n",
-      "  time_since_restore: 550.2158420085907\n",
-      "  time_this_iter_s: 27.309541702270508\n",
-      "  time_total_s: 550.2158420085907\n",
-      "  timers:\n",
-      "    learn_throughput: 8238.594\n",
-      "    learn_time_ms: 19638.301\n",
-      "    sample_throughput: 21617.958\n",
-      "    sample_time_ms: 7484.148\n",
-      "    update_time_ms: 35.351\n",
-      "  timestamp: 1602158113\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3235840\n",
-      "  training_iteration: 20\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     20 |          550.216 | 3235840 |  234.815 |               289.98 |              115.788 |            817.555 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-55-40\n",
-      "  done: false\n",
-      "  episode_len_mean: 816.6701557935735\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 235.22827594346575\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 182\n",
-      "  episodes_total: 4108\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7638061985373497\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007330618624109775\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03147139406064525\n",
-      "        total_loss: 1.8828283458948136\n",
-      "        vf_explained_var: 0.9963488578796387\n",
-      "        vf_loss: 1.912833634018898\n",
-      "    num_steps_sampled: 3397632\n",
-      "    num_steps_trained: 3397632\n",
-      "  iterations_since_restore: 21\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.924999999999997\n",
-      "    gpu_util_percent0: 0.301875\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.481249999999999\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15050530919609634\n",
-      "    mean_env_wait_ms: 1.623724292281501\n",
-      "    mean_inference_ms: 4.497921157414929\n",
-      "    mean_raw_obs_processing_ms: 0.3914896591205486\n",
-      "  time_since_restore: 577.2629189491272\n",
-      "  time_this_iter_s: 27.0470769405365\n",
-      "  time_total_s: 577.2629189491272\n",
-      "  timers:\n",
-      "    learn_throughput: 8242.44\n",
-      "    learn_time_ms: 19629.139\n",
-      "    sample_throughput: 21663.425\n",
-      "    sample_time_ms: 7468.441\n",
-      "    update_time_ms: 36.165\n",
-      "  timestamp: 1602158140\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3397632\n",
-      "  training_iteration: 21\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     21 |          577.263 | 3397632 |  235.228 |               289.98 |              115.788 |             816.67 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-56-08\n",
-      "  done: true\n",
-      "  episode_len_mean: 815.9498359118612\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 235.53961319713775\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4266\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7843831703066826\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007404250220861286\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03531548953615129\n",
-      "        total_loss: 1.534095871448517\n",
-      "        vf_explained_var: 0.996734619140625\n",
-      "        vf_loss: 1.5679305166006088\n",
-      "    num_steps_sampled: 3559424\n",
-      "    num_steps_trained: 3559424\n",
-      "  iterations_since_restore: 22\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.875\n",
-      "    gpu_util_percent0: 0.2996875\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.4875\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15040791303314213\n",
-      "    mean_env_wait_ms: 1.6246785514214\n",
-      "    mean_inference_ms: 4.4913398893005585\n",
-      "    mean_raw_obs_processing_ms: 0.39114072918445014\n",
-      "  time_since_restore: 604.5293033123016\n",
-      "  time_this_iter_s: 27.26638436317444\n",
-      "  time_total_s: 604.5293033123016\n",
-      "  timers:\n",
-      "    learn_throughput: 8243.137\n",
-      "    learn_time_ms: 19627.479\n",
-      "    sample_throughput: 21703.935\n",
-      "    sample_time_ms: 7454.501\n",
-      "    update_time_ms: 41.057\n",
-      "  timestamp: 1602158168\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3559424\n",
-      "  training_iteration: 22\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | TERMINATED |       |     22 |          604.529 | 3559424 |   235.54 |               289.98 |              115.788 |             815.95 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | TERMINATED |       |     22 |          604.529 | 3559424 |   235.54 |               289.98 |              115.788 |             815.95 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 2895, in get_loc\n",
-      "    return self._engine.get_loc(casted_key)\n",
-      "  File \"pandas/_libs/index.pyx\", line 70, in pandas._libs.index.IndexEngine.get_loc\n",
-      "  File \"pandas/_libs/index.pyx\", line 101, in pandas._libs.index.IndexEngine.get_loc\n",
-      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1675, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
-      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1683, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
-      "KeyError: 'custom_metrics'\n",
-      "\n",
-      "The above exception was the direct cause of the following exception:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"train.py\", line 66, in <module>\n",
-      "    train_func()\n",
-      "  File \"train.py\", line 55, in train_func\n",
-      "    my_custom_metric = result['custom_metrics']\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 2902, in __getitem__\n",
-      "    indexer = self.columns.get_loc(key)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 2897, in get_loc\n",
-      "    raise KeyError(key) from err\n",
-      "KeyError: 'custom_metrics'\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 79778\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201008_114550-82d8n3my/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201008_114550-82d8n3my/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33musual-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/82d8n3my\u001b[0m\n",
-      "2020-10-08 11:56:16,232 - wandb.wandb_agent - INFO - Cleaning up finished run: 82d8n3my\n",
-      "2020-10-08 11:56:16,524 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 11:56:16,524 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.2\n",
-      "\tlambda: 0.95\n",
-      "\tlr: 0.0001\n",
-      "\tnum_envs_per_worker: 2\n",
-      "\tnum_sgd_iter: 20\n",
-      "\tsgd_minibatch_size: 8192\n",
-      "2020-10-08 11:56:16,529 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=8192\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.5 is available!  To upgrade, please run:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.4\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msandy-sweep-2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/mq1j5yvs\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/uaw0r211\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_115618-uaw0r211\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-08 11:56:20,530\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8268\u001b[39m\u001b[22m\n",
-      "2020-10-08 11:56:21,566 - wandb.wandb_agent - INFO - Running runs: ['uaw0r211']\n",
-      "== Status ==\n",
-      "Memory usage on this node: 17.1/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_4898a_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
-      "\n",
-      "\n",
-      "\u001b[2m\u001b[36m(pid=22161)\u001b[0m 2020-10-08 11:56:23,493\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=22120)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22120)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22113)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22113)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22156)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22156)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22145)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22145)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22167)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22167)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22038)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22038)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22121)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22121)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22035)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22035)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22151)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22151)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22097)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22097)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22051)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22051)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22136)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22136)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22129)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22129)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22115)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22115)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22105)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22105)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22128)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22128)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22059)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22059)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22108)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22108)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22141)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22141)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22101)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22101)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22118)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22118)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22039)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22039)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22160)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22160)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22091)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22091)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22036)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22036)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22060)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22060)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22107)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22107)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22062)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22062)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22154)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22154)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22029)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22029)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22134)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22134)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22103)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22103)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22027)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22027)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22122)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22122)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22024)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22024)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22040)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22040)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22155)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22155)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22084)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22084)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22106)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22106)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22139)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22139)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22081)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22081)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22037)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22037)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22147)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22147)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22048)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22048)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22065)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22065)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22045)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22045)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22142)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22142)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22042)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22042)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22025)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22025)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22033)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22033)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22163)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22163)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22083)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22083)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22058)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22058)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22171)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22171)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22092)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22092)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22053)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22053)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22165)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22165)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22034)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22034)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22028)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22028)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22041)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22041)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22152)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22152)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22026)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22026)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22112)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22112)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22104)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22104)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22054)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22054)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22030)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22030)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22032)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22032)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22131)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22131)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22031)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22031)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22109)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22109)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22050)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22050)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22124)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22124)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22111)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22111)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22110)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22110)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22114)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22114)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22123)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22123)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22133)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22133)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22116)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22116)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22125)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22125)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_4898a_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_11-56-55\n",
-      "  done: false\n",
-      "  episode_len_mean: 877.1708860759494\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.28870988364636\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 8196fe3f2c5c4e22af63c11ec84b6459\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1611746549606323\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005718740075826645\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013096390827558934\n",
-      "        total_loss: 7.403090405464172\n",
-      "        vf_explained_var: 0.7892305254936218\n",
-      "        vf_loss: 7.415043115615845\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 32.55\n",
-      "    gpu_util_percent0: 0.22966666666666669\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.250000000000002\n",
-      "    vram_util_percent0: 0.06902809664370832\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 22161\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17109087125207587\n",
-      "    mean_env_wait_ms: 1.5727916416028063\n",
-      "    mean_inference_ms: 5.579640846923753\n",
-      "    mean_raw_obs_processing_ms: 0.4581124033961777\n",
-      "  time_since_restore: 25.996026754379272\n",
-      "  time_this_iter_s: 25.996026754379272\n",
-      "  time_total_s: 25.996026754379272\n",
-      "  timers:\n",
-      "    learn_throughput: 9708.757\n",
-      "    learn_time_ms: 16664.542\n",
-      "    sample_throughput: 17496.047\n",
-      "    sample_time_ms: 9247.346\n",
-      "    update_time_ms: 51.617\n",
-      "  timestamp: 1602158215\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: 4898a_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 32.9/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_4898a_00000 | RUNNING  | 172.17.0.4:22161 |      1 |           25.996 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_4898a_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3265.0\n",
-      "  date: 2020-10-08_11-57-19\n",
-      "  done: false\n",
-      "  episode_len_mean: 873.4715189873418\n",
-      "  episode_reward_max: 274.85858585858557\n",
-      "  episode_reward_mean: 227.3690384861269\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 8196fe3f2c5c4e22af63c11ec84b6459\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.132627922296524\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006706285546533764\n",
-      "        model: {}\n",
-      "        policy_loss: -0.016248987091239543\n",
-      "        total_loss: 5.631959009170532\n",
-      "        vf_explained_var: 0.9176143407821655\n",
-      "        vf_loss: 5.646866726875305\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 30.485714285714288\n",
-      "    gpu_util_percent0: 0.1157142857142857\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.446428571428571\n",
-      "    vram_util_percent0: 0.08043620859298131\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 22161\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1665971035079177\n",
-      "    mean_env_wait_ms: 1.5718622755619396\n",
-      "    mean_inference_ms: 5.344314668249787\n",
-      "    mean_raw_obs_processing_ms: 0.44582337103132463\n",
-      "  time_since_restore: 50.581798791885376\n",
-      "  time_this_iter_s: 24.585772037506104\n",
-      "  time_total_s: 50.581798791885376\n",
-      "  timers:\n",
-      "    learn_throughput: 9785.94\n",
-      "    learn_time_ms: 16533.108\n",
-      "    sample_throughput: 18656.081\n",
-      "    sample_time_ms: 8672.347\n",
-      "    update_time_ms: 45.172\n",
-      "  timestamp: 1602158239\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: 4898a_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_4898a_00000 | RUNNING  | 172.17.0.4:22161 |      2 |          50.5818 | 323584 |  227.369 |              274.859 |              115.788 |            873.472 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n"
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n"
      ]
     }
    ],
    "source": [
-    "!wandb agent mq1j5yvs"
+    "!wandb agent rfs7la4y"
    ]
   },
   {
diff --git a/JSS/.ipynb_checkpoints/train-checkpoint.py b/JSS/.ipynb_checkpoints/train-checkpoint.py
index 7209fb9..863e891 100644
--- a/JSS/.ipynb_checkpoints/train-checkpoint.py
+++ b/JSS/.ipynb_checkpoints/train-checkpoint.py
@@ -45,20 +45,24 @@ def train_func():
     config.pop('layer_size', None)
     config.pop('layer_nb', None)
 
-    
     ray.init()
+    
     stop = {
         "time_total_s": 600,
     }
-    analysis = tune.run(PPOTrainer, config=config, stop=stop)
-    result = analysis.results_df
-    my_custom_metric = result['custom_metrics']
-    wandb.log(my_custom_metric)
+    
+    analysis = tune.run(PPOTrainer, config=config, stop=stop, name="ppo-jss")
+    result = analysis.dataframe(metric='custom_metrics/time_step_min', mode='min').to_dict('index')[0]
+    wandb.log({'time_step_min': result['custom_metrics/time_step_min']})
+    if result['custom_metrics/time_step_max'] != float('inf'):
+        wandb.log({'time_step_max': result['custom_metrics/time_step_max']})
+        wandb.log({'time_step_mean': result['custom_metrics/time_step_mean']})
     wandb.log({'episode_reward_max': result['episode_reward_max']})
     wandb.log({'episode_reward_min': result['episode_reward_min']})
     wandb.log({'episode_reward_mean': result['episode_reward_mean']})
     wandb.log({'episodes_total': result['episodes_total']})
     wandb.log({'training_iteration': result['training_iteration']})
+
     ray.shutdown()
 
 
diff --git a/JSS/Untitled.ipynb b/JSS/Untitled.ipynb
index 71f6e33..f56932b 100644
--- a/JSS/Untitled.ipynb
+++ b/JSS/Untitled.ipynb
@@ -79,8 +79,8 @@
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Create sweep with ID: mq1j5yvs\n",
-      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/mq1j5yvs\n"
+      "Create sweep with ID: rfs7la4y\n",
+      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\n"
      ]
     }
    ],
@@ -90,7 +90,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": null,
    "metadata": {},
    "outputs": [
     {
@@ -98,207 +98,205 @@
      "output_type": "stream",
      "text": [
       "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n",
-      "2020-10-08 11:45:48,119 - wandb.wandb_agent - INFO - Running runs: []\n",
-      "2020-10-08 11:45:48,430 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 11:45:48,431 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "2020-10-08 14:03:50,854 - wandb.wandb_agent - INFO - Running runs: []\n",
+      "2020-10-08 14:03:51,189 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-08 14:03:51,189 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
       "\tclip_param: 0.2\n",
       "\tlambda: 0.95\n",
       "\tlr: 0.0001\n",
       "\tnum_envs_per_worker: 2\n",
       "\tnum_sgd_iter: 20\n",
       "\tsgd_minibatch_size: 4096\n",
-      "2020-10-08 11:45:48,434 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=4096\n",
+      "2020-10-08 14:03:51,192 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=4096\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.5 is available!  To upgrade, please run:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.4\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33musual-sweep-1\u001b[0m\n",
+      "2020-10-08 14:03:56,246 - wandb.wandb_agent - INFO - Running runs: ['5nvugt1y']\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfast-sweep-1\u001b[0m\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/mq1j5yvs\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/82d8n3my\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_114550-82d8n3my\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/5nvugt1y\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_140356-5nvugt1y\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-08 11:45:52,454\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8268\u001b[39m\u001b[22m\n",
-      "2020-10-08 11:45:53,470 - wandb.wandb_agent - INFO - Running runs: ['82d8n3my']\n",
+      "2020-10-08 14:03:58,257\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8271\u001b[39m\u001b[22m\n",
       "== Status ==\n",
-      "Memory usage on this node: 17.1/754.6 GiB\n",
+      "Memory usage on this node: 77.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
       "| Trial name              | status   | loc   |\n",
       "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  |       |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  |       |\n",
       "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=80010)\u001b[0m 2020-10-08 11:45:55,254\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=79990)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79990)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80020)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80020)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79986)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79986)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79996)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79996)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79992)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79992)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79974)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79974)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80017)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80017)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79966)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79966)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79993)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79993)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79977)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79977)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80000)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80000)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79965)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79965)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79975)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79975)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79970)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79970)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80002)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80002)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80012)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80012)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79960)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79960)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79941)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79941)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80004)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80004)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79976)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79976)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79957)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79957)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80006)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80006)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79888)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79888)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79902)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79902)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79901)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79901)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79891)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79891)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79962)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79962)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79879)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79879)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79972)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79972)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79898)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79898)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79985)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79985)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79978)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79978)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79880)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79880)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79895)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79895)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79908)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79908)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79967)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79967)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79875)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79875)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79953)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79953)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79907)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79907)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79968)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79968)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79910)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79910)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79887)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79887)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79878)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79878)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79959)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79959)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79886)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79886)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79958)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79958)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79981)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79981)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79955)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79955)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79948)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79948)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79877)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79877)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79973)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79973)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79917)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79917)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79890)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79890)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79997)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79997)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79964)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79964)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79956)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79956)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79914)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79914)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79942)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79942)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79989)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79989)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79889)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79889)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79900)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79900)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79916)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79916)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79984)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79984)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79885)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79885)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79896)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79896)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79893)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79893)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79876)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79876)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79894)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79894)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79944)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79944)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79904)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79904)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79943)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79943)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79971)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79971)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79969)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79969)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79987)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79987)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79961)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79961)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79952)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79952)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79913)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79913)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79892)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79892)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79963)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79963)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "\u001b[2m\u001b[36m(pid=57899)\u001b[0m 2020-10-08 14:04:01,486\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=57850)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57850)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57859)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57859)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57849)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57849)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57857)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57857)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57863)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57863)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57769)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57769)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57820)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57820)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57847)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57847)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57865)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57865)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57904)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57904)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57881)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57881)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57883)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57883)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57825)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57825)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57879)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57879)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57844)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57844)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57852)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57852)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57855)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57855)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57831)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57831)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57752)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57752)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57853)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57853)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57843)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57843)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57862)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57862)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57834)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57834)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57768)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57768)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57762)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57762)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57750)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57750)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57780)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57780)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57848)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57848)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57766)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57766)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57818)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57818)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57767)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57767)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57755)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57755)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57777)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57777)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57827)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57827)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57871)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57871)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57756)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57756)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57775)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57775)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57815)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57815)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57856)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57856)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57774)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57774)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57765)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57765)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57830)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57830)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57753)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57753)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57826)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57826)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57748)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57748)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57822)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57822)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57832)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57832)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57833)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57833)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57868)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57868)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57829)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57829)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57771)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57771)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57836)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57836)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57824)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57824)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57749)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57749)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57837)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57837)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57747)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57747)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57828)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57828)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57845)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57845)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57814)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57814)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57772)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57772)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57758)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57758)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57819)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57819)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57889)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57889)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57839)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57839)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57751)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57751)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57770)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57770)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57764)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57764)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57821)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57821)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57835)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57835)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57846)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57846)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57872)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57872)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57754)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57754)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57776)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57776)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57763)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57763)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57761)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57761)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57816)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57816)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57757)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57757)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57760)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57760)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57858)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57858)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_11-46-31\n",
+      "  date: 2020-10-08_14-04-38\n",
       "  done: false\n",
       "  episode_len_mean: 877.1708860759494\n",
       "  episode_reward_max: 273.13131313131294\n",
@@ -306,7 +304,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 158\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -330,59 +328,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.499999999999993\n",
-      "    gpu_util_percent0: 0.2733333333333334\n",
+      "    cpu_util_percent: 36.00833333333333\n",
+      "    gpu_util_percent0: 0.3225\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0002777777777777778\n",
-      "    ram_util_percent: 4.261111111111112\n",
-      "    vram_util_percent0: 0.06302157355781494\n",
+      "    ram_util_percent: 10.413888888888891\n",
+      "    vram_util_percent0: 0.27462328267920266\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16875616228481102\n",
-      "    mean_env_wait_ms: 1.5739218855242776\n",
-      "    mean_inference_ms: 5.591068856691865\n",
-      "    mean_raw_obs_processing_ms: 0.4506270552020118\n",
-      "  time_since_restore: 30.11682629585266\n",
-      "  time_this_iter_s: 30.11682629585266\n",
-      "  time_total_s: 30.11682629585266\n",
+      "    mean_action_processing_ms: 0.18350994266746734\n",
+      "    mean_env_wait_ms: 1.6865222444501913\n",
+      "    mean_inference_ms: 5.985971555624452\n",
+      "    mean_raw_obs_processing_ms: 0.49480385234157925\n",
+      "  time_since_restore: 30.92910385131836\n",
+      "  time_this_iter_s: 30.92910385131836\n",
+      "  time_total_s: 30.92910385131836\n",
       "  timers:\n",
-      "    learn_throughput: 7796.6\n",
-      "    learn_time_ms: 20751.61\n",
-      "    sample_throughput: 17419.067\n",
-      "    sample_time_ms: 9288.213\n",
-      "    update_time_ms: 44.874\n",
-      "  timestamp: 1602157591\n",
+      "    learn_throughput: 7789.468\n",
+      "    learn_time_ms: 20770.611\n",
+      "    sample_throughput: 16046.653\n",
+      "    sample_time_ms: 10082.601\n",
+      "    update_time_ms: 36.409\n",
+      "  timestamp: 1602165878\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 161792\n",
       "  training_iteration: 1\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 32.9/754.6 GiB\n",
+      "Memory usage on this node: 72.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      1 |          30.1168 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      1 |          30.9291 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_11-46-59\n",
+      "  date: 2020-10-08_14-05-08\n",
       "  done: false\n",
       "  episode_len_mean: 869.3417721518987\n",
       "  episode_reward_max: 273.13131313131294\n",
@@ -390,7 +388,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 316\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -414,59 +412,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 26.066666666666663\n",
-      "    gpu_util_percent0: 0.29\n",
+      "    cpu_util_percent: 30.90294117647059\n",
+      "    gpu_util_percent0: 0.26941176470588235\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.451515151515152\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.747058823529413\n",
+      "    vram_util_percent0: 0.257051492292555\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1640005638893568\n",
-      "    mean_env_wait_ms: 1.5775274092583902\n",
-      "    mean_inference_ms: 5.302413775269009\n",
-      "    mean_raw_obs_processing_ms: 0.43677931133826275\n",
-      "  time_since_restore: 58.54918050765991\n",
-      "  time_this_iter_s: 28.43235421180725\n",
-      "  time_total_s: 58.54918050765991\n",
+      "    mean_action_processing_ms: 0.17676173480204843\n",
+      "    mean_env_wait_ms: 1.6752662514608032\n",
+      "    mean_inference_ms: 5.6785297305935405\n",
+      "    mean_raw_obs_processing_ms: 0.4787812236414886\n",
+      "  time_since_restore: 59.91080617904663\n",
+      "  time_this_iter_s: 28.98170232772827\n",
+      "  time_total_s: 59.91080617904663\n",
       "  timers:\n",
-      "    learn_throughput: 7837.771\n",
-      "    learn_time_ms: 20642.602\n",
-      "    sample_throughput: 18926.883\n",
-      "    sample_time_ms: 8548.264\n",
-      "    update_time_ms: 42.329\n",
-      "  timestamp: 1602157619\n",
+      "    learn_throughput: 7835.536\n",
+      "    learn_time_ms: 20648.493\n",
+      "    sample_throughput: 17536.73\n",
+      "    sample_time_ms: 9225.893\n",
+      "    update_time_ms: 38.294\n",
+      "  timestamp: 1602165908\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 323584\n",
       "  training_iteration: 2\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      2 |          58.5492 | 323584 |    224.9 |              273.131 |              115.788 |            869.342 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      2 |          59.9108 | 323584 |    224.9 |              273.131 |              115.788 |            869.342 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3247.0\n",
-      "  date: 2020-10-08_11-47-27\n",
+      "  date: 2020-10-08_14-05-37\n",
       "  done: false\n",
       "  episode_len_mean: 864.6983122362869\n",
       "  episode_reward_max: 278.99999999999983\n",
@@ -474,7 +472,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 474\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -498,59 +496,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.75151515151515\n",
-      "    gpu_util_percent0: 0.2918181818181818\n",
+      "    cpu_util_percent: 31.057142857142864\n",
+      "    gpu_util_percent0: 0.2717142857142857\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.466666666666667\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.762857142857143\n",
+      "    vram_util_percent0: 0.257051492292555\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1610433593452084\n",
-      "    mean_env_wait_ms: 1.5791339042559354\n",
-      "    mean_inference_ms: 5.141168556600388\n",
-      "    mean_raw_obs_processing_ms: 0.4272760547189869\n",
-      "  time_since_restore: 86.52022004127502\n",
-      "  time_this_iter_s: 27.971039533615112\n",
-      "  time_total_s: 86.52022004127502\n",
+      "    mean_action_processing_ms: 0.17253118731808845\n",
+      "    mean_env_wait_ms: 1.669123154241675\n",
+      "    mean_inference_ms: 5.508714332828136\n",
+      "    mean_raw_obs_processing_ms: 0.46803146600593976\n",
+      "  time_since_restore: 89.00577521324158\n",
+      "  time_this_iter_s: 29.094969034194946\n",
+      "  time_total_s: 89.00577521324158\n",
       "  timers:\n",
-      "    learn_throughput: 7892.613\n",
-      "    learn_time_ms: 20499.168\n",
-      "    sample_throughput: 19596.92\n",
-      "    sample_time_ms: 8255.991\n",
-      "    update_time_ms: 42.426\n",
-      "  timestamp: 1602157647\n",
+      "    learn_throughput: 7852.583\n",
+      "    learn_time_ms: 20603.665\n",
+      "    sample_throughput: 18018.223\n",
+      "    sample_time_ms: 8979.354\n",
+      "    update_time_ms: 41.291\n",
+      "  timestamp: 1602165937\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 485376\n",
       "  training_iteration: 3\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
+      "Memory usage on this node: 73.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      3 |          86.5202 | 485376 |  225.522 |                  279 |              115.788 |            864.698 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      3 |          89.0058 | 485376 |  225.522 |                  279 |              115.788 |            864.698 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3247.0\n",
-      "  date: 2020-10-08_11-47-55\n",
+      "  date: 2020-10-08_14-06-05\n",
       "  done: false\n",
       "  episode_len_mean: 860.242088607595\n",
       "  episode_reward_max: 278.99999999999983\n",
@@ -558,7 +556,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 632\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -582,59 +580,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.815625\n",
-      "    gpu_util_percent0: 0.26625\n",
+      "    cpu_util_percent: 29.938235294117646\n",
+      "    gpu_util_percent0: 0.24941176470588236\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.46875\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.761764705882353\n",
+      "    vram_util_percent0: 0.257051492292555\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1590423832293999\n",
-      "    mean_env_wait_ms: 1.5820174193292231\n",
-      "    mean_inference_ms: 5.0251596991819705\n",
-      "    mean_raw_obs_processing_ms: 0.42029578233494164\n",
-      "  time_since_restore: 114.42771482467651\n",
-      "  time_this_iter_s: 27.90749478340149\n",
-      "  time_total_s: 114.42771482467651\n",
+      "    mean_action_processing_ms: 0.16972262222291365\n",
+      "    mean_env_wait_ms: 1.6663911084469907\n",
+      "    mean_inference_ms: 5.381286213374226\n",
+      "    mean_raw_obs_processing_ms: 0.46035908038467466\n",
+      "  time_since_restore: 117.6076283454895\n",
+      "  time_this_iter_s: 28.601853132247925\n",
+      "  time_total_s: 117.6076283454895\n",
       "  timers:\n",
-      "    learn_throughput: 7915.515\n",
-      "    learn_time_ms: 20439.858\n",
-      "    sample_throughput: 20021.505\n",
-      "    sample_time_ms: 8080.911\n",
-      "    update_time_ms: 41.717\n",
-      "  timestamp: 1602157675\n",
+      "    learn_throughput: 7898.804\n",
+      "    learn_time_ms: 20483.102\n",
+      "    sample_throughput: 18320.006\n",
+      "    sample_time_ms: 8831.438\n",
+      "    update_time_ms: 41.53\n",
+      "  timestamp: 1602165965\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 647168\n",
       "  training_iteration: 4\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      4 |          114.428 | 647168 |  225.506 |                  279 |              115.788 |            860.242 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      4 |          117.608 | 647168 |  225.506 |                  279 |              115.788 |            860.242 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3235.0\n",
-      "  date: 2020-10-08_11-48-23\n",
+      "  date: 2020-10-08_14-06-34\n",
       "  done: false\n",
       "  episode_len_mean: 853.6054421768707\n",
       "  episode_reward_max: 278.99999999999983\n",
@@ -642,7 +640,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 250\n",
       "  episodes_total: 882\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -666,59 +664,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.309374999999996\n",
-      "    gpu_util_percent0: 0.2690625\n",
+      "    cpu_util_percent: 30.05\n",
+      "    gpu_util_percent0: 0.27676470588235297\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.4593750000000005\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.755882352941178\n",
+      "    vram_util_percent0: 0.257051492292555\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1569472608169185\n",
-      "    mean_env_wait_ms: 1.5876407685008682\n",
-      "    mean_inference_ms: 4.901463646021808\n",
-      "    mean_raw_obs_processing_ms: 0.4132403078994484\n",
-      "  time_since_restore: 142.0127465724945\n",
-      "  time_this_iter_s: 27.585031747817993\n",
-      "  time_total_s: 142.0127465724945\n",
+      "    mean_action_processing_ms: 0.1668569945682094\n",
+      "    mean_env_wait_ms: 1.6661518036410352\n",
+      "    mean_inference_ms: 5.245339771382172\n",
+      "    mean_raw_obs_processing_ms: 0.45204585691645865\n",
+      "  time_since_restore: 146.34429287910461\n",
+      "  time_this_iter_s: 28.736664533615112\n",
+      "  time_total_s: 146.34429287910461\n",
       "  timers:\n",
-      "    learn_throughput: 7949.618\n",
-      "    learn_time_ms: 20352.173\n",
-      "    sample_throughput: 20316.996\n",
-      "    sample_time_ms: 7963.382\n",
-      "    update_time_ms: 40.79\n",
-      "  timestamp: 1602157703\n",
+      "    learn_throughput: 7912.652\n",
+      "    learn_time_ms: 20447.253\n",
+      "    sample_throughput: 18556.235\n",
+      "    sample_time_ms: 8719.01\n",
+      "    update_time_ms: 53.489\n",
+      "  timestamp: 1602165994\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 808960\n",
       "  training_iteration: 5\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      5 |          142.013 | 808960 |  226.644 |                  279 |              115.788 |            853.605 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      5 |          146.344 | 808960 |  226.644 |                  279 |              115.788 |            853.605 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3235.0\n",
-      "  date: 2020-10-08_11-48-50\n",
+      "  date: 2020-10-08_14-07-03\n",
       "  done: false\n",
       "  episode_len_mean: 847.8264014466546\n",
       "  episode_reward_max: 278.99999999999983\n",
@@ -726,7 +724,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 224\n",
       "  episodes_total: 1106\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -750,59 +748,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.978125\n",
-      "    gpu_util_percent0: 0.294375\n",
+      "    cpu_util_percent: 31.087878787878783\n",
+      "    gpu_util_percent0: 0.2751515151515152\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.4625\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.751515151515152\n",
+      "    vram_util_percent0: 0.2570514922925549\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1557195397072005\n",
-      "    mean_env_wait_ms: 1.5919018099970674\n",
-      "    mean_inference_ms: 4.826965344047954\n",
-      "    mean_raw_obs_processing_ms: 0.4091659356791254\n",
-      "  time_since_restore: 168.97307991981506\n",
-      "  time_this_iter_s: 26.960333347320557\n",
-      "  time_total_s: 168.97307991981506\n",
+      "    mean_action_processing_ms: 0.16521363319543925\n",
+      "    mean_env_wait_ms: 1.6677695579501226\n",
+      "    mean_inference_ms: 5.160918708210536\n",
+      "    mean_raw_obs_processing_ms: 0.4472775860567577\n",
+      "  time_since_restore: 174.83844447135925\n",
+      "  time_this_iter_s: 28.49415159225464\n",
+      "  time_total_s: 174.83844447135925\n",
       "  timers:\n",
-      "    learn_throughput: 8004.051\n",
-      "    learn_time_ms: 20213.764\n",
-      "    sample_throughput: 20586.195\n",
-      "    sample_time_ms: 7859.248\n",
-      "    update_time_ms: 40.239\n",
-      "  timestamp: 1602157730\n",
+      "    learn_throughput: 7937.482\n",
+      "    learn_time_ms: 20383.289\n",
+      "    sample_throughput: 18693.433\n",
+      "    sample_time_ms: 8655.018\n",
+      "    update_time_ms: 51.581\n",
+      "  timestamp: 1602166023\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 970752\n",
       "  training_iteration: 6\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      6 |          168.973 | 970752 |  227.106 |                  279 |              115.788 |            847.826 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      6 |          174.838 | 970752 |  227.106 |                  279 |              115.788 |            847.826 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-49-17\n",
+      "  date: 2020-10-08_14-07-31\n",
       "  done: false\n",
       "  episode_len_mean: 844.1083860759494\n",
       "  episode_reward_max: 282.4848484848477\n",
@@ -810,7 +808,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 1264\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -834,59 +832,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.95\n",
-      "    gpu_util_percent0: 0.28812499999999996\n",
+      "    cpu_util_percent: 30.423529411764708\n",
+      "    gpu_util_percent0: 0.25617647058823534\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.475\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.76764705882353\n",
+      "    vram_util_percent0: 0.257051492292555\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15503429170730368\n",
-      "    mean_env_wait_ms: 1.594563087955357\n",
-      "    mean_inference_ms: 4.785002724236677\n",
-      "    mean_raw_obs_processing_ms: 0.4068913211080966\n",
-      "  time_since_restore: 195.9782907962799\n",
-      "  time_this_iter_s: 27.005210876464844\n",
-      "  time_total_s: 195.9782907962799\n",
+      "    mean_action_processing_ms: 0.16428938352115002\n",
+      "    mean_env_wait_ms: 1.6688146539398103\n",
+      "    mean_inference_ms: 5.1135213379920055\n",
+      "    mean_raw_obs_processing_ms: 0.4445629925416077\n",
+      "  time_since_restore: 203.33799719810486\n",
+      "  time_this_iter_s: 28.499552726745605\n",
+      "  time_total_s: 203.33799719810486\n",
       "  timers:\n",
-      "    learn_throughput: 8045.813\n",
-      "    learn_time_ms: 20108.844\n",
-      "    sample_throughput: 20766.024\n",
-      "    sample_time_ms: 7791.188\n",
-      "    update_time_ms: 38.206\n",
-      "  timestamp: 1602157757\n",
+      "    learn_throughput: 7953.152\n",
+      "    learn_time_ms: 20343.13\n",
+      "    sample_throughput: 18800.381\n",
+      "    sample_time_ms: 8605.783\n",
+      "    update_time_ms: 48.851\n",
+      "  timestamp: 1602166051\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1132544\n",
       "  training_iteration: 7\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      7 |          195.978 | 1132544 |   227.63 |              282.485 |              115.788 |            844.108 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      7 |          203.338 | 1132544 |   227.63 |              282.485 |              115.788 |            844.108 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-49-44\n",
+      "  date: 2020-10-08_14-08-00\n",
       "  done: false\n",
       "  episode_len_mean: 840.8741209563995\n",
       "  episode_reward_max: 282.4848484848477\n",
@@ -894,7 +892,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 1422\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -918,59 +916,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.5625\n",
-      "    gpu_util_percent0: 0.2934375\n",
+      "    cpu_util_percent: 30.724242424242426\n",
+      "    gpu_util_percent0: 0.2678787878787879\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.471875\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.763636363636364\n",
+      "    vram_util_percent0: 0.2570514922925549\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15445205035357232\n",
-      "    mean_env_wait_ms: 1.5970754276033823\n",
-      "    mean_inference_ms: 4.748860951121171\n",
-      "    mean_raw_obs_processing_ms: 0.40491847437517203\n",
-      "  time_since_restore: 223.42373943328857\n",
-      "  time_this_iter_s: 27.445448637008667\n",
-      "  time_total_s: 223.42373943328857\n",
+      "    mean_action_processing_ms: 0.16348854866217513\n",
+      "    mean_env_wait_ms: 1.6700574598453726\n",
+      "    mean_inference_ms: 5.072164794599845\n",
+      "    mean_raw_obs_processing_ms: 0.44213624402114293\n",
+      "  time_since_restore: 231.6390438079834\n",
+      "  time_this_iter_s: 28.30104660987854\n",
+      "  time_total_s: 231.6390438079834\n",
       "  timers:\n",
-      "    learn_throughput: 8055.885\n",
-      "    learn_time_ms: 20083.703\n",
-      "    sample_throughput: 20900.724\n",
-      "    sample_time_ms: 7740.976\n",
-      "    update_time_ms: 44.602\n",
-      "  timestamp: 1602157784\n",
+      "    learn_throughput: 7959.464\n",
+      "    learn_time_ms: 20326.997\n",
+      "    sample_throughput: 18968.066\n",
+      "    sample_time_ms: 8529.705\n",
+      "    update_time_ms: 47.225\n",
+      "  timestamp: 1602166080\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1294336\n",
       "  training_iteration: 8\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      8 |          223.424 | 1294336 |  227.879 |              282.485 |              115.788 |            840.874 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      8 |          231.639 | 1294336 |  227.879 |              282.485 |              115.788 |            840.874 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-50-12\n",
+      "  date: 2020-10-08_14-08-28\n",
       "  done: false\n",
       "  episode_len_mean: 835.0944055944055\n",
       "  episode_reward_max: 282.4848484848477\n",
@@ -978,7 +976,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 294\n",
       "  episodes_total: 1716\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1002,59 +1000,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 26.15625\n",
-      "    gpu_util_percent0: 0.2734375\n",
+      "    cpu_util_percent: 30.59705882352941\n",
+      "    gpu_util_percent0: 0.25941176470588234\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.465625\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.755882352941178\n",
+      "    vram_util_percent0: 0.257051492292555\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15359854017386879\n",
-      "    mean_env_wait_ms: 1.601715352177999\n",
-      "    mean_inference_ms: 4.694742071474369\n",
-      "    mean_raw_obs_processing_ms: 0.4019907511305347\n",
-      "  time_since_restore: 250.65174460411072\n",
-      "  time_this_iter_s: 27.228005170822144\n",
-      "  time_total_s: 250.65174460411072\n",
+      "    mean_action_processing_ms: 0.162284443845516\n",
+      "    mean_env_wait_ms: 1.6727489665801578\n",
+      "    mean_inference_ms: 5.009821132584934\n",
+      "    mean_raw_obs_processing_ms: 0.4384857629606629\n",
+      "  time_since_restore: 259.97689414024353\n",
+      "  time_this_iter_s: 28.337850332260132\n",
+      "  time_total_s: 259.97689414024353\n",
       "  timers:\n",
-      "    learn_throughput: 8078.417\n",
-      "    learn_time_ms: 20027.685\n",
-      "    sample_throughput: 20977.883\n",
-      "    sample_time_ms: 7712.504\n",
-      "    update_time_ms: 43.814\n",
-      "  timestamp: 1602157812\n",
+      "    learn_throughput: 7968.61\n",
+      "    learn_time_ms: 20303.667\n",
+      "    sample_throughput: 19067.411\n",
+      "    sample_time_ms: 8485.263\n",
+      "    update_time_ms: 45.663\n",
+      "  timestamp: 1602166108\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1456128\n",
       "  training_iteration: 9\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      9 |          250.652 | 1456128 |  228.169 |              282.485 |              115.788 |            835.094 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      9 |          259.977 | 1456128 |  228.169 |              282.485 |              115.788 |            835.094 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-50-39\n",
+      "  date: 2020-10-08_14-08-57\n",
       "  done: false\n",
       "  episode_len_mean: 832.079641350211\n",
       "  episode_reward_max: 282.4848484848477\n",
@@ -1062,7 +1060,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 180\n",
       "  episodes_total: 1896\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1086,59 +1084,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.484375\n",
-      "    gpu_util_percent0: 0.288125\n",
+      "    cpu_util_percent: 29.339393939393936\n",
+      "    gpu_util_percent0: 0.29575757575757583\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.471875\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.769696969696971\n",
+      "    vram_util_percent0: 0.2570514922925549\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15317220656345867\n",
-      "    mean_env_wait_ms: 1.604245414768565\n",
-      "    mean_inference_ms: 4.668108436640403\n",
-      "    mean_raw_obs_processing_ms: 0.40059241178385674\n",
-      "  time_since_restore: 278.01485896110535\n",
-      "  time_this_iter_s: 27.36311435699463\n",
-      "  time_total_s: 278.01485896110535\n",
+      "    mean_action_processing_ms: 0.16170883141459513\n",
+      "    mean_env_wait_ms: 1.6746347609608598\n",
+      "    mean_inference_ms: 4.978956771385591\n",
+      "    mean_raw_obs_processing_ms: 0.43667186446988804\n",
+      "  time_since_restore: 288.5126984119415\n",
+      "  time_this_iter_s: 28.535804271697998\n",
+      "  time_total_s: 288.5126984119415\n",
       "  timers:\n",
-      "    learn_throughput: 8090.085\n",
-      "    learn_time_ms: 19998.802\n",
-      "    sample_throughput: 21045.891\n",
-      "    sample_time_ms: 7687.581\n",
-      "    update_time_ms: 43.4\n",
-      "  timestamp: 1602157839\n",
+      "    learn_throughput: 7972.454\n",
+      "    learn_time_ms: 20293.877\n",
+      "    sample_throughput: 19124.35\n",
+      "    sample_time_ms: 8460.0\n",
+      "    update_time_ms: 44.735\n",
+      "  timestamp: 1602166137\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1617920\n",
       "  training_iteration: 10\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     10 |          278.015 | 1617920 |  228.597 |              282.485 |              115.788 |             832.08 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     10 |          288.513 | 1617920 |  228.597 |              282.485 |              115.788 |             832.08 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-51-07\n",
+      "  date: 2020-10-08_14-09-25\n",
       "  done: false\n",
       "  episode_len_mean: 830.1703992210321\n",
       "  episode_reward_max: 282.4848484848477\n",
@@ -1146,7 +1144,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 2054\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1170,59 +1168,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 26.23548387096774\n",
-      "    gpu_util_percent0: 0.26903225806451614\n",
+      "    cpu_util_percent: 29.45151515151515\n",
+      "    gpu_util_percent0: 0.2739393939393939\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.47741935483871\n",
-      "    vram_util_percent0: 0.06928501147917349\n",
+      "    ram_util_percent: 9.763636363636364\n",
+      "    vram_util_percent0: 0.2570514922925549\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15283766436808183\n",
-      "    mean_env_wait_ms: 1.6062695046004585\n",
-      "    mean_inference_ms: 4.647350806058767\n",
-      "    mean_raw_obs_processing_ms: 0.39949114295740445\n",
-      "  time_since_restore: 305.27174377441406\n",
-      "  time_this_iter_s: 27.256884813308716\n",
-      "  time_total_s: 305.27174377441406\n",
+      "    mean_action_processing_ms: 0.16125382205207386\n",
+      "    mean_env_wait_ms: 1.6761243985903949\n",
+      "    mean_inference_ms: 4.954596343237678\n",
+      "    mean_raw_obs_processing_ms: 0.4352361222242559\n",
+      "  time_since_restore: 316.5878527164459\n",
+      "  time_this_iter_s: 28.075154304504395\n",
+      "  time_total_s: 316.5878527164459\n",
       "  timers:\n",
-      "    learn_throughput: 8137.51\n",
-      "    learn_time_ms: 19882.248\n",
-      "    sample_throughput: 21520.396\n",
-      "    sample_time_ms: 7518.077\n",
-      "    update_time_ms: 41.114\n",
-      "  timestamp: 1602157867\n",
+      "    learn_throughput: 8000.406\n",
+      "    learn_time_ms: 20222.974\n",
+      "    sample_throughput: 19629.04\n",
+      "    sample_time_ms: 8242.482\n",
+      "    update_time_ms: 45.435\n",
+      "  timestamp: 1602166165\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1779712\n",
       "  training_iteration: 11\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     11 |          305.272 | 1779712 |  229.068 |              282.485 |              115.788 |             830.17 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     11 |          316.588 | 1779712 |  229.068 |              282.485 |              115.788 |             830.17 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-51-34\n",
+      "  date: 2020-10-08_14-09-54\n",
       "  done: false\n",
       "  episode_len_mean: 828.50904159132\n",
       "  episode_reward_max: 287.9191919191919\n",
@@ -1230,7 +1228,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 2212\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1254,59 +1252,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.678787878787883\n",
-      "    gpu_util_percent0: 0.2809090909090909\n",
+      "    cpu_util_percent: 29.993939393939392\n",
+      "    gpu_util_percent0: 0.26969696969696966\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.466666666666667\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.757575757575758\n",
+      "    vram_util_percent0: 0.2570514922925549\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15253638840628728\n",
-      "    mean_env_wait_ms: 1.6081161690939731\n",
-      "    mean_inference_ms: 4.628595571108588\n",
-      "    mean_raw_obs_processing_ms: 0.39846808184493565\n",
-      "  time_since_restore: 332.607017993927\n",
-      "  time_this_iter_s: 27.33527421951294\n",
-      "  time_total_s: 332.607017993927\n",
+      "    mean_action_processing_ms: 0.16085250209822033\n",
+      "    mean_env_wait_ms: 1.6775510346401423\n",
+      "    mean_inference_ms: 4.932401985457557\n",
+      "    mean_raw_obs_processing_ms: 0.4338907507677086\n",
+      "  time_since_restore: 345.2145109176636\n",
+      "  time_this_iter_s: 28.62665820121765\n",
+      "  time_total_s: 345.2145109176636\n",
       "  timers:\n",
-      "    learn_throughput: 8176.778\n",
-      "    learn_time_ms: 19786.766\n",
-      "    sample_throughput: 21563.454\n",
-      "    sample_time_ms: 7503.065\n",
-      "    update_time_ms: 41.647\n",
-      "  timestamp: 1602157894\n",
+      "    learn_throughput: 8013.686\n",
+      "    learn_time_ms: 20189.46\n",
+      "    sample_throughput: 19635.364\n",
+      "    sample_time_ms: 8239.827\n",
+      "    update_time_ms: 45.402\n",
+      "  timestamp: 1602166194\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1941504\n",
       "  training_iteration: 12\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.6/754.6 GiB\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     12 |          332.607 | 1941504 |  229.548 |              287.919 |              115.788 |            828.509 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     12 |          345.215 | 1941504 |  229.548 |              287.919 |              115.788 |            828.509 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-52-01\n",
+      "  date: 2020-10-08_14-10-22\n",
       "  done: false\n",
       "  episode_len_mean: 825.9173259493671\n",
       "  episode_reward_max: 289.9797979797982\n",
@@ -1314,7 +1312,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 316\n",
       "  episodes_total: 2528\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1338,59 +1336,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.699999999999996\n",
-      "    gpu_util_percent0: 0.2815625\n",
+      "    cpu_util_percent: 30.370588235294115\n",
+      "    gpu_util_percent0: 0.2747058823529412\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.465625\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.75294117647059\n",
+      "    vram_util_percent0: 0.257051492292555\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15202521348457168\n",
-      "    mean_env_wait_ms: 1.6115012963552209\n",
-      "    mean_inference_ms: 4.596639178335069\n",
-      "    mean_raw_obs_processing_ms: 0.3967428044141634\n",
-      "  time_since_restore: 359.82592964172363\n",
-      "  time_this_iter_s: 27.21891164779663\n",
-      "  time_total_s: 359.82592964172363\n",
+      "    mean_action_processing_ms: 0.16017287678084888\n",
+      "    mean_env_wait_ms: 1.6802277086992836\n",
+      "    mean_inference_ms: 4.89439148640374\n",
+      "    mean_raw_obs_processing_ms: 0.4316389620412026\n",
+      "  time_since_restore: 373.45997977256775\n",
+      "  time_this_iter_s: 28.245468854904175\n",
+      "  time_total_s: 373.45997977256775\n",
       "  timers:\n",
-      "    learn_throughput: 8195.68\n",
-      "    learn_time_ms: 19741.132\n",
-      "    sample_throughput: 21654.113\n",
-      "    sample_time_ms: 7471.652\n",
-      "    update_time_ms: 42.032\n",
-      "  timestamp: 1602157921\n",
+      "    learn_throughput: 8026.419\n",
+      "    learn_time_ms: 20157.433\n",
+      "    sample_throughput: 19763.446\n",
+      "    sample_time_ms: 8186.427\n",
+      "    update_time_ms: 44.475\n",
+      "  timestamp: 1602166222\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2103296\n",
       "  training_iteration: 13\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     13 |          359.826 | 2103296 |  230.738 |               289.98 |              115.788 |            825.917 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     13 |           373.46 | 2103296 |  230.738 |               289.98 |              115.788 |            825.917 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-52-29\n",
+      "  date: 2020-10-08_14-10-50\n",
       "  done: false\n",
       "  episode_len_mean: 824.9274013402829\n",
       "  episode_reward_max: 289.9797979797982\n",
@@ -1398,7 +1396,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 2686\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1422,59 +1420,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.40625\n",
-      "    gpu_util_percent0: 0.2846875\n",
+      "    cpu_util_percent: 30.312121212121212\n",
+      "    gpu_util_percent0: 0.26151515151515153\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.4781249999999995\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.772727272727275\n",
+      "    vram_util_percent0: 0.2570514922925549\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15180800096963903\n",
-      "    mean_env_wait_ms: 1.613010827888792\n",
-      "    mean_inference_ms: 4.582932598838708\n",
-      "    mean_raw_obs_processing_ms: 0.39601789200760174\n",
-      "  time_since_restore: 387.4496352672577\n",
-      "  time_this_iter_s: 27.623705625534058\n",
-      "  time_total_s: 387.4496352672577\n",
+      "    mean_action_processing_ms: 0.15988462752258317\n",
+      "    mean_env_wait_ms: 1.6814425515145586\n",
+      "    mean_inference_ms: 4.878041025826835\n",
+      "    mean_raw_obs_processing_ms: 0.430664812314108\n",
+      "  time_since_restore: 401.80727195739746\n",
+      "  time_this_iter_s: 28.347292184829712\n",
+      "  time_total_s: 401.80727195739746\n",
       "  timers:\n",
-      "    learn_throughput: 8204.033\n",
-      "    learn_time_ms: 19721.031\n",
-      "    sample_throughput: 21680.325\n",
-      "    sample_time_ms: 7462.619\n",
-      "    update_time_ms: 41.93\n",
-      "  timestamp: 1602157949\n",
+      "    learn_throughput: 8023.866\n",
+      "    learn_time_ms: 20163.846\n",
+      "    sample_throughput: 19841.783\n",
+      "    sample_time_ms: 8154.106\n",
+      "    update_time_ms: 44.12\n",
+      "  timestamp: 1602166250\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2265088\n",
       "  training_iteration: 14\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     14 |           387.45 | 2265088 |  231.187 |               289.98 |              115.788 |            824.927 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     14 |          401.807 | 2265088 |  231.187 |               289.98 |              115.788 |            824.927 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-52-57\n",
+      "  date: 2020-10-08_14-11-19\n",
       "  done: false\n",
       "  episode_len_mean: 824.0777074542897\n",
       "  episode_reward_max: 289.9797979797982\n",
@@ -1482,7 +1480,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 2844\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1506,59 +1504,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.83125\n",
-      "    gpu_util_percent0: 0.285625\n",
+      "    cpu_util_percent: 29.59705882352941\n",
+      "    gpu_util_percent0: 0.27\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.475\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.761764705882353\n",
+      "    vram_util_percent0: 0.257051492292555\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15161473875055903\n",
-      "    mean_env_wait_ms: 1.6144244916591914\n",
-      "    mean_inference_ms: 4.570359858195114\n",
-      "    mean_raw_obs_processing_ms: 0.3953474948059144\n",
-      "  time_since_restore: 414.69566917419434\n",
-      "  time_this_iter_s: 27.246033906936646\n",
-      "  time_total_s: 414.69566917419434\n",
+      "    mean_action_processing_ms: 0.15962256586295442\n",
+      "    mean_env_wait_ms: 1.6825632050368664\n",
+      "    mean_inference_ms: 4.862887505621167\n",
+      "    mean_raw_obs_processing_ms: 0.42975456496408376\n",
+      "  time_since_restore: 430.180118560791\n",
+      "  time_this_iter_s: 28.372846603393555\n",
+      "  time_total_s: 430.180118560791\n",
       "  timers:\n",
-      "    learn_throughput: 8216.436\n",
-      "    learn_time_ms: 19691.264\n",
-      "    sample_throughput: 21698.645\n",
-      "    sample_time_ms: 7456.318\n",
-      "    update_time_ms: 43.356\n",
-      "  timestamp: 1602157977\n",
+      "    learn_throughput: 8029.244\n",
+      "    learn_time_ms: 20150.342\n",
+      "    sample_throughput: 19898.49\n",
+      "    sample_time_ms: 8130.868\n",
+      "    update_time_ms: 37.742\n",
+      "  timestamp: 1602166279\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2426880\n",
       "  training_iteration: 15\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     15 |          414.696 | 2426880 |  231.633 |               289.98 |              115.788 |            824.078 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     15 |           430.18 | 2426880 |  231.633 |               289.98 |              115.788 |            824.078 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-53-24\n",
+      "  date: 2020-10-08_14-11-48\n",
       "  done: false\n",
       "  episode_len_mean: 822.9910447761195\n",
       "  episode_reward_max: 289.9797979797982\n",
@@ -1566,7 +1564,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 171\n",
       "  episodes_total: 3015\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1590,59 +1588,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.764516129032256\n",
-      "    gpu_util_percent0: 0.297741935483871\n",
+      "    cpu_util_percent: 31.03030303030303\n",
+      "    gpu_util_percent0: 0.28878787878787876\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.470967741935484\n",
-      "    vram_util_percent0: 0.06928501147917349\n",
+      "    ram_util_percent: 9.76060606060606\n",
+      "    vram_util_percent0: 0.2570514922925549\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15141989112198903\n",
-      "    mean_env_wait_ms: 1.6159236661106888\n",
-      "    mean_inference_ms: 4.557815570915645\n",
-      "    mean_raw_obs_processing_ms: 0.39467050753293315\n",
-      "  time_since_restore: 441.87632274627686\n",
-      "  time_this_iter_s: 27.18065357208252\n",
-      "  time_total_s: 441.87632274627686\n",
+      "    mean_action_processing_ms: 0.15936424957771478\n",
+      "    mean_env_wait_ms: 1.6837075606485503\n",
+      "    mean_inference_ms: 4.8476482100837615\n",
+      "    mean_raw_obs_processing_ms: 0.4288385279340961\n",
+      "  time_since_restore: 458.61421608924866\n",
+      "  time_this_iter_s: 28.43409752845764\n",
+      "  time_total_s: 458.61421608924866\n",
       "  timers:\n",
-      "    learn_throughput: 8211.786\n",
-      "    learn_time_ms: 19702.413\n",
-      "    sample_throughput: 21667.308\n",
-      "    sample_time_ms: 7467.102\n",
-      "    update_time_ms: 43.552\n",
-      "  timestamp: 1602158004\n",
+      "    learn_throughput: 8025.775\n",
+      "    learn_time_ms: 20159.051\n",
+      "    sample_throughput: 19933.741\n",
+      "    sample_time_ms: 8116.489\n",
+      "    update_time_ms: 36.891\n",
+      "  timestamp: 1602166308\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2588672\n",
       "  training_iteration: 16\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     16 |          441.876 | 2588672 |  232.337 |               289.98 |              115.788 |            822.991 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     16 |          458.614 | 2588672 |  232.337 |               289.98 |              115.788 |            822.991 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-53-51\n",
+      "  date: 2020-10-08_14-12-16\n",
       "  done: false\n",
       "  episode_len_mean: 821.0216998191681\n",
       "  episode_reward_max: 289.9797979797982\n",
@@ -1650,7 +1648,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 303\n",
       "  episodes_total: 3318\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1674,59 +1672,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.715625000000003\n",
-      "    gpu_util_percent0: 0.301875\n",
+      "    cpu_util_percent: 30.170588235294122\n",
+      "    gpu_util_percent0: 0.22911764705882354\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.4593750000000005\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.75294117647059\n",
+      "    vram_util_percent0: 0.257051492292555\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15111617742851072\n",
-      "    mean_env_wait_ms: 1.6183026472863848\n",
-      "    mean_inference_ms: 4.5380869771344665\n",
-      "    mean_raw_obs_processing_ms: 0.3936242667088673\n",
-      "  time_since_restore: 469.05478024482727\n",
-      "  time_this_iter_s: 27.178457498550415\n",
-      "  time_total_s: 469.05478024482727\n",
+      "    mean_action_processing_ms: 0.1589481712029165\n",
+      "    mean_env_wait_ms: 1.6856610626461734\n",
+      "    mean_inference_ms: 4.823647348850542\n",
+      "    mean_raw_obs_processing_ms: 0.4273782452417025\n",
+      "  time_since_restore: 486.7920489311218\n",
+      "  time_this_iter_s: 28.17783284187317\n",
+      "  time_total_s: 486.7920489311218\n",
       "  timers:\n",
-      "    learn_throughput: 8204.084\n",
-      "    learn_time_ms: 19720.91\n",
-      "    sample_throughput: 21655.953\n",
-      "    sample_time_ms: 7471.017\n",
-      "    update_time_ms: 43.943\n",
-      "  timestamp: 1602158031\n",
+      "    learn_throughput: 8025.414\n",
+      "    learn_time_ms: 20159.958\n",
+      "    sample_throughput: 20020.205\n",
+      "    sample_time_ms: 8081.436\n",
+      "    update_time_ms: 37.784\n",
+      "  timestamp: 1602166336\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2750464\n",
       "  training_iteration: 17\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     17 |          469.055 | 2750464 |  233.155 |               289.98 |              115.788 |            821.022 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     17 |          486.792 | 2750464 |  233.155 |               289.98 |              115.788 |            821.022 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-54-19\n",
+      "  date: 2020-10-08_14-12-44\n",
       "  done: false\n",
       "  episode_len_mean: 820.0376869965478\n",
       "  episode_reward_max: 289.9797979797982\n",
@@ -1734,7 +1732,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 3476\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1758,59 +1756,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.784375\n",
-      "    gpu_util_percent0: 0.2903125\n",
+      "    cpu_util_percent: 30.263636363636362\n",
+      "    gpu_util_percent0: 0.2739393939393939\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.481249999999999\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.769696969696971\n",
+      "    vram_util_percent0: 0.2570514922925549\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15097538572791852\n",
-      "    mean_env_wait_ms: 1.6194704277376637\n",
-      "    mean_inference_ms: 4.52891423862918\n",
-      "    mean_raw_obs_processing_ms: 0.3931393304580003\n",
-      "  time_since_restore: 496.22354912757874\n",
-      "  time_this_iter_s: 27.168768882751465\n",
-      "  time_total_s: 496.22354912757874\n",
+      "    mean_action_processing_ms: 0.15875079551526766\n",
+      "    mean_env_wait_ms: 1.6865974079727117\n",
+      "    mean_inference_ms: 4.812393081904589\n",
+      "    mean_raw_obs_processing_ms: 0.42669712128025067\n",
+      "  time_since_restore: 515.002126455307\n",
+      "  time_this_iter_s: 28.21007752418518\n",
+      "  time_total_s: 515.002126455307\n",
       "  timers:\n",
-      "    learn_throughput: 8215.377\n",
-      "    learn_time_ms: 19693.8\n",
-      "    sample_throughput: 21639.305\n",
-      "    sample_time_ms: 7476.765\n",
-      "    update_time_ms: 37.093\n",
-      "  timestamp: 1602158059\n",
+      "    learn_throughput: 8034.771\n",
+      "    learn_time_ms: 20136.48\n",
+      "    sample_throughput: 19987.012\n",
+      "    sample_time_ms: 8094.857\n",
+      "    update_time_ms: 37.274\n",
+      "  timestamp: 1602166364\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2912256\n",
       "  training_iteration: 18\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     18 |          496.224 | 2912256 |  233.582 |               289.98 |              115.788 |            820.038 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     18 |          515.002 | 2912256 |  233.582 |               289.98 |              115.788 |            820.038 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-54-45\n",
+      "  date: 2020-10-08_14-13-13\n",
       "  done: false\n",
       "  episode_len_mean: 819.1164006604292\n",
       "  episode_reward_max: 289.9797979797982\n",
@@ -1818,7 +1816,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 3634\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1842,59 +1840,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 26.36774193548387\n",
-      "    gpu_util_percent0: 0.30548387096774193\n",
+      "    cpu_util_percent: 30.017647058823528\n",
+      "    gpu_util_percent0: 0.2832352941176471\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.480645161290322\n",
-      "    vram_util_percent0: 0.06928501147917349\n",
+      "    ram_util_percent: 9.76764705882353\n",
+      "    vram_util_percent0: 0.257051492292555\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15084453438607362\n",
-      "    mean_env_wait_ms: 1.6205942190593885\n",
-      "    mean_inference_ms: 4.520349568470547\n",
-      "    mean_raw_obs_processing_ms: 0.3926786361932948\n",
-      "  time_since_restore: 522.9063003063202\n",
-      "  time_this_iter_s: 26.682751178741455\n",
-      "  time_total_s: 522.9063003063202\n",
+      "    mean_action_processing_ms: 0.15856558726293105\n",
+      "    mean_env_wait_ms: 1.6874969155605837\n",
+      "    mean_inference_ms: 4.801814859500953\n",
+      "    mean_raw_obs_processing_ms: 0.42604884838564067\n",
+      "  time_since_restore: 543.3891928195953\n",
+      "  time_this_iter_s: 28.38706636428833\n",
+      "  time_total_s: 543.3891928195953\n",
       "  timers:\n",
-      "    learn_throughput: 8235.447\n",
-      "    learn_time_ms: 19645.806\n",
-      "    sample_throughput: 21635.851\n",
-      "    sample_time_ms: 7477.959\n",
-      "    update_time_ms: 35.387\n",
-      "  timestamp: 1602158085\n",
+      "    learn_throughput: 8037.512\n",
+      "    learn_time_ms: 20129.612\n",
+      "    sample_throughput: 19971.836\n",
+      "    sample_time_ms: 8101.008\n",
+      "    update_time_ms: 41.201\n",
+      "  timestamp: 1602166393\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3074048\n",
       "  training_iteration: 19\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.6/754.6 GiB\n",
+      "Memory usage on this node: 73.5/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     19 |          522.906 | 3074048 |  234.031 |               289.98 |              115.788 |            819.116 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     19 |          543.389 | 3074048 |  234.031 |               289.98 |              115.788 |            819.116 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-55-13\n",
+      "  date: 2020-10-08_14-13-42\n",
       "  done: false\n",
       "  episode_len_mean: 817.554763117677\n",
       "  episode_reward_max: 289.9797979797982\n",
@@ -1902,7 +1900,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 292\n",
       "  episodes_total: 3926\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1926,632 +1924,58 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.421875\n",
-      "    gpu_util_percent0: 0.2903125\n",
+      "    cpu_util_percent: 30.500000000000007\n",
+      "    gpu_util_percent0: 0.2582352941176471\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.471875000000001\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.755882352941178\n",
+      "    vram_util_percent0: 0.257051492292555\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15062615343426108\n",
-      "    mean_env_wait_ms: 1.6226010223295135\n",
-      "    mean_inference_ms: 4.5059904498713115\n",
-      "    mean_raw_obs_processing_ms: 0.3919086060605794\n",
-      "  time_since_restore: 550.2158420085907\n",
-      "  time_this_iter_s: 27.309541702270508\n",
-      "  time_total_s: 550.2158420085907\n",
+      "    mean_action_processing_ms: 0.15824728170515573\n",
+      "    mean_env_wait_ms: 1.689080359464987\n",
+      "    mean_inference_ms: 4.783977737237845\n",
+      "    mean_raw_obs_processing_ms: 0.4249789923662631\n",
+      "  time_since_restore: 572.0331726074219\n",
+      "  time_this_iter_s: 28.643979787826538\n",
+      "  time_total_s: 572.0331726074219\n",
       "  timers:\n",
-      "    learn_throughput: 8238.594\n",
-      "    learn_time_ms: 19638.301\n",
-      "    sample_throughput: 21617.958\n",
-      "    sample_time_ms: 7484.148\n",
-      "    update_time_ms: 35.351\n",
-      "  timestamp: 1602158113\n",
+      "    learn_throughput: 8035.517\n",
+      "    learn_time_ms: 20134.61\n",
+      "    sample_throughput: 19976.949\n",
+      "    sample_time_ms: 8098.935\n",
+      "    update_time_ms: 46.558\n",
+      "  timestamp: 1602166422\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3235840\n",
       "  training_iteration: 20\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     20 |          550.216 | 3235840 |  234.815 |               289.98 |              115.788 |            817.555 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-55-40\n",
-      "  done: false\n",
-      "  episode_len_mean: 816.6701557935735\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 235.22827594346575\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 182\n",
-      "  episodes_total: 4108\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7638061985373497\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007330618624109775\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03147139406064525\n",
-      "        total_loss: 1.8828283458948136\n",
-      "        vf_explained_var: 0.9963488578796387\n",
-      "        vf_loss: 1.912833634018898\n",
-      "    num_steps_sampled: 3397632\n",
-      "    num_steps_trained: 3397632\n",
-      "  iterations_since_restore: 21\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.924999999999997\n",
-      "    gpu_util_percent0: 0.301875\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.481249999999999\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15050530919609634\n",
-      "    mean_env_wait_ms: 1.623724292281501\n",
-      "    mean_inference_ms: 4.497921157414929\n",
-      "    mean_raw_obs_processing_ms: 0.3914896591205486\n",
-      "  time_since_restore: 577.2629189491272\n",
-      "  time_this_iter_s: 27.0470769405365\n",
-      "  time_total_s: 577.2629189491272\n",
-      "  timers:\n",
-      "    learn_throughput: 8242.44\n",
-      "    learn_time_ms: 19629.139\n",
-      "    sample_throughput: 21663.425\n",
-      "    sample_time_ms: 7468.441\n",
-      "    update_time_ms: 36.165\n",
-      "  timestamp: 1602158140\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3397632\n",
-      "  training_iteration: 21\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     21 |          577.263 | 3397632 |  235.228 |               289.98 |              115.788 |             816.67 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     20 |          572.033 | 3235840 |  234.815 |               289.98 |              115.788 |            817.555 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-56-08\n",
-      "  done: true\n",
-      "  episode_len_mean: 815.9498359118612\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 235.53961319713775\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4266\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7843831703066826\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007404250220861286\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03531548953615129\n",
-      "        total_loss: 1.534095871448517\n",
-      "        vf_explained_var: 0.996734619140625\n",
-      "        vf_loss: 1.5679305166006088\n",
-      "    num_steps_sampled: 3559424\n",
-      "    num_steps_trained: 3559424\n",
-      "  iterations_since_restore: 22\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.875\n",
-      "    gpu_util_percent0: 0.2996875\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.4875\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15040791303314213\n",
-      "    mean_env_wait_ms: 1.6246785514214\n",
-      "    mean_inference_ms: 4.4913398893005585\n",
-      "    mean_raw_obs_processing_ms: 0.39114072918445014\n",
-      "  time_since_restore: 604.5293033123016\n",
-      "  time_this_iter_s: 27.26638436317444\n",
-      "  time_total_s: 604.5293033123016\n",
-      "  timers:\n",
-      "    learn_throughput: 8243.137\n",
-      "    learn_time_ms: 19627.479\n",
-      "    sample_throughput: 21703.935\n",
-      "    sample_time_ms: 7454.501\n",
-      "    update_time_ms: 41.057\n",
-      "  timestamp: 1602158168\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3559424\n",
-      "  training_iteration: 22\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | TERMINATED |       |     22 |          604.529 | 3559424 |   235.54 |               289.98 |              115.788 |             815.95 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | TERMINATED |       |     22 |          604.529 | 3559424 |   235.54 |               289.98 |              115.788 |             815.95 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 2895, in get_loc\n",
-      "    return self._engine.get_loc(casted_key)\n",
-      "  File \"pandas/_libs/index.pyx\", line 70, in pandas._libs.index.IndexEngine.get_loc\n",
-      "  File \"pandas/_libs/index.pyx\", line 101, in pandas._libs.index.IndexEngine.get_loc\n",
-      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1675, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
-      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1683, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
-      "KeyError: 'custom_metrics'\n",
-      "\n",
-      "The above exception was the direct cause of the following exception:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"train.py\", line 66, in <module>\n",
-      "    train_func()\n",
-      "  File \"train.py\", line 55, in train_func\n",
-      "    my_custom_metric = result['custom_metrics']\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 2902, in __getitem__\n",
-      "    indexer = self.columns.get_loc(key)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 2897, in get_loc\n",
-      "    raise KeyError(key) from err\n",
-      "KeyError: 'custom_metrics'\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 79778\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201008_114550-82d8n3my/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201008_114550-82d8n3my/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33musual-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/82d8n3my\u001b[0m\n",
-      "2020-10-08 11:56:16,232 - wandb.wandb_agent - INFO - Cleaning up finished run: 82d8n3my\n",
-      "2020-10-08 11:56:16,524 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 11:56:16,524 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.2\n",
-      "\tlambda: 0.95\n",
-      "\tlr: 0.0001\n",
-      "\tnum_envs_per_worker: 2\n",
-      "\tnum_sgd_iter: 20\n",
-      "\tsgd_minibatch_size: 8192\n",
-      "2020-10-08 11:56:16,529 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=8192\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.5 is available!  To upgrade, please run:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.4\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msandy-sweep-2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/mq1j5yvs\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/uaw0r211\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_115618-uaw0r211\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-08 11:56:20,530\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8268\u001b[39m\u001b[22m\n",
-      "2020-10-08 11:56:21,566 - wandb.wandb_agent - INFO - Running runs: ['uaw0r211']\n",
-      "== Status ==\n",
-      "Memory usage on this node: 17.1/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_4898a_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
-      "\n",
-      "\n",
-      "\u001b[2m\u001b[36m(pid=22161)\u001b[0m 2020-10-08 11:56:23,493\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=22120)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22120)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22113)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22113)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22156)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22156)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22145)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22145)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22167)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22167)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22038)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22038)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22121)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22121)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22035)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22035)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22151)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22151)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22097)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22097)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22051)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22051)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22136)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22136)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22129)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22129)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22115)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22115)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22105)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22105)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22128)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22128)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22059)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22059)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22108)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22108)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22141)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22141)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22101)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22101)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22118)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22118)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22039)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22039)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22160)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22160)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22091)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22091)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22036)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22036)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22060)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22060)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22107)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22107)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22062)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22062)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22154)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22154)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22029)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22029)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22134)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22134)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22103)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22103)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22027)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22027)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22122)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22122)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22024)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22024)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22040)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22040)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22155)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22155)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22084)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22084)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22106)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22106)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22139)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22139)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22081)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22081)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22037)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22037)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22147)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22147)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22048)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22048)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22065)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22065)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22045)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22045)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22142)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22142)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22042)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22042)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22025)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22025)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22033)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22033)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22163)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22163)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22083)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22083)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22058)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22058)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22171)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22171)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22092)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22092)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22053)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22053)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22165)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22165)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22034)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22034)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22028)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22028)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22041)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22041)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22152)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22152)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22026)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22026)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22112)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22112)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22104)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22104)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22054)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22054)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22030)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22030)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22032)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22032)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22131)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22131)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22031)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22031)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22109)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22109)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22050)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22050)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22124)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22124)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22111)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22111)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22110)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22110)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22114)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22114)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22123)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22123)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22133)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22133)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22116)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22116)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22125)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22125)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_4898a_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_11-56-55\n",
-      "  done: false\n",
-      "  episode_len_mean: 877.1708860759494\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.28870988364636\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 8196fe3f2c5c4e22af63c11ec84b6459\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1611746549606323\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005718740075826645\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013096390827558934\n",
-      "        total_loss: 7.403090405464172\n",
-      "        vf_explained_var: 0.7892305254936218\n",
-      "        vf_loss: 7.415043115615845\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 32.55\n",
-      "    gpu_util_percent0: 0.22966666666666669\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.250000000000002\n",
-      "    vram_util_percent0: 0.06902809664370832\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 22161\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17109087125207587\n",
-      "    mean_env_wait_ms: 1.5727916416028063\n",
-      "    mean_inference_ms: 5.579640846923753\n",
-      "    mean_raw_obs_processing_ms: 0.4581124033961777\n",
-      "  time_since_restore: 25.996026754379272\n",
-      "  time_this_iter_s: 25.996026754379272\n",
-      "  time_total_s: 25.996026754379272\n",
-      "  timers:\n",
-      "    learn_throughput: 9708.757\n",
-      "    learn_time_ms: 16664.542\n",
-      "    sample_throughput: 17496.047\n",
-      "    sample_time_ms: 9247.346\n",
-      "    update_time_ms: 51.617\n",
-      "  timestamp: 1602158215\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: 4898a_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 32.9/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_4898a_00000 | RUNNING  | 172.17.0.4:22161 |      1 |           25.996 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_4898a_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3265.0\n",
-      "  date: 2020-10-08_11-57-19\n",
-      "  done: false\n",
-      "  episode_len_mean: 873.4715189873418\n",
-      "  episode_reward_max: 274.85858585858557\n",
-      "  episode_reward_mean: 227.3690384861269\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 8196fe3f2c5c4e22af63c11ec84b6459\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.132627922296524\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006706285546533764\n",
-      "        model: {}\n",
-      "        policy_loss: -0.016248987091239543\n",
-      "        total_loss: 5.631959009170532\n",
-      "        vf_explained_var: 0.9176143407821655\n",
-      "        vf_loss: 5.646866726875305\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 30.485714285714288\n",
-      "    gpu_util_percent0: 0.1157142857142857\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.446428571428571\n",
-      "    vram_util_percent0: 0.08043620859298131\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 22161\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1665971035079177\n",
-      "    mean_env_wait_ms: 1.5718622755619396\n",
-      "    mean_inference_ms: 5.344314668249787\n",
-      "    mean_raw_obs_processing_ms: 0.44582337103132463\n",
-      "  time_since_restore: 50.581798791885376\n",
-      "  time_this_iter_s: 24.585772037506104\n",
-      "  time_total_s: 50.581798791885376\n",
-      "  timers:\n",
-      "    learn_throughput: 9785.94\n",
-      "    learn_time_ms: 16533.108\n",
-      "    sample_throughput: 18656.081\n",
-      "    sample_time_ms: 8672.347\n",
-      "    update_time_ms: 45.172\n",
-      "  timestamp: 1602158239\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: 4898a_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_4898a_00000 | RUNNING  | 172.17.0.4:22161 |      2 |          50.5818 | 323584 |  227.369 |              274.859 |              115.788 |            873.472 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
       "\n"
      ]
     }
    ],
    "source": [
-    "!wandb agent mq1j5yvs"
+    "!wandb agent rfs7la4y"
    ]
   },
   {
diff --git a/JSS/train.py b/JSS/train.py
index f228f49..863e891 100644
--- a/JSS/train.py
+++ b/JSS/train.py
@@ -46,11 +46,13 @@ def train_func():
     config.pop('layer_nb', None)
 
     ray.init()
+    
     stop = {
         "time_total_s": 600,
     }
+    
     analysis = tune.run(PPOTrainer, config=config, stop=stop, name="ppo-jss")
-    result = analysis.dataframe().to_dict('index')[0]
+    result = analysis.dataframe(metric='custom_metrics/time_step_min', mode='min').to_dict('index')[0]
     wandb.log({'time_step_min': result['custom_metrics/time_step_min']})
     if result['custom_metrics/time_step_max'] != float('inf'):
         wandb.log({'time_step_max': result['custom_metrics/time_step_max']})
