2020-10-10 21:43:54,077	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_b21db_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=19011)[0m 2020-10-10 21:43:57,085	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=19067)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19067)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19040)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19040)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19042)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19042)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19055)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19055)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19037)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19037)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19000)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19000)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18997)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18997)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19059)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19059)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19036)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19036)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19035)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19035)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18994)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18994)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19030)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19030)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19043)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19043)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19046)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19046)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18999)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18999)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19003)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19003)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19051)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19051)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18959)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18959)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18993)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18993)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19012)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19012)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19027)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19027)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19054)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19054)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19020)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19020)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18953)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18953)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19026)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19026)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19063)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19063)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18998)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18998)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18954)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18954)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19002)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19002)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19009)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19009)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18944)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18944)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18932)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18932)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18943)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18943)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19052)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19052)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18941)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18941)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19008)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19008)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18951)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18951)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18940)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18940)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18968)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18968)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19007)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19007)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18956)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18956)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18991)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18991)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19048)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19048)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19010)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19010)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19017)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19017)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19006)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19006)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18937)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18937)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19005)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19005)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18961)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18961)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19019)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19019)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18949)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18949)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19001)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19001)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19004)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19004)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19013)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19013)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18933)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18933)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18927)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18927)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19034)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19034)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18964)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18964)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19072)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19072)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19061)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19061)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18929)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18929)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19015)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19015)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18942)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18942)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18935)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18935)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18996)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18996)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18930)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18930)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18992)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18992)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18926)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18926)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18995)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18995)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18938)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18938)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19021)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19021)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18934)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18934)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18939)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18939)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18965)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18965)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18947)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18947)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18958)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18958)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18970)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18970)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18928)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18928)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=19014)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=19014)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_b21db_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-10_21-44-35
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: bb588637d19840c98656b899e48e2ada
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.183196416922978
        entropy_coeff: 0.0
        kl: 0.006221698031627706
        model: {}
        policy_loss: -0.005186644478921413
        total_loss: 19.856052807399205
        vf_explained_var: 0.45542749762535095
        vf_loss: 19.85999502454485
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.90789473684211
    gpu_util_percent0: 0.2818421052631579
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0002631578947368421
    ram_util_percent: 6.286842105263159
    vram_util_percent0: 0.1920776440938358
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 19011
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1699556631598807
    mean_env_wait_ms: 1.1905947641370913
    mean_inference_ms: 5.529230417532477
    mean_raw_obs_processing_ms: 0.4553824392650259
  time_since_restore: 32.66426730155945
  time_this_iter_s: 32.66426730155945
  time_total_s: 32.66426730155945
  timers:
    learn_throughput: 6824.18
    learn_time_ms: 23708.638
    sample_throughput: 18216.416
    sample_time_ms: 8881.659
    update_time_ms: 38.268
  timestamp: 1602366275
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: b21db_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b21db_00000 | RUNNING  | 172.17.0.4:19011 |      1 |          32.6643 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b21db_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3610.2256944444443
    time_step_min: 3326
  date: 2020-10-10_21-45-07
  done: false
  episode_len_mean: 880.8132911392405
  episode_reward_max: 262.0808080808081
  episode_reward_mean: 217.4130865618205
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: bb588637d19840c98656b899e48e2ada
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.152367285319737
        entropy_coeff: 0.0
        kl: 0.00892393896356225
        model: {}
        policy_loss: -0.005702339478635362
        total_loss: 12.366759640829903
        vf_explained_var: 0.7787513732910156
        vf_loss: 12.370676926204137
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.497297297297298
    gpu_util_percent0: 0.3686486486486486
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.45945945945946
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 19011
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16566566408779856
    mean_env_wait_ms: 1.1907227640865372
    mean_inference_ms: 5.357955295282384
    mean_raw_obs_processing_ms: 0.4458286237883874
  time_since_restore: 64.11909055709839
  time_this_iter_s: 31.45482325553894
  time_total_s: 64.11909055709839
  timers:
    learn_throughput: 6847.384
    learn_time_ms: 23628.293
    sample_throughput: 19357.993
    sample_time_ms: 8357.891
    update_time_ms: 30.051
  timestamp: 1602366307
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: b21db_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b21db_00000 | RUNNING  | 172.17.0.4:19011 |      2 |          64.1191 | 323584 |  217.413 |              262.081 |              145.717 |            880.813 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b21db_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3597.255605381166
    time_step_min: 3271
  date: 2020-10-10_21-45-38
  done: false
  episode_len_mean: 870.5464135021097
  episode_reward_max: 270.4141414141416
  episode_reward_mean: 220.60561309295466
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: bb588637d19840c98656b899e48e2ada
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1344394172940935
        entropy_coeff: 0.0
        kl: 0.007885392655485443
        model: {}
        policy_loss: -0.003997512012054878
        total_loss: 13.007328919001989
        vf_explained_var: 0.8600739240646362
        vf_loss: 13.009749480656215
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.962162162162162
    gpu_util_percent0: 0.3189189189189189
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4837837837837835
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 19011
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1629569274067111
    mean_env_wait_ms: 1.1931064567708205
    mean_inference_ms: 5.214917683852175
    mean_raw_obs_processing_ms: 0.43792448214122864
  time_since_restore: 95.41135835647583
  time_this_iter_s: 31.29226779937744
  time_total_s: 95.41135835647583
  timers:
    learn_throughput: 6845.326
    learn_time_ms: 23635.398
    sample_throughput: 19998.724
    sample_time_ms: 8090.116
    update_time_ms: 33.401
  timestamp: 1602366338
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: b21db_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b21db_00000 | RUNNING  | 172.17.0.4:19011 |      3 |          95.4114 | 485376 |  220.606 |              270.414 |              145.717 |            870.546 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b21db_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3587.53642384106
    time_step_min: 3271
  date: 2020-10-10_21-46-09
  done: false
  episode_len_mean: 861.0743670886076
  episode_reward_max: 270.4141414141416
  episode_reward_mean: 221.90891510037062
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: bb588637d19840c98656b899e48e2ada
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1029963152749198
        entropy_coeff: 0.0
        kl: 0.007062608243099281
        model: {}
        policy_loss: -0.0065814954162176165
        total_loss: 15.176173073904854
        vf_explained_var: 0.8925638794898987
        vf_loss: 15.181341511862618
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.31351351351351
    gpu_util_percent0: 0.2602702702702702
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486486486486487
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 19011
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16105485435613362
    mean_env_wait_ms: 1.1967758991275197
    mean_inference_ms: 5.108176326700419
    mean_raw_obs_processing_ms: 0.43186725074927085
  time_since_restore: 126.64277935028076
  time_this_iter_s: 31.23142099380493
  time_total_s: 126.64277935028076
  timers:
    learn_throughput: 6839.474
    learn_time_ms: 23655.621
    sample_throughput: 20405.576
    sample_time_ms: 7928.813
    update_time_ms: 30.079
  timestamp: 1602366369
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: b21db_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b21db_00000 | RUNNING  | 172.17.0.4:19011 |      4 |          126.643 | 647168 |  221.909 |              270.414 |              145.717 |            861.074 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b21db_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3581.5868852459016
    time_step_min: 3271
  date: 2020-10-10_21-46-41
  done: false
  episode_len_mean: 845.4411452810181
  episode_reward_max: 274.65656565656553
  episode_reward_mean: 223.8183317801556
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 311
  episodes_total: 943
  experiment_id: bb588637d19840c98656b899e48e2ada
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.0798470888819014
        entropy_coeff: 0.0
        kl: 0.005525811741660748
        model: {}
        policy_loss: -0.006506109011492559
        total_loss: 21.168358666556223
        vf_explained_var: 0.9352614283561707
        vf_loss: 21.173759732927596
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.218918918918916
    gpu_util_percent0: 0.3464864864864865
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.472972972972974
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 19011
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15864822865116113
    mean_env_wait_ms: 1.2054831502601189
    mean_inference_ms: 4.971620631764281
    mean_raw_obs_processing_ms: 0.4243517957131912
  time_since_restore: 157.9573917388916
  time_this_iter_s: 31.31461238861084
  time_total_s: 157.9573917388916
  timers:
    learn_throughput: 6831.664
    learn_time_ms: 23682.665
    sample_throughput: 20695.093
    sample_time_ms: 7817.892
    update_time_ms: 28.207
  timestamp: 1602366401
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: b21db_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b21db_00000 | RUNNING  | 172.17.0.4:19011 |      5 |          157.957 | 808960 |  223.818 |              274.657 |              145.717 |            845.441 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b21db_00000:
  custom_metrics:
    time_step_max: 4125
    time_step_mean: 3577.3905380333954
    time_step_min: 3271
  date: 2020-10-10_21-47-12
  done: false
  episode_len_mean: 839.0271247739602
  episode_reward_max: 274.65656565656553
  episode_reward_mean: 224.44710212431715
  episode_reward_min: 141.0202020202019
  episodes_this_iter: 163
  episodes_total: 1106
  experiment_id: bb588637d19840c98656b899e48e2ada
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.059916308947972
        entropy_coeff: 0.0
        kl: 0.006831658604953971
        model: {}
        policy_loss: -0.004639473698002153
        total_loss: 14.30281857081822
        vf_explained_var: 0.9448420405387878
        vf_loss: 14.306091444832939
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.061111111111114
    gpu_util_percent0: 0.33944444444444444
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494444444444444
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 19011
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15775600106529608
    mean_env_wait_ms: 1.2089377212307788
    mean_inference_ms: 4.9213528295252065
    mean_raw_obs_processing_ms: 0.42161164338634954
  time_since_restore: 189.050790309906
  time_this_iter_s: 31.093398571014404
  time_total_s: 189.050790309906
  timers:
    learn_throughput: 6825.882
    learn_time_ms: 23702.724
    sample_throughput: 20972.605
    sample_time_ms: 7714.445
    update_time_ms: 30.249
  timestamp: 1602366432
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: b21db_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b21db_00000 | RUNNING  | 172.17.0.4:19011 |      6 |          189.051 | 970752 |  224.447 |              274.657 |               141.02 |            839.027 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b21db_00000:
  custom_metrics:
    time_step_max: 4168
    time_step_mean: 3573.394012944984
    time_step_min: 3226
  date: 2020-10-10_21-47-43
  done: false
  episode_len_mean: 833.568829113924
  episode_reward_max: 277.232323232323
  episode_reward_mean: 224.75006393044353
  episode_reward_min: 134.5050505050507
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: bb588637d19840c98656b899e48e2ada
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.0309960756983076
        entropy_coeff: 0.0
        kl: 0.0066709023833807024
        model: {}
        policy_loss: -0.006437805739031839
        total_loss: 12.728531769343785
        vf_explained_var: 0.9603498578071594
        vf_loss: 12.73363549368722
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.394594594594594
    gpu_util_percent0: 0.31405405405405407
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.489189189189189
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 19011
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1570189059249108
    mean_env_wait_ms: 1.2119583596309111
    mean_inference_ms: 4.879615486953013
    mean_raw_obs_processing_ms: 0.41923915898356234
  time_since_restore: 220.14554286003113
  time_this_iter_s: 31.094752550125122
  time_total_s: 220.14554286003113
  timers:
    learn_throughput: 6826.052
    learn_time_ms: 23702.136
    sample_throughput: 21133.401
    sample_time_ms: 7655.748
    update_time_ms: 31.751
  timestamp: 1602366463
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: b21db_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b21db_00000 | RUNNING  | 172.17.0.4:19011 |      7 |          220.146 | 1132544 |   224.75 |              277.232 |              134.505 |            833.569 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b21db_00000:
  custom_metrics:
    time_step_max: 4168
    time_step_mean: 3572.309949892627
    time_step_min: 3226
  date: 2020-10-10_21-48-14
  done: false
  episode_len_mean: 829.2877192982456
  episode_reward_max: 277.232323232323
  episode_reward_mean: 224.8970760233917
  episode_reward_min: 134.5050505050507
  episodes_this_iter: 161
  episodes_total: 1425
  experiment_id: bb588637d19840c98656b899e48e2ada
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.9710189870425633
        entropy_coeff: 0.0
        kl: 0.0052007088836814675
        model: {}
        policy_loss: -0.004799154121428728
        total_loss: 12.273709229060582
        vf_explained_var: 0.9737722277641296
        vf_loss: 12.277468204498291
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.619444444444447
    gpu_util_percent0: 0.32333333333333336
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494444444444444
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 19011
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15638481872682627
    mean_env_wait_ms: 1.2150818887576265
    mean_inference_ms: 4.842873069232327
    mean_raw_obs_processing_ms: 0.417056461282983
  time_since_restore: 251.12467312812805
  time_this_iter_s: 30.979130268096924
  time_total_s: 251.12467312812805
  timers:
    learn_throughput: 6828.211
    learn_time_ms: 23694.64
    sample_throughput: 21271.967
    sample_time_ms: 7605.879
    update_time_ms: 30.394
  timestamp: 1602366494
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: b21db_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b21db_00000 | RUNNING  | 172.17.0.4:19011 |      8 |          251.125 | 1294336 |  224.897 |              277.232 |              134.505 |            829.288 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b21db_00000:
  custom_metrics:
    time_step_max: 4168
    time_step_mean: 3566.527485380117
    time_step_min: 3226
  date: 2020-10-10_21-48-45
  done: false
  episode_len_mean: 821.9614499424627
  episode_reward_max: 277.232323232323
  episode_reward_mean: 225.48397089421246
  episode_reward_min: 134.5050505050507
  episodes_this_iter: 313
  episodes_total: 1738
  experiment_id: bb588637d19840c98656b899e48e2ada
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.9425250376973834
        entropy_coeff: 0.0
        kl: 0.006032602429123861
        model: {}
        policy_loss: -0.003808679368895745
        total_loss: 13.566944462912423
        vf_explained_var: 0.9784101247787476
        vf_loss: 13.56954676764352
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.032432432432433
    gpu_util_percent0: 0.38702702702702696
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.47027027027027
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 19011
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15540925616607
    mean_env_wait_ms: 1.2207262215403578
    mean_inference_ms: 4.7861407278645025
    mean_raw_obs_processing_ms: 0.4137948996413228
  time_since_restore: 282.1550850868225
  time_this_iter_s: 31.030411958694458
  time_total_s: 282.1550850868225
  timers:
    learn_throughput: 6827.832
    learn_time_ms: 23695.956
    sample_throughput: 21406.304
    sample_time_ms: 7558.148
    update_time_ms: 29.544
  timestamp: 1602366525
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: b21db_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b21db_00000 | RUNNING  | 172.17.0.4:19011 |      9 |          282.155 | 1456128 |  225.484 |              277.232 |              134.505 |            821.961 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b21db_00000:
  custom_metrics:
    time_step_max: 4168
    time_step_mean: 3565.4710920770876
    time_step_min: 3226
  date: 2020-10-10_21-49-17
  done: false
  episode_len_mean: 819.1714135021097
  episode_reward_max: 277.232323232323
  episode_reward_mean: 225.71549354302508
  episode_reward_min: 134.5050505050507
  episodes_this_iter: 158
  episodes_total: 1896
  experiment_id: bb588637d19840c98656b899e48e2ada
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.8999134983335223
        entropy_coeff: 0.0
        kl: 0.006196862951453243
        model: {}
        policy_loss: -0.00718099856749177
        total_loss: 7.526422160012381
        vf_explained_var: 0.9850539565086365
        vf_loss: 7.53236368724278
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.480555555555554
    gpu_util_percent0: 0.3108333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486111111111111
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 19011
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1550111954498358
    mean_env_wait_ms: 1.2230779405550716
    mean_inference_ms: 4.7629189412207555
    mean_raw_obs_processing_ms: 0.41244744422245766
  time_since_restore: 313.4070999622345
  time_this_iter_s: 31.252014875411987
  time_total_s: 313.4070999622345
  timers:
    learn_throughput: 6826.399
    learn_time_ms: 23700.929
    sample_throughput: 21442.956
    sample_time_ms: 7545.228
    update_time_ms: 28.853
  timestamp: 1602366557
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: b21db_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b21db_00000 | RUNNING  | 172.17.0.4:19011 |     10 |          313.407 | 1617920 |  225.715 |              277.232 |              134.505 |            819.171 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b21db_00000:
  custom_metrics:
    time_step_max: 4168
    time_step_mean: 3563.389930898322
    time_step_min: 3226
  date: 2020-10-10_21-49-48
  done: false
  episode_len_mean: 816.6689386562804
  episode_reward_max: 277.232323232323
  episode_reward_mean: 226.04174166199476
  episode_reward_min: 134.5050505050507
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: bb588637d19840c98656b899e48e2ada
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.8575975128582546
        entropy_coeff: 0.0
        kl: 0.00551458345060902
        model: {}
        policy_loss: -0.005612059014051088
        total_loss: 6.319687162126813
        vf_explained_var: 0.988250732421875
        vf_loss: 6.3241963386535645
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.848648648648652
    gpu_util_percent0: 0.2913513513513514
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486486486486487
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 19011
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15465465658715713
    mean_env_wait_ms: 1.2253763007413363
    mean_inference_ms: 4.7419586936923315
    mean_raw_obs_processing_ms: 0.41116832112852486
  time_since_restore: 344.466490983963
  time_this_iter_s: 31.059391021728516
  time_total_s: 344.466490983963
  timers:
    learn_throughput: 6827.746
    learn_time_ms: 23696.252
    sample_throughput: 21917.544
    sample_time_ms: 7381.849
    update_time_ms: 27.682
  timestamp: 1602366588
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: b21db_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b21db_00000 | RUNNING  | 172.17.0.4:19011 |     11 |          344.466 | 1779712 |  226.042 |              277.232 |              134.505 |            816.669 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b21db_00000:
  custom_metrics:
    time_step_max: 4168
    time_step_mean: 3562.792912040991
    time_step_min: 3226
  date: 2020-10-10_21-50-19
  done: false
  episode_len_mean: 811.9244725738397
  episode_reward_max: 277.232323232323
  episode_reward_mean: 226.3211226185909
  episode_reward_min: 134.5050505050507
  episodes_this_iter: 316
  episodes_total: 2370
  experiment_id: bb588637d19840c98656b899e48e2ada
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.8261858906064715
        entropy_coeff: 0.0
        kl: 0.0041634205263108015
        model: {}
        policy_loss: -0.004049419016934864
        total_loss: 8.41431110245841
        vf_explained_var: 0.9896541237831116
        vf_loss: 8.417527879987444
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.42777777777778
    gpu_util_percent0: 0.22861111111111107
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888888
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 19011
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15404186181672433
    mean_env_wait_ms: 1.2297936425686888
    mean_inference_ms: 4.706386258351867
    mean_raw_obs_processing_ms: 0.40904749112987276
  time_since_restore: 375.7243461608887
  time_this_iter_s: 31.25785517692566
  time_total_s: 375.7243461608887
  timers:
    learn_throughput: 6821.085
    learn_time_ms: 23719.392
    sample_throughput: 22051.662
    sample_time_ms: 7336.953
    update_time_ms: 29.342
  timestamp: 1602366619
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: b21db_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b21db_00000 | RUNNING  | 172.17.0.4:19011 |     12 |          375.724 | 1941504 |  226.321 |              277.232 |              134.505 |            811.924 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b21db_00000:
  custom_metrics:
    time_step_max: 4168
    time_step_mean: 3559.7308
    time_step_min: 3226
  date: 2020-10-10_21-50-50
  done: false
  episode_len_mean: 809.8761867088608
  episode_reward_max: 277.232323232323
  episode_reward_mean: 226.66917593658098
  episode_reward_min: 134.5050505050507
  episodes_this_iter: 158
  episodes_total: 2528
  experiment_id: bb588637d19840c98656b899e48e2ada
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.7761573110307965
        entropy_coeff: 0.0
        kl: 0.0066431463429970404
        model: {}
        policy_loss: -0.0037241796913544283
        total_loss: 5.0413669518062045
        vf_explained_var: 0.9909216165542603
        vf_loss: 5.044426918029785
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.824324324324323
    gpu_util_percent0: 0.2562162162162162
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491891891891892
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 19011
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15377779647169387
    mean_env_wait_ms: 1.231737396031745
    mean_inference_ms: 4.691200840984136
    mean_raw_obs_processing_ms: 0.40813728628357315
  time_since_restore: 406.9912323951721
  time_this_iter_s: 31.266886234283447
  time_total_s: 406.9912323951721
  timers:
    learn_throughput: 6814.179
    learn_time_ms: 23743.433
    sample_throughput: 22131.751
    sample_time_ms: 7310.402
    update_time_ms: 27.692
  timestamp: 1602366650
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: b21db_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b21db_00000 | RUNNING  | 172.17.0.4:19011 |     13 |          406.991 | 2103296 |  226.669 |              277.232 |              134.505 |            809.876 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b21db_00000:
  custom_metrics:
    time_step_max: 4168
    time_step_mean: 3557.999623777276
    time_step_min: 3226
  date: 2020-10-10_21-51-22
  done: false
  episode_len_mean: 808.1850335070737
  episode_reward_max: 277.232323232323
  episode_reward_mean: 226.86927352452292
  episode_reward_min: 134.5050505050507
  episodes_this_iter: 158
  episodes_total: 2686
  experiment_id: bb588637d19840c98656b899e48e2ada
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.7491126613957542
        entropy_coeff: 0.0
        kl: 0.005594369323392
        model: {}
        policy_loss: -0.003753382947512104
        total_loss: 4.2002193076269965
        vf_explained_var: 0.992246150970459
        vf_loss: 4.203413265092032
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.650000000000002
    gpu_util_percent0: 0.27888888888888885
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.502777777777776
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 19011
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15353403461155765
    mean_env_wait_ms: 1.233597284184796
    mean_inference_ms: 4.677174368579551
    mean_raw_obs_processing_ms: 0.4072816484183201
  time_since_restore: 438.06555700302124
  time_this_iter_s: 31.07432460784912
  time_total_s: 438.06555700302124
  timers:
    learn_throughput: 6818.681
    learn_time_ms: 23727.757
    sample_throughput: 22139.728
    sample_time_ms: 7307.768
    update_time_ms: 29.421
  timestamp: 1602366682
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: b21db_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b21db_00000 | RUNNING  | 172.17.0.4:19011 |     14 |          438.066 | 2265088 |  226.869 |              277.232 |              134.505 |            808.185 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b21db_00000:
  custom_metrics:
    time_step_max: 4168
    time_step_mean: 3555.4529193385083
    time_step_min: 3226
  date: 2020-10-10_21-51-53
  done: false
  episode_len_mean: 805.2798395185557
  episode_reward_max: 277.232323232323
  episode_reward_mean: 227.24245463663718
  episode_reward_min: 134.5050505050507
  episodes_this_iter: 305
  episodes_total: 2991
  experiment_id: bb588637d19840c98656b899e48e2ada
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.7252707949706486
        entropy_coeff: 0.0
        kl: 0.005028669323240008
        model: {}
        policy_loss: -0.0034435302118903826
        total_loss: 5.796021563666208
        vf_explained_var: 0.9927676320075989
        vf_loss: 5.798962320600237
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.100000000000005
    gpu_util_percent0: 0.26837837837837836
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4837837837837835
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 19011
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15312490295054518
    mean_env_wait_ms: 1.2370868812135993
    mean_inference_ms: 4.653512751051031
    mean_raw_obs_processing_ms: 0.4058677116200735
  time_since_restore: 469.4883441925049
  time_this_iter_s: 31.422787189483643
  time_total_s: 469.4883441925049
  timers:
    learn_throughput: 6818.077
    learn_time_ms: 23729.859
    sample_throughput: 22093.051
    sample_time_ms: 7323.208
    update_time_ms: 29.37
  timestamp: 1602366713
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: b21db_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b21db_00000 | RUNNING  | 172.17.0.4:19011 |     15 |          469.488 | 2426880 |  227.242 |              277.232 |              134.505 |             805.28 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b21db_00000:
  custom_metrics:
    time_step_max: 4168
    time_step_mean: 3551.7477650063856
    time_step_min: 3226
  date: 2020-10-10_21-52-24
  done: false
  episode_len_mean: 803.8832278481012
  episode_reward_max: 277.232323232323
  episode_reward_mean: 227.71827451732514
  episode_reward_min: 134.5050505050507
  episodes_this_iter: 169
  episodes_total: 3160
  experiment_id: bb588637d19840c98656b899e48e2ada
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.6696313236440931
        entropy_coeff: 0.0
        kl: 0.005516889172473124
        model: {}
        policy_loss: -0.005660281336791481
        total_loss: 3.7366250583103726
        vf_explained_var: 0.9933170080184937
        vf_loss: 3.741733602115086
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.941666666666674
    gpu_util_percent0: 0.26666666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486111111111111
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 19011
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15292073888232124
    mean_env_wait_ms: 1.2387541070499128
    mean_inference_ms: 4.641665652502916
    mean_raw_obs_processing_ms: 0.40518085621022354
  time_since_restore: 500.6611292362213
  time_this_iter_s: 31.17278504371643
  time_total_s: 500.6611292362213
  timers:
    learn_throughput: 6819.803
    learn_time_ms: 23723.852
    sample_throughput: 22048.735
    sample_time_ms: 7337.927
    update_time_ms: 27.805
  timestamp: 1602366744
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: b21db_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b21db_00000 | RUNNING  | 172.17.0.4:19011 |     16 |          500.661 | 2588672 |  227.718 |              277.232 |              134.505 |            803.883 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b21db_00000:
  custom_metrics:
    time_step_max: 4168
    time_step_mean: 3549.768085106383
    time_step_min: 3226
  date: 2020-10-10_21-52-56
  done: false
  episode_len_mean: 802.7254370102471
  episode_reward_max: 277.232323232323
  episode_reward_mean: 228.05127221582913
  episode_reward_min: 134.5050505050507
  episodes_this_iter: 158
  episodes_total: 3318
  experiment_id: bb588637d19840c98656b899e48e2ada
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.6654533573559352
        entropy_coeff: 0.0
        kl: 0.004462837507682187
        model: {}
        policy_loss: -0.0035467461878267515
        total_loss: 3.1160662344523837
        vf_explained_var: 0.9938944578170776
        vf_loss: 3.119166680744716
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.624324324324323
    gpu_util_percent0: 0.26432432432432434
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497297297297297
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 19011
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1527461246424471
    mean_env_wait_ms: 1.240253901699169
    mean_inference_ms: 4.631496609961822
    mean_raw_obs_processing_ms: 0.40458095983571934
  time_since_restore: 532.0142550468445
  time_this_iter_s: 31.35312581062317
  time_total_s: 532.0142550468445
  timers:
    learn_throughput: 6816.008
    learn_time_ms: 23737.062
    sample_throughput: 22010.287
    sample_time_ms: 7350.745
    update_time_ms: 25.643
  timestamp: 1602366776
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: b21db_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b21db_00000 | RUNNING  | 172.17.0.4:19011 |     17 |          532.014 | 2750464 |  228.051 |              277.232 |              134.505 |            802.725 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b21db_00000:
  custom_metrics:
    time_step_max: 4168
    time_step_mean: 3545.35792734441
    time_step_min: 3226
  date: 2020-10-10_21-53-27
  done: false
  episode_len_mean: 801.1039396479464
  episode_reward_max: 277.232323232323
  episode_reward_mean: 228.61501011794394
  episode_reward_min: 134.5050505050507
  episodes_this_iter: 261
  episodes_total: 3579
  experiment_id: bb588637d19840c98656b899e48e2ada
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 0.6325086738382067
        entropy_coeff: 0.0
        kl: 0.005371310914467488
        model: {}
        policy_loss: -0.0033162830846517216
        total_loss: 4.03606573172978
        vf_explained_var: 0.9943237900733948
        vf_loss: 4.039113572665623
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.854054054054053
    gpu_util_percent0: 0.312972972972973
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.481081081081081
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 19011
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15247955348726464
    mean_env_wait_ms: 1.2426546140696282
    mean_inference_ms: 4.616321205802713
    mean_raw_obs_processing_ms: 0.4036968002093595
  time_since_restore: 563.2522301673889
  time_this_iter_s: 31.237975120544434
  time_total_s: 563.2522301673889
  timers:
    learn_throughput: 6814.582
    learn_time_ms: 23742.028
    sample_throughput: 21953.919
    sample_time_ms: 7369.618
    update_time_ms: 27.62
  timestamp: 1602366807
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: b21db_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b21db_00000 | RUNNING  | 172.17.0.4:19011 |     18 |          563.252 | 2912256 |  228.615 |              277.232 |              134.505 |            801.104 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b21db_00000:
  custom_metrics:
    time_step_max: 4168
    time_step_mean: 3542.536131774708
    time_step_min: 3226
  date: 2020-10-10_21-53-59
  done: false
  episode_len_mean: 799.7167721518987
  episode_reward_max: 277.232323232323
  episode_reward_mean: 229.07244118399183
  episode_reward_min: 134.5050505050507
  episodes_this_iter: 213
  episodes_total: 3792
  experiment_id: bb588637d19840c98656b899e48e2ada
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 0.6007546952792576
        entropy_coeff: 0.0
        kl: 0.004691943559529526
        model: {}
        policy_loss: -0.002559523348691885
        total_loss: 3.3267393623079573
        vf_explained_var: 0.993971049785614
        vf_loss: 3.3290643181119646
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.674999999999997
    gpu_util_percent0: 0.25916666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.499999999999999
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 19011
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15228865894940274
    mean_env_wait_ms: 1.2444410943814708
    mean_inference_ms: 4.60497102220279
    mean_raw_obs_processing_ms: 0.4030402303573981
  time_since_restore: 594.2394464015961
  time_this_iter_s: 30.987216234207153
  time_total_s: 594.2394464015961
  timers:
    learn_throughput: 6818.517
    learn_time_ms: 23728.327
    sample_throughput: 21910.045
    sample_time_ms: 7384.376
    update_time_ms: 27.364
  timestamp: 1602366839
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: b21db_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b21db_00000 | RUNNING  | 172.17.0.4:19011 |     19 |          594.239 | 3074048 |  229.072 |              277.232 |              134.505 |            799.717 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b21db_00000:
  custom_metrics:
    time_step_max: 4168
    time_step_mean: 3540.3431922488526
    time_step_min: 3226
  date: 2020-10-10_21-54-30
  done: true
  episode_len_mean: 798.6607594936709
  episode_reward_max: 277.232323232323
  episode_reward_mean: 229.38007927375017
  episode_reward_min: 134.5050505050507
  episodes_this_iter: 158
  episodes_total: 3950
  experiment_id: bb588637d19840c98656b899e48e2ada
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 1.0e-05
        entropy: 0.5880485730511802
        entropy_coeff: 0.0
        kl: 0.005069278479952898
        model: {}
        policy_loss: -0.0028726169340578572
        total_loss: 2.7497929675238475
        vf_explained_var: 0.9940618276596069
        vf_loss: 2.7525388853890553
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.305555555555554
    gpu_util_percent0: 0.31555555555555553
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494444444444444
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 19011
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15215609019076565
    mean_env_wait_ms: 1.2456925918224266
    mean_inference_ms: 4.597222333936634
    mean_raw_obs_processing_ms: 0.40259240628506643
  time_since_restore: 625.1837990283966
  time_this_iter_s: 30.944352626800537
  time_total_s: 625.1837990283966
  timers:
    learn_throughput: 6822.475
    learn_time_ms: 23714.56
    sample_throughput: 21964.778
    sample_time_ms: 7365.975
    update_time_ms: 27.61
  timestamp: 1602366870
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: b21db_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b21db_00000 | TERMINATED |       |     20 |          625.184 | 3235840 |   229.38 |              277.232 |              134.505 |            798.661 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b21db_00000 | TERMINATED |       |     20 |          625.184 | 3235840 |   229.38 |              277.232 |              134.505 |            798.661 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


[2m[33m(pid=raylet)[0m E1010 21:54:30.328970 18885 18885 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed
