2020-10-10 22:16:14,122	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_36729_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=80969)[0m 2020-10-10 22:16:16,918	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=80946)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80946)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80865)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80865)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80921)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80921)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80944)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80944)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80900)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80900)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80867)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80867)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80871)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80871)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80939)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80939)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81001)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81001)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80983)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80983)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80941)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80941)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80962)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80962)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80977)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80977)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80951)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80951)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80919)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80919)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80961)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80961)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80985)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80985)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80863)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80863)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80925)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80925)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80876)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80876)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80931)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80931)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80987)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80987)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80968)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80968)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80937)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80937)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80932)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80932)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80996)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80996)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80948)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80948)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80956)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80956)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80896)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80896)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80972)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80972)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80954)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80954)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80980)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80980)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80877)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80877)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80879)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80879)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80938)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80938)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80872)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80872)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80882)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80882)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80884)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80884)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80994)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80994)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80899)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80899)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80959)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80959)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80990)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80990)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80915)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80915)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80943)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80943)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80927)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80927)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80860)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80860)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80970)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80970)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80930)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80930)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80889)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80889)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80936)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80936)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80886)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80886)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80894)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80894)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80868)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80868)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80861)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80861)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80953)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80953)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80940)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80940)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80875)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80875)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80858)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80858)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80859)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80859)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80866)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80866)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80965)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80965)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80933)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80933)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80892)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80892)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80929)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80929)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80922)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80922)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80945)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80945)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80942)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80942)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80957)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80957)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80935)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80935)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80964)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80964)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80934)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80934)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80862)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80862)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80918)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80918)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80874)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80874)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80870)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80870)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80893)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80893)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80974)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80974)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80883)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80883)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80873)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80873)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_36729_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-10_22-16-55
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: f085b3f1540f4966a9dca8555a934b34
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1841116547584534
        entropy_coeff: 0.0
        kl: 0.005300223029085568
        model: {}
        policy_loss: -0.012787067414527493
        total_loss: 499.54825265066967
        vf_explained_var: 0.5819914937019348
        vf_loss: 499.55997358049666
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.46153846153846
    gpu_util_percent0: 0.3271794871794872
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0002564102564102564
    ram_util_percent: 6.282051282051283
    vram_util_percent0: 0.19107567844858767
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 80969
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17035399222307715
    mean_env_wait_ms: 1.1918543444330512
    mean_inference_ms: 5.675229778919885
    mean_raw_obs_processing_ms: 0.4605580877838182
  time_since_restore: 32.341155767440796
  time_this_iter_s: 32.341155767440796
  time_total_s: 32.341155767440796
  timers:
    learn_throughput: 6999.932
    learn_time_ms: 23113.367
    sample_throughput: 17657.063
    sample_time_ms: 9163.019
    update_time_ms: 25.535
  timestamp: 1602368215
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: '36729_00000'
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36729_00000 | RUNNING  | 172.17.0.4:80969 |      1 |          32.3412 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36729_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3619.8888888888887
    time_step_min: 3196
  date: 2020-10-10_22-17-26
  done: false
  episode_len_mean: 889.0601265822785
  episode_reward_max: 281.77777777777743
  episode_reward_mean: 216.99450198184354
  episode_reward_min: 139.50505050505046
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: f085b3f1540f4966a9dca8555a934b34
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1527548602649145
        entropy_coeff: 0.0
        kl: 0.006693749788350293
        model: {}
        policy_loss: -0.012824262563039415
        total_loss: 116.40482602800641
        vf_explained_var: 0.8278390169143677
        vf_loss: 116.41631262642997
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.41578947368421
    gpu_util_percent0: 0.33947368421052637
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.46578947368421
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 80969
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16647571445891607
    mean_env_wait_ms: 1.1875799794845645
    mean_inference_ms: 5.515259849469935
    mean_raw_obs_processing_ms: 0.4519677707805226
  time_since_restore: 63.77262210845947
  time_this_iter_s: 31.431466341018677
  time_total_s: 63.77262210845947
  timers:
    learn_throughput: 6998.625
    learn_time_ms: 23117.685
    sample_throughput: 18619.723
    sample_time_ms: 8689.281
    update_time_ms: 31.83
  timestamp: 1602368246
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: '36729_00000'
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36729_00000 | RUNNING  | 172.17.0.4:80969 |      2 |          63.7726 | 323584 |  216.995 |              281.778 |              139.505 |             889.06 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36729_00000:
  custom_metrics:
    time_step_max: 4097
    time_step_mean: 3612.5717488789237
    time_step_min: 3196
  date: 2020-10-10_22-17-57
  done: false
  episode_len_mean: 886.3354430379746
  episode_reward_max: 281.77777777777743
  episode_reward_mean: 218.77943996931316
  episode_reward_min: 139.50505050505046
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: f085b3f1540f4966a9dca8555a934b34
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1426018391336714
        entropy_coeff: 0.0
        kl: 0.0076399668385939935
        model: {}
        policy_loss: -0.015652929366167103
        total_loss: 49.5256290435791
        vf_explained_var: 0.913610577583313
        vf_loss: 49.53975323268345
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.032432432432433
    gpu_util_percent0: 0.3275675675675676
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494594594594595
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 80969
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16374049231714896
    mean_env_wait_ms: 1.186463994909793
    mean_inference_ms: 5.354201073536087
    mean_raw_obs_processing_ms: 0.44347502857195426
  time_since_restore: 94.44258761405945
  time_this_iter_s: 30.669965505599976
  time_total_s: 94.44258761405945
  timers:
    learn_throughput: 6979.235
    learn_time_ms: 23181.91
    sample_throughput: 19677.991
    sample_time_ms: 8221.977
    update_time_ms: 29.016
  timestamp: 1602368277
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: '36729_00000'
  
== Status ==
Memory usage on this node: 48.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36729_00000 | RUNNING  | 172.17.0.4:80969 |      3 |          94.4426 | 485376 |  218.779 |              281.778 |              139.505 |            886.335 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36729_00000:
  custom_metrics:
    time_step_max: 4097
    time_step_mean: 3610.0165562913908
    time_step_min: 3196
  date: 2020-10-10_22-18-27
  done: false
  episode_len_mean: 884.9731012658228
  episode_reward_max: 281.77777777777743
  episode_reward_mean: 219.0039956527296
  episode_reward_min: 139.50505050505046
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: f085b3f1540f4966a9dca8555a934b34
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.127725635256086
        entropy_coeff: 0.0
        kl: 0.007639913453853556
        model: {}
        policy_loss: -0.014846562809127915
        total_loss: 33.55625779288156
        vf_explained_var: 0.9441773295402527
        vf_loss: 33.569576263427734
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.997222222222224
    gpu_util_percent0: 0.34805555555555556
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.483333333333333
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 80969
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16177647058501912
    mean_env_wait_ms: 1.1860262325257305
    mean_inference_ms: 5.2301596836035875
    mean_raw_obs_processing_ms: 0.4365715731275011
  time_since_restore: 124.66279125213623
  time_this_iter_s: 30.220203638076782
  time_total_s: 124.66279125213623
  timers:
    learn_throughput: 6989.269
    learn_time_ms: 23148.631
    sample_throughput: 20371.729
    sample_time_ms: 7941.987
    update_time_ms: 28.088
  timestamp: 1602368307
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: '36729_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36729_00000 | RUNNING  | 172.17.0.4:80969 |      4 |          124.663 | 647168 |  219.004 |              281.778 |              139.505 |            884.973 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36729_00000:
  custom_metrics:
    time_step_max: 4097
    time_step_mean: 3603.3845144356956
    time_step_min: 3196
  date: 2020-10-10_22-18-58
  done: false
  episode_len_mean: 882.5075949367089
  episode_reward_max: 281.77777777777743
  episode_reward_mean: 220.2133358905509
  episode_reward_min: 139.50505050505046
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: f085b3f1540f4966a9dca8555a934b34
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1012338399887085
        entropy_coeff: 0.0
        kl: 0.008112173926617419
        model: {}
        policy_loss: -0.016979970170983245
        total_loss: 23.64970302581787
        vf_explained_var: 0.9601014852523804
        vf_loss: 23.665061133248464
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.351351351351347
    gpu_util_percent0: 0.3486486486486486
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486486486486487
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 80969
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16029061345563222
    mean_env_wait_ms: 1.1864108943246319
    mean_inference_ms: 5.134137756563481
    mean_raw_obs_processing_ms: 0.43101936135064656
  time_since_restore: 155.0214946269989
  time_this_iter_s: 30.35870337486267
  time_total_s: 155.0214946269989
  timers:
    learn_throughput: 6989.037
    learn_time_ms: 23149.398
    sample_throughput: 20807.976
    sample_time_ms: 7775.48
    update_time_ms: 32.185
  timestamp: 1602368338
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: '36729_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36729_00000 | RUNNING  | 172.17.0.4:80969 |      5 |          155.021 | 808960 |  220.213 |              281.778 |              139.505 |            882.508 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36729_00000:
  custom_metrics:
    time_step_max: 4251
    time_step_mean: 3586.1778202676865
    time_step_min: 3196
  date: 2020-10-10_22-19-28
  done: false
  episode_len_mean: 873.8640595903166
  episode_reward_max: 281.77777777777743
  episode_reward_mean: 222.65794819705417
  episode_reward_min: 119.65656565656559
  episodes_this_iter: 284
  episodes_total: 1074
  experiment_id: f085b3f1540f4966a9dca8555a934b34
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.079986376421792
        entropy_coeff: 0.0
        kl: 0.007906210741826467
        model: {}
        policy_loss: -0.014968184022498983
        total_loss: 37.97165053231375
        vf_explained_var: 0.9574574828147888
        vf_loss: 37.985038484845845
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.466666666666665
    gpu_util_percent0: 0.33249999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.477777777777778
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 80969
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15844006074140496
    mean_env_wait_ms: 1.189068191392655
    mean_inference_ms: 5.0133930411413985
    mean_raw_obs_processing_ms: 0.42399290978869136
  time_since_restore: 185.27864384651184
  time_this_iter_s: 30.25714921951294
  time_total_s: 185.27864384651184
  timers:
    learn_throughput: 6993.234
    learn_time_ms: 23135.506
    sample_throughput: 21104.513
    sample_time_ms: 7666.227
    update_time_ms: 30.418
  timestamp: 1602368368
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: '36729_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36729_00000 | RUNNING  | 172.17.0.4:80969 |      6 |          185.279 | 970752 |  222.658 |              281.778 |              119.657 |            873.864 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36729_00000:
  custom_metrics:
    time_step_max: 4303
    time_step_mean: 3580.7289644012944
    time_step_min: 3196
  date: 2020-10-10_22-19-58
  done: false
  episode_len_mean: 868.5205696202531
  episode_reward_max: 281.77777777777743
  episode_reward_mean: 224.01214678429852
  episode_reward_min: 114.05050505050473
  episodes_this_iter: 190
  episodes_total: 1264
  experiment_id: f085b3f1540f4966a9dca8555a934b34
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.088431945868901
        entropy_coeff: 0.0
        kl: 0.007041851424479059
        model: {}
        policy_loss: -0.016468127191598927
        total_loss: 22.47141102382115
        vf_explained_var: 0.964137852191925
        vf_loss: 22.486470767429896
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.952777777777776
    gpu_util_percent0: 0.30888888888888894
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 80969
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15756262650587557
    mean_env_wait_ms: 1.1907540082440784
    mean_inference_ms: 4.954813178462148
    mean_raw_obs_processing_ms: 0.42078661115048305
  time_since_restore: 215.5262188911438
  time_this_iter_s: 30.247575044631958
  time_total_s: 215.5262188911438
  timers:
    learn_throughput: 6990.304
    learn_time_ms: 23145.202
    sample_throughput: 21381.84
    sample_time_ms: 7566.795
    update_time_ms: 29.204
  timestamp: 1602368398
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: '36729_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36729_00000 | RUNNING  | 172.17.0.4:80969 |      7 |          215.526 | 1132544 |  224.012 |              281.778 |              114.051 |            868.521 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36729_00000:
  custom_metrics:
    time_step_max: 4303
    time_step_mean: 3570.455523672884
    time_step_min: 3196
  date: 2020-10-10_22-20-28
  done: false
  episode_len_mean: 864.3818565400844
  episode_reward_max: 281.77777777777743
  episode_reward_mean: 225.39197886033313
  episode_reward_min: 114.05050505050473
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: f085b3f1540f4966a9dca8555a934b34
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0665446008954729
        entropy_coeff: 0.0
        kl: 0.007665551899533186
        model: {}
        policy_loss: -0.016175311507790217
        total_loss: 14.175525529044014
        vf_explained_var: 0.9751126170158386
        vf_loss: 14.190167427062988
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.83055555555556
    gpu_util_percent0: 0.37722222222222224
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491666666666666
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 80969
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15694671315820008
    mean_env_wait_ms: 1.1921449058542617
    mean_inference_ms: 4.913667376917961
    mean_raw_obs_processing_ms: 0.4184614593374131
  time_since_restore: 245.68737959861755
  time_this_iter_s: 30.161160707473755
  time_total_s: 245.68737959861755
  timers:
    learn_throughput: 6995.245
    learn_time_ms: 23128.854
    sample_throughput: 21557.709
    sample_time_ms: 7505.064
    update_time_ms: 28.662
  timestamp: 1602368428
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: '36729_00000'
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36729_00000 | RUNNING  | 172.17.0.4:80969 |      8 |          245.687 | 1294336 |  225.392 |              281.778 |              114.051 |            864.382 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36729_00000:
  custom_metrics:
    time_step_max: 4303
    time_step_mean: 3561.5934278350514
    time_step_min: 3194
  date: 2020-10-10_22-20-59
  done: false
  episode_len_mean: 860.5588607594937
  episode_reward_max: 282.0808080808079
  episode_reward_mean: 226.5427375015981
  episode_reward_min: 114.05050505050473
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: f085b3f1540f4966a9dca8555a934b34
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0351796575954981
        entropy_coeff: 0.0
        kl: 0.007022759078868798
        model: {}
        policy_loss: -0.01678860852760928
        total_loss: 14.72852999823434
        vf_explained_var: 0.9733273386955261
        vf_loss: 14.743913786751884
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.802777777777777
    gpu_util_percent0: 0.34944444444444445
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888889
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 80969
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1564151652793407
    mean_env_wait_ms: 1.1934996906703665
    mean_inference_ms: 4.877758027295612
    mean_raw_obs_processing_ms: 0.41638625278273517
  time_since_restore: 275.77181816101074
  time_this_iter_s: 30.08443856239319
  time_total_s: 275.77181816101074
  timers:
    learn_throughput: 6997.931
    learn_time_ms: 23119.976
    sample_throughput: 21732.63
    sample_time_ms: 7444.658
    update_time_ms: 27.581
  timestamp: 1602368459
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: '36729_00000'
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36729_00000 | RUNNING  | 172.17.0.4:80969 |      9 |          275.772 | 1456128 |  226.543 |              282.081 |              114.051 |            860.559 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36729_00000:
  custom_metrics:
    time_step_max: 4303
    time_step_mean: 3547.306830907055
    time_step_min: 3194
  date: 2020-10-10_22-21-29
  done: false
  episode_len_mean: 855.2398015435501
  episode_reward_max: 288.1414141414135
  episode_reward_mean: 228.7625093270075
  episode_reward_min: 114.05050505050473
  episodes_this_iter: 234
  episodes_total: 1814
  experiment_id: f085b3f1540f4966a9dca8555a934b34
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9952197372913361
        entropy_coeff: 0.0
        kl: 0.007141879959298032
        model: {}
        policy_loss: -0.01597247430722096
        total_loss: 20.718485559735978
        vf_explained_var: 0.973305881023407
        vf_loss: 20.733030455453054
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.98611111111111
    gpu_util_percent0: 0.3188888888888889
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.483333333333333
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 80969
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15574963756910679
    mean_env_wait_ms: 1.1957808350074601
    mean_inference_ms: 4.833336841335022
    mean_raw_obs_processing_ms: 0.41381084256928213
  time_since_restore: 306.041339635849
  time_this_iter_s: 30.269521474838257
  time_total_s: 306.041339635849
  timers:
    learn_throughput: 6998.173
    learn_time_ms: 23119.179
    sample_throughput: 21839.206
    sample_time_ms: 7408.328
    update_time_ms: 26.754
  timestamp: 1602368489
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: '36729_00000'
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36729_00000 | RUNNING  | 172.17.0.4:80969 |     10 |          306.041 | 1617920 |  228.763 |              288.141 |              114.051 |             855.24 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36729_00000:
  custom_metrics:
    time_step_max: 4303
    time_step_mean: 3534.677690029615
    time_step_min: 3194
  date: 2020-10-10_22-21-59
  done: false
  episode_len_mean: 850.2005842259007
  episode_reward_max: 288.1414141414135
  episode_reward_mean: 230.69437805513738
  episode_reward_min: 114.05050505050473
  episodes_this_iter: 240
  episodes_total: 2054
  experiment_id: f085b3f1540f4966a9dca8555a934b34
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0022696341787065
        entropy_coeff: 0.0
        kl: 0.006672133392255221
        model: {}
        policy_loss: -0.014310187395104939
        total_loss: 14.419054099491664
        vf_explained_var: 0.9772568941116333
        vf_loss: 14.432030405317034
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.691666666666666
    gpu_util_percent0: 0.36527777777777776
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4833333333333325
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 80969
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15517311204314804
    mean_env_wait_ms: 1.1976704158786058
    mean_inference_ms: 4.795228449947462
    mean_raw_obs_processing_ms: 0.41168248284869635
  time_since_restore: 336.2323377132416
  time_this_iter_s: 30.190998077392578
  time_total_s: 336.2323377132416
  timers:
    learn_throughput: 6998.508
    learn_time_ms: 23118.07
    sample_throughput: 22491.37
    sample_time_ms: 7193.515
    update_time_ms: 26.004
  timestamp: 1602368519
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: '36729_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36729_00000 | RUNNING  | 172.17.0.4:80969 |     11 |          336.232 | 1779712 |  230.694 |              288.141 |              114.051 |            850.201 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36729_00000:
  custom_metrics:
    time_step_max: 4303
    time_step_mean: 3526.731227106227
    time_step_min: 3194
  date: 2020-10-10_22-22-29
  done: false
  episode_len_mean: 847.4222423146474
  episode_reward_max: 288.1414141414135
  episode_reward_mean: 231.86607028695624
  episode_reward_min: 114.05050505050473
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: f085b3f1540f4966a9dca8555a934b34
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9825596681662968
        entropy_coeff: 0.0
        kl: 0.007190442677321178
        model: {}
        policy_loss: -0.016495846756567647
        total_loss: 10.942831243787493
        vf_explained_var: 0.9799414873123169
        vf_loss: 10.957889216286796
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.736111111111107
    gpu_util_percent0: 0.3836111111111111
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888889
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 80969
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15485060007739626
    mean_env_wait_ms: 1.1988484408258933
    mean_inference_ms: 4.773738792283381
    mean_raw_obs_processing_ms: 0.41045548934389536
  time_since_restore: 366.41630578041077
  time_this_iter_s: 30.18396806716919
  time_total_s: 366.41630578041077
  timers:
    learn_throughput: 7001.358
    learn_time_ms: 23108.66
    sample_throughput: 22858.61
    sample_time_ms: 7077.946
    update_time_ms: 26.326
  timestamp: 1602368549
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: '36729_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36729_00000 | RUNNING  | 172.17.0.4:80969 |     12 |          366.416 | 1941504 |  231.866 |              288.141 |              114.051 |            847.422 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36729_00000:
  custom_metrics:
    time_step_max: 4303
    time_step_mean: 3518.8710503842867
    time_step_min: 3190
  date: 2020-10-10_22-23-00
  done: false
  episode_len_mean: 844.6008438818566
  episode_reward_max: 288.1414141414135
  episode_reward_mean: 233.01694156757432
  episode_reward_min: 114.05050505050473
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: f085b3f1540f4966a9dca8555a934b34
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9532334719385419
        entropy_coeff: 0.0
        kl: 0.006864012817719153
        model: {}
        policy_loss: -0.015160712147397655
        total_loss: 12.22871732711792
        vf_explained_var: 0.9776762127876282
        vf_loss: 12.242505277906146
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.954054054054055
    gpu_util_percent0: 0.3491891891891892
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5027027027027025
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 80969
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15455960122611753
    mean_env_wait_ms: 1.2000016527230162
    mean_inference_ms: 4.754175366974543
    mean_raw_obs_processing_ms: 0.4093288104612237
  time_since_restore: 396.69767475128174
  time_this_iter_s: 30.28136897087097
  time_total_s: 396.69767475128174
  timers:
    learn_throughput: 7009.339
    learn_time_ms: 23082.347
    sample_throughput: 22922.313
    sample_time_ms: 7058.275
    update_time_ms: 26.306
  timestamp: 1602368580
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: '36729_00000'
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36729_00000 | RUNNING  | 172.17.0.4:80969 |     13 |          396.698 | 2103296 |  233.017 |              288.141 |              114.051 |            844.601 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36729_00000:
  custom_metrics:
    time_step_max: 4303
    time_step_mean: 3506.2192716236723
    time_step_min: 3190
  date: 2020-10-10_22-23-30
  done: false
  episode_len_mean: 840.201951951952
  episode_reward_max: 288.1414141414135
  episode_reward_mean: 234.91620029120017
  episode_reward_min: 114.05050505050473
  episodes_this_iter: 294
  episodes_total: 2664
  experiment_id: f085b3f1540f4966a9dca8555a934b34
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9333444918904986
        entropy_coeff: 0.0
        kl: 0.006352690480915564
        model: {}
        policy_loss: -0.014562149648554623
        total_loss: 17.91054126194545
        vf_explained_var: 0.9774199724197388
        vf_loss: 17.923832484654017
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.858333333333334
    gpu_util_percent0: 0.3416666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.480555555555555
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 80969
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1540965836231898
    mean_env_wait_ms: 1.2021518404380527
    mean_inference_ms: 4.722556336019199
    mean_raw_obs_processing_ms: 0.4075392293877902
  time_since_restore: 427.14697766304016
  time_this_iter_s: 30.449302911758423
  time_total_s: 427.14697766304016
  timers:
    learn_throughput: 7004.397
    learn_time_ms: 23098.633
    sample_throughput: 22904.559
    sample_time_ms: 7063.747
    update_time_ms: 25.866
  timestamp: 1602368610
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: '36729_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36729_00000 | RUNNING  | 172.17.0.4:80969 |     14 |          427.147 | 2265088 |  234.916 |              288.141 |              114.051 |            840.202 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36729_00000:
  custom_metrics:
    time_step_max: 4303
    time_step_mean: 3499.4921875
    time_step_min: 3190
  date: 2020-10-10_22-24-01
  done: false
  episode_len_mean: 837.943741209564
  episode_reward_max: 288.1414141414135
  episode_reward_mean: 235.91807313642744
  episode_reward_min: 114.05050505050473
  episodes_this_iter: 180
  episodes_total: 2844
  experiment_id: f085b3f1540f4966a9dca8555a934b34
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9300316103867122
        entropy_coeff: 0.0
        kl: 0.006316113784643156
        model: {}
        policy_loss: -0.015499370413765843
        total_loss: 10.209105695996966
        vf_explained_var: 0.9823247194290161
        vf_loss: 10.223342282431465
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.380555555555553
    gpu_util_percent0: 0.35305555555555557
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497222222222222
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 80969
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15384556434979849
    mean_env_wait_ms: 1.2032506695949323
    mean_inference_ms: 4.70574167432005
    mean_raw_obs_processing_ms: 0.4065875615884821
  time_since_restore: 457.211562871933
  time_this_iter_s: 30.064585208892822
  time_total_s: 457.211562871933
  timers:
    learn_throughput: 7010.271
    learn_time_ms: 23079.28
    sample_throughput: 22930.518
    sample_time_ms: 7055.75
    update_time_ms: 22.762
  timestamp: 1602368641
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: '36729_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36729_00000 | RUNNING  | 172.17.0.4:80969 |     15 |          457.212 | 2426880 |  235.918 |              288.141 |              114.051 |            837.944 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36729_00000:
  custom_metrics:
    time_step_max: 4303
    time_step_mean: 3493.899798251513
    time_step_min: 3190
  date: 2020-10-10_22-24-31
  done: false
  episode_len_mean: 836.2415056628914
  episode_reward_max: 290.2626262626263
  episode_reward_mean: 236.703635286913
  episode_reward_min: 114.05050505050473
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: f085b3f1540f4966a9dca8555a934b34
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9151422040803092
        entropy_coeff: 0.0
        kl: 0.007028906772445355
        model: {}
        policy_loss: -0.01741702914504068
        total_loss: 8.814400809151786
        vf_explained_var: 0.9832267165184021
        vf_loss: 8.830412115369525
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.769444444444446
    gpu_util_percent0: 0.3938888888888889
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491666666666666
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 80969
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15364801825376231
    mean_env_wait_ms: 1.2041887518171255
    mean_inference_ms: 4.6922084617308695
    mean_raw_obs_processing_ms: 0.4058162688696547
  time_since_restore: 487.4429335594177
  time_this_iter_s: 30.23137068748474
  time_total_s: 487.4429335594177
  timers:
    learn_throughput: 7006.329
    learn_time_ms: 23092.263
    sample_throughput: 22983.964
    sample_time_ms: 7039.343
    update_time_ms: 22.404
  timestamp: 1602368671
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: '36729_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36729_00000 | RUNNING  | 172.17.0.4:80969 |     16 |          487.443 | 2588672 |  236.704 |              290.263 |              114.051 |            836.242 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36729_00000:
  custom_metrics:
    time_step_max: 4303
    time_step_mean: 3488.436248012719
    time_step_min: 3173
  date: 2020-10-10_22-25-01
  done: false
  episode_len_mean: 834.4160100850929
  episode_reward_max: 290.2626262626263
  episode_reward_mean: 237.56281058298063
  episode_reward_min: 114.05050505050473
  episodes_this_iter: 171
  episodes_total: 3173
  experiment_id: f085b3f1540f4966a9dca8555a934b34
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8753004883016858
        entropy_coeff: 0.0
        kl: 0.007265183276363781
        model: {}
        policy_loss: -0.017465409756238972
        total_loss: 9.076903683798653
        vf_explained_var: 0.9850045442581177
        vf_loss: 9.092916284288679
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.235135135135135
    gpu_util_percent0: 0.2956756756756757
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494594594594595
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 80969
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15345060182971954
    mean_env_wait_ms: 1.2051825784708023
    mean_inference_ms: 4.678683151906386
    mean_raw_obs_processing_ms: 0.4050239608288592
  time_since_restore: 517.7724215984344
  time_this_iter_s: 30.329488039016724
  time_total_s: 517.7724215984344
  timers:
    learn_throughput: 7006.577
    learn_time_ms: 23091.447
    sample_throughput: 22961.551
    sample_time_ms: 7046.214
    update_time_ms: 23.793
  timestamp: 1602368701
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: '36729_00000'
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36729_00000 | RUNNING  | 172.17.0.4:80969 |     17 |          517.772 | 2750464 |  237.563 |              290.263 |              114.051 |            834.416 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36729_00000:
  custom_metrics:
    time_step_max: 4303
    time_step_mean: 3479.0188679245284
    time_step_min: 3173
  date: 2020-10-10_22-25-32
  done: false
  episode_len_mean: 831.6515980420386
  episode_reward_max: 290.2626262626263
  episode_reward_mean: 238.94296550299995
  episode_reward_min: 114.05050505050473
  episodes_this_iter: 300
  episodes_total: 3473
  experiment_id: f085b3f1540f4966a9dca8555a934b34
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8742827475070953
        entropy_coeff: 0.0
        kl: 0.005919049926368254
        model: {}
        policy_loss: -0.013929123607730227
        total_loss: 13.369625772748675
        vf_explained_var: 0.9821587800979614
        vf_loss: 13.382371016911097
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.761111111111113
    gpu_util_percent0: 0.31583333333333335
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888889
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 80969
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15313858456176727
    mean_env_wait_ms: 1.2068508135938638
    mean_inference_ms: 4.657396529498119
    mean_raw_obs_processing_ms: 0.4038158060166156
  time_since_restore: 547.9876182079315
  time_this_iter_s: 30.21519660949707
  time_total_s: 547.9876182079315
  timers:
    learn_throughput: 7001.596
    learn_time_ms: 23107.873
    sample_throughput: 23001.48
    sample_time_ms: 7033.982
    update_time_ms: 23.428
  timestamp: 1602368732
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: '36729_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36729_00000 | RUNNING  | 172.17.0.4:80969 |     18 |          547.988 | 2912256 |  238.943 |              290.263 |              114.051 |            831.652 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36729_00000:
  custom_metrics:
    time_step_max: 4303
    time_step_mean: 3474.0097060454796
    time_step_min: 3173
  date: 2020-10-10_22-26-02
  done: false
  episode_len_mean: 830.2713263621354
  episode_reward_max: 290.2626262626263
  episode_reward_mean: 239.59973705130548
  episode_reward_min: 114.05050505050473
  episodes_this_iter: 161
  episodes_total: 3634
  experiment_id: f085b3f1540f4966a9dca8555a934b34
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8663489818572998
        entropy_coeff: 0.0
        kl: 0.006448308804205486
        model: {}
        policy_loss: -0.016884449802871262
        total_loss: 8.629943302699498
        vf_explained_var: 0.9841316938400269
        vf_loss: 8.64553792136056
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.344444444444445
    gpu_util_percent0: 0.4055555555555556
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888889
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 80969
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15298603287078047
    mean_env_wait_ms: 1.2076555533474451
    mean_inference_ms: 4.6471951662330175
    mean_raw_obs_processing_ms: 0.4032287420300522
  time_since_restore: 578.2203404903412
  time_this_iter_s: 30.232722282409668
  time_total_s: 578.2203404903412
  timers:
    learn_throughput: 6998.73
    learn_time_ms: 23117.338
    sample_throughput: 22987.765
    sample_time_ms: 7038.179
    update_time_ms: 24.26
  timestamp: 1602368762
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: '36729_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36729_00000 | RUNNING  | 172.17.0.4:80969 |     19 |           578.22 | 3074048 |    239.6 |              290.263 |              114.051 |            830.271 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36729_00000:
  custom_metrics:
    time_step_max: 4303
    time_step_mean: 3469.875166002656
    time_step_min: 3170
  date: 2020-10-10_22-26-33
  done: true
  episode_len_mean: 828.9472712892169
  episode_reward_max: 290.2626262626263
  episode_reward_mean: 240.24752667726557
  episode_reward_min: 114.05050505050473
  episodes_this_iter: 159
  episodes_total: 3793
  experiment_id: f085b3f1540f4966a9dca8555a934b34
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8450761479990823
        entropy_coeff: 0.0
        kl: 0.006639857510370868
        model: {}
        policy_loss: -0.01456013007555157
        total_loss: 8.633735724857875
        vf_explained_var: 0.9832630753517151
        vf_loss: 8.646967615400042
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.33783783783784
    gpu_util_percent0: 0.31405405405405407
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 80969
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15284379405598278
    mean_env_wait_ms: 1.2084192067854371
    mean_inference_ms: 4.637726078009607
    mean_raw_obs_processing_ms: 0.40267378181086494
  time_since_restore: 608.5894124507904
  time_this_iter_s: 30.36907196044922
  time_total_s: 608.5894124507904
  timers:
    learn_throughput: 6997.851
    learn_time_ms: 23120.24
    sample_throughput: 22965.835
    sample_time_ms: 7044.899
    update_time_ms: 24.211
  timestamp: 1602368793
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: '36729_00000'
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36729_00000 | TERMINATED |       |     20 |          608.589 | 3235840 |  240.248 |              290.263 |              114.051 |            828.947 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


[2m[33m(pid=raylet)[0m E1010 22:26:33.426215 80817 80817 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed
[2m[33m(pid=raylet)[0m E1010 22:26:33.426440 80817 80817 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.3 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36729_00000 | TERMINATED |       |     20 |          608.589 | 3235840 |  240.248 |              290.263 |              114.051 |            828.947 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


