2020-10-12 00:13:10,514	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_b6f43_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=61637)[0m 2020-10-12 00:13:13,313	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=61607)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61607)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61603)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61603)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61634)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61634)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61550)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61550)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61529)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61529)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61588)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61588)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61577)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61577)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61643)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61643)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61642)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61642)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61644)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61644)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61619)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61619)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61605)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61605)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61594)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61594)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61609)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61609)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61622)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61622)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61624)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61624)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61639)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61639)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61590)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61590)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61606)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61606)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61616)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61616)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61654)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61654)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61628)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61628)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61534)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61534)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61591)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61591)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61641)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61641)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61584)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61584)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61556)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61556)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61596)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61596)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61612)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61612)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61629)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61629)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61601)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61601)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61526)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61526)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61553)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61553)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61620)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61620)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61557)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61557)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61536)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61536)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61630)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61630)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61610)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61610)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61659)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61659)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61614)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61614)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61528)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61528)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61649)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61649)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61522)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61522)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61604)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61604)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61523)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61523)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61650)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61650)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61541)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61541)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61548)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61548)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61648)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61648)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61549)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61549)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61532)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61532)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61539)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61539)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61542)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61542)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61537)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61537)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61592)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61592)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61533)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61533)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61646)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61646)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61527)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61527)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61543)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61543)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61633)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61633)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61555)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61555)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61531)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61531)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61655)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61655)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61538)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61538)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61551)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61551)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61608)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61608)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61613)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61613)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61602)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61602)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61625)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61625)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61587)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61587)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61618)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61618)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61621)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61621)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61525)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61525)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61524)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61524)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61546)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61546)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61544)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61544)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61611)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61611)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61540)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61540)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61580)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61580)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_b6f43_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_00-13-51
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: ceb8c0b2d6494dadafb61fa92eb733aa
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1810798048973083
        entropy_coeff: 0.0005000000000000001
        kl: 0.008566662125910321
        model: {}
        policy_loss: -0.012310020567383617
        total_loss: 502.2355448404948
        vf_explained_var: 0.5664147734642029
        vf_loss: 502.24672444661456
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.74871794871795
    gpu_util_percent0: 0.27794871794871795
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5743589743589737
    vram_util_percent0: 0.08867766649006405
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61637
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1692018423525041
    mean_env_wait_ms: 1.1732382655106934
    mean_inference_ms: 6.167974018616306
    mean_raw_obs_processing_ms: 0.4568851608742751
  time_since_restore: 33.17054009437561
  time_this_iter_s: 33.17054009437561
  time_total_s: 33.17054009437561
  timers:
    learn_throughput: 6940.41
    learn_time_ms: 23311.589
    sample_throughput: 16529.969
    sample_time_ms: 9787.798
    update_time_ms: 44.634
  timestamp: 1602461631
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: b6f43_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b6f43_00000 | RUNNING  | 172.17.0.4:61637 |      1 |          33.1705 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b6f43_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3623.7708333333335
    time_step_min: 3280
  date: 2020-10-12_00-14-22
  done: false
  episode_len_mean: 890.2120253164557
  episode_reward_max: 271.77777777777766
  episode_reward_mean: 216.57352001022863
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: ceb8c0b2d6494dadafb61fa92eb733aa
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1473211546738942
        entropy_coeff: 0.0005000000000000001
        kl: 0.011223212660600742
        model: {}
        policy_loss: -0.013796255535756549
        total_loss: 126.24822680155437
        vf_explained_var: 0.813798725605011
        vf_loss: 126.26034990946452
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.53611111111111
    gpu_util_percent0: 0.40444444444444444
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7638888888888897
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61637
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.164677071746204
    mean_env_wait_ms: 1.1692332201030007
    mean_inference_ms: 5.806792730782163
    mean_raw_obs_processing_ms: 0.44357286028328946
  time_since_restore: 63.94163393974304
  time_this_iter_s: 30.77109384536743
  time_total_s: 63.94163393974304
  timers:
    learn_throughput: 6961.572
    learn_time_ms: 23240.728
    sample_throughput: 18701.711
    sample_time_ms: 8651.187
    update_time_ms: 42.243
  timestamp: 1602461662
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: b6f43_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b6f43_00000 | RUNNING  | 172.17.0.4:61637 |      2 |          63.9416 | 323584 |  216.574 |              271.778 |              145.717 |            890.212 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b6f43_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3623.7892376681616
    time_step_min: 3280
  date: 2020-10-12_00-14-52
  done: false
  episode_len_mean: 886.9367088607595
  episode_reward_max: 271.77777777777766
  episode_reward_mean: 217.08176703746304
  episode_reward_min: 140.7171717171715
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: ceb8c0b2d6494dadafb61fa92eb733aa
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1341195205847423
        entropy_coeff: 0.0005000000000000001
        kl: 0.0113501554975907
        model: {}
        policy_loss: -0.015694307706629235
        total_loss: 56.475844065348305
        vf_explained_var: 0.9051428437232971
        vf_loss: 56.4898354212443
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.348571428571425
    gpu_util_percent0: 0.3088571428571429
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7800000000000002
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61637
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16189087642914787
    mean_env_wait_ms: 1.1678303929915976
    mean_inference_ms: 5.567055404825706
    mean_raw_obs_processing_ms: 0.4344693479675048
  time_since_restore: 94.1636643409729
  time_this_iter_s: 30.22203040122986
  time_total_s: 94.1636643409729
  timers:
    learn_throughput: 6984.705
    learn_time_ms: 23163.756
    sample_throughput: 19856.398
    sample_time_ms: 8148.104
    update_time_ms: 36.972
  timestamp: 1602461692
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: b6f43_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b6f43_00000 | RUNNING  | 172.17.0.4:61637 |      3 |          94.1637 | 485376 |  217.082 |              271.778 |              140.717 |            886.937 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b6f43_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3621.864238410596
    time_step_min: 3259
  date: 2020-10-12_00-15-23
  done: false
  episode_len_mean: 884.7626582278481
  episode_reward_max: 272.23232323232315
  episode_reward_mean: 217.0697800792735
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: ceb8c0b2d6494dadafb61fa92eb733aa
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1208285590012868
        entropy_coeff: 0.0005000000000000001
        kl: 0.011465752497315407
        model: {}
        policy_loss: -0.01761480169564796
        total_loss: 38.10077794392904
        vf_explained_var: 0.9357242584228516
        vf_loss: 38.11666043599447
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.474999999999998
    gpu_util_percent0: 0.46111111111111114
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7722222222222235
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61637
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15988189609793613
    mean_env_wait_ms: 1.1672918859297843
    mean_inference_ms: 5.398941640408404
    mean_raw_obs_processing_ms: 0.4276804138867485
  time_since_restore: 124.37213110923767
  time_this_iter_s: 30.20846676826477
  time_total_s: 124.37213110923767
  timers:
    learn_throughput: 6987.493
    learn_time_ms: 23154.512
    sample_throughput: 20590.356
    sample_time_ms: 7857.659
    update_time_ms: 39.401
  timestamp: 1602461723
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: b6f43_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b6f43_00000 | RUNNING  | 172.17.0.4:61637 |      4 |          124.372 | 647168 |   217.07 |              272.232 |              138.899 |            884.763 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b6f43_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3614.723097112861
    time_step_min: 3259
  date: 2020-10-12_00-15-53
  done: false
  episode_len_mean: 880.6405063291139
  episode_reward_max: 272.23232323232315
  episode_reward_mean: 218.68169032093064
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: ceb8c0b2d6494dadafb61fa92eb733aa
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0919292469819386
        entropy_coeff: 0.0005000000000000001
        kl: 0.011500499909743667
        model: {}
        policy_loss: -0.016317931944892432
        total_loss: 29.171505610148113
        vf_explained_var: 0.9493789076805115
        vf_loss: 29.186068852742512
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.77714285714286
    gpu_util_percent0: 0.342
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7771428571428576
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61637
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1583793919730019
    mean_env_wait_ms: 1.1676874689452459
    mean_inference_ms: 5.273696877346157
    mean_raw_obs_processing_ms: 0.4223152253944356
  time_since_restore: 154.91761422157288
  time_this_iter_s: 30.545483112335205
  time_total_s: 154.91761422157288
  timers:
    learn_throughput: 6973.504
    learn_time_ms: 23200.961
    sample_throughput: 21008.437
    sample_time_ms: 7701.287
    update_time_ms: 38.459
  timestamp: 1602461753
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: b6f43_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b6f43_00000 | RUNNING  | 172.17.0.4:61637 |      5 |          154.918 | 808960 |  218.682 |              272.232 |              138.899 |            880.641 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b6f43_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3587.817334575955
    time_step_min: 3253
  date: 2020-10-12_00-16-23
  done: false
  episode_len_mean: 869.0708446866485
  episode_reward_max: 281.77777777777794
  episode_reward_mean: 222.88462279470437
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 311
  episodes_total: 1101
  experiment_id: ceb8c0b2d6494dadafb61fa92eb733aa
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0718796054522197
        entropy_coeff: 0.0005000000000000001
        kl: 0.01130249296935896
        model: {}
        policy_loss: -0.017208602143606793
        total_loss: 30.61871035893758
        vf_explained_var: 0.9621255397796631
        vf_loss: 30.63419500986735
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.482857142857142
    gpu_util_percent0: 0.44
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7685714285714287
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61637
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15639199121282815
    mean_env_wait_ms: 1.1711064514002298
    mean_inference_ms: 5.107036667637594
    mean_raw_obs_processing_ms: 0.41534181408238247
  time_since_restore: 184.97382259368896
  time_this_iter_s: 30.05620837211609
  time_total_s: 184.97382259368896
  timers:
    learn_throughput: 6982.761
    learn_time_ms: 23170.204
    sample_throughput: 21360.632
    sample_time_ms: 7574.308
    update_time_ms: 38.402
  timestamp: 1602461783
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: b6f43_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b6f43_00000 | RUNNING  | 172.17.0.4:61637 |      6 |          184.974 | 970752 |  222.885 |              281.778 |              138.899 |            869.071 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b6f43_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3574.628640776699
    time_step_min: 3194
  date: 2020-10-12_00-16-53
  done: false
  episode_len_mean: 863.879746835443
  episode_reward_max: 282.08080808080786
  episode_reward_mean: 224.91116864851026
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 163
  episodes_total: 1264
  experiment_id: ceb8c0b2d6494dadafb61fa92eb733aa
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.060988982518514
        entropy_coeff: 0.0005000000000000001
        kl: 0.011702353289971748
        model: {}
        policy_loss: -0.019268650217175793
        total_loss: 18.453628063201904
        vf_explained_var: 0.9659398198127747
        vf_loss: 18.471086502075195
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.48
    gpu_util_percent0: 0.2971428571428571
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.782857142857143
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61637
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15563483456496152
    mean_env_wait_ms: 1.17265959240783
    mean_inference_ms: 5.044802032162399
    mean_raw_obs_processing_ms: 0.41264717117282046
  time_since_restore: 214.85929441452026
  time_this_iter_s: 29.8854718208313
  time_total_s: 214.85929441452026
  timers:
    learn_throughput: 6994.238
    learn_time_ms: 23132.184
    sample_throughput: 21631.963
    sample_time_ms: 7479.303
    update_time_ms: 35.991
  timestamp: 1602461813
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: b6f43_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b6f43_00000 | RUNNING  | 172.17.0.4:61637 |      7 |          214.859 | 1132544 |  224.911 |              282.081 |              138.899 |             863.88 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b6f43_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3559.687230989957
    time_step_min: 3194
  date: 2020-10-12_00-17-24
  done: false
  episode_len_mean: 858.7841068917019
  episode_reward_max: 282.08080808080786
  episode_reward_mean: 227.159442526531
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: ceb8c0b2d6494dadafb61fa92eb733aa
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0327277580897014
        entropy_coeff: 0.0005000000000000001
        kl: 0.011306605534628034
        model: {}
        policy_loss: -0.0188012203531495
        total_loss: 15.273218075434366
        vf_explained_var: 0.9682538509368896
        vf_loss: 15.290274302164713
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.18333333333333
    gpu_util_percent0: 0.38138888888888894
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7777777777777786
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61637
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15500435939243423
    mean_env_wait_ms: 1.1741109092235873
    mean_inference_ms: 4.992762502769453
    mean_raw_obs_processing_ms: 0.4103615708216445
  time_since_restore: 245.16387510299683
  time_this_iter_s: 30.304580688476562
  time_total_s: 245.16387510299683
  timers:
    learn_throughput: 6995.592
    learn_time_ms: 23127.705
    sample_throughput: 21794.524
    sample_time_ms: 7423.516
    update_time_ms: 45.098
  timestamp: 1602461844
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: b6f43_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b6f43_00000 | RUNNING  | 172.17.0.4:61637 |      8 |          245.164 | 1294336 |  227.159 |              282.081 |              138.899 |            858.784 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b6f43_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3548.699742268041
    time_step_min: 3194
  date: 2020-10-12_00-17-54
  done: false
  episode_len_mean: 854.1525316455696
  episode_reward_max: 292.5353535353532
  episode_reward_mean: 228.90723692622413
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: ceb8c0b2d6494dadafb61fa92eb733aa
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0014687329530716
        entropy_coeff: 0.0005000000000000001
        kl: 0.01150376326404512
        model: {}
        policy_loss: -0.016004978213459253
        total_loss: 19.093974113464355
        vf_explained_var: 0.9633541107177734
        vf_loss: 19.108178933461506
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.86
    gpu_util_percent0: 0.282
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7800000000000002
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61637
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1544596103853558
    mean_env_wait_ms: 1.1756243651929121
    mean_inference_ms: 4.94761631390108
    mean_raw_obs_processing_ms: 0.40831557884124825
  time_since_restore: 275.21378993988037
  time_this_iter_s: 30.049914836883545
  time_total_s: 275.21378993988037
  timers:
    learn_throughput: 6998.825
    learn_time_ms: 23117.024
    sample_throughput: 21957.605
    sample_time_ms: 7368.381
    update_time_ms: 44.419
  timestamp: 1602461874
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: b6f43_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b6f43_00000 | RUNNING  | 172.17.0.4:61637 |      9 |          275.214 | 1456128 |  228.907 |              292.535 |              138.899 |            854.153 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b6f43_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3527.288317256163
    time_step_min: 3194
  date: 2020-10-12_00-18-24
  done: false
  episode_len_mean: 845.3901795142556
  episode_reward_max: 292.5353535353532
  episode_reward_mean: 232.04648917901278
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 314
  episodes_total: 1894
  experiment_id: ceb8c0b2d6494dadafb61fa92eb733aa
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9655029277006785
        entropy_coeff: 0.0005000000000000001
        kl: 0.010109123696262637
        model: {}
        policy_loss: -0.016467383014969528
        total_loss: 19.649176279703777
        vf_explained_var: 0.9746022820472717
        vf_loss: 19.664104143778484
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.611428571428572
    gpu_util_percent0: 0.3797142857142858
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774285714285715
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61637
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1535784639916909
    mean_env_wait_ms: 1.1788863469152493
    mean_inference_ms: 4.875056562058976
    mean_raw_obs_processing_ms: 0.4050783712163888
  time_since_restore: 305.59238505363464
  time_this_iter_s: 30.378595113754272
  time_total_s: 305.59238505363464
  timers:
    learn_throughput: 6992.069
    learn_time_ms: 23139.358
    sample_throughput: 22083.686
    sample_time_ms: 7326.313
    update_time_ms: 43.609
  timestamp: 1602461904
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: b6f43_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b6f43_00000 | RUNNING  | 172.17.0.4:61637 |     10 |          305.592 | 1617920 |  232.046 |              292.535 |              138.899 |             845.39 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b6f43_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3518.6243830207304
    time_step_min: 3194
  date: 2020-10-12_00-18-54
  done: false
  episode_len_mean: 841.65141187926
  episode_reward_max: 292.5353535353532
  episode_reward_mean: 233.41700353092745
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 160
  episodes_total: 2054
  experiment_id: ceb8c0b2d6494dadafb61fa92eb733aa
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9469701697429022
        entropy_coeff: 0.0005000000000000001
        kl: 0.010086450492963195
        model: {}
        policy_loss: -0.018124834440338116
        total_loss: 12.415512720743815
        vf_explained_var: 0.9763712286949158
        vf_loss: 12.432093620300293
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.26285714285714
    gpu_util_percent0: 0.39057142857142857
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.788571428571429
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61637
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15320700146765293
    mean_env_wait_ms: 1.1803430675001672
    mean_inference_ms: 4.844872197374595
    mean_raw_obs_processing_ms: 0.4037107262839844
  time_since_restore: 335.3579626083374
  time_this_iter_s: 29.76557755470276
  time_total_s: 335.3579626083374
  timers:
    learn_throughput: 7009.894
    learn_time_ms: 23080.522
    sample_throughput: 22968.35
    sample_time_ms: 7044.128
    update_time_ms: 41.415
  timestamp: 1602461934
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: b6f43_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b6f43_00000 | RUNNING  | 172.17.0.4:61637 |     11 |          335.358 | 1779712 |  233.417 |              292.535 |              138.899 |            841.651 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b6f43_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3509.8141025641025
    time_step_min: 3194
  date: 2020-10-12_00-19-25
  done: false
  episode_len_mean: 838.3146473779385
  episode_reward_max: 292.5353535353532
  episode_reward_mean: 234.829383345206
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: ceb8c0b2d6494dadafb61fa92eb733aa
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9210369984308878
        entropy_coeff: 0.0005000000000000001
        kl: 0.010504102567210793
        model: {}
        policy_loss: -0.016645007805588346
        total_loss: 10.698445002237955
        vf_explained_var: 0.9771132469177246
        vf_loss: 10.713449398676554
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.180555555555557
    gpu_util_percent0: 0.46333333333333343
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7916666666666674
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61637
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15287598170610783
    mean_env_wait_ms: 1.1816810584577313
    mean_inference_ms: 4.817906055897082
    mean_raw_obs_processing_ms: 0.40245426846307714
  time_since_restore: 365.7774329185486
  time_this_iter_s: 30.41947031021118
  time_total_s: 365.7774329185486
  timers:
    learn_throughput: 7009.213
    learn_time_ms: 23082.763
    sample_throughput: 23113.614
    sample_time_ms: 6999.857
    update_time_ms: 46.631
  timestamp: 1602461965
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: b6f43_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b6f43_00000 | RUNNING  | 172.17.0.4:61637 |     12 |          365.777 | 1941504 |  234.829 |              292.535 |              138.899 |            838.315 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b6f43_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3496.74555968608
    time_step_min: 3194
  date: 2020-10-12_00-19-55
  done: false
  episode_len_mean: 833.5634953042058
  episode_reward_max: 292.5353535353532
  episode_reward_mean: 236.63003658471183
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 237
  episodes_total: 2449
  experiment_id: ceb8c0b2d6494dadafb61fa92eb733aa
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.874845951795578
        entropy_coeff: 0.0005000000000000001
        kl: 0.009460883758341273
        model: {}
        policy_loss: -0.01588716957970367
        total_loss: 14.987916946411133
        vf_explained_var: 0.9778693318367004
        vf_loss: 15.002349376678467
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.96
    gpu_util_percent0: 0.324
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7771428571428576
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61637
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1524454669479051
    mean_env_wait_ms: 1.1837818180116448
    mean_inference_ms: 4.782116753099106
    mean_raw_obs_processing_ms: 0.4007940964029894
  time_since_restore: 396.03626823425293
  time_this_iter_s: 30.258835315704346
  time_total_s: 396.03626823425293
  timers:
    learn_throughput: 7004.007
    learn_time_ms: 23099.919
    sample_throughput: 23165.665
    sample_time_ms: 6984.129
    update_time_ms: 47.65
  timestamp: 1602461995
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: b6f43_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b6f43_00000 | RUNNING  | 172.17.0.4:61637 |     13 |          396.036 | 2103296 |   236.63 |              292.535 |              138.899 |            833.563 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b6f43_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3485.0489089541006
    time_step_min: 3159
  date: 2020-10-12_00-20-25
  done: false
  episode_len_mean: 829.1816827997021
  episode_reward_max: 292.5353535353532
  episode_reward_mean: 238.27470911648115
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 237
  episodes_total: 2686
  experiment_id: ceb8c0b2d6494dadafb61fa92eb733aa
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8784356613953909
        entropy_coeff: 0.0005000000000000001
        kl: 0.008936016277099649
        model: {}
        policy_loss: -0.0144694714108482
        total_loss: 12.34289781252543
        vf_explained_var: 0.9786873459815979
        vf_loss: 12.356019179026285
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.939999999999998
    gpu_util_percent0: 0.44428571428571423
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7714285714285714
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61637
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1520581207446017
    mean_env_wait_ms: 1.1857602047992148
    mean_inference_ms: 4.751669652537678
    mean_raw_obs_processing_ms: 0.3993845931071477
  time_since_restore: 426.3242726325989
  time_this_iter_s: 30.288004398345947
  time_total_s: 426.3242726325989
  timers:
    learn_throughput: 7005.31
    learn_time_ms: 23095.623
    sample_throughput: 23118.512
    sample_time_ms: 6998.374
    update_time_ms: 44.942
  timestamp: 1602462025
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: b6f43_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b6f43_00000 | RUNNING  | 172.17.0.4:61637 |     14 |          426.324 | 2265088 |  238.275 |              292.535 |              138.899 |            829.182 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b6f43_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3478.615411931818
    time_step_min: 3159
  date: 2020-10-12_00-20-56
  done: false
  episode_len_mean: 826.7542194092827
  episode_reward_max: 292.5353535353532
  episode_reward_mean: 239.19818437539945
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: ceb8c0b2d6494dadafb61fa92eb733aa
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8649471998214722
        entropy_coeff: 0.0005000000000000001
        kl: 0.01006123865954578
        model: {}
        policy_loss: -0.017844289424829185
        total_loss: 9.70694867769877
        vf_explained_var: 0.9796954989433289
        vf_loss: 9.723213116327921
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.816666666666666
    gpu_util_percent0: 0.32805555555555554
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7777777777777786
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61637
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15183198993926805
    mean_env_wait_ms: 1.1869829948066135
    mean_inference_ms: 4.7333811422795256
    mean_raw_obs_processing_ms: 0.3985383344564578
  time_since_restore: 456.7568287849426
  time_this_iter_s: 30.43255615234375
  time_total_s: 456.7568287849426
  timers:
    learn_throughput: 7006.028
    learn_time_ms: 23093.258
    sample_throughput: 23152.866
    sample_time_ms: 6987.99
    update_time_ms: 45.285
  timestamp: 1602462056
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: b6f43_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b6f43_00000 | RUNNING  | 172.17.0.4:61637 |     15 |          456.757 | 2426880 |  239.198 |              292.535 |              138.899 |            826.754 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b6f43_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3472.0551311856525
    time_step_min: 3159
  date: 2020-10-12_00-21-26
  done: false
  episode_len_mean: 823.651201052978
  episode_reward_max: 292.5353535353532
  episode_reward_mean: 240.11829050624695
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 195
  episodes_total: 3039
  experiment_id: ceb8c0b2d6494dadafb61fa92eb733aa
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8254145234823227
        entropy_coeff: 0.0005000000000000001
        kl: 0.009458012490843734
        model: {}
        policy_loss: -0.01512273036253949
        total_loss: 13.99141558011373
        vf_explained_var: 0.9766866564750671
        vf_loss: 14.005059798558554
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.6
    gpu_util_percent0: 0.4045714285714285
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7771428571428576
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61637
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1515747330118417
    mean_env_wait_ms: 1.1885628584844803
    mean_inference_ms: 4.712714978119779
    mean_raw_obs_processing_ms: 0.39756938206993037
  time_since_restore: 487.02479457855225
  time_this_iter_s: 30.26796579360962
  time_total_s: 487.02479457855225
  timers:
    learn_throughput: 6999.919
    learn_time_ms: 23113.412
    sample_throughput: 23149.383
    sample_time_ms: 6989.041
    update_time_ms: 45.385
  timestamp: 1602462086
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: b6f43_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b6f43_00000 | RUNNING  | 172.17.0.4:61637 |     16 |          487.025 | 2588672 |  240.118 |              292.535 |              138.899 |            823.651 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b6f43_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3463.277591973244
    time_step_min: 3122
  date: 2020-10-12_00-21-57
  done: false
  episode_len_mean: 820.0826047633403
  episode_reward_max: 292.989898989899
  episode_reward_mean: 241.4787671712603
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 278
  episodes_total: 3317
  experiment_id: ceb8c0b2d6494dadafb61fa92eb733aa
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8151738196611404
        entropy_coeff: 0.0005000000000000001
        kl: 0.009590728984524807
        model: {}
        policy_loss: -0.01601108305233841
        total_loss: 10.88164758682251
        vf_explained_var: 0.9833198189735413
        vf_loss: 10.896148045857748
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.40277777777778
    gpu_util_percent0: 0.39972222222222226
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769444444444445
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61637
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1512467449286999
    mean_env_wait_ms: 1.190597132557969
    mean_inference_ms: 4.6865522521945495
    mean_raw_obs_processing_ms: 0.39636917140139327
  time_since_restore: 517.3570261001587
  time_this_iter_s: 30.332231521606445
  time_total_s: 517.3570261001587
  timers:
    learn_throughput: 6987.787
    learn_time_ms: 23153.54
    sample_throughput: 23141.76
    sample_time_ms: 6991.344
    update_time_ms: 46.769
  timestamp: 1602462117
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: b6f43_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b6f43_00000 | RUNNING  | 172.17.0.4:61637 |     17 |          517.357 | 2750464 |  241.479 |               292.99 |              138.899 |            820.083 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b6f43_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3459.457366589327
    time_step_min: 3122
  date: 2020-10-12_00-22-27
  done: false
  episode_len_mean: 818.1067318757192
  episode_reward_max: 292.989898989899
  episode_reward_mean: 242.01891178761136
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 159
  episodes_total: 3476
  experiment_id: ceb8c0b2d6494dadafb61fa92eb733aa
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7972376495599747
        entropy_coeff: 0.0005000000000000001
        kl: 0.009708141054337224
        model: {}
        policy_loss: -0.017444406868889928
        total_loss: 9.293004115422567
        vf_explained_var: 0.9813184142112732
        vf_loss: 9.308905283610025
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.47142857142857
    gpu_util_percent0: 0.31257142857142856
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7857142857142856
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61637
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15107856711642728
    mean_env_wait_ms: 1.191685670516451
    mean_inference_ms: 4.673155481964662
    mean_raw_obs_processing_ms: 0.3957456620932592
  time_since_restore: 547.7002272605896
  time_this_iter_s: 30.343201160430908
  time_total_s: 547.7002272605896
  timers:
    learn_throughput: 6986.153
    learn_time_ms: 23158.955
    sample_throughput: 23115.561
    sample_time_ms: 6999.268
    update_time_ms: 37.763
  timestamp: 1602462147
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: b6f43_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b6f43_00000 | RUNNING  | 172.17.0.4:61637 |     18 |            547.7 | 2912256 |  242.019 |               292.99 |              138.899 |            818.107 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b6f43_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3455.4910146530274
    time_step_min: 3122
  date: 2020-10-12_00-22-58
  done: false
  episode_len_mean: 816.3349794238683
  episode_reward_max: 292.989898989899
  episode_reward_mean: 242.54158872677382
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 169
  episodes_total: 3645
  experiment_id: ceb8c0b2d6494dadafb61fa92eb733aa
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7739134132862091
        entropy_coeff: 0.0005000000000000001
        kl: 0.009328874681765834
        model: {}
        policy_loss: -0.01628954194408531
        total_loss: 9.141257365544638
        vf_explained_var: 0.9834416508674622
        vf_loss: 9.156067848205566
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.144444444444446
    gpu_util_percent0: 0.3072222222222222
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333337
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61637
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15091389571040242
    mean_env_wait_ms: 1.192849353776385
    mean_inference_ms: 4.66000792013561
    mean_raw_obs_processing_ms: 0.39512322378292214
  time_since_restore: 578.0747630596161
  time_this_iter_s: 30.37453579902649
  time_total_s: 578.0747630596161
  timers:
    learn_throughput: 6977.588
    learn_time_ms: 23187.384
    sample_throughput: 23127.399
    sample_time_ms: 6995.685
    update_time_ms: 43.769
  timestamp: 1602462178
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: b6f43_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b6f43_00000 | RUNNING  | 172.17.0.4:61637 |     19 |          578.075 | 3074048 |  242.542 |               292.99 |              138.899 |            816.335 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b6f43_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3450.714504596527
    time_step_min: 3122
  date: 2020-10-12_00-23-28
  done: true
  episode_len_mean: 813.685598377282
  episode_reward_max: 292.989898989899
  episode_reward_mean: 243.27625647960326
  episode_reward_min: 138.8989898989893
  episodes_this_iter: 299
  episodes_total: 3944
  experiment_id: ceb8c0b2d6494dadafb61fa92eb733aa
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7598459174235662
        entropy_coeff: 0.0005000000000000001
        kl: 0.008437203515010575
        model: {}
        policy_loss: -0.014525203267112374
        total_loss: 12.6011643409729
        vf_explained_var: 0.9831928610801697
        vf_loss: 12.614381790161133
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.54857142857143
    gpu_util_percent0: 0.44285714285714284
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7714285714285714
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61637
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15063924079084026
    mean_env_wait_ms: 1.1947256192308946
    mean_inference_ms: 4.638425249963567
    mean_raw_obs_processing_ms: 0.39413110570148413
  time_since_restore: 608.1269459724426
  time_this_iter_s: 30.052182912826538
  time_total_s: 608.1269459724426
  timers:
    learn_throughput: 6984.392
    learn_time_ms: 23164.795
    sample_throughput: 23168.185
    sample_time_ms: 6983.37
    update_time_ms: 43.965
  timestamp: 1602462208
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: b6f43_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b6f43_00000 | TERMINATED |       |     20 |          608.127 | 3235840 |  243.276 |               292.99 |              138.899 |            813.686 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b6f43_00000 | TERMINATED |       |     20 |          608.127 | 3235840 |  243.276 |               292.99 |              138.899 |            813.686 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


