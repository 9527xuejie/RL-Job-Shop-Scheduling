2020-10-08 16:11:45,466	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8270[39m[22m
== Status ==
Memory usage on this node: 57.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_f6f2a_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=20395)[0m 2020-10-08 16:11:48,491	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=20353)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20353)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20347)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20347)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20339)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20339)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20304)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20304)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20283)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20283)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20371)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20371)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20388)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20388)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20376)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20376)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20383)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20383)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20368)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20368)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20377)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20377)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20380)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20380)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20314)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20314)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20373)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20373)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20357)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20357)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20276)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20276)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20308)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20308)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20386)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20386)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20242)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20242)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20264)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20264)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20367)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20367)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20278)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20278)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20329)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20329)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20336)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20336)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20315)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20315)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20325)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20325)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20356)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20356)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20363)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20363)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20254)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20254)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20312)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20312)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20360)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20360)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20391)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20391)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20354)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20354)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20365)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20365)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20320)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20320)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20309)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20309)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20267)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20267)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20335)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20335)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20302)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20302)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20323)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20323)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20255)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20255)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20332)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20332)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20301)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20301)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20258)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20258)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20243)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20243)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20251)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20251)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20245)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20245)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20256)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20256)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20348)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20348)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20311)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20311)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20240)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20240)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20272)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20272)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20253)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20253)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20286)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20286)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20260)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20260)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20333)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20333)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20269)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20269)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20257)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20257)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20262)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20262)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20351)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20351)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20327)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20327)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20285)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20285)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20241)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20241)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20328)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20328)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20344)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20344)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20244)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20244)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20337)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20337)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20281)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20281)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20246)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20246)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20334)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20334)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20350)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20350)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20252)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20252)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20275)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20275)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20298)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20298)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20266)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20266)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20294)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20294)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20326)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20326)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20340)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20340)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20259)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20259)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_f6f2a_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3225.0
  date: 2020-10-08_16-12-52
  done: false
  episode_len_mean: 875.496835443038
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 227.93504666922368
  episode_reward_min: 147.0606060606061
  episodes_this_iter: 316
  episodes_total: 316
  experiment_id: 29d4dc72446446878e479f0a7308541e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999993
        cur_lr: 0.00010000000000000003
        entropy: 1.1628720715076108
        entropy_coeff: 0.0
        kl: 0.006727450886812014
        model: {}
        policy_loss: -0.015732387163310865
        total_loss: 6.2172124355654175
        vf_explained_var: 0.8219460844993591
        vf_loss: 6.231599361081667
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.105882352941173
    gpu_util_percent0: 0.2864705882352942
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.00014705882352941178
    ram_util_percent: 9.823529411764707
    vram_util_percent0: 0.25132396349815744
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20395
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.2471468337489779
    mean_env_wait_ms: 3.2817900346436226
    mean_inference_ms: 9.815926559179717
    mean_raw_obs_processing_ms: 0.8791118390989286
  time_since_restore: 57.734742403030396
  time_this_iter_s: 57.734742403030396
  time_total_s: 57.734742403030396
  timers:
    learn_throughput: 7900.737
    learn_time_ms: 40956.179
    sample_throughput: 19380.392
    sample_time_ms: 16696.463
    update_time_ms: 45.662
  timestamp: 1602173572
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 1
  trial_id: f6f2a_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 75.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f6f2a_00000 | RUNNING  | 172.17.0.4:20395 |      1 |          57.7347 | 323584 |  227.935 |              284.798 |              147.061 |            875.497 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f6f2a_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3225.0
  date: 2020-10-08_16-13-47
  done: false
  episode_len_mean: 869.9588607594936
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 229.17670374632382
  episode_reward_min: 147.0606060606061
  episodes_this_iter: 316
  episodes_total: 632
  experiment_id: 29d4dc72446446878e479f0a7308541e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999993
        cur_lr: 0.00010000000000000003
        entropy: 1.132290837130969
        entropy_coeff: 0.0
        kl: 0.007701371089095557
        model: {}
        policy_loss: -0.021045617099049726
        total_loss: 4.107488849495031
        vf_explained_var: 0.9418060779571533
        vf_loss: 4.12699422051635
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.581250000000004
    gpu_util_percent0: 0.26671875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.1703125
    vram_util_percent0: 0.2570514922925549
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20395
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.24055122939043674
    mean_env_wait_ms: 3.2708265875649385
    mean_inference_ms: 9.244058398910663
    mean_raw_obs_processing_ms: 0.8560969445694445
  time_since_restore: 112.80094170570374
  time_this_iter_s: 55.06619930267334
  time_total_s: 112.80094170570374
  timers:
    learn_throughput: 7904.228
    learn_time_ms: 40938.092
    sample_throughput: 21112.127
    sample_time_ms: 15326.926
    update_time_ms: 43.342
  timestamp: 1602173627
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 2
  trial_id: f6f2a_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f6f2a_00000 | RUNNING  | 172.17.0.4:20395 |      2 |          112.801 | 647168 |  229.177 |              284.798 |              147.061 |            869.959 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f6f2a_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3225.0
  date: 2020-10-08_16-14-42
  done: false
  episode_len_mean: 866.6603375527426
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 228.86495759280555
  episode_reward_min: 118.96969696969748
  episodes_this_iter: 316
  episodes_total: 948
  experiment_id: 29d4dc72446446878e479f0a7308541e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999993
        cur_lr: 0.00010000000000000003
        entropy: 1.1185616903667208
        entropy_coeff: 0.0
        kl: 0.008565768528776833
        model: {}
        policy_loss: -0.025035713607728292
        total_loss: 4.0342997387994695
        vf_explained_var: 0.9684340953826904
        vf_loss: 4.0576223210443425
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.27142857142857
    gpu_util_percent0: 0.29000000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.190476190476193
    vram_util_percent0: 0.257051492292555
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20395
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.2368398867994428
    mean_env_wait_ms: 3.2652731669627886
    mean_inference_ms: 8.887063265476307
    mean_raw_obs_processing_ms: 0.8408938933957992
  time_since_restore: 167.60969758033752
  time_this_iter_s: 54.80875587463379
  time_total_s: 167.60969758033752
  timers:
    learn_throughput: 7883.361
    learn_time_ms: 41046.452
    sample_throughput: 22017.899
    sample_time_ms: 14696.407
    update_time_ms: 36.543
  timestamp: 1602173682
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 3
  trial_id: f6f2a_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f6f2a_00000 | RUNNING  | 172.17.0.4:20395 |      3 |           167.61 | 970752 |  228.865 |              284.798 |               118.97 |             866.66 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f6f2a_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3225.0
  date: 2020-10-08_16-15-37
  done: false
  episode_len_mean: 862.7745253164557
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 228.44896752333443
  episode_reward_min: 118.96969696969748
  episodes_this_iter: 316
  episodes_total: 1264
  experiment_id: 29d4dc72446446878e479f0a7308541e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999993
        cur_lr: 0.00010000000000000003
        entropy: 1.0916968659509587
        entropy_coeff: 0.0
        kl: 0.00943956660884845
        model: {}
        policy_loss: -0.02906761356759109
        total_loss: 3.291026269333272
        vf_explained_var: 0.9820578098297119
        vf_loss: 3.3182059420814998
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.670312499999994
    gpu_util_percent0: 0.275625
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.189062500000002
    vram_util_percent0: 0.2570514922925549
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20395
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.23445485656820697
    mean_env_wait_ms: 3.2661959641028444
    mean_inference_ms: 8.644139417029413
    mean_raw_obs_processing_ms: 0.830077443038289
  time_since_restore: 222.57791924476624
  time_this_iter_s: 54.96822166442871
  time_total_s: 222.57791924476624
  timers:
    learn_throughput: 7864.839
    learn_time_ms: 41143.117
    sample_throughput: 22505.75
    sample_time_ms: 14377.836
    update_time_ms: 33.548
  timestamp: 1602173737
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 4
  trial_id: f6f2a_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f6f2a_00000 | RUNNING  | 172.17.0.4:20395 |      4 |          222.578 | 1294336 |  228.449 |              284.798 |               118.97 |            862.775 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f6f2a_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3225.0
  date: 2020-10-08_16-16-32
  done: false
  episode_len_mean: 855.9976905311778
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 228.90878764550806
  episode_reward_min: 118.96969696969748
  episodes_this_iter: 468
  episodes_total: 1732
  experiment_id: 29d4dc72446446878e479f0a7308541e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999993
        cur_lr: 0.00010000000000000003
        entropy: 1.0521378803856765
        entropy_coeff: 0.0
        kl: 0.008749178864203299
        model: {}
        policy_loss: -0.03251636762885212
        total_loss: 4.781731210177457
        vf_explained_var: 0.987223207950592
        vf_loss: 4.81249775162226
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.446875000000002
    gpu_util_percent0: 0.2596875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.171875
    vram_util_percent0: 0.2570514922925549
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20395
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.23218510925469427
    mean_env_wait_ms: 3.272772156459422
    mean_inference_ms: 8.40549401204213
    mean_raw_obs_processing_ms: 0.8186852609491969
  time_since_restore: 277.9877362251282
  time_this_iter_s: 55.40981698036194
  time_total_s: 277.9877362251282
  timers:
    learn_throughput: 7847.606
    learn_time_ms: 41233.467
    sample_throughput: 22746.512
    sample_time_ms: 14225.654
    update_time_ms: 34.872
  timestamp: 1602173792
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 5
  trial_id: f6f2a_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f6f2a_00000 | RUNNING  | 172.17.0.4:20395 |      5 |          277.988 | 1617920 |  228.909 |              284.798 |               118.97 |            855.998 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f6f2a_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3225.0
  date: 2020-10-08_16-17-27
  done: false
  episode_len_mean: 849.1627486437613
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 229.15573456079775
  episode_reward_min: 118.96969696969748
  episodes_this_iter: 480
  episodes_total: 2212
  experiment_id: 29d4dc72446446878e479f0a7308541e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999993
        cur_lr: 0.00010000000000000003
        entropy: 1.0676897432230696
        entropy_coeff: 0.0
        kl: 0.008774750913151457
        model: {}
        policy_loss: -0.03206979384928753
        total_loss: 3.5328615436071082
        vf_explained_var: 0.9890159964561462
        vf_loss: 3.563176393508911
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.753968253968257
    gpu_util_percent0: 0.27031746031746035
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.23492063492063
    vram_util_percent0: 0.257051492292555
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20395
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.23065153196529553
    mean_env_wait_ms: 3.279964889597941
    mean_inference_ms: 8.24041924931049
    mean_raw_obs_processing_ms: 0.811349268515555
  time_since_restore: 333.03123712539673
  time_this_iter_s: 55.043500900268555
  time_total_s: 333.03123712539673
  timers:
    learn_throughput: 7839.257
    learn_time_ms: 41277.383
    sample_throughput: 22959.925
    sample_time_ms: 14093.426
    update_time_ms: 33.428
  timestamp: 1602173847
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 6
  trial_id: f6f2a_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f6f2a_00000 | RUNNING  | 172.17.0.4:20395 |      6 |          333.031 | 1941504 |  229.156 |              284.798 |               118.97 |            849.163 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f6f2a_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3225.0
  date: 2020-10-08_16-18-23
  done: false
  episode_len_mean: 845.3136867088608
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 229.6234856476153
  episode_reward_min: 118.96969696969748
  episodes_this_iter: 316
  episodes_total: 2528
  experiment_id: 29d4dc72446446878e479f0a7308541e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999993
        cur_lr: 0.00010000000000000003
        entropy: 1.0405298561989507
        entropy_coeff: 0.0
        kl: 0.008360135398475053
        model: {}
        policy_loss: -0.035940379835665226
        total_loss: 2.64414319810988
        vf_explained_var: 0.9921635389328003
        vf_loss: 2.678411547141739
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.559375000000003
    gpu_util_percent0: 0.26437499999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.196875000000002
    vram_util_percent0: 0.2570514922925549
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20395
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.22986973145320713
    mean_env_wait_ms: 3.2847587996605268
    mean_inference_ms: 8.157414942678885
    mean_raw_obs_processing_ms: 0.8077475761012674
  time_since_restore: 388.48057103157043
  time_this_iter_s: 55.449333906173706
  time_total_s: 388.48057103157043
  timers:
    learn_throughput: 7825.282
    learn_time_ms: 41351.098
    sample_throughput: 23090.142
    sample_time_ms: 14013.946
    update_time_ms: 32.054
  timestamp: 1602173903
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 7
  trial_id: f6f2a_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f6f2a_00000 | RUNNING  | 172.17.0.4:20395 |      7 |          388.481 | 2265088 |  229.623 |              284.798 |               118.97 |            845.314 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f6f2a_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3225.0
  date: 2020-10-08_16-19-18
  done: false
  episode_len_mean: 841.7440225035161
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 229.97069499495652
  episode_reward_min: 118.96969696969748
  episodes_this_iter: 316
  episodes_total: 2844
  experiment_id: 29d4dc72446446878e479f0a7308541e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999993
        cur_lr: 0.00010000000000000003
        entropy: 1.0157186404059204
        entropy_coeff: 0.0
        kl: 0.008110861706582807
        model: {}
        policy_loss: -0.0382360904772259
        total_loss: 2.4541007733043236
        vf_explained_var: 0.9932549595832825
        vf_loss: 2.490714699407167
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.875
    gpu_util_percent0: 0.2946875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.18125
    vram_util_percent0: 0.2570514922925549
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20395
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.22921245145013258
    mean_env_wait_ms: 3.2896696517058057
    mean_inference_ms: 8.086472458730404
    mean_raw_obs_processing_ms: 0.804674397129185
  time_since_restore: 443.4897484779358
  time_this_iter_s: 55.009177446365356
  time_total_s: 443.4897484779358
  timers:
    learn_throughput: 7826.735
    learn_time_ms: 41343.423
    sample_throughput: 23190.705
    sample_time_ms: 13953.177
    update_time_ms: 31.73
  timestamp: 1602173958
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 8
  trial_id: f6f2a_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f6f2a_00000 | RUNNING  | 172.17.0.4:20395 |      8 |           443.49 | 2588672 |  229.971 |              284.798 |               118.97 |            841.744 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f6f2a_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3219.0
  date: 2020-10-08_16-20-13
  done: false
  episode_len_mean: 836.3370621136297
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 230.59824919789588
  episode_reward_min: 118.96969696969748
  episodes_this_iter: 553
  episodes_total: 3397
  experiment_id: 29d4dc72446446878e479f0a7308541e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999993
        cur_lr: 0.00010000000000000003
        entropy: 0.9799617777896833
        entropy_coeff: 0.0
        kl: 0.007874595985712506
        model: {}
        policy_loss: -0.03658816516045717
        total_loss: 3.831922983821434
        vf_explained_var: 0.9939987659454346
        vf_loss: 3.866936240015151
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.088888888888896
    gpu_util_percent0: 0.27095238095238094
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.238095238095234
    vram_util_percent0: 0.257051492292555
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20395
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.22827502991375404
    mean_env_wait_ms: 3.297835033254287
    mean_inference_ms: 7.986212446922276
    mean_raw_obs_processing_ms: 0.8002377240562172
  time_since_restore: 498.70590472221375
  time_this_iter_s: 55.216156244277954
  time_total_s: 498.70590472221375
  timers:
    learn_throughput: 7828.52
    learn_time_ms: 41333.993
    sample_throughput: 23212.785
    sample_time_ms: 13939.904
    update_time_ms: 31.128
  timestamp: 1602174013
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 9
  trial_id: f6f2a_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f6f2a_00000 | RUNNING  | 172.17.0.4:20395 |      9 |          498.706 | 2912256 |  230.598 |              284.798 |               118.97 |            836.337 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f6f2a_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3219.0
  date: 2020-10-08_16-21-08
  done: false
  episode_len_mean: 833.1157700421941
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 230.7907956143715
  episode_reward_min: 118.96969696969748
  episodes_this_iter: 395
  episodes_total: 3792
  experiment_id: 29d4dc72446446878e479f0a7308541e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999993
        cur_lr: 0.00010000000000000003
        entropy: 0.9685566327239894
        entropy_coeff: 0.0
        kl: 0.008005684954880537
        model: {}
        policy_loss: -0.036445736189526096
        total_loss: 2.465822099130365
        vf_explained_var: 0.9947481751441956
        vf_loss: 2.500666708885869
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.971875
    gpu_util_percent0: 0.28890625000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.245312499999999
    vram_util_percent0: 0.2570514922925549
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20395
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.22778221876144206
    mean_env_wait_ms: 3.3036118174343887
    mean_inference_ms: 7.928531166017931
    mean_raw_obs_processing_ms: 0.7979706382327793
  time_since_restore: 553.4599733352661
  time_this_iter_s: 54.75406861305237
  time_total_s: 553.4599733352661
  timers:
    learn_throughput: 7829.844
    learn_time_ms: 41327.004
    sample_throughput: 23312.135
    sample_time_ms: 13880.496
    update_time_ms: 32.757
  timestamp: 1602174068
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 10
  trial_id: f6f2a_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f6f2a_00000 | RUNNING  | 172.17.0.4:20395 |     10 |           553.46 | 3235840 |  230.791 |              284.798 |               118.97 |            833.116 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f6f2a_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3190.0
  date: 2020-10-08_16-22-04
  done: true
  episode_len_mean: 830.7560856864654
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 231.31268625888873
  episode_reward_min: 118.96969696969748
  episodes_this_iter: 316
  episodes_total: 4108
  experiment_id: 29d4dc72446446878e479f0a7308541e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999993
        cur_lr: 0.00010000000000000003
        entropy: 0.9535844808892359
        entropy_coeff: 0.0
        kl: 0.007924806468094452
        model: {}
        policy_loss: -0.040895366887974585
        total_loss: 1.7646686578098731
        vf_explained_var: 0.9962751865386963
        vf_loss: 1.8039790527730049
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.14285714285714
    gpu_util_percent0: 0.28714285714285714
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.203174603174604
    vram_util_percent0: 0.257051492292555
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20395
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.22742158075218566
    mean_env_wait_ms: 3.3079099262870084
    mean_inference_ms: 7.887861356360856
    mean_raw_obs_processing_ms: 0.7962347814236167
  time_since_restore: 608.610111951828
  time_this_iter_s: 55.15013861656189
  time_total_s: 608.610111951828
  timers:
    learn_throughput: 7823.79
    learn_time_ms: 41358.985
    sample_throughput: 23819.733
    sample_time_ms: 13584.703
    update_time_ms: 32.135
  timestamp: 1602174124
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 11
  trial_id: f6f2a_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f6f2a_00000 | TERMINATED |       |     11 |           608.61 | 3559424 |  231.313 |              284.798 |               118.97 |            830.756 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 76.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f6f2a_00000 | TERMINATED |       |     11 |           608.61 | 3559424 |  231.313 |              284.798 |               118.97 |            830.756 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


