2020-10-08 20:11:09,716	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8270[39m[22m
== Status ==
Memory usage on this node: 57.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_68b43_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=41219)[0m 2020-10-08 20:11:12,737	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=41163)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41163)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41179)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41179)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41199)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41199)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41225)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41225)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41171)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41171)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41190)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41190)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41213)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41213)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41227)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41227)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41168)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41168)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41164)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41164)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41200)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41200)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41206)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41206)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41222)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41222)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41229)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41229)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41223)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41223)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41178)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41178)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41169)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41169)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41156)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41156)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41097)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41097)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41127)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41127)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41120)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41120)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41197)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41197)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41180)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41180)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41090)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41090)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41162)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41162)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41185)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41185)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41092)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41092)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41091)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41091)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41177)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41177)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41124)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41124)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41101)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41101)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41108)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41108)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41081)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41081)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41093)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41093)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41096)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41096)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41094)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41094)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41196)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41196)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41107)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41107)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41204)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41204)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41125)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41125)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41084)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41084)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41159)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41159)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41114)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41114)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41173)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41173)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41167)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41167)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41217)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41217)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41119)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41119)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41082)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41082)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41210)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41210)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41104)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41104)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41105)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41105)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41161)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41161)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41193)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41193)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41099)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41099)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41085)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41085)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41239)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41239)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41095)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41095)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41111)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41111)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41176)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41176)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41165)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41165)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41128)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41128)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41208)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41208)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41160)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41160)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41172)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41172)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41121)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41121)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41158)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41158)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41235)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41235)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41182)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41182)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41220)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41220)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41174)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41174)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41188)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41188)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41110)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41110)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41083)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41083)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41192)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41192)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41166)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41166)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41103)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41103)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41170)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41170)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41155)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41155)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41154)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41154)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_68b43_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3279.0
  date: 2020-10-08_20-11-58
  done: false
  episode_len_mean: 877.1708860759494
  episode_reward_max: 273.13131313131294
  episode_reward_mean: 224.28870988364636
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 11bc2816db564f249a17d0abb92c88b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.162318229675293
        entropy_coeff: 0.0
        kl: 0.004731082823127508
        model: {}
        policy_loss: -0.010713341319933534
        total_loss: 8.187121057510376
        vf_explained_var: 0.7552558183670044
        vf_loss: 8.196888065338134
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.541666666666668
    gpu_util_percent0: 0.33
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.00020833333333333335
    ram_util_percent: 9.54375
    vram_util_percent0: 0.2829445446594512
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41219
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17578308432880246
    mean_env_wait_ms: 1.6485609659334506
    mean_inference_ms: 5.7164288332669155
    mean_raw_obs_processing_ms: 0.4812666353306383
  time_since_restore: 40.21009922027588
  time_this_iter_s: 40.21009922027588
  time_total_s: 40.21009922027588
  timers:
    learn_throughput: 5274.222
    learn_time_ms: 30675.995
    sample_throughput: 17113.943
    sample_time_ms: 9453.812
    update_time_ms: 43.88
  timestamp: 1602187918
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 68b43_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 72.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68b43_00000 | RUNNING  | 172.17.0.4:41219 |      1 |          40.2101 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68b43_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3267.0
  date: 2020-10-08_20-12-37
  done: false
  episode_len_mean: 870.1835443037975
  episode_reward_max: 273.13131313131294
  episode_reward_mean: 227.3506584835697
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 11bc2816db564f249a17d0abb92c88b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.1340928554534913
        entropy_coeff: 0.0
        kl: 0.007195395650342107
        model: {}
        policy_loss: -0.013835118897259236
        total_loss: 7.302509212493897
        vf_explained_var: 0.8906704783439636
        vf_loss: 7.315624713897705
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.165217391304346
    gpu_util_percent0: 0.358695652173913
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.765217391304349
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41219
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17070679479896012
    mean_env_wait_ms: 1.6451912005463725
    mean_inference_ms: 5.436916863041444
    mean_raw_obs_processing_ms: 0.4663503016557789
  time_since_restore: 79.13256883621216
  time_this_iter_s: 38.92246961593628
  time_total_s: 79.13256883621216
  timers:
    learn_throughput: 5293.872
    learn_time_ms: 30562.132
    sample_throughput: 18201.021
    sample_time_ms: 8889.172
    update_time_ms: 66.652
  timestamp: 1602187957
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 68b43_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68b43_00000 | RUNNING  | 172.17.0.4:41219 |      2 |          79.1326 | 323584 |  227.351 |              273.131 |              115.788 |            870.184 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68b43_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3244.0
  date: 2020-10-08_20-13-17
  done: false
  episode_len_mean: 862.6118143459915
  episode_reward_max: 276.10101010101005
  episode_reward_mean: 228.53993521715023
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 11bc2816db564f249a17d0abb92c88b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.1205695867538452
        entropy_coeff: 0.0
        kl: 0.008213823288679123
        model: {}
        policy_loss: -0.014858398027718068
        total_loss: 7.968429660797119
        vf_explained_var: 0.9321330785751343
        vf_loss: 7.9824668884277346
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.832608695652176
    gpu_util_percent0: 0.35108695652173916
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.771739130434783
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41219
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16757981499535374
    mean_env_wait_ms: 1.645241770747459
    mean_inference_ms: 5.285610339929257
    mean_raw_obs_processing_ms: 0.4560499444489762
  time_since_restore: 118.2429370880127
  time_this_iter_s: 39.11036825180054
  time_total_s: 118.2429370880127
  timers:
    learn_throughput: 5298.017
    learn_time_ms: 30538.216
    sample_throughput: 18484.397
    sample_time_ms: 8752.896
    update_time_ms: 52.539
  timestamp: 1602187997
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 68b43_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68b43_00000 | RUNNING  | 172.17.0.4:41219 |      3 |          118.243 | 485376 |   228.54 |              276.101 |              115.788 |            862.612 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68b43_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3200.0
  date: 2020-10-08_20-13-55
  done: false
  episode_len_mean: 856.1724683544304
  episode_reward_max: 280.2626262626263
  episode_reward_mean: 229.03303605677004
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 11bc2816db564f249a17d0abb92c88b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0832990646362304
        entropy_coeff: 0.0
        kl: 0.00898239379748702
        model: {}
        policy_loss: -0.015685980790294707
        total_loss: 7.713797998428345
        vf_explained_var: 0.9562352299690247
        vf_loss: 7.7285857677459715
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.62666666666667
    gpu_util_percent0: 0.3642222222222222
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.773333333333335
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41219
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16549859643448883
    mean_env_wait_ms: 1.6477266457082052
    mean_inference_ms: 5.177128099258211
    mean_raw_obs_processing_ms: 0.44900660463611886
  time_since_restore: 156.84764790534973
  time_this_iter_s: 38.604710817337036
  time_total_s: 156.84764790534973
  timers:
    learn_throughput: 5296.079
    learn_time_ms: 30549.396
    sample_throughput: 18935.745
    sample_time_ms: 8544.264
    update_time_ms: 49.115
  timestamp: 1602188035
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 68b43_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68b43_00000 | RUNNING  | 172.17.0.4:41219 |      4 |          156.848 | 647168 |  229.033 |              280.263 |              115.788 |            856.172 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68b43_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3200.0
  date: 2020-10-08_20-14-34
  done: false
  episode_len_mean: 843.2766631467794
  episode_reward_max: 280.2626262626263
  episode_reward_mean: 229.6797222488879
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 315
  episodes_total: 947
  experiment_id: 11bc2816db564f249a17d0abb92c88b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0548597812652587
        entropy_coeff: 0.0
        kl: 0.00882936203852296
        model: {}
        policy_loss: -0.01529089007526636
        total_loss: 10.99287977218628
        vf_explained_var: 0.9722448587417603
        vf_loss: 11.007288074493408
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.964444444444446
    gpu_util_percent0: 0.35244444444444445
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.766666666666667
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41219
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16298607403783083
    mean_env_wait_ms: 1.6561573915754162
    mean_inference_ms: 5.0416580136236675
    mean_raw_obs_processing_ms: 0.4408854660816189
  time_since_restore: 195.57763624191284
  time_this_iter_s: 38.72998833656311
  time_total_s: 195.57763624191284
  timers:
    learn_throughput: 5292.329
    learn_time_ms: 30571.039
    sample_throughput: 19190.453
    sample_time_ms: 8430.859
    update_time_ms: 47.956
  timestamp: 1602188074
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 68b43_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68b43_00000 | RUNNING  | 172.17.0.4:41219 |      5 |          195.578 | 808960 |   229.68 |              280.263 |              115.788 |            843.277 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68b43_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3200.0
  date: 2020-10-08_20-15-13
  done: false
  episode_len_mean: 837.1690777576854
  episode_reward_max: 280.2626262626263
  episode_reward_mean: 230.20979231738713
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 159
  episodes_total: 1106
  experiment_id: 11bc2816db564f249a17d0abb92c88b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.036234736442566
        entropy_coeff: 0.0
        kl: 0.0067431801464408634
        model: {}
        policy_loss: -0.015551020298153162
        total_loss: 5.48110990524292
        vf_explained_var: 0.9815567135810852
        vf_loss: 5.495986652374268
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.582608695652176
    gpu_util_percent0: 0.3339130434782609
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.77826086956522
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41219
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1621094415035839
    mean_env_wait_ms: 1.6600134971688945
    mean_inference_ms: 4.994171405696587
    mean_raw_obs_processing_ms: 0.4381870011322221
  time_since_restore: 234.5546534061432
  time_this_iter_s: 38.97701716423035
  time_total_s: 234.5546534061432
  timers:
    learn_throughput: 5289.38
    learn_time_ms: 30588.083
    sample_throughput: 19272.927
    sample_time_ms: 8394.781
    update_time_ms: 46.125
  timestamp: 1602188113
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 68b43_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68b43_00000 | RUNNING  | 172.17.0.4:41219 |      6 |          234.555 | 970752 |   230.21 |              280.263 |              115.788 |            837.169 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68b43_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3200.0
  date: 2020-10-08_20-15-52
  done: false
  episode_len_mean: 832.1487341772151
  episode_reward_max: 280.2626262626263
  episode_reward_mean: 230.6685366321441
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 11bc2816db564f249a17d0abb92c88b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0126346468925476
        entropy_coeff: 0.0
        kl: 0.006759198429062962
        model: {}
        policy_loss: -0.015973649104125798
        total_loss: 4.599111318588257
        vf_explained_var: 0.9868476986885071
        vf_loss: 4.614409017562866
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.23913043478261
    gpu_util_percent0: 0.41282608695652173
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.776086956521741
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41219
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16138588930524037
    mean_env_wait_ms: 1.6636582986993105
    mean_inference_ms: 4.95389535955674
    mean_raw_obs_processing_ms: 0.4358578027808479
  time_since_restore: 273.25363397598267
  time_this_iter_s: 38.69898056983948
  time_total_s: 273.25363397598267
  timers:
    learn_throughput: 5293.226
    learn_time_ms: 30565.859
    sample_throughput: 19367.331
    sample_time_ms: 8353.861
    update_time_ms: 52.667
  timestamp: 1602188152
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 68b43_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68b43_00000 | RUNNING  | 172.17.0.4:41219 |      7 |          273.254 | 1132544 |  230.669 |              280.263 |              115.788 |            832.149 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68b43_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3200.0
  date: 2020-10-08_20-16-31
  done: false
  episode_len_mean: 828.4378074490513
  episode_reward_max: 280.2626262626263
  episode_reward_mean: 231.20232543282427
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 159
  episodes_total: 1423
  experiment_id: 11bc2816db564f249a17d0abb92c88b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9667941927909851
        entropy_coeff: 0.0
        kl: 0.005753325996920466
        model: {}
        policy_loss: -0.01585369314998388
        total_loss: 4.924538946151733
        vf_explained_var: 0.989865779876709
        vf_loss: 4.939817428588867
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.257777777777783
    gpu_util_percent0: 0.2906666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.784444444444444
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41219
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16078003174567101
    mean_env_wait_ms: 1.6671877586630208
    mean_inference_ms: 4.9191326072809005
    mean_raw_obs_processing_ms: 0.4338033546323904
  time_since_restore: 311.9060056209564
  time_this_iter_s: 38.652371644973755
  time_total_s: 311.9060056209564
  timers:
    learn_throughput: 5291.468
    learn_time_ms: 30576.016
    sample_throughput: 19500.707
    sample_time_ms: 8296.725
    update_time_ms: 51.26
  timestamp: 1602188191
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 68b43_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68b43_00000 | RUNNING  | 172.17.0.4:41219 |      8 |          311.906 | 1294336 |  231.202 |              280.263 |              115.788 |            828.438 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68b43_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3200.0
  date: 2020-10-08_20-17-10
  done: false
  episode_len_mean: 822.7031070195627
  episode_reward_max: 280.2626262626263
  episode_reward_mean: 232.2742499796584
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 315
  episodes_total: 1738
  experiment_id: 11bc2816db564f249a17d0abb92c88b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9496608018875122
        entropy_coeff: 0.0
        kl: 0.005855906242504716
        model: {}
        policy_loss: -0.013903905916959048
        total_loss: 5.467583179473877
        vf_explained_var: 0.9907912015914917
        vf_loss: 5.480901384353638
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.3195652173913
    gpu_util_percent0: 0.3634782608695652
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.773913043478263
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41219
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15983264999572644
    mean_env_wait_ms: 1.673440668971992
    mean_inference_ms: 4.865115112193397
    mean_raw_obs_processing_ms: 0.43081636610901125
  time_since_restore: 350.8394441604614
  time_this_iter_s: 38.933438539505005
  time_total_s: 350.8394441604614
  timers:
    learn_throughput: 5289.201
    learn_time_ms: 30589.119
    sample_throughput: 19546.028
    sample_time_ms: 8277.487
    update_time_ms: 50.435
  timestamp: 1602188230
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 68b43_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68b43_00000 | RUNNING  | 172.17.0.4:41219 |      9 |          350.839 | 1456128 |  232.274 |              280.263 |              115.788 |            822.703 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68b43_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3200.0
  date: 2020-10-08_20-17-49
  done: false
  episode_len_mean: 820.4762658227849
  episode_reward_max: 280.2626262626263
  episode_reward_mean: 232.71721433746742
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1896
  experiment_id: 11bc2816db564f249a17d0abb92c88b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9213549196720123
        entropy_coeff: 0.0
        kl: 0.0055309166200459
        model: {}
        policy_loss: -0.014019256143365055
        total_loss: 3.8987928867340087
        vf_explained_var: 0.9916488528251648
        vf_loss: 3.912259006500244
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.439130434782605
    gpu_util_percent0: 0.3521739130434782
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.77826086956522
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41219
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15943687102190035
    mean_env_wait_ms: 1.6760701518048353
    mean_inference_ms: 4.843208301617476
    mean_raw_obs_processing_ms: 0.4296037971588526
  time_since_restore: 389.79420709609985
  time_this_iter_s: 38.95476293563843
  time_total_s: 389.79420709609985
  timers:
    learn_throughput: 5289.696
    learn_time_ms: 30586.257
    sample_throughput: 19555.538
    sample_time_ms: 8273.462
    update_time_ms: 54.706
  timestamp: 1602188269
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 68b43_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68b43_00000 | RUNNING  | 172.17.0.4:41219 |     10 |          389.794 | 1617920 |  232.717 |              280.263 |              115.788 |            820.476 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68b43_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3200.0
  date: 2020-10-08_20-18-28
  done: false
  episode_len_mean: 818.8266796494645
  episode_reward_max: 280.2626262626263
  episode_reward_mean: 232.81009215819338
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 11bc2816db564f249a17d0abb92c88b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9045248448848724
        entropy_coeff: 0.0
        kl: 0.0051944993901997805
        model: {}
        policy_loss: -0.014451906457543373
        total_loss: 3.6093626260757445
        vf_explained_var: 0.9925416111946106
        vf_loss: 3.6232951164245604
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.773333333333333
    gpu_util_percent0: 0.31377777777777777
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.784444444444446
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41219
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15909176801888222
    mean_env_wait_ms: 1.6784788947973328
    mean_inference_ms: 4.823482280462787
    mean_raw_obs_processing_ms: 0.42848707082399645
  time_since_restore: 428.59845757484436
  time_this_iter_s: 38.80425047874451
  time_total_s: 428.59845757484436
  timers:
    learn_throughput: 5291.515
    learn_time_ms: 30575.743
    sample_throughput: 19871.987
    sample_time_ms: 8141.712
    update_time_ms: 54.53
  timestamp: 1602188308
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 68b43_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68b43_00000 | RUNNING  | 172.17.0.4:41219 |     11 |          428.598 | 1779712 |   232.81 |              280.263 |              115.788 |            818.827 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68b43_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3200.0
  date: 2020-10-08_20-19-07
  done: false
  episode_len_mean: 816.5308117297068
  episode_reward_max: 280.2626262626263
  episode_reward_mean: 233.44554340686932
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 299
  episodes_total: 2353
  experiment_id: 11bc2816db564f249a17d0abb92c88b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8660034239292145
        entropy_coeff: 0.0
        kl: 0.004795211041346193
        model: {}
        policy_loss: -0.012316765962168574
        total_loss: 4.8031073093414305
        vf_explained_var: 0.993579089641571
        vf_loss: 4.814944505691528
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.726086956521737
    gpu_util_percent0: 0.29891304347826086
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.771739130434783
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41219
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15853722867258221
    mean_env_wait_ms: 1.6824231116324035
    mean_inference_ms: 4.791843243262035
    mean_raw_obs_processing_ms: 0.42668285480281964
  time_since_restore: 467.65169382095337
  time_this_iter_s: 39.05323624610901
  time_total_s: 467.65169382095337
  timers:
    learn_throughput: 5288.639
    learn_time_ms: 30592.37
    sample_throughput: 19876.68
    sample_time_ms: 8139.79
    update_time_ms: 49.664
  timestamp: 1602188347
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 68b43_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68b43_00000 | RUNNING  | 172.17.0.4:41219 |     12 |          467.652 | 1941504 |  233.446 |              280.263 |              115.788 |            816.531 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68b43_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3200.0
  date: 2020-10-08_20-19-46
  done: false
  episode_len_mean: 815.4810126582279
  episode_reward_max: 280.2626262626263
  episode_reward_mean: 234.01812827643522
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 175
  episodes_total: 2528
  experiment_id: 11bc2816db564f249a17d0abb92c88b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 5.0e-05
        entropy: 0.833269065618515
        entropy_coeff: 0.0
        kl: 0.005938654113560915
        model: {}
        policy_loss: -0.014144810545258225
        total_loss: 2.786199927330017
        vf_explained_var: 0.9945484399795532
        vf_loss: 2.800047779083252
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.26521739130435
    gpu_util_percent0: 0.30630434782608695
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.786956521739132
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41219
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15825644273290007
    mean_env_wait_ms: 1.6844431966872275
    mean_inference_ms: 4.775937939005843
    mean_raw_obs_processing_ms: 0.425783525672554
  time_since_restore: 506.4974400997162
  time_this_iter_s: 38.84574627876282
  time_total_s: 506.4974400997162
  timers:
    learn_throughput: 5287.791
    learn_time_ms: 30597.277
    sample_throughput: 19946.377
    sample_time_ms: 8111.348
    update_time_ms: 51.081
  timestamp: 1602188386
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 68b43_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68b43_00000 | RUNNING  | 172.17.0.4:41219 |     13 |          506.497 | 2103296 |  234.018 |              280.263 |              115.788 |            815.481 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68b43_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3200.0
  date: 2020-10-08_20-20-25
  done: false
  episode_len_mean: 814.5614296351451
  episode_reward_max: 290.747474747475
  episode_reward_mean: 234.54156230961888
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2686
  experiment_id: 11bc2816db564f249a17d0abb92c88b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 5.0e-05
        entropy: 0.8292674541473388
        entropy_coeff: 0.0
        kl: 0.005054647708311677
        model: {}
        policy_loss: -0.013824614835903049
        total_loss: 2.7466143369674683
        vf_explained_var: 0.9943804740905762
        vf_loss: 2.7601861715316773
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.323913043478257
    gpu_util_percent0: 0.3393478260869565
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.780434782608697
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41219
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15802461493292058
    mean_env_wait_ms: 1.6860549810222116
    mean_inference_ms: 4.762787065263051
    mean_raw_obs_processing_ms: 0.42503456571002435
  time_since_restore: 545.3493638038635
  time_this_iter_s: 38.85192370414734
  time_total_s: 545.3493638038635
  timers:
    learn_throughput: 5287.961
    learn_time_ms: 30596.292
    sample_throughput: 19898.272
    sample_time_ms: 8130.957
    update_time_ms: 50.966
  timestamp: 1602188425
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 68b43_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68b43_00000 | RUNNING  | 172.17.0.4:41219 |     14 |          545.349 | 2265088 |  234.542 |              290.747 |              115.788 |            814.561 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68b43_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3145.0
  date: 2020-10-08_20-21-04
  done: false
  episode_len_mean: 813.7223198594024
  episode_reward_max: 290.747474747475
  episode_reward_mean: 235.0214837300953
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 159
  episodes_total: 2845
  experiment_id: 11bc2816db564f249a17d0abb92c88b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 5.0e-05
        entropy: 0.8051592528820037
        entropy_coeff: 0.0
        kl: 0.005207990668714047
        model: {}
        policy_loss: -0.014131434354931116
        total_loss: 2.620920443534851
        vf_explained_var: 0.9952912330627441
        vf_loss: 2.6347915172576903
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.79555555555556
    gpu_util_percent0: 0.35044444444444445
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.782222222222224
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41219
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15781825556804308
    mean_env_wait_ms: 1.6876288592200313
    mean_inference_ms: 4.750619125220124
    mean_raw_obs_processing_ms: 0.4243305877714689
  time_since_restore: 584.0842595100403
  time_this_iter_s: 38.73489570617676
  time_total_s: 584.0842595100403
  timers:
    learn_throughput: 5288.428
    learn_time_ms: 30593.592
    sample_throughput: 19891.04
    sample_time_ms: 8133.913
    update_time_ms: 48.911
  timestamp: 1602188464
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 68b43_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68b43_00000 | RUNNING  | 172.17.0.4:41219 |     15 |          584.084 | 2426880 |  235.021 |              290.747 |              115.788 |            813.722 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68b43_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3145.0
  date: 2020-10-08_20-21-43
  done: true
  episode_len_mean: 812.5120253164557
  episode_reward_max: 290.747474747475
  episode_reward_mean: 236.05007032348806
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 315
  episodes_total: 3160
  experiment_id: 11bc2816db564f249a17d0abb92c88b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 5.0e-05
        entropy: 0.7667382717132568
        entropy_coeff: 0.0
        kl: 0.004800642700865864
        model: {}
        policy_loss: -0.011965872603468597
        total_loss: 3.2429625034332275
        vf_explained_var: 0.9950441122055054
        vf_loss: 3.254688286781311
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.617391304347827
    gpu_util_percent0: 0.3532608695652173
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.773913043478261
    vram_util_percent0: 0.2967366349622827
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41219
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15744464877849607
    mean_env_wait_ms: 1.690319434062582
    mean_inference_ms: 4.729209353717556
    mean_raw_obs_processing_ms: 0.42309434450059685
  time_since_restore: 623.0836753845215
  time_this_iter_s: 38.9994158744812
  time_total_s: 623.0836753845215
  timers:
    learn_throughput: 5289.305
    learn_time_ms: 30588.519
    sample_throughput: 19876.766
    sample_time_ms: 8139.755
    update_time_ms: 48.915
  timestamp: 1602188503
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 68b43_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68b43_00000 | TERMINATED |       |     16 |          623.084 | 2588672 |   236.05 |              290.747 |              115.788 |            812.512 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68b43_00000 | TERMINATED |       |     16 |          623.084 | 2588672 |   236.05 |              290.747 |              115.788 |            812.512 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


