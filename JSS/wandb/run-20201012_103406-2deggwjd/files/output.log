2020-10-12 10:34:10,061	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_7762f_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=732)[0m 2020-10-12 10:34:12,767	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=699)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=699)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=716)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=716)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=722)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=722)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=680)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=680)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=695)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=695)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=730)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=730)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=687)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=687)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=708)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=708)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=679)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=679)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=729)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=729)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=691)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=691)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=744)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=744)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=727)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=727)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=705)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=705)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=668)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=668)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=735)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=735)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=714)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=714)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=613)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=613)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=604)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=604)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=696)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=696)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=720)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=720)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=671)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=671)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=689)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=689)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=623)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=623)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=620)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=620)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=673)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=673)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=605)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=605)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=737)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=737)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=698)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=698)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=663)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=663)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=694)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=694)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=660)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=660)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=640)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=640)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=603)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=603)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=607)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=607)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=686)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=686)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=609)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=609)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=739)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=739)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=614)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=614)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=612)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=612)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=674)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=674)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=618)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=618)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=681)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=681)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=635)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=635)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=619)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=619)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=611)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=611)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=606)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=606)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=683)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=683)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=616)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=616)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=624)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=624)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=643)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=643)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=667)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=667)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=704)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=704)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=676)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=676)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=662)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=662)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=631)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=631)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=626)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=626)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=685)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=685)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=666)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=666)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=642)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=642)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=711)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=711)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=625)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=625)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=693)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=693)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=675)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=675)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=633)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=633)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=709)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=709)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=628)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=628)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=608)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=608)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=617)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=617)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=636)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=636)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=706)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=706)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=713)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=713)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=670)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=670)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=684)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=684)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=682)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=682)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=690)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=690)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=639)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=639)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=712)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=712)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=622)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=622)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_7762f_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_10-34-46
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 63ae217839db4112bfec6bdab0a75ac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1850829323132832
        entropy_coeff: 0.0001
        kl: 0.004093626630492508
        model: {}
        policy_loss: -0.007868677183675269
        total_loss: 507.0761362711589
        vf_explained_var: 0.540532648563385
        vf_loss: 507.0832926432292
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.13030303030303
    gpu_util_percent0: 0.34545454545454546
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.566666666666667
    vram_util_percent0: 0.08750757824224535
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 732
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16933092256871662
    mean_env_wait_ms: 1.1741114030763227
    mean_inference_ms: 5.667092522635582
    mean_raw_obs_processing_ms: 0.4496598044969888
  time_since_restore: 28.243332386016846
  time_this_iter_s: 28.243332386016846
  time_total_s: 28.243332386016846
  timers:
    learn_throughput: 8451.021
    learn_time_ms: 19144.668
    sample_throughput: 17931.057
    sample_time_ms: 9023.004
    update_time_ms: 32.461
  timestamp: 1602498886
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 7762f_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |      1 |          28.2433 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7762f_00000:
  custom_metrics:
    time_step_max: 4139
    time_step_mean: 3608.8055555555557
    time_step_min: 3250
  date: 2020-10-12_10-35-13
  done: false
  episode_len_mean: 890.7056962025316
  episode_reward_max: 273.5959595959592
  episode_reward_mean: 217.07793121084234
  episode_reward_min: 138.89898989898958
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 63ae217839db4112bfec6bdab0a75ac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1567376752694447
        entropy_coeff: 0.0001
        kl: 0.0070590757532045245
        model: {}
        policy_loss: -0.010883362002156597
        total_loss: 129.9215234120687
        vf_explained_var: 0.8072310090065002
        vf_loss: 129.93181800842285
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.084374999999998
    gpu_util_percent0: 0.3503125
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7593750000000004
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 732
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1649267986261869
    mean_env_wait_ms: 1.1701357295854296
    mean_inference_ms: 5.452435751356474
    mean_raw_obs_processing_ms: 0.4394414823862937
  time_since_restore: 55.3238570690155
  time_this_iter_s: 27.080524682998657
  time_total_s: 55.3238570690155
  timers:
    learn_throughput: 8423.471
    learn_time_ms: 19207.283
    sample_throughput: 19301.756
    sample_time_ms: 8382.242
    update_time_ms: 25.876
  timestamp: 1602498913
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 7762f_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |      2 |          55.3239 | 323584 |  217.078 |              273.596 |              138.899 |            890.706 |
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7762f_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3602.798206278027
    time_step_min: 3250
  date: 2020-10-12_10-35-39
  done: false
  episode_len_mean: 886.1392405063291
  episode_reward_max: 273.5959595959592
  episode_reward_mean: 218.34343434343413
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 63ae217839db4112bfec6bdab0a75ac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.143834412097931
        entropy_coeff: 0.0001
        kl: 0.00900065409950912
        model: {}
        policy_loss: -0.012952111646882258
        total_loss: 62.266885121663414
        vf_explained_var: 0.8935738205909729
        vf_loss: 62.279051780700684
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.68064516129032
    gpu_util_percent0: 0.30032258064516126
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7741935483870965
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 732
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16206126907167195
    mean_env_wait_ms: 1.1694681355227807
    mean_inference_ms: 5.281464279659669
    mean_raw_obs_processing_ms: 0.43116658445242273
  time_since_restore: 81.6922254562378
  time_this_iter_s: 26.36836838722229
  time_total_s: 81.6922254562378
  timers:
    learn_throughput: 8411.993
    learn_time_ms: 19233.491
    sample_throughput: 20490.931
    sample_time_ms: 7895.786
    update_time_ms: 31.698
  timestamp: 1602498939
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 7762f_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |      3 |          81.6922 | 485376 |  218.343 |              273.596 |               137.99 |            886.139 |
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7762f_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3596.7533112582782
    time_step_min: 3250
  date: 2020-10-12_10-36-06
  done: false
  episode_len_mean: 882.5870253164557
  episode_reward_max: 273.5959595959592
  episode_reward_mean: 219.16725802327048
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 63ae217839db4112bfec6bdab0a75ac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1256821552912395
        entropy_coeff: 0.0001
        kl: 0.00838832138106227
        model: {}
        policy_loss: -0.013208418832315752
        total_loss: 44.44708792368571
        vf_explained_var: 0.9239999651908875
        vf_loss: 44.45957056681315
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.003225806451614
    gpu_util_percent0: 0.3496774193548387
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 732
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16006576052477228
    mean_env_wait_ms: 1.1692682755662736
    mean_inference_ms: 5.156015909406596
    mean_raw_obs_processing_ms: 0.42467633120668596
  time_since_restore: 108.28819131851196
  time_this_iter_s: 26.59596586227417
  time_total_s: 108.28819131851196
  timers:
    learn_throughput: 8384.595
    learn_time_ms: 19296.341
    sample_throughput: 21117.84
    sample_time_ms: 7661.39
    update_time_ms: 31.674
  timestamp: 1602498966
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 7762f_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |      4 |          108.288 | 647168 |  219.167 |              273.596 |               137.99 |            882.587 |
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7762f_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3591.5629921259842
    time_step_min: 3242
  date: 2020-10-12_10-36-32
  done: false
  episode_len_mean: 878.2569620253165
  episode_reward_max: 274.8080808080809
  episode_reward_mean: 220.1586753612068
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 63ae217839db4112bfec6bdab0a75ac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0966354012489319
        entropy_coeff: 0.0001
        kl: 0.008652650052681565
        model: {}
        policy_loss: -0.013121832271281164
        total_loss: 35.068282763163246
        vf_explained_var: 0.9439868927001953
        vf_loss: 35.080649058024086
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.403333333333332
    gpu_util_percent0: 0.2933333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769999999999999
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 732
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1586091055156298
    mean_env_wait_ms: 1.1701168023423736
    mean_inference_ms: 5.060829505330093
    mean_raw_obs_processing_ms: 0.41969310004805094
  time_since_restore: 134.52119374275208
  time_this_iter_s: 26.233002424240112
  time_total_s: 134.52119374275208
  timers:
    learn_throughput: 8384.916
    learn_time_ms: 19295.602
    sample_throughput: 21571.257
    sample_time_ms: 7500.351
    update_time_ms: 33.014
  timestamp: 1602498992
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 7762f_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |      5 |          134.521 | 808960 |  220.159 |              274.808 |               137.99 |            878.257 |
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7762f_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3575.0697674418607
    time_step_min: 3187
  date: 2020-10-12_10-36-59
  done: false
  episode_len_mean: 868.2937443336356
  episode_reward_max: 283.14141414141375
  episode_reward_mean: 223.16600272901252
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 313
  episodes_total: 1103
  experiment_id: 63ae217839db4112bfec6bdab0a75ac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0826950172583263
        entropy_coeff: 0.0001
        kl: 0.008017374784685671
        model: {}
        policy_loss: -0.009852176726174852
        total_loss: 37.77317714691162
        vf_explained_var: 0.9565708637237549
        vf_loss: 37.78233687082926
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.190322580645162
    gpu_util_percent0: 0.23612903225806453
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.764516129032258
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 732
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15664185353614687
    mean_env_wait_ms: 1.1733919147808136
    mean_inference_ms: 4.933464734194755
    mean_raw_obs_processing_ms: 0.41334844709820934
  time_since_restore: 161.07573556900024
  time_this_iter_s: 26.55454182624817
  time_total_s: 161.07573556900024
  timers:
    learn_throughput: 8371.537
    learn_time_ms: 19326.439
    sample_throughput: 21813.622
    sample_time_ms: 7417.017
    update_time_ms: 30.93
  timestamp: 1602499019
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 7762f_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |      6 |          161.076 | 970752 |  223.166 |              283.141 |               137.99 |            868.294 |
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7762f_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3561.846278317152
    time_step_min: 3187
  date: 2020-10-12_10-37-26
  done: false
  episode_len_mean: 862.3742088607595
  episode_reward_max: 283.14141414141375
  episode_reward_mean: 225.2731747858328
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 161
  episodes_total: 1264
  experiment_id: 63ae217839db4112bfec6bdab0a75ac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0706466734409332
        entropy_coeff: 0.0001
        kl: 0.007869300238477686
        model: {}
        policy_loss: -0.013351764432930699
        total_loss: 18.482054869333904
        vf_explained_var: 0.9659532904624939
        vf_loss: 18.49472649892171
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.938709677419357
    gpu_util_percent0: 0.3
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7838709677419353
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 732
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15591166101973544
    mean_env_wait_ms: 1.1749379809941753
    mean_inference_ms: 4.886064883205583
    mean_raw_obs_processing_ms: 0.41093302096182477
  time_since_restore: 187.52741384506226
  time_this_iter_s: 26.45167827606201
  time_total_s: 187.52741384506226
  timers:
    learn_throughput: 8363.488
    learn_time_ms: 19345.04
    sample_throughput: 22033.156
    sample_time_ms: 7343.115
    update_time_ms: 33.276
  timestamp: 1602499046
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 7762f_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |      7 |          187.527 | 1132544 |  225.273 |              283.141 |               137.99 |            862.374 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7762f_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3551.647776183644
    time_step_min: 3187
  date: 2020-10-12_10-37-52
  done: false
  episode_len_mean: 858.2130801687764
  episode_reward_max: 286.9292929292936
  episode_reward_mean: 227.1781954566763
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 63ae217839db4112bfec6bdab0a75ac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0530053079128265
        entropy_coeff: 0.0001
        kl: 0.007424288894981146
        model: {}
        policy_loss: -0.014031020080437884
        total_loss: 18.28844420115153
        vf_explained_var: 0.9650914669036865
        vf_loss: 18.30183744430542
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.380645161290314
    gpu_util_percent0: 0.22225806451612906
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903227
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 732
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15530326568095648
    mean_env_wait_ms: 1.1764298007735843
    mean_inference_ms: 4.846314058519118
    mean_raw_obs_processing_ms: 0.40887256534763894
  time_since_restore: 214.2479329109192
  time_this_iter_s: 26.720519065856934
  time_total_s: 214.2479329109192
  timers:
    learn_throughput: 8345.973
    learn_time_ms: 19385.636
    sample_throughput: 22180.4
    sample_time_ms: 7294.368
    update_time_ms: 34.431
  timestamp: 1602499072
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 7762f_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |      8 |          214.248 | 1294336 |  227.178 |              286.929 |               137.99 |            858.213 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7762f_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3540.2345360824743
    time_step_min: 3187
  date: 2020-10-12_10-38-19
  done: false
  episode_len_mean: 854.4341772151898
  episode_reward_max: 286.9292929292936
  episode_reward_mean: 228.90886715253788
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 63ae217839db4112bfec6bdab0a75ac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0118485788504283
        entropy_coeff: 0.0001
        kl: 0.007579043585186203
        model: {}
        policy_loss: -0.010258643926742176
        total_loss: 15.40296204884847
        vf_explained_var: 0.9705337882041931
        vf_loss: 15.412563880284628
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.158064516129027
    gpu_util_percent0: 0.38258064516129037
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7741935483870965
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 732
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15476785735377394
    mean_env_wait_ms: 1.1778500832508265
    mean_inference_ms: 4.811731373476194
    mean_raw_obs_processing_ms: 0.40699710981876513
  time_since_restore: 240.72339725494385
  time_this_iter_s: 26.475464344024658
  time_total_s: 240.72339725494385
  timers:
    learn_throughput: 8342.974
    learn_time_ms: 19392.605
    sample_throughput: 22304.999
    sample_time_ms: 7253.621
    update_time_ms: 34.828
  timestamp: 1602499099
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 7762f_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |      9 |          240.723 | 1456128 |  228.909 |              286.929 |               137.99 |            854.434 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7762f_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3518.7373791621912
    time_step_min: 3186
  date: 2020-10-12_10-38-45
  done: false
  episode_len_mean: 847.1243386243386
  episode_reward_max: 286.9292929292936
  episode_reward_mean: 232.65247715247702
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 310
  episodes_total: 1890
  experiment_id: 63ae217839db4112bfec6bdab0a75ac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9885825465122858
        entropy_coeff: 0.0001
        kl: 0.00694818701595068
        model: {}
        policy_loss: -0.011202118165480593
        total_loss: 19.333553791046143
        vf_explained_var: 0.9741263389587402
        vf_loss: 19.344160079956055
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.709677419354836
    gpu_util_percent0: 0.27290322580645165
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 732
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15392287472502042
    mean_env_wait_ms: 1.1807863849799112
    mean_inference_ms: 4.7571964111281115
    mean_raw_obs_processing_ms: 0.4041469352140854
  time_since_restore: 267.1956088542938
  time_this_iter_s: 26.472211599349976
  time_total_s: 267.1956088542938
  timers:
    learn_throughput: 8346.803
    learn_time_ms: 19383.71
    sample_throughput: 22356.441
    sample_time_ms: 7236.93
    update_time_ms: 33.941
  timestamp: 1602499125
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 7762f_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     10 |          267.196 | 1617920 |  232.652 |              286.929 |               137.99 |            847.124 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7762f_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3508.0286278381045
    time_step_min: 3186
  date: 2020-10-12_10-39-12
  done: false
  episode_len_mean: 843.8758519961052
  episode_reward_max: 286.9292929292936
  episode_reward_mean: 234.34446214825948
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 164
  episodes_total: 2054
  experiment_id: 63ae217839db4112bfec6bdab0a75ac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9782296568155289
        entropy_coeff: 0.0001
        kl: 0.0074202436953783035
        model: {}
        policy_loss: -0.011524421182305863
        total_loss: 11.349893887837728
        vf_explained_var: 0.9778836369514465
        vf_loss: 11.360774596532186
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.56129032258064
    gpu_util_percent0: 0.3477419354838709
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.783870967741935
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 732
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15355425518756677
    mean_env_wait_ms: 1.1820984902846068
    mean_inference_ms: 4.73331126022154
    mean_raw_obs_processing_ms: 0.4029051173011415
  time_since_restore: 293.6323890686035
  time_this_iter_s: 26.436780214309692
  time_total_s: 293.6323890686035
  timers:
    learn_throughput: 8335.377
    learn_time_ms: 19410.281
    sample_throughput: 23016.163
    sample_time_ms: 7029.495
    update_time_ms: 32.961
  timestamp: 1602499152
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 7762f_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     11 |          293.632 | 1779712 |  234.344 |              286.929 |               137.99 |            843.876 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7762f_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3497.526098901099
    time_step_min: 3186
  date: 2020-10-12_10-39-39
  done: false
  episode_len_mean: 840.8141952983725
  episode_reward_max: 289.5050505050505
  episode_reward_mean: 236.0104069629385
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 63ae217839db4112bfec6bdab0a75ac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9659954756498337
        entropy_coeff: 0.0001
        kl: 0.00687529263086617
        model: {}
        policy_loss: -0.011743300943635404
        total_loss: 12.973399877548218
        vf_explained_var: 0.9719108939170837
        vf_loss: 12.984552383422852
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.412903225806446
    gpu_util_percent0: 0.3206451612903226
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7838709677419353
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 732
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15323285279483564
    mean_env_wait_ms: 1.1832804784605555
    mean_inference_ms: 4.712784382778184
    mean_raw_obs_processing_ms: 0.4018179425599785
  time_since_restore: 320.4737470149994
  time_this_iter_s: 26.841357946395874
  time_total_s: 320.4737470149994
  timers:
    learn_throughput: 8319.589
    learn_time_ms: 19447.113
    sample_throughput: 23226.654
    sample_time_ms: 6965.79
    update_time_ms: 33.642
  timestamp: 1602499179
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 7762f_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     12 |          320.474 | 1941504 |   236.01 |              289.505 |               137.99 |            840.814 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7762f_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3487.3178360101438
    time_step_min: 3170
  date: 2020-10-12_10-40-06
  done: false
  episode_len_mean: 837.5388471177945
  episode_reward_max: 289.5050505050505
  episode_reward_mean: 237.452001215159
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 182
  episodes_total: 2394
  experiment_id: 63ae217839db4112bfec6bdab0a75ac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9220593820015589
        entropy_coeff: 0.0001
        kl: 0.007104225301494201
        model: {}
        policy_loss: -0.013087665856194993
        total_loss: 14.173670689264933
        vf_explained_var: 0.976102352142334
        vf_loss: 14.186140378316244
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.419354838709673
    gpu_util_percent0: 0.2954838709677419
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7774193548387096
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 732
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15289814529481696
    mean_env_wait_ms: 1.1846964701491667
    mean_inference_ms: 4.691346183301928
    mean_raw_obs_processing_ms: 0.40064349388162007
  time_since_restore: 347.0233097076416
  time_this_iter_s: 26.549562692642212
  time_total_s: 347.0233097076416
  timers:
    learn_throughput: 8314.854
    learn_time_ms: 19458.189
    sample_throughput: 23179.376
    sample_time_ms: 6979.998
    update_time_ms: 31.984
  timestamp: 1602499206
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 7762f_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     13 |          347.023 | 2103296 |  237.452 |              289.505 |               137.99 |            837.539 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7762f_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3473.3540255831454
    time_step_min: 3170
  date: 2020-10-12_10-40-32
  done: false
  episode_len_mean: 833.4810126582279
  episode_reward_max: 289.5050505050505
  episode_reward_mean: 239.5821054927532
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 292
  episodes_total: 2686
  experiment_id: 63ae217839db4112bfec6bdab0a75ac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9201588133970896
        entropy_coeff: 0.0001
        kl: 0.006468101870268583
        model: {}
        policy_loss: -0.012541183774980405
        total_loss: 12.514065821965536
        vf_explained_var: 0.980458676815033
        vf_loss: 12.526052554448446
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.877419354838718
    gpu_util_percent0: 0.23096774193548392
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770967741935483
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 732
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1524375582923526
    mean_env_wait_ms: 1.1867413039923655
    mean_inference_ms: 4.662413518353599
    mean_raw_obs_processing_ms: 0.39911492607401206
  time_since_restore: 373.6990442276001
  time_this_iter_s: 26.675734519958496
  time_total_s: 373.6990442276001
  timers:
    learn_throughput: 8311.21
    learn_time_ms: 19466.719
    sample_throughput: 23157.733
    sample_time_ms: 6986.522
    update_time_ms: 31.223
  timestamp: 1602499232
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 7762f_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     14 |          373.699 | 2265088 |  239.582 |              289.505 |               137.99 |            833.481 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7762f_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3466.54296875
    time_step_min: 3170
  date: 2020-10-12_10-40-59
  done: false
  episode_len_mean: 831.3913502109705
  episode_reward_max: 289.5050505050505
  episode_reward_mean: 240.64524996803468
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 63ae217839db4112bfec6bdab0a75ac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9064158648252487
        entropy_coeff: 0.0001
        kl: 0.00678737946630766
        model: {}
        policy_loss: -0.012710827655003717
        total_loss: 10.679505268732706
        vf_explained_var: 0.9777107238769531
        vf_loss: 10.691628138224283
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.619354838709675
    gpu_util_percent0: 0.3261290322580645
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7838709677419353
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 732
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15222078204296272
    mean_env_wait_ms: 1.1877630325702035
    mean_inference_ms: 4.648666565690875
    mean_raw_obs_processing_ms: 0.39837897466394867
  time_since_restore: 400.2849922180176
  time_this_iter_s: 26.58594799041748
  time_total_s: 400.2849922180176
  timers:
    learn_throughput: 8302.729
    learn_time_ms: 19486.604
    sample_throughput: 23107.773
    sample_time_ms: 7001.627
    update_time_ms: 29.563
  timestamp: 1602499259
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 7762f_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     15 |          400.285 | 2426880 |  240.645 |              289.505 |               137.99 |            831.391 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7762f_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3459.892737054472
    time_step_min: 3170
  date: 2020-10-12_10-41-26
  done: false
  episode_len_mean: 830.020652898068
  episode_reward_max: 289.5050505050505
  episode_reward_mean: 241.5691289981762
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: 63ae217839db4112bfec6bdab0a75ac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8919036090373993
        entropy_coeff: 0.0001
        kl: 0.0065164086408913136
        model: {}
        policy_loss: -0.011898661767190788
        total_loss: 10.162490367889404
        vf_explained_var: 0.9785982966423035
        vf_loss: 10.173826615015665
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.887096774193544
    gpu_util_percent0: 0.3709677419354839
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.787096774193548
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 732
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15202076624090607
    mean_env_wait_ms: 1.1887146176559318
    mean_inference_ms: 4.635949922921678
    mean_raw_obs_processing_ms: 0.39768803533396757
  time_since_restore: 426.76628279685974
  time_this_iter_s: 26.481290578842163
  time_total_s: 426.76628279685974
  timers:
    learn_throughput: 8309.412
    learn_time_ms: 19470.933
    sample_throughput: 23085.494
    sample_time_ms: 7008.384
    update_time_ms: 29.45
  timestamp: 1602499286
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 7762f_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     16 |          426.766 | 2588672 |  241.569 |              289.505 |               137.99 |            830.021 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7762f_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3451.432941903585
    time_step_min: 3158
  date: 2020-10-12_10-41-52
  done: false
  episode_len_mean: 827.9087009803922
  episode_reward_max: 289.5050505050505
  episode_reward_mean: 242.70980020796188
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 262
  episodes_total: 3264
  experiment_id: 63ae217839db4112bfec6bdab0a75ac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8572876205046972
        entropy_coeff: 0.0001
        kl: 0.006706862438780566
        model: {}
        policy_loss: -0.011741302907466888
        total_loss: 15.199506441752115
        vf_explained_var: 0.97942715883255
        vf_loss: 15.210662841796875
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.719354838709684
    gpu_util_percent0: 0.32548387096774195
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7612903225806447
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 732
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15172864965332547
    mean_env_wait_ms: 1.1902196110419858
    mean_inference_ms: 4.617188440695888
    mean_raw_obs_processing_ms: 0.3966868085580042
  time_since_restore: 453.4419045448303
  time_this_iter_s: 26.67562174797058
  time_total_s: 453.4419045448303
  timers:
    learn_throughput: 8310.197
    learn_time_ms: 19469.093
    sample_throughput: 23005.301
    sample_time_ms: 7032.814
    update_time_ms: 28.266
  timestamp: 1602499312
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 7762f_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     17 |          453.442 | 2750464 |   242.71 |              289.505 |               137.99 |            827.909 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7762f_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3445.4002320185614
    time_step_min: 3146
  date: 2020-10-12_10-42-19
  done: false
  episode_len_mean: 826.5290563866513
  episode_reward_max: 289.5050505050505
  episode_reward_mean: 243.6558072090292
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 212
  episodes_total: 3476
  experiment_id: 63ae217839db4112bfec6bdab0a75ac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8529605269432068
        entropy_coeff: 0.0001
        kl: 0.005917649987774591
        model: {}
        policy_loss: -0.011277009830034027
        total_loss: 11.547587235768637
        vf_explained_var: 0.9794904589653015
        vf_loss: 11.558358192443848
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.622580645161293
    gpu_util_percent0: 0.407741935483871
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 732
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15151245459591453
    mean_env_wait_ms: 1.191304723107444
    mean_inference_ms: 4.603265801752061
    mean_raw_obs_processing_ms: 0.39595422067554054
  time_since_restore: 479.8950695991516
  time_this_iter_s: 26.45316505432129
  time_total_s: 479.8950695991516
  timers:
    learn_throughput: 8321.629
    learn_time_ms: 19442.346
    sample_throughput: 23005.85
    sample_time_ms: 7032.646
    update_time_ms: 28.083
  timestamp: 1602499339
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 7762f_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     18 |          479.895 | 2912256 |  243.656 |              289.505 |               137.99 |            826.529 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7762f_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3440.769828064337
    time_step_min: 3110
  date: 2020-10-12_10-42-46
  done: false
  episode_len_mean: 825.8247110621904
  episode_reward_max: 294.80808080808083
  episode_reward_mean: 244.29612303552858
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: 63ae217839db4112bfec6bdab0a75ac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8457075009743372
        entropy_coeff: 0.0001
        kl: 0.0065199139062315226
        model: {}
        policy_loss: -0.01116289470034341
        total_loss: 10.043978214263916
        vf_explained_var: 0.9801807403564453
        vf_loss: 10.05457361539205
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.23548387096774
    gpu_util_percent0: 0.29129032258064513
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 732
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1513673572672517
    mean_env_wait_ms: 1.1920175917054816
    mean_inference_ms: 4.593864716977697
    mean_raw_obs_processing_ms: 0.39545767616024086
  time_since_restore: 506.6568546295166
  time_this_iter_s: 26.76178503036499
  time_total_s: 506.6568546295166
  timers:
    learn_throughput: 8311.575
    learn_time_ms: 19465.865
    sample_throughput: 22990.042
    sample_time_ms: 7037.482
    update_time_ms: 28.491
  timestamp: 1602499366
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 7762f_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     19 |          506.657 | 3074048 |  244.296 |              294.808 |               137.99 |            825.825 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7762f_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3436.3805732484075
    time_step_min: 3110
  date: 2020-10-12_10-43-12
  done: false
  episode_len_mean: 825.2513171759747
  episode_reward_max: 294.80808080808083
  episode_reward_mean: 244.92866228140193
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 162
  episodes_total: 3796
  experiment_id: 63ae217839db4112bfec6bdab0a75ac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8178661465644836
        entropy_coeff: 0.0001
        kl: 0.006614145318356653
        model: {}
        policy_loss: -0.012304873768395433
        total_loss: 9.505411148071289
        vf_explained_var: 0.9820902943611145
        vf_loss: 9.517136255900065
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.777419354838703
    gpu_util_percent0: 0.3029032258064516
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774193548387097
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 732
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15122639986088446
    mean_env_wait_ms: 1.1926882058948682
    mean_inference_ms: 4.584833213203808
    mean_raw_obs_processing_ms: 0.3949704778072739
  time_since_restore: 533.0624232292175
  time_this_iter_s: 26.405568599700928
  time_total_s: 533.0624232292175
  timers:
    learn_throughput: 8310.33
    learn_time_ms: 19468.781
    sample_throughput: 23027.336
    sample_time_ms: 7026.084
    update_time_ms: 29.68
  timestamp: 1602499392
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 7762f_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     20 |          533.062 | 3235840 |  244.929 |              294.808 |               137.99 |            825.251 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7762f_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3430.280848963475
    time_step_min: 3110
  date: 2020-10-12_10-43-39
  done: false
  episode_len_mean: 824.5730392156863
  episode_reward_max: 297.6868686868688
  episode_reward_mean: 245.9245023767082
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 284
  episodes_total: 4080
  experiment_id: 63ae217839db4112bfec6bdab0a75ac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7949359466632208
        entropy_coeff: 0.0001
        kl: 0.005695687839761376
        model: {}
        policy_loss: -0.010721294248166183
        total_loss: 15.119903961817423
        vf_explained_var: 0.9795476794242859
        vf_loss: 15.13013505935669
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.409677419354836
    gpu_util_percent0: 0.41064516129032247
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7612903225806447
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 732
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15100422673970484
    mean_env_wait_ms: 1.1937338300371503
    mean_inference_ms: 4.57043850055062
    mean_raw_obs_processing_ms: 0.39420999465212736
  time_since_restore: 559.6542797088623
  time_this_iter_s: 26.591856479644775
  time_total_s: 559.6542797088623
  timers:
    learn_throughput: 8309.624
    learn_time_ms: 19470.435
    sample_throughput: 22984.662
    sample_time_ms: 7039.129
    update_time_ms: 29.704
  timestamp: 1602499419
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 7762f_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     21 |          559.654 | 3397632 |  245.925 |              297.687 |               137.99 |            824.573 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7762f_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3425.592968381312
    time_step_min: 3110
  date: 2020-10-12_10-44-06
  done: false
  episode_len_mean: 824.3506797937177
  episode_reward_max: 297.6868686868688
  episode_reward_mean: 246.62825157339924
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 186
  episodes_total: 4266
  experiment_id: 63ae217839db4112bfec6bdab0a75ac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7829316059748331
        entropy_coeff: 0.0001
        kl: 0.006042617450778683
        model: {}
        policy_loss: -0.012270252065112194
        total_loss: 7.568831443786621
        vf_explained_var: 0.9859895706176758
        vf_loss: 7.580575466156006
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.18125
    gpu_util_percent0: 0.234375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7843750000000003
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 732
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1508696818648715
    mean_env_wait_ms: 1.1943520393111597
    mean_inference_ms: 4.5617273912222736
    mean_raw_obs_processing_ms: 0.3937429550222564
  time_since_restore: 586.5587210655212
  time_this_iter_s: 26.904441356658936
  time_total_s: 586.5587210655212
  timers:
    learn_throughput: 8309.025
    learn_time_ms: 19471.84
    sample_throughput: 22972.149
    sample_time_ms: 7042.963
    update_time_ms: 31.012
  timestamp: 1602499446
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 7762f_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     22 |          586.559 | 3559424 |  246.628 |              297.687 |               137.99 |            824.351 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7762f_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3422.125568698817
    time_step_min: 3110
  date: 2020-10-12_10-44-33
  done: true
  episode_len_mean: 823.993444846293
  episode_reward_max: 297.6868686868688
  episode_reward_mean: 247.1778681936909
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 158
  episodes_total: 4424
  experiment_id: 63ae217839db4112bfec6bdab0a75ac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7830241670211157
        entropy_coeff: 0.0001
        kl: 0.005572947518279155
        model: {}
        policy_loss: -0.008857697199952478
        total_loss: 9.253699541091919
        vf_explained_var: 0.9810841679573059
        vf_loss: 9.262078205744425
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.612903225806452
    gpu_util_percent0: 0.3764516129032258
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7838709677419353
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 732
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1507628397075941
    mean_env_wait_ms: 1.1948203537338653
    mean_inference_ms: 4.554879763789217
    mean_raw_obs_processing_ms: 0.3933762180280804
  time_since_restore: 613.339967250824
  time_this_iter_s: 26.781246185302734
  time_total_s: 613.339967250824
  timers:
    learn_throughput: 8307.761
    learn_time_ms: 19474.802
    sample_throughput: 22910.952
    sample_time_ms: 7061.775
    update_time_ms: 32.075
  timestamp: 1602499473
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 7762f_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7762f_00000 | TERMINATED |       |     23 |           613.34 | 3721216 |  247.178 |              297.687 |               137.99 |            823.993 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7762f_00000 | TERMINATED |       |     23 |           613.34 | 3721216 |  247.178 |              297.687 |               137.99 |            823.993 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


