2020-10-10 12:35:28,015	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 13.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_14959_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=35865)[0m 2020-10-10 12:35:30,987	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=35857)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35857)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35847)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35847)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35805)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35805)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35855)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35855)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35866)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35866)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35838)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35838)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35864)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35864)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35848)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35848)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35841)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35841)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35843)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35843)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35853)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35853)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35815)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35815)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35844)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35844)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35796)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35796)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35839)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35839)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35816)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35816)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35860)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35860)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35835)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35835)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35836)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35836)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35842)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35842)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35804)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35804)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35859)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35859)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35850)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35850)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35737)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35737)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35849)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35849)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35800)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35800)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35733)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35733)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35791)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35791)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35827)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35827)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35747)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35747)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35802)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35802)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35730)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35730)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35817)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35817)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35755)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35755)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35858)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35858)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35790)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35790)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35749)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35749)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35729)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35729)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35807)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35807)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35753)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35753)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35863)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35863)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35794)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35794)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35736)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35736)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35728)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35728)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35798)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35798)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35783)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35783)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35801)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35801)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35725)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35725)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35786)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35786)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35834)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35834)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35739)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35739)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35731)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35731)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35726)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35726)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35833)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35833)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35741)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35741)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35727)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35727)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35840)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35840)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35740)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35740)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35820)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35820)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35732)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35732)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35814)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35814)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35757)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35757)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35748)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35748)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35754)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35754)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35751)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35751)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35735)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35735)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35724)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35724)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35756)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35756)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35738)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35738)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35746)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35746)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35824)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35824)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35803)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35803)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35734)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35734)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35788)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35788)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35750)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35750)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35846)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35846)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35818)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35818)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35752)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35752)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35852)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35852)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_14959_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-10_12-36-13
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: fe5981e87b4044a689d9921393bd9570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.1828449845314026
        entropy_coeff: 0.0
        kl: 0.00622168998233974
        model: {}
        policy_loss: -0.009677909384481608
        total_loss: 3.511433553695679
        vf_explained_var: 0.7412754893302917
        vf_loss: 3.5198671340942385
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.575
    gpu_util_percent0: 0.5611363636363637
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7113636363636378
    vram_util_percent0: 0.24115209159485973
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35865
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1985698086349049
    mean_env_wait_ms: 1.538289221174447
    mean_inference_ms: 6.771049110857782
    mean_raw_obs_processing_ms: 0.518867195885503
  time_since_restore: 36.59973764419556
  time_this_iter_s: 36.59973764419556
  time_total_s: 36.59973764419556
  timers:
    learn_throughput: 6435.473
    learn_time_ms: 25140.656
    sample_throughput: 14205.153
    sample_time_ms: 11389.67
    update_time_ms: 34.114
  timestamp: 1602333373
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: '14959_00000'
  
== Status ==
Memory usage on this node: 29.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_14959_00000 | RUNNING  | 172.17.0.4:35865 |      1 |          36.5997 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_14959_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3607.628472222222
    time_step_min: 3244
  date: 2020-10-10_12-36-48
  done: false
  episode_len_mean: 879.8417721518987
  episode_reward_max: 274.5050505050503
  episode_reward_mean: 218.26464007160186
  episode_reward_min: 76.77777777777783
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: fe5981e87b4044a689d9921393bd9570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.1498533725738525
        entropy_coeff: 0.0
        kl: 0.007868265081197024
        model: {}
        policy_loss: -0.012046631495468318
        total_loss: 3.7854323863983153
        vf_explained_var: 0.8837206959724426
        vf_loss: 3.7959053993225096
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.94146341463414
    gpu_util_percent0: 0.6041463414634146
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.9536585365853663
    vram_util_percent0: 0.2600852738602821
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35865
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.19886256818974127
    mean_env_wait_ms: 1.5446531088101114
    mean_inference_ms: 6.611655658087836
    mean_raw_obs_processing_ms: 0.526204443410598
  time_since_restore: 71.62320256233215
  time_this_iter_s: 35.0234649181366
  time_total_s: 71.62320256233215
  timers:
    learn_throughput: 6495.791
    learn_time_ms: 24907.205
    sample_throughput: 14935.911
    sample_time_ms: 10832.416
    update_time_ms: 27.434
  timestamp: 1602333408
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: '14959_00000'
  
== Status ==
Memory usage on this node: 29.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_14959_00000 | RUNNING  | 172.17.0.4:35865 |      2 |          71.6232 | 323584 |  218.265 |              274.505 |              76.7778 |            879.842 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_14959_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3605.4708520179374
    time_step_min: 3244
  date: 2020-10-10_12-37-24
  done: false
  episode_len_mean: 870.2151898734177
  episode_reward_max: 274.5050505050503
  episode_reward_mean: 218.45563227208777
  episode_reward_min: 76.77777777777783
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: fe5981e87b4044a689d9921393bd9570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.1295758008956909
        entropy_coeff: 0.0
        kl: 0.008161910064518451
        model: {}
        policy_loss: -0.013109228992834687
        total_loss: 4.262129878997802
        vf_explained_var: 0.93101966381073
        vf_loss: 4.273606872558593
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.604761904761915
    gpu_util_percent0: 0.6035714285714286
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.9642857142857144
    vram_util_percent0: 0.2600852738602821
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35865
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.19778942192089638
    mean_env_wait_ms: 1.5485710413046743
    mean_inference_ms: 6.515895031940042
    mean_raw_obs_processing_ms: 0.5298594815240416
  time_since_restore: 107.01449036598206
  time_this_iter_s: 35.3912878036499
  time_total_s: 107.01449036598206
  timers:
    learn_throughput: 6544.798
    learn_time_ms: 24720.703
    sample_throughput: 14878.466
    sample_time_ms: 10874.239
    update_time_ms: 28.638
  timestamp: 1602333444
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: '14959_00000'
  
== Status ==
Memory usage on this node: 29.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_14959_00000 | RUNNING  | 172.17.0.4:35865 |      3 |          107.014 | 485376 |  218.456 |              274.505 |              76.7778 |            870.215 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_14959_00000:
  custom_metrics:
    time_step_max: 4300
    time_step_mean: 3603.2798013245033
    time_step_min: 3244
  date: 2020-10-10_12-37-58
  done: false
  episode_len_mean: 861.8971518987341
  episode_reward_max: 274.5050505050503
  episode_reward_mean: 219.05386139879792
  episode_reward_min: 76.77777777777783
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: fe5981e87b4044a689d9921393bd9570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.0939962148666382
        entropy_coeff: 0.0
        kl: 0.0071998144499957565
        model: {}
        policy_loss: -0.012075114203616977
        total_loss: 4.806238746643066
        vf_explained_var: 0.9495649337768555
        vf_loss: 4.816873836517334
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 59.85
    gpu_util_percent0: 0.2905
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.9725
    vram_util_percent0: 0.2600852738602821
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35865
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.19632205434071745
    mean_env_wait_ms: 1.5520254743048454
    mean_inference_ms: 6.42341694506509
    mean_raw_obs_processing_ms: 0.5301067553331963
  time_since_restore: 141.15132570266724
  time_this_iter_s: 34.13683533668518
  time_total_s: 141.15132570266724
  timers:
    learn_throughput: 6576.449
    learn_time_ms: 24601.726
    sample_throughput: 15251.198
    sample_time_ms: 10608.478
    update_time_ms: 26.555
  timestamp: 1602333478
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: '14959_00000'
  
== Status ==
Memory usage on this node: 29.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_14959_00000 | RUNNING  | 172.17.0.4:35865 |      4 |          141.151 | 647168 |  219.054 |              274.505 |              76.7778 |            861.897 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_14959_00000:
  custom_metrics:
    time_step_max: 4300
    time_step_mean: 3609.5495594713657
    time_step_min: 3244
  date: 2020-10-10_12-38-33
  done: false
  episode_len_mean: 847.0555555555555
  episode_reward_max: 274.5050505050503
  episode_reward_mean: 218.38730251230237
  episode_reward_min: 76.77777777777783
  episodes_this_iter: 304
  episodes_total: 936
  experiment_id: fe5981e87b4044a689d9921393bd9570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.0672452688217162
        entropy_coeff: 0.0
        kl: 0.005605764081701636
        model: {}
        policy_loss: -0.011303234822116792
        total_loss: 8.473299789428712
        vf_explained_var: 0.9637423753738403
        vf_loss: 8.48348159790039
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.643902439024394
    gpu_util_percent0: 0.5234146341463415
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.958536585365854
    vram_util_percent0: 0.2600852738602821
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35865
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1947436829725767
    mean_env_wait_ms: 1.5614400156063015
    mean_inference_ms: 6.300060080932681
    mean_raw_obs_processing_ms: 0.5296331677541641
  time_since_restore: 175.76896214485168
  time_this_iter_s: 34.61763644218445
  time_total_s: 175.76896214485168
  timers:
    learn_throughput: 6566.643
    learn_time_ms: 24638.465
    sample_throughput: 15500.736
    sample_time_ms: 10437.698
    update_time_ms: 25.567
  timestamp: 1602333513
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: '14959_00000'
  
== Status ==
Memory usage on this node: 29.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_14959_00000 | RUNNING  | 172.17.0.4:35865 |      5 |          175.769 | 808960 |  218.387 |              274.505 |              76.7778 |            847.056 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_14959_00000:
  custom_metrics:
    time_step_max: 4300
    time_step_mean: 3609.265306122449
    time_step_min: 3244
  date: 2020-10-10_12-39-08
  done: false
  episode_len_mean: 839.8571428571429
  episode_reward_max: 274.5050505050503
  episode_reward_mean: 218.91131934169894
  episode_reward_min: 76.77777777777783
  episodes_this_iter: 170
  episodes_total: 1106
  experiment_id: fe5981e87b4044a689d9921393bd9570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.0431532502174377
        entropy_coeff: 0.0
        kl: 0.005941291060298681
        model: {}
        policy_loss: -0.011821834603324533
        total_loss: 4.575836658477783
        vf_explained_var: 0.9749056100845337
        vf_loss: 4.586470222473144
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 62.27804878048781
    gpu_util_percent0: 0.42195121951219516
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.975609756097561
    vram_util_percent0: 0.2600852738602821
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35865
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.19409216341208774
    mean_env_wait_ms: 1.5662742675403614
    mean_inference_ms: 6.24333137481906
    mean_raw_obs_processing_ms: 0.5284013078050284
  time_since_restore: 210.5823528766632
  time_this_iter_s: 34.81339073181152
  time_total_s: 210.5823528766632
  timers:
    learn_throughput: 6552.655
    learn_time_ms: 24691.061
    sample_throughput: 15664.683
    sample_time_ms: 10328.456
    update_time_ms: 25.312
  timestamp: 1602333548
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: '14959_00000'
  
== Status ==
Memory usage on this node: 29.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_14959_00000 | RUNNING  | 172.17.0.4:35865 |      6 |          210.582 | 970752 |  218.911 |              274.505 |              76.7778 |            839.857 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_14959_00000:
  custom_metrics:
    time_step_max: 4300
    time_step_mean: 3610.080097087379
    time_step_min: 3244
  date: 2020-10-10_12-39-43
  done: false
  episode_len_mean: 834.2571202531645
  episode_reward_max: 274.5050505050503
  episode_reward_mean: 219.1092411456335
  episode_reward_min: 76.77777777777783
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: fe5981e87b4044a689d9921393bd9570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.0129761576652527
        entropy_coeff: 0.0
        kl: 0.005227606184780598
        model: {}
        policy_loss: -0.012139736069366336
        total_loss: 3.826973056793213
        vf_explained_var: 0.9828845858573914
        vf_loss: 3.838067317008972
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 63.25365853658537
    gpu_util_percent0: 0.5990243902439024
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.965853658536586
    vram_util_percent0: 0.2600852738602821
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35865
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.19373272858080864
    mean_env_wait_ms: 1.5715476302362443
    mean_inference_ms: 6.199646443451515
    mean_raw_obs_processing_ms: 0.5277671366744754
  time_since_restore: 245.46014881134033
  time_this_iter_s: 34.877795934677124
  time_total_s: 245.46014881134033
  timers:
    learn_throughput: 6541.699
    learn_time_ms: 24732.413
    sample_throughput: 15778.681
    sample_time_ms: 10253.836
    update_time_ms: 27.122
  timestamp: 1602333583
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: '14959_00000'
  
== Status ==
Memory usage on this node: 29.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_14959_00000 | RUNNING  | 172.17.0.4:35865 |      7 |           245.46 | 1132544 |  219.109 |              274.505 |              76.7778 |            834.257 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_14959_00000:
  custom_metrics:
    time_step_max: 4300
    time_step_mean: 3607.239628040057
    time_step_min: 3244
  date: 2020-10-10_12-40-17
  done: false
  episode_len_mean: 829.26507713885
  episode_reward_max: 274.5050505050503
  episode_reward_mean: 219.5396886112173
  episode_reward_min: 76.77777777777783
  episodes_this_iter: 162
  episodes_total: 1426
  experiment_id: fe5981e87b4044a689d9921393bd9570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.9668255746364594
        entropy_coeff: 0.0
        kl: 0.0052318656351417305
        model: {}
        policy_loss: -0.012421235267538577
        total_loss: 4.2317636728286745
        vf_explained_var: 0.9871546030044556
        vf_loss: 4.2431385040283205
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.49268292682926
    gpu_util_percent0: 0.5758536585365855
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.9634146341463414
    vram_util_percent0: 0.2600852738602821
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35865
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.19323044876996706
    mean_env_wait_ms: 1.5760754827966603
    mean_inference_ms: 6.156265187319367
    mean_raw_obs_processing_ms: 0.5266627996698018
  time_since_restore: 279.9256556034088
  time_this_iter_s: 34.46550679206848
  time_total_s: 279.9256556034088
  timers:
    learn_throughput: 6538.34
    learn_time_ms: 24745.12
    sample_throughput: 15914.874
    sample_time_ms: 10166.087
    update_time_ms: 27.643
  timestamp: 1602333617
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: '14959_00000'
  
== Status ==
Memory usage on this node: 29.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_14959_00000 | RUNNING  | 172.17.0.4:35865 |      8 |          279.926 | 1294336 |   219.54 |              274.505 |              76.7778 |            829.265 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_14959_00000:
  custom_metrics:
    time_step_max: 4300
    time_step_mean: 3603.3777777777777
    time_step_min: 3244
  date: 2020-10-10_12-40-52
  done: false
  episode_len_mean: 821.6461449942462
  episode_reward_max: 274.5050505050503
  episode_reward_mean: 219.9155711313363
  episode_reward_min: 76.77777777777783
  episodes_this_iter: 312
  episodes_total: 1738
  experiment_id: fe5981e87b4044a689d9921393bd9570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.9444138944149018
        entropy_coeff: 0.0
        kl: 0.005521268071606755
        model: {}
        policy_loss: -0.011216377699747681
        total_loss: 4.231334209442139
        vf_explained_var: 0.990566611289978
        vf_loss: 4.241446161270142
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.41707317073172
    gpu_util_percent0: 0.6009756097560975
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.9536585365853663
    vram_util_percent0: 0.2600852738602821
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35865
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.19241213142021124
    mean_env_wait_ms: 1.5830960170049853
    mean_inference_ms: 6.087823756125087
    mean_raw_obs_processing_ms: 0.5249726512902579
  time_since_restore: 314.7206406593323
  time_this_iter_s: 34.79498505592346
  time_total_s: 314.7206406593323
  timers:
    learn_throughput: 6539.796
    learn_time_ms: 24739.611
    sample_throughput: 15939.886
    sample_time_ms: 10150.135
    update_time_ms: 27.24
  timestamp: 1602333652
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: '14959_00000'
  
== Status ==
Memory usage on this node: 29.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_14959_00000 | RUNNING  | 172.17.0.4:35865 |      9 |          314.721 | 1456128 |  219.916 |              274.505 |              76.7778 |            821.646 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_14959_00000:
  custom_metrics:
    time_step_max: 4300
    time_step_mean: 3601.4700214132763
    time_step_min: 3244
  date: 2020-10-10_12-41-27
  done: false
  episode_len_mean: 818.8502109704641
  episode_reward_max: 274.5050505050503
  episode_reward_mean: 220.19981460171329
  episode_reward_min: 76.77777777777783
  episodes_this_iter: 158
  episodes_total: 1896
  experiment_id: fe5981e87b4044a689d9921393bd9570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.9138161420822144
        entropy_coeff: 0.0
        kl: 0.005318886274471879
        model: {}
        policy_loss: -0.012548227468505502
        total_loss: 2.4675506114959718
        vf_explained_var: 0.9929584264755249
        vf_loss: 2.4790350914001467
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.6875
    gpu_util_percent0: 0.5307499999999999
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.97
    vram_util_percent0: 0.2600852738602821
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35865
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1920036892450141
    mean_env_wait_ms: 1.5856194970164634
    mean_inference_ms: 6.056875500210334
    mean_raw_obs_processing_ms: 0.5240396523573858
  time_since_restore: 349.27080631256104
  time_this_iter_s: 34.55016565322876
  time_total_s: 349.27080631256104
  timers:
    learn_throughput: 6534.657
    learn_time_ms: 24759.066
    sample_throughput: 16037.041
    sample_time_ms: 10088.644
    update_time_ms: 27.717
  timestamp: 1602333687
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: '14959_00000'
  
== Status ==
Memory usage on this node: 29.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_14959_00000 | RUNNING  | 172.17.0.4:35865 |     10 |          349.271 | 1617920 |    220.2 |              274.505 |              76.7778 |             818.85 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_14959_00000:
  custom_metrics:
    time_step_max: 4300
    time_step_mean: 3600.291707798618
    time_step_min: 3244
  date: 2020-10-10_12-42-01
  done: false
  episode_len_mean: 816.141187925998
  episode_reward_max: 274.5050505050503
  episode_reward_mean: 220.31522134686688
  episode_reward_min: 76.77777777777783
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: fe5981e87b4044a689d9921393bd9570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.8788309514522552
        entropy_coeff: 0.0
        kl: 0.0048537369351834055
        model: {}
        policy_loss: -0.011975262057967484
        total_loss: 2.5137741804122924
        vf_explained_var: 0.9934164881706238
        vf_loss: 2.524778652191162
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 59.75609756097561
    gpu_util_percent0: 0.5258536585365854
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.965853658536586
    vram_util_percent0: 0.2600852738602821
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35865
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.19160379063577807
    mean_env_wait_ms: 1.587817986385621
    mean_inference_ms: 6.027409226866352
    mean_raw_obs_processing_ms: 0.5230404430902966
  time_since_restore: 383.4998950958252
  time_this_iter_s: 34.22908878326416
  time_total_s: 383.4998950958252
  timers:
    learn_throughput: 6543.544
    learn_time_ms: 24725.439
    sample_throughput: 16368.714
    sample_time_ms: 9884.222
    update_time_ms: 26.711
  timestamp: 1602333721
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: '14959_00000'
  
== Status ==
Memory usage on this node: 29.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_14959_00000 | RUNNING  | 172.17.0.4:35865 |     11 |            383.5 | 1779712 |  220.315 |              274.505 |              76.7778 |            816.141 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_14959_00000:
  custom_metrics:
    time_step_max: 4300
    time_step_mean: 3600.090559589919
    time_step_min: 3244
  date: 2020-10-10_12-42-36
  done: false
  episode_len_mean: 811.8868720979316
  episode_reward_max: 274.5050505050503
  episode_reward_mean: 220.3164784186312
  episode_reward_min: 76.77777777777783
  episodes_this_iter: 315
  episodes_total: 2369
  experiment_id: fe5981e87b4044a689d9921393bd9570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8393935322761535
        entropy_coeff: 0.0
        kl: 0.0057399526704102755
        model: {}
        policy_loss: -0.010811011726036667
        total_loss: 3.5562233448028566
        vf_explained_var: 0.9943920373916626
        vf_loss: 3.566460394859314
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.773170731707324
    gpu_util_percent0: 0.5800000000000001
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.9560975609756093
    vram_util_percent0: 0.2600852738602821
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35865
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1908884228567585
    mean_env_wait_ms: 1.5918146145831087
    mean_inference_ms: 5.977151318063367
    mean_raw_obs_processing_ms: 0.5212176620468814
  time_since_restore: 418.2862980365753
  time_this_iter_s: 34.78640294075012
  time_total_s: 418.2862980365753
  timers:
    learn_throughput: 6542.379
    learn_time_ms: 24729.842
    sample_throughput: 16416.579
    sample_time_ms: 9855.403
    update_time_ms: 26.745
  timestamp: 1602333756
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: '14959_00000'
  
== Status ==
Memory usage on this node: 29.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_14959_00000 | RUNNING  | 172.17.0.4:35865 |     12 |          418.286 | 1941504 |  220.316 |              274.505 |              76.7778 |            811.887 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_14959_00000:
  custom_metrics:
    time_step_max: 4300
    time_step_mean: 3601.8092
    time_step_min: 3244
  date: 2020-10-10_12-43-10
  done: false
  episode_len_mean: 810.2650316455696
  episode_reward_max: 274.5050505050503
  episode_reward_mean: 220.06058608234235
  episode_reward_min: 76.77777777777783
  episodes_this_iter: 159
  episodes_total: 2528
  experiment_id: fe5981e87b4044a689d9921393bd9570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.7995639324188233
        entropy_coeff: 0.0
        kl: 0.005581407342106104
        model: {}
        policy_loss: -0.011483547289390116
        total_loss: 2.28704149723053
        vf_explained_var: 0.9948097467422485
        vf_loss: 2.2979668617248534
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 61.495000000000005
    gpu_util_percent0: 0.6235
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.975
    vram_util_percent0: 0.2600852738602821
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35865
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.19056528876863746
    mean_env_wait_ms: 1.5935824291010638
    mean_inference_ms: 5.9545825144388
    mean_raw_obs_processing_ms: 0.520387700813116
  time_since_restore: 452.486793756485
  time_this_iter_s: 34.20049571990967
  time_total_s: 452.486793756485
  timers:
    learn_throughput: 6529.173
    learn_time_ms: 24779.861
    sample_throughput: 16702.9
    sample_time_ms: 9686.461
    update_time_ms: 25.911
  timestamp: 1602333790
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: '14959_00000'
  
== Status ==
Memory usage on this node: 29.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_14959_00000 | RUNNING  | 172.17.0.4:35865 |     13 |          452.487 | 2103296 |  220.061 |              274.505 |              76.7778 |            810.265 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_14959_00000:
  custom_metrics:
    time_step_max: 4300
    time_step_mean: 3601.5737396538752
    time_step_min: 3244
  date: 2020-10-10_12-43-45
  done: false
  episode_len_mean: 809.0640357408786
  episode_reward_max: 274.5050505050503
  episode_reward_mean: 220.17265356468633
  episode_reward_min: 76.77777777777783
  episodes_this_iter: 158
  episodes_total: 2686
  experiment_id: fe5981e87b4044a689d9921393bd9570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.7864831805229187
        entropy_coeff: 0.0
        kl: 0.0047326154541224245
        model: {}
        policy_loss: -0.011462518665939569
        total_loss: 1.9168771505355835
        vf_explained_var: 0.9957062602043152
        vf_loss: 1.9278664588928223
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.325
    gpu_util_percent0: 0.20775000000000002
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.9775
    vram_util_percent0: 0.2600852738602821
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35865
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.19027832681098636
    mean_env_wait_ms: 1.595364944944046
    mean_inference_ms: 5.9342300620977895
    mean_raw_obs_processing_ms: 0.5196353596523059
  time_since_restore: 486.8639426231384
  time_this_iter_s: 34.37714886665344
  time_total_s: 486.8639426231384
  timers:
    learn_throughput: 6516.197
    learn_time_ms: 24829.205
    sample_throughput: 16746.012
    sample_time_ms: 9661.524
    update_time_ms: 25.862
  timestamp: 1602333825
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: '14959_00000'
  
== Status ==
Memory usage on this node: 29.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_14959_00000 | RUNNING  | 172.17.0.4:35865 |     14 |          486.864 | 2265088 |  220.173 |              274.505 |              76.7778 |            809.064 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_14959_00000:
  custom_metrics:
    time_step_max: 4300
    time_step_mean: 3598.4792092706202
    time_step_min: 3244
  date: 2020-10-10_12-44-19
  done: false
  episode_len_mean: 807.3909520594193
  episode_reward_max: 274.5050505050503
  episode_reward_mean: 220.41189068265368
  episode_reward_min: 76.77777777777783
  episodes_this_iter: 276
  episodes_total: 2962
  experiment_id: fe5981e87b4044a689d9921393bd9570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 5.0e-05
        entropy: 0.7766002297401429
        entropy_coeff: 0.0
        kl: 0.005718279723078012
        model: {}
        policy_loss: -0.010715055884793401
        total_loss: 2.545193886756897
        vf_explained_var: 0.996320366859436
        vf_loss: 2.555623006820679
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 59.146341463414636
    gpu_util_percent0: 0.6146341463414634
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.958536585365854
    vram_util_percent0: 0.2600852738602821
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35865
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.18982402525717473
    mean_env_wait_ms: 1.5982894848690545
    mean_inference_ms: 5.903520914178468
    mean_raw_obs_processing_ms: 0.518538088830204
  time_since_restore: 521.0827014446259
  time_this_iter_s: 34.21875882148743
  time_total_s: 521.0827014446259
  timers:
    learn_throughput: 6524.59
    learn_time_ms: 24797.267
    sample_throughput: 16762.012
    sample_time_ms: 9652.302
    update_time_ms: 26.234
  timestamp: 1602333859
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: '14959_00000'
  
== Status ==
Memory usage on this node: 29.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_14959_00000 | RUNNING  | 172.17.0.4:35865 |     15 |          521.083 | 2426880 |  220.412 |              274.505 |              76.7778 |            807.391 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_14959_00000:
  custom_metrics:
    time_step_max: 4300
    time_step_mean: 3597.6736909323117
    time_step_min: 3244
  date: 2020-10-10_12-44-53
  done: false
  episode_len_mean: 806.4579113924051
  episode_reward_max: 274.5050505050503
  episode_reward_mean: 220.55012146784296
  episode_reward_min: 76.77777777777783
  episodes_this_iter: 198
  episodes_total: 3160
  experiment_id: fe5981e87b4044a689d9921393bd9570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 5.0e-05
        entropy: 0.7104055643081665
        entropy_coeff: 0.0
        kl: 0.004665934154763818
        model: {}
        policy_loss: -0.010823860147502274
        total_loss: 1.8320143938064575
        vf_explained_var: 0.9962557554244995
        vf_loss: 1.84260493516922
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 60.185365853658546
    gpu_util_percent0: 0.6021951219512195
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.9560975609756093
    vram_util_percent0: 0.2600852738602821
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35865
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1895199579707842
    mean_env_wait_ms: 1.5999667420040657
    mean_inference_ms: 5.8830592364716
    mean_raw_obs_processing_ms: 0.5177113328701938
  time_since_restore: 555.496237039566
  time_this_iter_s: 34.413535594940186
  time_total_s: 555.496237039566
  timers:
    learn_throughput: 6533.303
    learn_time_ms: 24764.196
    sample_throughput: 16776.696
    sample_time_ms: 9643.853
    update_time_ms: 27.147
  timestamp: 1602333893
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: '14959_00000'
  
== Status ==
Memory usage on this node: 29.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_14959_00000 | RUNNING  | 172.17.0.4:35865 |     16 |          555.496 | 2588672 |   220.55 |              274.505 |              76.7778 |            806.458 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


