2020-10-12 16:07:43,282	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_102c7_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=78955)[0m 2020-10-12 16:07:46,014	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=78910)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78910)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78933)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78933)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78912)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78912)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78926)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78926)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78975)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78975)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78951)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78951)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78928)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78928)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78944)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78944)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78950)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78950)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78960)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78960)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78957)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78957)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78911)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78911)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78970)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78970)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78929)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78929)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78947)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78947)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78940)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78940)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78941)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78941)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78847)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78847)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78845)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78845)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78914)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78914)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78863)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78863)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78924)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78924)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78903)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78903)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78916)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78916)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78921)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78921)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78844)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78844)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78862)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78862)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78918)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78918)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78850)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78850)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78852)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78852)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78843)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78843)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78907)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78907)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78846)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78846)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78908)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78908)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78909)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78909)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78952)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78952)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78919)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78919)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78913)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78913)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78946)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78946)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78917)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78917)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78965)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78965)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78964)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78964)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78922)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78922)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78868)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78868)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78902)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78902)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78872)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78872)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78923)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78923)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78840)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78840)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78963)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78963)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78967)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78967)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78864)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78864)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78931)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78931)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78871)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78871)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78849)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78849)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78866)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78866)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78932)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78932)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78855)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78855)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78915)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78915)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78937)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78937)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78948)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78948)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78842)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78842)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78938)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78938)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78858)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78858)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78953)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78953)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78879)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78879)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78861)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78861)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78860)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78860)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78851)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78851)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78906)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78906)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78856)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78856)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78927)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78927)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78920)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78920)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78853)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78853)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78841)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78841)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78857)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78857)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78859)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78859)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78876)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78876)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78925)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78925)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=78873)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=78873)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_102c7_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_16-08-20
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 9e70ee58519e42ea9a1f64b9d00bc678
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1826098163922627
        entropy_coeff: 0.009999999999999998
        kl: 0.006638795409041147
        model: {}
        policy_loss: -0.009126687606719011
        total_loss: 507.06367746988934
        vf_explained_var: 0.540532648563385
        vf_loss: 507.0832926432292
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.87575757575758
    gpu_util_percent0: 0.3315151515151515
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.56969696969697
    vram_util_percent0: 0.08750757824224535
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 78955
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16764572204797126
    mean_env_wait_ms: 1.1750559204704563
    mean_inference_ms: 5.557681366631041
    mean_raw_obs_processing_ms: 0.4472622278112805
  time_since_restore: 28.622952938079834
  time_this_iter_s: 28.622952938079834
  time_total_s: 28.622952938079834
  timers:
    learn_throughput: 8232.536
    learn_time_ms: 19652.755
    sample_throughput: 18210.899
    sample_time_ms: 8884.35
    update_time_ms: 45.573
  timestamp: 1602518900
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 102c7_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_102c7_00000 | RUNNING  | 172.17.0.4:78955 |      1 |           28.623 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_102c7_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3613.746527777778
    time_step_min: 3322
  date: 2020-10-12_16-08-47
  done: false
  episode_len_mean: 892.3101265822785
  episode_reward_max: 269.6565656565654
  episode_reward_mean: 218.14524996803453
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 9e70ee58519e42ea9a1f64b9d00bc678
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1535668969154358
        entropy_coeff: 0.009999999999999998
        kl: 0.007729921489953995
        model: {}
        policy_loss: -0.012381040625768946
        total_loss: 125.58944956461589
        vf_explained_var: 0.8107180595397949
        vf_loss: 125.61182085673015
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.471875
    gpu_util_percent0: 0.259375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7593750000000004
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 78955
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16378828174641094
    mean_env_wait_ms: 1.16876962477846
    mean_inference_ms: 5.402405811625511
    mean_raw_obs_processing_ms: 0.43786752623465447
  time_since_restore: 56.14572882652283
  time_this_iter_s: 27.522775888442993
  time_total_s: 56.14572882652283
  timers:
    learn_throughput: 8252.82
    learn_time_ms: 19604.45
    sample_throughput: 19283.827
    sample_time_ms: 8390.036
    update_time_ms: 34.34
  timestamp: 1602518927
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 102c7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_102c7_00000 | RUNNING  | 172.17.0.4:78955 |      2 |          56.1457 | 323584 |  218.145 |              269.657 |              145.717 |             892.31 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_102c7_00000:
  custom_metrics:
    time_step_max: 4108
    time_step_mean: 3616.5
    time_step_min: 3322
  date: 2020-10-12_16-09-14
  done: false
  episode_len_mean: 887.5189873417721
  episode_reward_max: 269.6565656565654
  episode_reward_mean: 218.29676511954972
  episode_reward_min: 143.59595959595921
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 9e70ee58519e42ea9a1f64b9d00bc678
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1438795626163483
        entropy_coeff: 0.009999999999999998
        kl: 0.009981099322127799
        model: {}
        policy_loss: -0.013407240464099838
        total_loss: 62.006144523620605
        vf_explained_var: 0.8911029696464539
        vf_loss: 62.02899328867594
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.54193548387097
    gpu_util_percent0: 0.42935483870967744
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322573
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 78955
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16115990513207593
    mean_env_wait_ms: 1.166755785229277
    mean_inference_ms: 5.253719924664197
    mean_raw_obs_processing_ms: 0.4300195203566868
  time_since_restore: 82.91436958312988
  time_this_iter_s: 26.768640756607056
  time_total_s: 82.91436958312988
  timers:
    learn_throughput: 8262.655
    learn_time_ms: 19581.114
    sample_throughput: 20272.912
    sample_time_ms: 7980.699
    update_time_ms: 29.542
  timestamp: 1602518954
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 102c7_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_102c7_00000 | RUNNING  | 172.17.0.4:78955 |      3 |          82.9144 | 485376 |  218.297 |              269.657 |              143.596 |            887.519 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_102c7_00000:
  custom_metrics:
    time_step_max: 4108
    time_step_mean: 3609.5397350993376
    time_step_min: 3309
  date: 2020-10-12_16-09-41
  done: false
  episode_len_mean: 885.9287974683544
  episode_reward_max: 269.6565656565654
  episode_reward_mean: 219.2746611686483
  episode_reward_min: 143.59595959595921
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 9e70ee58519e42ea9a1f64b9d00bc678
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1315575242042542
        entropy_coeff: 0.009999999999999998
        kl: 0.009686150665705403
        model: {}
        policy_loss: -0.012271062121726573
        total_loss: 40.926574071248375
        vf_explained_var: 0.9229447245597839
        vf_loss: 40.9482224782308
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.006451612903227
    gpu_util_percent0: 0.332258064516129
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322573
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 78955
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15926552253858214
    mean_env_wait_ms: 1.1656135395235732
    mean_inference_ms: 5.138332143968002
    mean_raw_obs_processing_ms: 0.42414156970795047
  time_since_restore: 109.70421266555786
  time_this_iter_s: 26.78984308242798
  time_total_s: 109.70421266555786
  timers:
    learn_throughput: 8267.991
    learn_time_ms: 19568.478
    sample_throughput: 20803.33
    sample_time_ms: 7777.217
    update_time_ms: 33.249
  timestamp: 1602518981
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 102c7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_102c7_00000 | RUNNING  | 172.17.0.4:78955 |      4 |          109.704 | 647168 |  219.275 |              269.657 |              143.596 |            885.929 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_102c7_00000:
  custom_metrics:
    time_step_max: 4108
    time_step_mean: 3598.288713910761
    time_step_min: 3309
  date: 2020-10-12_16-10-07
  done: false
  episode_len_mean: 881.9696202531645
  episode_reward_max: 273.2929292929291
  episode_reward_mean: 221.0303669607465
  episode_reward_min: 143.59595959595921
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 9e70ee58519e42ea9a1f64b9d00bc678
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.100959191719691
        entropy_coeff: 0.009999999999999998
        kl: 0.01154538911456863
        model: {}
        policy_loss: -0.015550933441166611
        total_loss: 29.794370810190838
        vf_explained_var: 0.9442993998527527
        vf_loss: 29.81862195332845
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.990322580645163
    gpu_util_percent0: 0.36064516129032254
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774193548387097
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 78955
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1578339304865576
    mean_env_wait_ms: 1.1659186529164804
    mean_inference_ms: 5.048127022128972
    mean_raw_obs_processing_ms: 0.4193117423946304
  time_since_restore: 136.16186380386353
  time_this_iter_s: 26.457651138305664
  time_total_s: 136.16186380386353
  timers:
    learn_throughput: 8280.842
    learn_time_ms: 19538.109
    sample_throughput: 21253.28
    sample_time_ms: 7612.566
    update_time_ms: 34.144
  timestamp: 1602519007
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 102c7_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_102c7_00000 | RUNNING  | 172.17.0.4:78955 |      5 |          136.162 | 808960 |   221.03 |              273.293 |              143.596 |             881.97 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_102c7_00000:
  custom_metrics:
    time_step_max: 4108
    time_step_mean: 3577.687380497132
    time_step_min: 3309
  date: 2020-10-12_16-10-34
  done: false
  episode_len_mean: 873.8175046554935
  episode_reward_max: 273.2929292929291
  episode_reward_mean: 223.5128660910782
  episode_reward_min: 143.59595959595921
  episodes_this_iter: 284
  episodes_total: 1074
  experiment_id: 9e70ee58519e42ea9a1f64b9d00bc678
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.087571382522583
        entropy_coeff: 0.009999999999999998
        kl: 0.010028440738096833
        model: {}
        policy_loss: -0.01318530043742309
        total_loss: 37.865370432535805
        vf_explained_var: 0.9525842666625977
        vf_loss: 37.887425104777016
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.261290322580653
    gpu_util_percent0: 0.2812903225806451
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.761290322580645
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 78955
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15603528065684358
    mean_env_wait_ms: 1.1685901357608561
    mean_inference_ms: 4.933685915513943
    mean_raw_obs_processing_ms: 0.4133319937856245
  time_since_restore: 162.70586347579956
  time_this_iter_s: 26.543999671936035
  time_total_s: 162.70586347579956
  timers:
    learn_throughput: 8289.786
    learn_time_ms: 19517.03
    sample_throughput: 21516.827
    sample_time_ms: 7519.324
    update_time_ms: 33.061
  timestamp: 1602519034
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 102c7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_102c7_00000 | RUNNING  | 172.17.0.4:78955 |      6 |          162.706 | 970752 |  223.513 |              273.293 |              143.596 |            873.818 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_102c7_00000:
  custom_metrics:
    time_step_max: 4191
    time_step_mean: 3571.418284789644
    time_step_min: 3244
  date: 2020-10-12_16-11-01
  done: false
  episode_len_mean: 870.3757911392405
  episode_reward_max: 276.4747474747472
  episode_reward_mean: 224.93274517325133
  episode_reward_min: 131.02020202020162
  episodes_this_iter: 190
  episodes_total: 1264
  experiment_id: 9e70ee58519e42ea9a1f64b9d00bc678
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0905858079592388
        entropy_coeff: 0.009999999999999998
        kl: 0.010375388354683915
        model: {}
        policy_loss: -0.013095076096457584
        total_loss: 21.903311729431152
        vf_explained_var: 0.9617595076560974
        vf_loss: 21.925238291422527
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.948387096774198
    gpu_util_percent0: 0.2787096774193549
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7838709677419353
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 78955
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1551675349434342
    mean_env_wait_ms: 1.1697270446015389
    mean_inference_ms: 4.878199813307256
    mean_raw_obs_processing_ms: 0.41050858155640046
  time_since_restore: 189.2214274406433
  time_this_iter_s: 26.51556396484375
  time_total_s: 189.2214274406433
  timers:
    learn_throughput: 8287.72
    learn_time_ms: 19521.896
    sample_throughput: 21784.075
    sample_time_ms: 7427.077
    update_time_ms: 33.963
  timestamp: 1602519061
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 102c7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_102c7_00000 | RUNNING  | 172.17.0.4:78955 |      7 |          189.221 | 1132544 |  224.933 |              276.475 |               131.02 |            870.376 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_102c7_00000:
  custom_metrics:
    time_step_max: 4191
    time_step_mean: 3563.106169296987
    time_step_min: 3240
  date: 2020-10-12_16-11-27
  done: false
  episode_len_mean: 866.3980309423347
  episode_reward_max: 276.4747474747472
  episode_reward_mean: 226.03788944295252
  episode_reward_min: 131.02020202020162
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 9e70ee58519e42ea9a1f64b9d00bc678
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0608182152112324
        entropy_coeff: 0.009999999999999998
        kl: 0.010341411146024862
        model: {}
        policy_loss: -0.01250516933699449
        total_loss: 20.254406770070393
        vf_explained_var: 0.9635797142982483
        vf_loss: 20.275452454884846
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.996774193548386
    gpu_util_percent0: 0.347741935483871
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.780645161290322
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 78955
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1545602682441058
    mean_env_wait_ms: 1.1708763046699386
    mean_inference_ms: 4.839008841131519
    mean_raw_obs_processing_ms: 0.40847211198627137
  time_since_restore: 215.67713856697083
  time_this_iter_s: 26.455711126327515
  time_total_s: 215.67713856697083
  timers:
    learn_throughput: 8295.561
    learn_time_ms: 19503.444
    sample_throughput: 21946.253
    sample_time_ms: 7372.193
    update_time_ms: 35.023
  timestamp: 1602519087
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 102c7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_102c7_00000 | RUNNING  | 172.17.0.4:78955 |      8 |          215.677 | 1294336 |  226.038 |              276.475 |               131.02 |            866.398 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_102c7_00000:
  custom_metrics:
    time_step_max: 4191
    time_step_mean: 3553.5599226804125
    time_step_min: 3223
  date: 2020-10-12_16-11-54
  done: false
  episode_len_mean: 862.5158227848101
  episode_reward_max: 277.6868686868685
  episode_reward_mean: 227.30529983378065
  episode_reward_min: 131.02020202020162
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 9e70ee58519e42ea9a1f64b9d00bc678
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0384237170219421
        entropy_coeff: 0.009999999999999998
        kl: 0.009627142610649267
        model: {}
        policy_loss: -0.01700612022007893
        total_loss: 16.662208875020344
        vf_explained_var: 0.9674143195152283
        vf_loss: 16.687673568725586
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.261290322580646
    gpu_util_percent0: 0.3535483870967742
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.767741935483871
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 78955
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1540295556317275
    mean_env_wait_ms: 1.1720038435786337
    mean_inference_ms: 4.804727241875149
    mean_raw_obs_processing_ms: 0.40666367581702734
  time_since_restore: 242.0832667350769
  time_this_iter_s: 26.40612816810608
  time_total_s: 242.0832667350769
  timers:
    learn_throughput: 8305.863
    learn_time_ms: 19479.251
    sample_throughput: 22081.394
    sample_time_ms: 7327.074
    update_time_ms: 34.437
  timestamp: 1602519114
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 102c7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_102c7_00000 | RUNNING  | 172.17.0.4:78955 |      9 |          242.083 | 1456128 |  227.305 |              277.687 |               131.02 |            862.516 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_102c7_00000:
  custom_metrics:
    time_step_max: 4191
    time_step_mean: 3544.2088535754824
    time_step_min: 3222
  date: 2020-10-12_16-12-20
  done: false
  episode_len_mean: 857.5910614525139
  episode_reward_max: 277.8383838383838
  episode_reward_mean: 228.86894080469483
  episode_reward_min: 131.02020202020162
  episodes_this_iter: 210
  episodes_total: 1790
  experiment_id: 9e70ee58519e42ea9a1f64b9d00bc678
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9974879175424576
        entropy_coeff: 0.009999999999999998
        kl: 0.008700317547967037
        model: {}
        policy_loss: -0.011329258915793616
        total_loss: 20.518777052561443
        vf_explained_var: 0.9708695411682129
        vf_loss: 20.538341681162517
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.55
    gpu_util_percent0: 0.3463333333333332
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7633333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 78955
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15343140485616613
    mean_env_wait_ms: 1.1737857295155567
    mean_inference_ms: 4.765203706811017
    mean_raw_obs_processing_ms: 0.40460075206445467
  time_since_restore: 268.5188524723053
  time_this_iter_s: 26.435585737228394
  time_total_s: 268.5188524723053
  timers:
    learn_throughput: 8308.202
    learn_time_ms: 19473.768
    sample_throughput: 22202.023
    sample_time_ms: 7287.264
    update_time_ms: 34.576
  timestamp: 1602519140
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 102c7_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_102c7_00000 | RUNNING  | 172.17.0.4:78955 |     10 |          268.519 | 1617920 |  228.869 |              277.838 |               131.02 |            857.591 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_102c7_00000:
  custom_metrics:
    time_step_max: 4191
    time_step_mean: 3528.8834567901235
    time_step_min: 3176
  date: 2020-10-12_16-12-47
  done: false
  episode_len_mean: 853.080370189966
  episode_reward_max: 284.8080808080809
  episode_reward_mean: 231.2347439322596
  episode_reward_min: 131.02020202020162
  episodes_this_iter: 263
  episodes_total: 2053
  experiment_id: 9e70ee58519e42ea9a1f64b9d00bc678
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0081463505824406
        entropy_coeff: 0.009999999999999998
        kl: 0.008999044075608253
        model: {}
        policy_loss: -0.014812325025559403
        total_loss: 15.672908067703247
        vf_explained_var: 0.9755696654319763
        vf_loss: 15.696002006530762
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.51290322580645
    gpu_util_percent0: 0.26903225806451614
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 78955
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15280332006903566
    mean_env_wait_ms: 1.1756410445019403
    mean_inference_ms: 4.7251827546088325
    mean_raw_obs_processing_ms: 0.4025093968493308
  time_since_restore: 295.1612915992737
  time_this_iter_s: 26.642439126968384
  time_total_s: 295.1612915992737
  timers:
    learn_throughput: 8305.132
    learn_time_ms: 19480.967
    sample_throughput: 22847.759
    sample_time_ms: 7081.307
    update_time_ms: 33.28
  timestamp: 1602519167
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 102c7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_102c7_00000 | RUNNING  | 172.17.0.4:78955 |     11 |          295.161 | 1779712 |  231.235 |              284.808 |               131.02 |             853.08 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_102c7_00000:
  custom_metrics:
    time_step_max: 4191
    time_step_mean: 3520.282967032967
    time_step_min: 3176
  date: 2020-10-12_16-13-13
  done: false
  episode_len_mean: 850.1858047016275
  episode_reward_max: 284.8080808080809
  episode_reward_mean: 232.62316656620436
  episode_reward_min: 131.02020202020162
  episodes_this_iter: 159
  episodes_total: 2212
  experiment_id: 9e70ee58519e42ea9a1f64b9d00bc678
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9895685414473215
        entropy_coeff: 0.009999999999999998
        kl: 0.00990258490977188
        model: {}
        policy_loss: -0.014284822701786956
        total_loss: 12.035956064860025
        vf_explained_var: 0.9765486121177673
        vf_loss: 12.05815601348877
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.24516129032259
    gpu_util_percent0: 0.27612903225806446
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 78955
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15247906627678712
    mean_env_wait_ms: 1.1766768254433808
    mean_inference_ms: 4.704267824055162
    mean_raw_obs_processing_ms: 0.4014101947175025
  time_since_restore: 321.65702199935913
  time_this_iter_s: 26.49573040008545
  time_total_s: 321.65702199935913
  timers:
    learn_throughput: 8312.14
    learn_time_ms: 19464.541
    sample_throughput: 23139.085
    sample_time_ms: 6992.152
    update_time_ms: 35.259
  timestamp: 1602519193
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 102c7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_102c7_00000 | RUNNING  | 172.17.0.4:78955 |     12 |          321.657 | 1941504 |  232.623 |              284.808 |               131.02 |            850.186 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_102c7_00000:
  custom_metrics:
    time_step_max: 4191
    time_step_mean: 3512.605465414176
    time_step_min: 3176
  date: 2020-10-12_16-13-40
  done: false
  episode_len_mean: 847.8417721518987
  episode_reward_max: 284.8080808080809
  episode_reward_mean: 233.73014959723804
  episode_reward_min: 131.02020202020162
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: 9e70ee58519e42ea9a1f64b9d00bc678
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9686161130666733
        entropy_coeff: 0.009999999999999998
        kl: 0.009234198369085789
        model: {}
        policy_loss: -0.013243761185246209
        total_loss: 11.995935757954916
        vf_explained_var: 0.9759342074394226
        vf_loss: 12.017018795013428
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.925806451612907
    gpu_util_percent0: 0.3529032258064517
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 78955
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15218696678444377
    mean_env_wait_ms: 1.177647501963579
    mean_inference_ms: 4.6853157598678985
    mean_raw_obs_processing_ms: 0.4003834374932623
  time_since_restore: 348.23713541030884
  time_this_iter_s: 26.580113410949707
  time_total_s: 348.23713541030884
  timers:
    learn_throughput: 8313.089
    learn_time_ms: 19462.32
    sample_throughput: 23199.939
    sample_time_ms: 6973.811
    update_time_ms: 36.649
  timestamp: 1602519220
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 102c7_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_102c7_00000 | RUNNING  | 172.17.0.4:78955 |     13 |          348.237 | 2103296 |   233.73 |              284.808 |               131.02 |            847.842 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_102c7_00000:
  custom_metrics:
    time_step_max: 4191
    time_step_mean: 3502.896350931677
    time_step_min: 3174
  date: 2020-10-12_16-14-07
  done: false
  episode_len_mean: 844.7246543778801
  episode_reward_max: 285.1111111111108
  episode_reward_mean: 235.17133314713945
  episode_reward_min: 131.02020202020162
  episodes_this_iter: 234
  episodes_total: 2604
  experiment_id: 9e70ee58519e42ea9a1f64b9d00bc678
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9322887063026428
        entropy_coeff: 0.009999999999999998
        kl: 0.011198417749255896
        model: {}
        policy_loss: -0.016642790210122865
        total_loss: 15.08353320757548
        vf_explained_var: 0.9785838723182678
        vf_loss: 15.107259432474772
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.71935483870968
    gpu_util_percent0: 0.3106451612903226
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 78955
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1518094651855349
    mean_env_wait_ms: 1.1791229421238958
    mean_inference_ms: 4.6601230147040225
    mean_raw_obs_processing_ms: 0.3990028792026067
  time_since_restore: 375.00765323638916
  time_this_iter_s: 26.770517826080322
  time_total_s: 375.00765323638916
  timers:
    learn_throughput: 8305.159
    learn_time_ms: 19480.904
    sample_throughput: 23267.816
    sample_time_ms: 6953.468
    update_time_ms: 35.644
  timestamp: 1602519247
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 102c7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_102c7_00000 | RUNNING  | 172.17.0.4:78955 |     14 |          375.008 | 2265088 |  235.171 |              285.111 |               131.02 |            844.725 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_102c7_00000:
  custom_metrics:
    time_step_max: 4191
    time_step_mean: 3492.4182658137884
    time_step_min: 3174
  date: 2020-10-12_16-14-34
  done: false
  episode_len_mean: 842.2617874736102
  episode_reward_max: 289.2020202020201
  episode_reward_mean: 236.75309392304453
  episode_reward_min: 131.02020202020162
  episodes_this_iter: 238
  episodes_total: 2842
  experiment_id: 9e70ee58519e42ea9a1f64b9d00bc678
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.942160944143931
        entropy_coeff: 0.009999999999999998
        kl: 0.008490514087801179
        model: {}
        policy_loss: -0.014706799091072753
        total_loss: 12.115392843882242
        vf_explained_var: 0.9794173836708069
        vf_loss: 12.137823581695557
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.24193548387096
    gpu_util_percent0: 0.3922580645161291
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.767741935483871
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 78955
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15146778042746853
    mean_env_wait_ms: 1.1803250689879987
    mean_inference_ms: 4.638216517319929
    mean_raw_obs_processing_ms: 0.39782775230984546
  time_since_restore: 401.7102859020233
  time_this_iter_s: 26.702632665634155
  time_total_s: 401.7102859020233
  timers:
    learn_throughput: 8305.395
    learn_time_ms: 19480.349
    sample_throughput: 23186.208
    sample_time_ms: 6977.941
    update_time_ms: 35.39
  timestamp: 1602519274
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 102c7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_102c7_00000 | RUNNING  | 172.17.0.4:78955 |     15 |           401.71 | 2426880 |  236.753 |              289.202 |               131.02 |            842.262 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_102c7_00000:
  custom_metrics:
    time_step_max: 4191
    time_step_mean: 3486.1889710827168
    time_step_min: 3161
  date: 2020-10-12_16-15-00
  done: false
  episode_len_mean: 840.8840772818121
  episode_reward_max: 289.2020202020201
  episode_reward_mean: 237.62766573126316
  episode_reward_min: 131.02020202020162
  episodes_this_iter: 160
  episodes_total: 3002
  experiment_id: 9e70ee58519e42ea9a1f64b9d00bc678
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9235694805781046
        entropy_coeff: 0.009999999999999998
        kl: 0.009157230999941627
        model: {}
        policy_loss: -0.016581699920304043
        total_loss: 10.273125410079956
        vf_explained_var: 0.9800928235054016
        vf_loss: 10.29711111386617
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.374193548387098
    gpu_util_percent0: 0.30580645161290315
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.783870967741935
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 78955
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15126416047244137
    mean_env_wait_ms: 1.1810708401494525
    mean_inference_ms: 4.624949081914499
    mean_raw_obs_processing_ms: 0.39710960963881753
  time_since_restore: 428.24319434165955
  time_this_iter_s: 26.53290843963623
  time_total_s: 428.24319434165955
  timers:
    learn_throughput: 8302.953
    learn_time_ms: 19486.08
    sample_throughput: 23213.074
    sample_time_ms: 6969.865
    update_time_ms: 35.975
  timestamp: 1602519300
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 102c7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_102c7_00000 | RUNNING  | 172.17.0.4:78955 |     16 |          428.243 | 2588672 |  237.628 |              289.202 |               131.02 |            840.884 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_102c7_00000:
  custom_metrics:
    time_step_max: 4191
    time_step_mean: 3479.985955952761
    time_step_min: 3161
  date: 2020-10-12_16-15-27
  done: false
  episode_len_mean: 839.0246757355268
  episode_reward_max: 289.2020202020201
  episode_reward_mean: 238.59030354158466
  episode_reward_min: 131.02020202020162
  episodes_this_iter: 159
  episodes_total: 3161
  experiment_id: 9e70ee58519e42ea9a1f64b9d00bc678
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9002384146054586
        entropy_coeff: 0.009999999999999998
        kl: 0.008823334239423275
        model: {}
        policy_loss: -0.014316967102786293
        total_loss: 9.811589002609253
        vf_explained_var: 0.9800631999969482
        vf_loss: 9.833143870035807
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.887096774193548
    gpu_util_percent0: 0.31322580645161285
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7838709677419353
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 78955
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15107607853956423
    mean_env_wait_ms: 1.181802698644644
    mean_inference_ms: 4.612676322933889
    mean_raw_obs_processing_ms: 0.3964359620714325
  time_since_restore: 454.8900806903839
  time_this_iter_s: 26.646886348724365
  time_total_s: 454.8900806903839
  timers:
    learn_throughput: 8302.699
    learn_time_ms: 19486.676
    sample_throughput: 23173.082
    sample_time_ms: 6981.894
    update_time_ms: 35.819
  timestamp: 1602519327
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 102c7_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_102c7_00000 | RUNNING  | 172.17.0.4:78955 |     17 |           454.89 | 2750464 |   238.59 |              289.202 |               131.02 |            839.025 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_102c7_00000:
  custom_metrics:
    time_step_max: 4191
    time_step_mean: 3470.5882180539274
    time_step_min: 3161
  date: 2020-10-12_16-15-54
  done: false
  episode_len_mean: 835.390988372093
  episode_reward_max: 289.2020202020201
  episode_reward_mean: 240.06794691097002
  episode_reward_min: 131.02020202020162
  episodes_this_iter: 279
  episodes_total: 3440
  experiment_id: 9e70ee58519e42ea9a1f64b9d00bc678
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8722178886334101
        entropy_coeff: 0.009999999999999998
        kl: 0.007830238707053164
        model: {}
        policy_loss: -0.012160427926573902
        total_loss: 12.402774810791016
        vf_explained_var: 0.9821564555168152
        vf_loss: 12.422091007232666
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.190322580645162
    gpu_util_percent0: 0.2516129032258065
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.761290322580645
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 78955
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1507798018173725
    mean_env_wait_ms: 1.1831554698122715
    mean_inference_ms: 4.593088386769362
    mean_raw_obs_processing_ms: 0.39537942941604926
  time_since_restore: 481.4604148864746
  time_this_iter_s: 26.5703341960907
  time_total_s: 481.4604148864746
  timers:
    learn_throughput: 8297.767
    learn_time_ms: 19498.258
    sample_throughput: 23169.609
    sample_time_ms: 6982.94
    update_time_ms: 33.838
  timestamp: 1602519354
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 102c7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_102c7_00000 | RUNNING  | 172.17.0.4:78955 |     18 |           481.46 | 2912256 |  240.068 |              289.202 |               131.02 |            835.391 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_102c7_00000:
  custom_metrics:
    time_step_max: 4191
    time_step_mean: 3463.726566833056
    time_step_min: 3161
  date: 2020-10-12_16-16-21
  done: false
  episode_len_mean: 833.0035773252614
  episode_reward_max: 291.6262626262628
  episode_reward_mean: 241.07482085577837
  episode_reward_min: 131.02020202020162
  episodes_this_iter: 194
  episodes_total: 3634
  experiment_id: 9e70ee58519e42ea9a1f64b9d00bc678
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.882185697555542
        entropy_coeff: 0.009999999999999998
        kl: 0.006953642121516168
        model: {}
        policy_loss: -0.012641504678564766
        total_loss: 10.862824281056723
        vf_explained_var: 0.9792599678039551
        vf_loss: 10.882896900177002
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.377419354838715
    gpu_util_percent0: 0.2803225806451613
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903227
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 78955
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15059152416994026
    mean_env_wait_ms: 1.184005052677095
    mean_inference_ms: 4.581181039473113
    mean_raw_obs_processing_ms: 0.39473374688363144
  time_since_restore: 508.0213782787323
  time_this_iter_s: 26.56096339225769
  time_total_s: 508.0213782787323
  timers:
    learn_throughput: 8283.566
    learn_time_ms: 19531.684
    sample_throughput: 23210.217
    sample_time_ms: 6970.723
    update_time_ms: 34.743
  timestamp: 1602519381
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 102c7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_102c7_00000 | RUNNING  | 172.17.0.4:78955 |     19 |          508.021 | 3074048 |  241.075 |              291.626 |               131.02 |            833.004 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_102c7_00000:
  custom_metrics:
    time_step_max: 4191
    time_step_mean: 3458.8060573857597
    time_step_min: 3161
  date: 2020-10-12_16-16-47
  done: false
  episode_len_mean: 831.6292194092827
  episode_reward_max: 293.14141414141415
  episode_reward_mean: 241.82077100115066
  episode_reward_min: 131.02020202020162
  episodes_this_iter: 158
  episodes_total: 3792
  experiment_id: 9e70ee58519e42ea9a1f64b9d00bc678
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8794340044260025
        entropy_coeff: 0.009999999999999998
        kl: 0.007723449457747241
        model: {}
        policy_loss: -0.013244249877364686
        total_loss: 9.308419386545816
        vf_explained_var: 0.9806717038154602
        vf_loss: 9.32891313234965
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.625806451612913
    gpu_util_percent0: 0.3080645161290323
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7838709677419344
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 78955
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15045272107380117
    mean_env_wait_ms: 1.1846777091376943
    mean_inference_ms: 4.572056234620662
    mean_raw_obs_processing_ms: 0.3942366011925718
  time_since_restore: 534.4065370559692
  time_this_iter_s: 26.38515877723694
  time_total_s: 534.4065370559692
  timers:
    learn_throughput: 8285.15
    learn_time_ms: 19527.951
    sample_throughput: 23221.386
    sample_time_ms: 6967.37
    update_time_ms: 35.107
  timestamp: 1602519407
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 102c7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_102c7_00000 | RUNNING  | 172.17.0.4:78955 |     20 |          534.407 | 3235840 |  241.821 |              293.141 |               131.02 |            831.629 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_102c7_00000:
  custom_metrics:
    time_step_max: 4191
    time_step_mean: 3453.252392947103
    time_step_min: 3146
  date: 2020-10-12_16-17-14
  done: false
  episode_len_mean: 829.6193096548274
  episode_reward_max: 293.14141414141415
  episode_reward_mean: 242.70013289473007
  episode_reward_min: 131.02020202020162
  episodes_this_iter: 206
  episodes_total: 3998
  experiment_id: 9e70ee58519e42ea9a1f64b9d00bc678
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8396754314502081
        entropy_coeff: 0.009999999999999998
        kl: 0.009555537719279528
        model: {}
        policy_loss: -0.012708824661482746
        total_loss: 12.030537525812784
        vf_explained_var: 0.980280339717865
        vf_loss: 12.049732128779093
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.777419354838713
    gpu_util_percent0: 0.262258064516129
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.777419354838709
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 78955
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15028708304595584
    mean_env_wait_ms: 1.1856030402527131
    mean_inference_ms: 4.561148800978762
    mean_raw_obs_processing_ms: 0.393633242359906
  time_since_restore: 561.0392868518829
  time_this_iter_s: 26.632749795913696
  time_total_s: 561.0392868518829
  timers:
    learn_throughput: 8288.21
    learn_time_ms: 19520.741
    sample_throughput: 23199.613
    sample_time_ms: 6973.91
    update_time_ms: 34.473
  timestamp: 1602519434
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 102c7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_102c7_00000 | RUNNING  | 172.17.0.4:78955 |     21 |          561.039 | 3397632 |    242.7 |              293.141 |               131.02 |            829.619 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_102c7_00000:
  custom_metrics:
    time_step_max: 4191
    time_step_mean: 3445.9284702549576
    time_step_min: 3139
  date: 2020-10-12_16-17-40
  done: false
  episode_len_mean: 827.4655253283302
  episode_reward_max: 293.14141414141415
  episode_reward_mean: 243.81669414596234
  episode_reward_min: 131.02020202020162
  episodes_this_iter: 266
  episodes_total: 4264
  experiment_id: 9e70ee58519e42ea9a1f64b9d00bc678
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8472862044970194
        entropy_coeff: 0.009999999999999998
        kl: 0.008006552428317567
        model: {}
        policy_loss: -0.013076546194497496
        total_loss: 10.48032832145691
        vf_explained_var: 0.9833491444587708
        vf_loss: 10.500276645024618
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.626666666666672
    gpu_util_percent0: 0.37000000000000005
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666657
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 78955
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15008989941752046
    mean_env_wait_ms: 1.1866426526708131
    mean_inference_ms: 4.547972538569563
    mean_raw_obs_processing_ms: 0.3929172443703756
  time_since_restore: 587.3895330429077
  time_this_iter_s: 26.35024619102478
  time_total_s: 587.3895330429077
  timers:
    learn_throughput: 8284.866
    learn_time_ms: 19528.62
    sample_throughput: 23269.407
    sample_time_ms: 6952.992
    update_time_ms: 32.315
  timestamp: 1602519460
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 102c7_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_102c7_00000 | RUNNING  | 172.17.0.4:78955 |     22 |           587.39 | 3559424 |  243.817 |              293.141 |               131.02 |            827.466 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_102c7_00000:
  custom_metrics:
    time_step_max: 4191
    time_step_mean: 3442.2172429481348
    time_step_min: 3139
  date: 2020-10-12_16-18-07
  done: true
  episode_len_mean: 826.1672694394214
  episode_reward_max: 293.14141414141415
  episode_reward_mean: 244.47097329534026
  episode_reward_min: 131.02020202020162
  episodes_this_iter: 160
  episodes_total: 4424
  experiment_id: 9e70ee58519e42ea9a1f64b9d00bc678
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8381559501091639
        entropy_coeff: 0.009999999999999998
        kl: 0.009343326945478717
        model: {}
        policy_loss: -0.015623889378427217
        total_loss: 8.732154051462809
        vf_explained_var: 0.9818219542503357
        vf_loss: 8.75429081916809
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.1
    gpu_util_percent0: 0.41129032258064524
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 78955
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14998026724886732
    mean_env_wait_ms: 1.1872245893226627
    mean_inference_ms: 4.5406822706478245
    mean_raw_obs_processing_ms: 0.39251409839821905
  time_since_restore: 613.6320834159851
  time_this_iter_s: 26.242550373077393
  time_total_s: 613.6320834159851
  timers:
    learn_throughput: 8290.503
    learn_time_ms: 19515.342
    sample_throughput: 23337.496
    sample_time_ms: 6932.706
    update_time_ms: 31.337
  timestamp: 1602519487
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 102c7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_102c7_00000 | TERMINATED |       |     23 |          613.632 | 3721216 |  244.471 |              293.141 |               131.02 |            826.167 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_102c7_00000 | TERMINATED |       |     23 |          613.632 | 3721216 |  244.471 |              293.141 |               131.02 |            826.167 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


