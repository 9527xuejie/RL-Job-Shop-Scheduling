2020-10-11 22:58:30,883	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_48e69_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=63297)[0m 2020-10-11 22:58:33,664	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=63273)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63273)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63256)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63256)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63283)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63283)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63266)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63266)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63274)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63274)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63236)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63236)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63257)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63257)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63301)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63301)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63254)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63254)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63282)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63282)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63296)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63296)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63272)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63272)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63230)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63230)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63306)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63306)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63300)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63300)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63261)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63261)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63303)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63303)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63263)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63263)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63262)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63262)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63251)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63251)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63267)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63267)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63194)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63194)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63184)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63184)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63180)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63180)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63259)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63259)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63228)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63228)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63276)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63276)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63241)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63241)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63240)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63240)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63176)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63176)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63179)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63179)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63289)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63289)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63191)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63191)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63200)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63200)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63177)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63177)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63188)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63188)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63192)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63192)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63234)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63234)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63291)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63291)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63280)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63280)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63226)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63226)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63252)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63252)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63193)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63193)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63264)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63264)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63213)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63213)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63198)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63198)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63206)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63206)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63278)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63278)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63299)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63299)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63253)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63253)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63284)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63284)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63190)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63190)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63185)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63185)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63195)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63195)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63260)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63260)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63270)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63270)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63295)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63295)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63237)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63237)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63178)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63178)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63189)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63189)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63258)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63258)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63199)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63199)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63181)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63181)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63197)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63197)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63250)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63250)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63211)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63211)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63208)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63208)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63233)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63233)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63269)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63269)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63186)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63186)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63215)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63215)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63245)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63245)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63204)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63204)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63287)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63287)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63292)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63292)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63201)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63201)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63182)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63182)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63255)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63255)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=63209)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=63209)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_48e69_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_22-59-07
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 8bc81864dac548238b7f4bf57cbe95cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.1862151523431141
        entropy_coeff: 0.0001
        kl: 0.00294280801123629
        model: {}
        policy_loss: -0.007659459273175647
        total_loss: 507.076416015625
        vf_explained_var: 0.540532648563385
        vf_loss: 507.0832926432292
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.57428571428571
    gpu_util_percent0: 0.3305714285714285
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5485714285714285
    vram_util_percent0: 0.08529494447828329
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 63297
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16727963359534795
    mean_env_wait_ms: 1.1655860522824624
    mean_inference_ms: 5.985251079558148
    mean_raw_obs_processing_ms: 0.4505250835978128
  time_since_restore: 28.254497289657593
  time_this_iter_s: 28.254497289657593
  time_total_s: 28.254497289657593
  timers:
    learn_throughput: 8637.176
    learn_time_ms: 18732.048
    sample_throughput: 17128.7
    sample_time_ms: 9445.667
    update_time_ms: 50.652
  timestamp: 1602457147
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 48e69_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_48e69_00000 | RUNNING  | 172.17.0.4:63297 |      1 |          28.2545 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_48e69_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3619.4236111111113
    time_step_min: 3336
  date: 2020-10-11_22-59-33
  done: false
  episode_len_mean: 890.6740506329114
  episode_reward_max: 264.35353535353516
  episode_reward_mean: 216.3409730213525
  episode_reward_min: 141.47474747474692
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 8bc81864dac548238b7f4bf57cbe95cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.1579083601633708
        entropy_coeff: 0.0001
        kl: 0.0058007537154480815
        model: {}
        policy_loss: -0.010627713326054314
        total_loss: 137.44344329833984
        vf_explained_var: 0.7980544567108154
        vf_loss: 137.45331446329752
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.384375
    gpu_util_percent0: 0.3628125
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7531250000000003
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 63297
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16271934056063297
    mean_env_wait_ms: 1.1627110508155212
    mean_inference_ms: 5.660226854785439
    mean_raw_obs_processing_ms: 0.43692795328238854
  time_since_restore: 54.75507473945618
  time_this_iter_s: 26.500577449798584
  time_total_s: 54.75507473945618
  timers:
    learn_throughput: 8640.966
    learn_time_ms: 18723.832
    sample_throughput: 18889.448
    sample_time_ms: 8565.205
    update_time_ms: 48.114
  timestamp: 1602457173
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 48e69_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_48e69_00000 | RUNNING  | 172.17.0.4:63297 |      2 |          54.7551 | 323584 |  216.341 |              264.354 |              141.475 |            890.674 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_48e69_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3623.269058295964
    time_step_min: 3336
  date: 2020-10-11_22-59-59
  done: false
  episode_len_mean: 887.3502109704641
  episode_reward_max: 264.35353535353516
  episode_reward_mean: 217.6887866001788
  episode_reward_min: 141.47474747474692
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 8bc81864dac548238b7f4bf57cbe95cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.1487484375635784
        entropy_coeff: 0.0001
        kl: 0.007445503103857239
        model: {}
        policy_loss: -0.012628068157937378
        total_loss: 61.94243876139323
        vf_explained_var: 0.8913432955741882
        vf_loss: 61.95406564076742
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.78064516129032
    gpu_util_percent0: 0.357741935483871
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 63297
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15998993136426443
    mean_env_wait_ms: 1.1621089651416092
    mean_inference_ms: 5.439936356684219
    mean_raw_obs_processing_ms: 0.4280483867741837
  time_since_restore: 80.29962754249573
  time_this_iter_s: 25.54455280303955
  time_total_s: 80.29962754249573
  timers:
    learn_throughput: 8671.511
    learn_time_ms: 18657.88
    sample_throughput: 20163.844
    sample_time_ms: 8023.867
    update_time_ms: 39.795
  timestamp: 1602457199
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 48e69_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_48e69_00000 | RUNNING  | 172.17.0.4:63297 |      3 |          80.2996 | 485376 |  217.689 |              264.354 |              141.475 |             887.35 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_48e69_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3607.8509933774835
    time_step_min: 3254
  date: 2020-10-11_23-00-25
  done: false
  episode_len_mean: 886.4731012658228
  episode_reward_max: 272.9898989898991
  episode_reward_mean: 219.43576588671502
  episode_reward_min: 141.47474747474692
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 8bc81864dac548238b7f4bf57cbe95cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.1361864705880482
        entropy_coeff: 0.0001
        kl: 0.007402953808195889
        model: {}
        policy_loss: -0.010153844331701597
        total_loss: 43.715614318847656
        vf_explained_var: 0.9209535121917725
        vf_loss: 43.72477149963379
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.40967741935484
    gpu_util_percent0: 0.3864516129032258
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 63297
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15812586394634143
    mean_env_wait_ms: 1.1617186677774514
    mean_inference_ms: 5.284398535816259
    mean_raw_obs_processing_ms: 0.4214738525100561
  time_since_restore: 106.01669096946716
  time_this_iter_s: 25.717063426971436
  time_total_s: 106.01669096946716
  timers:
    learn_throughput: 8665.374
    learn_time_ms: 18671.094
    sample_throughput: 20890.742
    sample_time_ms: 7744.675
    update_time_ms: 41.306
  timestamp: 1602457225
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 48e69_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_48e69_00000 | RUNNING  | 172.17.0.4:63297 |      4 |          106.017 | 647168 |  219.436 |               272.99 |              141.475 |            886.473 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_48e69_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3599.787401574803
    time_step_min: 3254
  date: 2020-10-11_23-00-50
  done: false
  episode_len_mean: 883.8088607594937
  episode_reward_max: 272.9898989898991
  episode_reward_mean: 220.40762050888617
  episode_reward_min: 141.47474747474692
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 8bc81864dac548238b7f4bf57cbe95cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.1127756138642628
        entropy_coeff: 0.0001
        kl: 0.00739862653426826
        model: {}
        policy_loss: -0.013200833762918288
        total_loss: 31.10459327697754
        vf_explained_var: 0.9458571076393127
        vf_loss: 31.116795698801678
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.490322580645163
    gpu_util_percent0: 0.41290322580645156
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 63297
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15677254549156155
    mean_env_wait_ms: 1.161981610814199
    mean_inference_ms: 5.170526786891286
    mean_raw_obs_processing_ms: 0.41655624719901707
  time_since_restore: 131.50379490852356
  time_this_iter_s: 25.487103939056396
  time_total_s: 131.50379490852356
  timers:
    learn_throughput: 8686.473
    learn_time_ms: 18625.741
    sample_throughput: 21317.177
    sample_time_ms: 7589.748
    update_time_ms: 38.619
  timestamp: 1602457250
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 48e69_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_48e69_00000 | RUNNING  | 172.17.0.4:63297 |      5 |          131.504 | 808960 |  220.408 |               272.99 |              141.475 |            883.809 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_48e69_00000:
  custom_metrics:
    time_step_max: 4227
    time_step_mean: 3589.1315014720312
    time_step_min: 3251
  date: 2020-10-11_23-01-16
  done: false
  episode_len_mean: 876.9608404966572
  episode_reward_max: 273.44444444444366
  episode_reward_mean: 222.32493994385092
  episode_reward_min: 125.56565656565654
  episodes_this_iter: 257
  episodes_total: 1047
  experiment_id: 8bc81864dac548238b7f4bf57cbe95cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.0918969015280406
        entropy_coeff: 0.0001
        kl: 0.00705903194223841
        model: {}
        policy_loss: -0.012454878218704835
        total_loss: 37.31601619720459
        vf_explained_var: 0.9562029242515564
        vf_loss: 37.32752068837484
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.506451612903227
    gpu_util_percent0: 0.3696774193548388
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.754838709677419
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 63297
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1552336033013439
    mean_env_wait_ms: 1.1643612169331357
    mean_inference_ms: 5.039490911342677
    mean_raw_obs_processing_ms: 0.41102246488873273
  time_since_restore: 157.01151251792908
  time_this_iter_s: 25.507717609405518
  time_total_s: 157.01151251792908
  timers:
    learn_throughput: 8705.151
    learn_time_ms: 18585.778
    sample_throughput: 21599.337
    sample_time_ms: 7490.6
    update_time_ms: 35.791
  timestamp: 1602457276
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 48e69_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_48e69_00000 | RUNNING  | 172.17.0.4:63297 |      6 |          157.012 | 970752 |  222.325 |              273.444 |              125.566 |            876.961 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_48e69_00000:
  custom_metrics:
    time_step_max: 4227
    time_step_mean: 3578.895631067961
    time_step_min: 3212
  date: 2020-10-11_23-01-42
  done: false
  episode_len_mean: 872.5601265822785
  episode_reward_max: 279.35353535353556
  episode_reward_mean: 223.7384845288325
  episode_reward_min: 125.56565656565654
  episodes_this_iter: 217
  episodes_total: 1264
  experiment_id: 8bc81864dac548238b7f4bf57cbe95cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.0996176103750865
        entropy_coeff: 0.0001
        kl: 0.0075638447888195515
        model: {}
        policy_loss: -0.014368308041108927
        total_loss: 21.99579095840454
        vf_explained_var: 0.9647292494773865
        vf_loss: 22.00913413365682
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.2741935483871
    gpu_util_percent0: 0.3132258064516129
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 63297
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1542931453351651
    mean_env_wait_ms: 1.1657399027311919
    mean_inference_ms: 4.961918012436782
    mean_raw_obs_processing_ms: 0.40775165258405904
  time_since_restore: 182.734929561615
  time_this_iter_s: 25.723417043685913
  time_total_s: 182.734929561615
  timers:
    learn_throughput: 8698.853
    learn_time_ms: 18599.233
    sample_throughput: 21829.853
    sample_time_ms: 7411.502
    update_time_ms: 37.152
  timestamp: 1602457302
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 48e69_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_48e69_00000 | RUNNING  | 172.17.0.4:63297 |      7 |          182.735 | 1132544 |  223.738 |              279.354 |              125.566 |             872.56 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_48e69_00000:
  custom_metrics:
    time_step_max: 4227
    time_step_mean: 3569.741032998565
    time_step_min: 3212
  date: 2020-10-11_23-02-08
  done: false
  episode_len_mean: 870.267229254571
  episode_reward_max: 279.35353535353556
  episode_reward_mean: 225.29864041256428
  episode_reward_min: 125.56565656565654
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 8bc81864dac548238b7f4bf57cbe95cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.075473149617513
        entropy_coeff: 0.0001
        kl: 0.0073449914731706185
        model: {}
        policy_loss: -0.011191240007368227
        total_loss: 15.782279968261719
        vf_explained_var: 0.9715707898139954
        vf_loss: 15.792476892471313
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.461290322580652
    gpu_util_percent0: 0.362258064516129
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.777419354838709
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 63297
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15373639278078333
    mean_env_wait_ms: 1.1666940755623367
    mean_inference_ms: 4.915687256243531
    mean_raw_obs_processing_ms: 0.40581957102450994
  time_since_restore: 208.60487818717957
  time_this_iter_s: 25.869948625564575
  time_total_s: 208.60487818717957
  timers:
    learn_throughput: 8692.274
    learn_time_ms: 18613.311
    sample_throughput: 21958.759
    sample_time_ms: 7367.994
    update_time_ms: 38.003
  timestamp: 1602457328
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 48e69_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_48e69_00000 | RUNNING  | 172.17.0.4:63297 |      8 |          208.605 | 1294336 |  225.299 |              279.354 |              125.566 |            870.267 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_48e69_00000:
  custom_metrics:
    time_step_max: 4227
    time_step_mean: 3560.5940721649486
    time_step_min: 3212
  date: 2020-10-11_23-02-33
  done: false
  episode_len_mean: 867.7240506329114
  episode_reward_max: 279.35353535353556
  episode_reward_mean: 226.71343178621646
  episode_reward_min: 125.56565656565654
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 8bc81864dac548238b7f4bf57cbe95cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.0578030447165172
        entropy_coeff: 0.0001
        kl: 0.00733223386729757
        model: {}
        policy_loss: -0.011695607642953595
        total_loss: 19.945802688598633
        vf_explained_var: 0.962311327457428
        vf_loss: 19.956504662831623
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.4
    gpu_util_percent0: 0.3729032258064516
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 63297
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15325171860866182
    mean_env_wait_ms: 1.1675698225737017
    mean_inference_ms: 4.875640571621494
    mean_raw_obs_processing_ms: 0.404107640804782
  time_since_restore: 234.06865334510803
  time_this_iter_s: 25.463775157928467
  time_total_s: 234.06865334510803
  timers:
    learn_throughput: 8698.641
    learn_time_ms: 18599.688
    sample_throughput: 22116.797
    sample_time_ms: 7315.345
    update_time_ms: 37.004
  timestamp: 1602457353
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 48e69_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_48e69_00000 | RUNNING  | 172.17.0.4:63297 |      9 |          234.069 | 1456128 |  226.713 |              279.354 |              125.566 |            867.724 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_48e69_00000:
  custom_metrics:
    time_step_max: 4227
    time_step_mean: 3548.992402104033
    time_step_min: 3212
  date: 2020-10-11_23-02-59
  done: false
  episode_len_mean: 864.8815411155837
  episode_reward_max: 284.8080808080811
  episode_reward_mean: 228.44217912303
  episode_reward_min: 125.56565656565654
  episodes_this_iter: 159
  episodes_total: 1739
  experiment_id: 8bc81864dac548238b7f4bf57cbe95cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.0201811095078785
        entropy_coeff: 0.0001
        kl: 0.006328966584987938
        model: {}
        policy_loss: -0.010433927411213517
        total_loss: 15.396056572596232
        vf_explained_var: 0.9729864597320557
        vf_loss: 15.405643304189047
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.62258064516129
    gpu_util_percent0: 0.32806451612903226
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 63297
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15282958471327382
    mean_env_wait_ms: 1.168397806100334
    mean_inference_ms: 4.840412396476564
    mean_raw_obs_processing_ms: 0.40254645871991523
  time_since_restore: 259.88638257980347
  time_this_iter_s: 25.817729234695435
  time_total_s: 259.88638257980347
  timers:
    learn_throughput: 8690.636
    learn_time_ms: 18616.82
    sample_throughput: 22227.828
    sample_time_ms: 7278.804
    update_time_ms: 37.495
  timestamp: 1602457379
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 48e69_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_48e69_00000 | RUNNING  | 172.17.0.4:63297 |     10 |          259.886 | 1617920 |  228.442 |              284.808 |              125.566 |            864.882 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_48e69_00000:
  custom_metrics:
    time_step_max: 4227
    time_step_mean: 3530.49751984127
    time_step_min: 3102
  date: 2020-10-11_23-03-25
  done: false
  episode_len_mean: 859.2348336594912
  episode_reward_max: 296.02020202020174
  episode_reward_mean: 231.1995888434243
  episode_reward_min: 125.56565656565654
  episodes_this_iter: 305
  episodes_total: 2044
  experiment_id: 8bc81864dac548238b7f4bf57cbe95cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.0036811729272206
        entropy_coeff: 0.0001
        kl: 0.00579226886232694
        model: {}
        policy_loss: -0.009194890964863589
        total_loss: 24.079482873280842
        vf_explained_var: 0.968719482421875
        vf_loss: 24.087908903757732
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.112903225806456
    gpu_util_percent0: 0.3890322580645162
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7580645161290316
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 63297
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1521527529243919
    mean_env_wait_ms: 1.170161361662686
    mean_inference_ms: 4.784654960080414
    mean_raw_obs_processing_ms: 0.4001578634725041
  time_since_restore: 285.5384020805359
  time_this_iter_s: 25.652019500732422
  time_total_s: 285.5384020805359
  timers:
    learn_throughput: 8695.666
    learn_time_ms: 18606.05
    sample_throughput: 23016.099
    sample_time_ms: 7029.514
    update_time_ms: 34.671
  timestamp: 1602457405
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 48e69_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_48e69_00000 | RUNNING  | 172.17.0.4:63297 |     11 |          285.538 | 1779712 |    231.2 |               296.02 |              125.566 |            859.235 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_48e69_00000:
  custom_metrics:
    time_step_max: 4227
    time_step_mean: 3522.3914835164837
    time_step_min: 3102
  date: 2020-10-11_23-03-50
  done: false
  episode_len_mean: 856.7007233273056
  episode_reward_max: 296.02020202020174
  episode_reward_mean: 232.6089192101849
  episode_reward_min: 125.56565656565654
  episodes_this_iter: 168
  episodes_total: 2212
  experiment_id: 8bc81864dac548238b7f4bf57cbe95cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9880742480357488
        entropy_coeff: 0.0001
        kl: 0.00625619226290534
        model: {}
        policy_loss: -0.010162066668272018
        total_loss: 13.876621723175049
        vf_explained_var: 0.9752354621887207
        vf_loss: 13.885944128036499
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.612903225806456
    gpu_util_percent0: 0.4045161290322581
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 63297
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15184517098792732
    mean_env_wait_ms: 1.171003458444195
    mean_inference_ms: 4.759321961170983
    mean_raw_obs_processing_ms: 0.39905846291628805
  time_since_restore: 311.10560727119446
  time_this_iter_s: 25.56720519065857
  time_total_s: 311.10560727119446
  timers:
    learn_throughput: 8703.207
    learn_time_ms: 18589.929
    sample_throughput: 23267.523
    sample_time_ms: 6953.555
    update_time_ms: 33.631
  timestamp: 1602457430
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 48e69_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_48e69_00000 | RUNNING  | 172.17.0.4:63297 |     12 |          311.106 | 1941504 |  232.609 |               296.02 |              125.566 |            856.701 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_48e69_00000:
  custom_metrics:
    time_step_max: 4227
    time_step_mean: 3514.689581554227
    time_step_min: 3102
  date: 2020-10-11_23-04-16
  done: false
  episode_len_mean: 853.9316455696203
  episode_reward_max: 296.02020202020174
  episode_reward_mean: 233.8170310701955
  episode_reward_min: 125.56565656565654
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: 8bc81864dac548238b7f4bf57cbe95cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9721720417340597
        entropy_coeff: 0.0001
        kl: 0.006670392428835233
        model: {}
        policy_loss: -0.011607924049409727
        total_loss: 13.177153905232748
        vf_explained_var: 0.9741199612617493
        vf_loss: 13.18785826365153
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.416129032258066
    gpu_util_percent0: 0.4174193548387097
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 63297
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15158309937029374
    mean_env_wait_ms: 1.1717594353167136
    mean_inference_ms: 4.737679768486558
    mean_raw_obs_processing_ms: 0.3980906516996171
  time_since_restore: 336.59609866142273
  time_this_iter_s: 25.49049139022827
  time_total_s: 336.59609866142273
  timers:
    learn_throughput: 8702.581
    learn_time_ms: 18591.266
    sample_throughput: 23300.05
    sample_time_ms: 6943.848
    update_time_ms: 36.354
  timestamp: 1602457456
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 48e69_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_48e69_00000 | RUNNING  | 172.17.0.4:63297 |     13 |          336.596 | 2103296 |  233.817 |               296.02 |              125.566 |            853.932 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_48e69_00000:
  custom_metrics:
    time_step_max: 4227
    time_step_mean: 3506.426517571885
    time_step_min: 3102
  date: 2020-10-11_23-04-42
  done: false
  episode_len_mean: 851.1998420221169
  episode_reward_max: 296.02020202020174
  episode_reward_mean: 235.12427593470235
  episode_reward_min: 125.56565656565654
  episodes_this_iter: 162
  episodes_total: 2532
  experiment_id: 8bc81864dac548238b7f4bf57cbe95cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9430739482243856
        entropy_coeff: 0.0001
        kl: 0.006305762644236286
        model: {}
        policy_loss: -0.011634490149541913
        total_loss: 13.086873213450113
        vf_explained_var: 0.977025032043457
        vf_loss: 13.097656091054281
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.29677419354839
    gpu_util_percent0: 0.3506451612903226
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770967741935483
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 63297
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15133365076945596
    mean_env_wait_ms: 1.1725777504840516
    mean_inference_ms: 4.717319543535857
    mean_raw_obs_processing_ms: 0.39715935400954855
  time_since_restore: 362.2361273765564
  time_this_iter_s: 25.640028715133667
  time_total_s: 362.2361273765564
  timers:
    learn_throughput: 8709.865
    learn_time_ms: 18575.718
    sample_throughput: 23290.628
    sample_time_ms: 6946.657
    update_time_ms: 40.496
  timestamp: 1602457482
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 48e69_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_48e69_00000 | RUNNING  | 172.17.0.4:63297 |     14 |          362.236 | 2265088 |  235.124 |               296.02 |              125.566 |              851.2 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_48e69_00000:
  custom_metrics:
    time_step_max: 4227
    time_step_mean: 3494.4085561497327
    time_step_min: 3102
  date: 2020-10-11_23-05-07
  done: false
  episode_len_mean: 847.4264031062478
  episode_reward_max: 296.02020202020174
  episode_reward_mean: 236.91094852513828
  episode_reward_min: 125.56565656565654
  episodes_this_iter: 301
  episodes_total: 2833
  experiment_id: 8bc81864dac548238b7f4bf57cbe95cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9282528956731161
        entropy_coeff: 0.0001
        kl: 0.005890571706307431
        model: {}
        policy_loss: -0.011069357162341475
        total_loss: 19.961422602335613
        vf_explained_var: 0.9731670022010803
        vf_loss: 19.971702257792156
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.803225806451614
    gpu_util_percent0: 0.3596774193548387
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7580645161290316
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 63297
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15094276090082046
    mean_env_wait_ms: 1.1740803497124825
    mean_inference_ms: 4.684613301493792
    mean_raw_obs_processing_ms: 0.39572041421466086
  time_since_restore: 387.79844427108765
  time_this_iter_s: 25.56231689453125
  time_total_s: 387.79844427108765
  timers:
    learn_throughput: 8712.317
    learn_time_ms: 18570.49
    sample_throughput: 23273.74
    sample_time_ms: 6951.698
    update_time_ms: 46.356
  timestamp: 1602457507
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 48e69_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_48e69_00000 | RUNNING  | 172.17.0.4:63297 |     15 |          387.798 | 2426880 |  236.911 |               296.02 |              125.566 |            847.426 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_48e69_00000:
  custom_metrics:
    time_step_max: 4227
    time_step_mean: 3488.558170813719
    time_step_min: 3102
  date: 2020-10-11_23-05-33
  done: false
  episode_len_mean: 845.3997335109926
  episode_reward_max: 296.02020202020174
  episode_reward_mean: 237.80042934340057
  episode_reward_min: 125.56565656565654
  episodes_this_iter: 169
  episodes_total: 3002
  experiment_id: 8bc81864dac548238b7f4bf57cbe95cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9187831381956736
        entropy_coeff: 0.0001
        kl: 0.005467495764605701
        model: {}
        policy_loss: -0.01129928109003231
        total_loss: 12.396842161814371
        vf_explained_var: 0.977431058883667
        vf_loss: 12.407412926355997
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.11666666666667
    gpu_util_percent0: 0.35566666666666674
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7866666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 63297
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15074568986899814
    mean_env_wait_ms: 1.1748347582597176
    mean_inference_ms: 4.668576661445401
    mean_raw_obs_processing_ms: 0.39500813088875303
  time_since_restore: 413.13722944259644
  time_this_iter_s: 25.33878517150879
  time_total_s: 413.13722944259644
  timers:
    learn_throughput: 8717.331
    learn_time_ms: 18559.809
    sample_throughput: 23278.942
    sample_time_ms: 6950.144
    update_time_ms: 46.22
  timestamp: 1602457533
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 48e69_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_48e69_00000 | RUNNING  | 172.17.0.4:63297 |     16 |          413.137 | 2588672 |    237.8 |               296.02 |              125.566 |              845.4 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_48e69_00000:
  custom_metrics:
    time_step_max: 4227
    time_step_mean: 3483.1340996168583
    time_step_min: 3102
  date: 2020-10-11_23-05-58
  done: false
  episode_len_mean: 843.6566455696203
  episode_reward_max: 296.02020202020174
  episode_reward_mean: 238.59106891701816
  episode_reward_min: 125.56565656565654
  episodes_this_iter: 158
  episodes_total: 3160
  experiment_id: 8bc81864dac548238b7f4bf57cbe95cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9104753931363424
        entropy_coeff: 0.0001
        kl: 0.005429654071728389
        model: {}
        policy_loss: -0.009332981154633066
        total_loss: 13.751052061716715
        vf_explained_var: 0.9732567667961121
        vf_loss: 13.759661595026651
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.12258064516129
    gpu_util_percent0: 0.3638709677419355
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7838709677419353
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 63297
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15057709627708885
    mean_env_wait_ms: 1.175519885629769
    mean_inference_ms: 4.6546736697785365
    mean_raw_obs_processing_ms: 0.3943808950045664
  time_since_restore: 438.4611427783966
  time_this_iter_s: 25.32391333580017
  time_total_s: 438.4611427783966
  timers:
    learn_throughput: 8729.95
    learn_time_ms: 18532.982
    sample_throughput: 23320.039
    sample_time_ms: 6937.896
    update_time_ms: 45.419
  timestamp: 1602457558
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 48e69_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_48e69_00000 | RUNNING  | 172.17.0.4:63297 |     17 |          438.461 | 2750464 |  238.591 |               296.02 |              125.566 |            843.657 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_48e69_00000:
  custom_metrics:
    time_step_max: 4227
    time_step_mean: 3477.3372513562385
    time_step_min: 3102
  date: 2020-10-11_23-06-24
  done: false
  episode_len_mean: 841.9208009563658
  episode_reward_max: 296.02020202020174
  episode_reward_mean: 239.40425172224326
  episode_reward_min: 125.56565656565654
  episodes_this_iter: 186
  episodes_total: 3346
  experiment_id: 8bc81864dac548238b7f4bf57cbe95cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.886641283830007
        entropy_coeff: 0.0001
        kl: 0.00620527445183446
        model: {}
        policy_loss: -0.011255039552149052
        total_loss: 13.679548025131226
        vf_explained_var: 0.978715181350708
        vf_loss: 13.689961036046347
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.458064516129035
    gpu_util_percent0: 0.3670967741935483
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 63297
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15038795922922749
    mean_env_wait_ms: 1.176320133200173
    mean_inference_ms: 4.639530972912769
    mean_raw_obs_processing_ms: 0.39368502699418917
  time_since_restore: 463.9178829193115
  time_this_iter_s: 25.456740140914917
  time_total_s: 463.9178829193115
  timers:
    learn_throughput: 8740.193
    learn_time_ms: 18511.262
    sample_throughput: 23384.12
    sample_time_ms: 6918.883
    update_time_ms: 43.532
  timestamp: 1602457584
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 48e69_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_48e69_00000 | RUNNING  | 172.17.0.4:63297 |     18 |          463.918 | 2912256 |  239.404 |               296.02 |              125.566 |            841.921 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_48e69_00000:
  custom_metrics:
    time_step_max: 4227
    time_step_mean: 3468.679166666667
    time_step_min: 3102
  date: 2020-10-11_23-06-50
  done: false
  episode_len_mean: 839.6113561190739
  episode_reward_max: 296.02020202020174
  episode_reward_mean: 240.68342743866435
  episode_reward_min: 125.56565656565654
  episodes_this_iter: 282
  episodes_total: 3628
  experiment_id: 8bc81864dac548238b7f4bf57cbe95cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.8755354881286621
        entropy_coeff: 0.0001
        kl: 0.005440560868009925
        model: {}
        policy_loss: -0.009500570168408254
        total_loss: 15.777640104293823
        vf_explained_var: 0.9773163199424744
        vf_loss: 15.786412556966146
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.377419354838707
    gpu_util_percent0: 0.39580645161290334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 63297
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15014217833807045
    mean_env_wait_ms: 1.1774390717825187
    mean_inference_ms: 4.6189541390243285
    mean_raw_obs_processing_ms: 0.3927739200880487
  time_since_restore: 489.66435408592224
  time_this_iter_s: 25.746471166610718
  time_total_s: 489.66435408592224
  timers:
    learn_throughput: 8730.501
    learn_time_ms: 18531.812
    sample_throughput: 23367.45
    sample_time_ms: 6923.819
    update_time_ms: 45.091
  timestamp: 1602457610
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 48e69_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_48e69_00000 | RUNNING  | 172.17.0.4:63297 |     19 |          489.664 | 3074048 |  240.683 |               296.02 |              125.566 |            839.611 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_48e69_00000:
  custom_metrics:
    time_step_max: 4227
    time_step_mean: 3464.4218916046757
    time_step_min: 3102
  date: 2020-10-11_23-07-15
  done: false
  episode_len_mean: 838.2054324894515
  episode_reward_max: 296.02020202020174
  episode_reward_mean: 241.375575373993
  episode_reward_min: 125.56565656565654
  episodes_this_iter: 164
  episodes_total: 3792
  experiment_id: 8bc81864dac548238b7f4bf57cbe95cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.8695132831732432
        entropy_coeff: 0.0001
        kl: 0.005018938526821633
        model: {}
        policy_loss: -0.013267358420610739
        total_loss: 10.960333267847696
        vf_explained_var: 0.9793431758880615
        vf_loss: 10.972934802373251
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.98387096774194
    gpu_util_percent0: 0.38354838709677425
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7774193548387096
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 63297
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15000855437150884
    mean_env_wait_ms: 1.1780273137071993
    mean_inference_ms: 4.6080369491574205
    mean_raw_obs_processing_ms: 0.3922768787758361
  time_since_restore: 515.1118485927582
  time_this_iter_s: 25.447494506835938
  time_total_s: 515.1118485927582
  timers:
    learn_throughput: 8742.679
    learn_time_ms: 18505.999
    sample_throughput: 23405.153
    sample_time_ms: 6912.666
    update_time_ms: 44.675
  timestamp: 1602457635
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 48e69_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_48e69_00000 | RUNNING  | 172.17.0.4:63297 |     20 |          515.112 | 3235840 |  241.376 |               296.02 |              125.566 |            838.205 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_48e69_00000:
  custom_metrics:
    time_step_max: 4227
    time_step_mean: 3460.1899541050484
    time_step_min: 3102
  date: 2020-10-11_23-07-41
  done: false
  episode_len_mean: 836.6521518987341
  episode_reward_max: 296.02020202020174
  episode_reward_mean: 242.02246515790807
  episode_reward_min: 125.56565656565654
  episodes_this_iter: 158
  episodes_total: 3950
  experiment_id: 8bc81864dac548238b7f4bf57cbe95cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.8560546189546585
        entropy_coeff: 0.0001
        kl: 0.005279934732243419
        model: {}
        policy_loss: -0.012147865762623647
        total_loss: 11.046411911646524
        vf_explained_var: 0.9777435660362244
        vf_loss: 11.05785338083903
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.158064516129034
    gpu_util_percent0: 0.34580645161290324
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7903225806451606
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 63297
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1498869510692123
    mean_env_wait_ms: 1.1786050154908079
    mean_inference_ms: 4.598147001836117
    mean_raw_obs_processing_ms: 0.39182392710075875
  time_since_restore: 540.764356136322
  time_this_iter_s: 25.652507543563843
  time_total_s: 540.764356136322
  timers:
    learn_throughput: 8739.867
    learn_time_ms: 18511.952
    sample_throughput: 23454.531
    sample_time_ms: 6898.113
    update_time_ms: 51.955
  timestamp: 1602457661
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 48e69_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_48e69_00000 | RUNNING  | 172.17.0.4:63297 |     21 |          540.764 | 3397632 |  242.022 |               296.02 |              125.566 |            836.652 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_48e69_00000:
  custom_metrics:
    time_step_max: 4227
    time_step_mean: 3453.6581278429494
    time_step_min: 3102
  date: 2020-10-11_23-08-07
  done: false
  episode_len_mean: 834.1678953626634
  episode_reward_max: 296.02020202020174
  episode_reward_mean: 243.04023589041415
  episode_reward_min: 125.56565656565654
  episodes_this_iter: 255
  episodes_total: 4205
  experiment_id: 8bc81864dac548238b7f4bf57cbe95cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.8309722244739532
        entropy_coeff: 0.0001
        kl: 0.005746861919760704
        model: {}
        policy_loss: -0.012008370579375574
        total_loss: 13.581704378128052
        vf_explained_var: 0.980219841003418
        vf_loss: 13.592933575312296
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.260000000000005
    gpu_util_percent0: 0.3483333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769999999999999
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 63297
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14969773067496872
    mean_env_wait_ms: 1.1795851253992111
    mean_inference_ms: 4.5831214823944055
    mean_raw_obs_processing_ms: 0.3911289411236421
  time_since_restore: 566.0584783554077
  time_this_iter_s: 25.294122219085693
  time_total_s: 566.0584783554077
  timers:
    learn_throughput: 8747.906
    learn_time_ms: 18494.94
    sample_throughput: 23492.469
    sample_time_ms: 6886.973
    update_time_ms: 51.591
  timestamp: 1602457687
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 48e69_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_48e69_00000 | RUNNING  | 172.17.0.4:63297 |     22 |          566.058 | 3559424 |   243.04 |               296.02 |              125.566 |            834.168 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_48e69_00000:
  custom_metrics:
    time_step_max: 4227
    time_step_mean: 3448.81483166515
    time_step_min: 3102
  date: 2020-10-11_23-08-32
  done: false
  episode_len_mean: 832.4093580470163
  episode_reward_max: 296.02020202020174
  episode_reward_mean: 243.80997817231986
  episode_reward_min: 125.56565656565654
  episodes_this_iter: 219
  episodes_total: 4424
  experiment_id: 8bc81864dac548238b7f4bf57cbe95cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.8197617729504904
        entropy_coeff: 0.0001
        kl: 0.005085625957387189
        model: {}
        policy_loss: -0.010267042419097075
        total_loss: 11.495140314102173
        vf_explained_var: 0.9809592366218567
        vf_loss: 11.50472648938497
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.14838709677419
    gpu_util_percent0: 0.3509677419354839
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 63297
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14956019945060003
    mean_env_wait_ms: 1.1803338558315892
    mean_inference_ms: 4.571699926618155
    mean_raw_obs_processing_ms: 0.39062729452595646
  time_since_restore: 591.5056533813477
  time_this_iter_s: 25.44717502593994
  time_total_s: 591.5056533813477
  timers:
    learn_throughput: 8746.103
    learn_time_ms: 18498.753
    sample_throughput: 23515.96
    sample_time_ms: 6880.093
    update_time_ms: 49.215
  timestamp: 1602457712
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 48e69_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_48e69_00000 | RUNNING  | 172.17.0.4:63297 |     23 |          591.506 | 3721216 |   243.81 |               296.02 |              125.566 |            832.409 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_48e69_00000:
  custom_metrics:
    time_step_max: 4227
    time_step_mean: 3444.945322793149
    time_step_min: 3102
  date: 2020-10-11_23-08-58
  done: true
  episode_len_mean: 831.0663465735487
  episode_reward_max: 296.02020202020174
  episode_reward_mean: 244.3402422302465
  episode_reward_min: 125.56565656565654
  episodes_this_iter: 158
  episodes_total: 4582
  experiment_id: 8bc81864dac548238b7f4bf57cbe95cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.8204845835765203
        entropy_coeff: 0.0001
        kl: 0.005384170760711034
        model: {}
        policy_loss: -0.01202069593515868
        total_loss: 9.937004407246908
        vf_explained_var: 0.9797911643981934
        vf_loss: 9.948299487431845
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.41290322580645
    gpu_util_percent0: 0.35806451612903223
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.777419354838709
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 63297
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14946206756558753
    mean_env_wait_ms: 1.180872080583204
    mean_inference_ms: 4.563795010869435
    mean_raw_obs_processing_ms: 0.39026677998061093
  time_since_restore: 617.1679072380066
  time_this_iter_s: 25.662253856658936
  time_total_s: 617.1679072380066
  timers:
    learn_throughput: 8735.2
    learn_time_ms: 18521.842
    sample_throughput: 23591.787
    sample_time_ms: 6857.98
    update_time_ms: 49.523
  timestamp: 1602457738
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: 48e69_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_48e69_00000 | TERMINATED |       |     24 |          617.168 | 3883008 |   244.34 |               296.02 |              125.566 |            831.066 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_48e69_00000 | TERMINATED |       |     24 |          617.168 | 3883008 |   244.34 |               296.02 |              125.566 |            831.066 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


