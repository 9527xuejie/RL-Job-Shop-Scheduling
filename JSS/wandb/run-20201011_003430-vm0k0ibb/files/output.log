2020-10-11 00:34:32,281	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_88a0a_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=30689)[0m 2020-10-11 00:34:35,281	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=30694)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30694)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30749)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30749)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30678)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30678)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30686)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30686)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30722)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30722)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30728)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30728)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30729)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30729)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30704)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30704)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30638)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30638)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30716)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30716)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30624)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30624)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30614)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30614)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30726)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30726)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30706)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30706)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30682)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30682)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30739)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30739)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30690)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30690)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30636)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30636)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30710)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30710)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30603)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30603)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30633)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30633)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30676)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30676)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30724)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30724)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30700)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30700)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30683)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30683)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30610)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30610)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30604)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30604)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30620)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30620)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30736)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30736)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30669)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30669)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30688)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30688)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30608)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30608)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30646)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30646)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30734)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30734)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30684)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30684)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30607)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30607)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30629)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30629)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30613)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30613)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30616)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30616)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30714)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30714)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30740)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30740)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30605)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30605)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30680)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30680)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30747)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30747)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30635)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30635)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30703)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30703)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30618)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30618)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30643)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30643)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30699)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30699)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30685)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30685)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30663)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30663)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30665)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30665)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30641)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30641)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30701)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30701)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30611)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30611)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30612)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30612)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30705)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30705)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30660)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30660)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30627)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30627)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30679)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30679)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30631)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30631)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30667)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30667)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30702)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30702)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30672)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30672)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30621)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30621)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30640)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30640)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30708)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30708)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30719)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30719)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30666)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30666)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30622)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30622)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30681)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30681)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30677)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30677)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30619)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30619)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30721)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30721)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30606)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30606)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30751)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30751)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30675)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30675)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30673)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30673)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30617)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30617)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_88a0a_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_00-35-18
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 372db4e12b5943daaa30a7e2cec90e32
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1828578795705522
        entropy_coeff: 0.00010000000000000002
        kl: 0.006107110995799303
        model: {}
        policy_loss: -0.015221669870827879
        total_loss: 498.0801740373884
        vf_explained_var: 0.5928232073783875
        vf_loss: 498.09429931640625
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.406666666666666
    gpu_util_percent0: 0.3544444444444445
    gpu_util_percent1: 0.00022222222222222223
    gpu_util_percent2: 0.00022222222222222223
    ram_util_percent: 6.291111111111109
    vram_util_percent0: 0.19191356000145762
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30689
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17189559394763404
    mean_env_wait_ms: 1.1992248336118323
    mean_inference_ms: 5.973080829103334
    mean_raw_obs_processing_ms: 0.46639319370101345
  time_since_restore: 37.38543176651001
  time_this_iter_s: 37.38543176651001
  time_total_s: 37.38543176651001
  timers:
    learn_throughput: 5836.523
    learn_time_ms: 27720.612
    sample_throughput: 16885.277
    sample_time_ms: 9581.839
    update_time_ms: 41.157
  timestamp: 1602376518
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 88a0a_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_88a0a_00000 | RUNNING  | 172.17.0.4:30689 |      1 |          37.3854 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_88a0a_00000:
  custom_metrics:
    time_step_max: 4095
    time_step_mean: 3626.7430555555557
    time_step_min: 3333
  date: 2020-10-11_00-35-53
  done: false
  episode_len_mean: 891.0443037974684
  episode_reward_max: 261.32323232323216
  episode_reward_mean: 216.00342027873648
  episode_reward_min: 145.5656565656569
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 372db4e12b5943daaa30a7e2cec90e32
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1529194968087333
        entropy_coeff: 0.00010000000000000002
        kl: 0.006868714466691017
        model: {}
        policy_loss: -0.01622242596308102
        total_loss: 118.0555921282087
        vf_explained_var: 0.8315331339836121
        vf_loss: 118.07055391584124
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.139534883720927
    gpu_util_percent0: 0.28139534883720935
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4837209302325585
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30689
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16711998207377243
    mean_env_wait_ms: 1.193632358188696
    mean_inference_ms: 5.667054519040028
    mean_raw_obs_processing_ms: 0.45368738861557906
  time_since_restore: 72.71089148521423
  time_this_iter_s: 35.325459718704224
  time_total_s: 72.71089148521423
  timers:
    learn_throughput: 5856.696
    learn_time_ms: 27625.13
    sample_throughput: 18720.242
    sample_time_ms: 8642.623
    update_time_ms: 41.792
  timestamp: 1602376553
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 88a0a_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_88a0a_00000 | RUNNING  | 172.17.0.4:30689 |      2 |          72.7109 | 323584 |  216.003 |              261.323 |              145.566 |            891.044 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_88a0a_00000:
  custom_metrics:
    time_step_max: 4095
    time_step_mean: 3626.603139013453
    time_step_min: 3333
  date: 2020-10-11_00-36-28
  done: false
  episode_len_mean: 891.831223628692
  episode_reward_max: 263.59595959595936
  episode_reward_mean: 217.02934407364765
  episode_reward_min: 145.5656565656569
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 372db4e12b5943daaa30a7e2cec90e32
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1419315593583244
        entropy_coeff: 0.00010000000000000002
        kl: 0.008443829736539296
        model: {}
        policy_loss: -0.019141364709607193
        total_loss: 38.801612854003906
        vf_explained_var: 0.9317184090614319
        vf_loss: 38.819180079868865
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.997619047619047
    gpu_util_percent0: 0.4083333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.490476190476191
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30689
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16411514691127405
    mean_env_wait_ms: 1.190741489803863
    mean_inference_ms: 5.454839694863686
    mean_raw_obs_processing_ms: 0.4441991733558165
  time_since_restore: 107.40215969085693
  time_this_iter_s: 34.6912682056427
  time_total_s: 107.40215969085693
  timers:
    learn_throughput: 5870.682
    learn_time_ms: 27559.319
    sample_throughput: 19847.983
    sample_time_ms: 8151.559
    update_time_ms: 43.073
  timestamp: 1602376588
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 88a0a_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_88a0a_00000 | RUNNING  | 172.17.0.4:30689 |      3 |          107.402 | 485376 |  217.029 |              263.596 |              145.566 |            891.831 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_88a0a_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3614.2798013245033
    time_step_min: 3246
  date: 2020-10-11_00-37-03
  done: false
  episode_len_mean: 888.9193037974684
  episode_reward_max: 274.20202020202044
  episode_reward_mean: 218.83665771640435
  episode_reward_min: 133.29292929292936
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 372db4e12b5943daaa30a7e2cec90e32
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1283075554030282
        entropy_coeff: 0.00010000000000000002
        kl: 0.008976911926375968
        model: {}
        policy_loss: -0.018492951190897396
        total_loss: 26.584789548601425
        vf_explained_var: 0.9515811800956726
        vf_loss: 26.601600102015905
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.13809523809524
    gpu_util_percent0: 0.3769047619047619
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.495238095238095
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30689
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16212161815571838
    mean_env_wait_ms: 1.1893194630953186
    mean_inference_ms: 5.305019605872157
    mean_raw_obs_processing_ms: 0.4370687352214906
  time_since_restore: 142.17253875732422
  time_this_iter_s: 34.770379066467285
  time_total_s: 142.17253875732422
  timers:
    learn_throughput: 5869.91
    learn_time_ms: 27562.943
    sample_throughput: 20541.551
    sample_time_ms: 7876.328
    update_time_ms: 41.122
  timestamp: 1602376623
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 88a0a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_88a0a_00000 | RUNNING  | 172.17.0.4:30689 |      4 |          142.173 | 647168 |  218.837 |              274.202 |              133.293 |            888.919 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_88a0a_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3606.024934383202
    time_step_min: 3246
  date: 2020-10-11_00-37-37
  done: false
  episode_len_mean: 885.6430379746836
  episode_reward_max: 274.20202020202044
  episode_reward_mean: 219.86791970336256
  episode_reward_min: 133.29292929292936
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 372db4e12b5943daaa30a7e2cec90e32
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1014837537493025
        entropy_coeff: 0.00010000000000000002
        kl: 0.0092503881481077
        model: {}
        policy_loss: -0.020115947118029
        total_loss: 20.615960666111537
        vf_explained_var: 0.9636393189430237
        vf_loss: 20.634336744035995
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.23170731707317
    gpu_util_percent0: 0.2921951219512195
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30689
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16061570585975718
    mean_env_wait_ms: 1.1889571170627877
    mean_inference_ms: 5.194868023477827
    mean_raw_obs_processing_ms: 0.4315170856374837
  time_since_restore: 176.7173080444336
  time_this_iter_s: 34.544769287109375
  time_total_s: 176.7173080444336
  timers:
    learn_throughput: 5873.763
    learn_time_ms: 27544.864
    sample_throughput: 21010.167
    sample_time_ms: 7700.653
    update_time_ms: 37.437
  timestamp: 1602376657
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 88a0a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_88a0a_00000 | RUNNING  | 172.17.0.4:30689 |      5 |          176.717 | 808960 |  219.868 |              274.202 |              133.293 |            885.643 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_88a0a_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3589.7339268051433
    time_step_min: 3229
  date: 2020-10-11_00-38-12
  done: false
  episode_len_mean: 878.7940327237728
  episode_reward_max: 276.7777777777777
  episode_reward_mean: 222.5987886565363
  episode_reward_min: 133.29292929292936
  episodes_this_iter: 249
  episodes_total: 1039
  experiment_id: 372db4e12b5943daaa30a7e2cec90e32
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0695556487355913
        entropy_coeff: 0.00010000000000000002
        kl: 0.008468269037881069
        model: {}
        policy_loss: -0.018453896727545986
        total_loss: 21.870992524283274
        vf_explained_var: 0.972388744354248
        vf_loss: 21.887858935764857
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.161904761904758
    gpu_util_percent0: 0.36
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.476190476190476
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30689
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15898019561758606
    mean_env_wait_ms: 1.1907822253763336
    mean_inference_ms: 5.071584826736338
    mean_raw_obs_processing_ms: 0.4251164833783766
  time_since_restore: 211.47844648361206
  time_this_iter_s: 34.76113843917847
  time_total_s: 211.47844648361206
  timers:
    learn_throughput: 5875.043
    learn_time_ms: 27538.86
    sample_throughput: 21282.73
    sample_time_ms: 7602.032
    update_time_ms: 35.299
  timestamp: 1602376692
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 88a0a_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_88a0a_00000 | RUNNING  | 172.17.0.4:30689 |      6 |          211.478 | 970752 |  222.599 |              276.778 |              133.293 |            878.794 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_88a0a_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3581.2516181229776
    time_step_min: 3229
  date: 2020-10-11_00-38-47
  done: false
  episode_len_mean: 872.4303797468355
  episode_reward_max: 276.7777777777777
  episode_reward_mean: 223.97390838767402
  episode_reward_min: 133.29292929292936
  episodes_this_iter: 225
  episodes_total: 1264
  experiment_id: 372db4e12b5943daaa30a7e2cec90e32
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0839158126286097
        entropy_coeff: 0.00010000000000000002
        kl: 0.008501882864428418
        model: {}
        policy_loss: -0.019645823032728264
        total_loss: 14.933275767735072
        vf_explained_var: 0.9761196374893188
        vf_loss: 14.951329571860176
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.290476190476188
    gpu_util_percent0: 0.39595238095238094
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.485714285714285
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30689
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15791209725485947
    mean_env_wait_ms: 1.1925602728172828
    mean_inference_ms: 4.994279525093695
    mean_raw_obs_processing_ms: 0.42120765197515
  time_since_restore: 246.2760829925537
  time_this_iter_s: 34.79763650894165
  time_total_s: 246.2760829925537
  timers:
    learn_throughput: 5874.828
    learn_time_ms: 27539.872
    sample_throughput: 21476.801
    sample_time_ms: 7533.338
    update_time_ms: 33.537
  timestamp: 1602376727
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 88a0a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_88a0a_00000 | RUNNING  | 172.17.0.4:30689 |      7 |          246.276 | 1132544 |  223.974 |              276.778 |              133.293 |             872.43 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_88a0a_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3569.7826398852226
    time_step_min: 3229
  date: 2020-10-11_00-39-22
  done: false
  episode_len_mean: 867.4085794655415
  episode_reward_max: 281.3232323232324
  episode_reward_mean: 225.58835187316183
  episode_reward_min: 133.29292929292936
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 372db4e12b5943daaa30a7e2cec90e32
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0571505427360535
        entropy_coeff: 0.00010000000000000002
        kl: 0.00868702573435647
        model: {}
        policy_loss: -0.01948666339740157
        total_loss: 13.064917836870466
        vf_explained_var: 0.9755368828773499
        vf_loss: 13.082772254943848
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.24047619047619
    gpu_util_percent0: 0.3730952380952381
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.492857142857143
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30689
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1572914516963269
    mean_env_wait_ms: 1.193822136274971
    mean_inference_ms: 4.949844281131671
    mean_raw_obs_processing_ms: 0.41894863564535845
  time_since_restore: 281.4103834629059
  time_this_iter_s: 35.13430047035217
  time_total_s: 281.4103834629059
  timers:
    learn_throughput: 5871.306
    learn_time_ms: 27556.391
    sample_throughput: 21529.52
    sample_time_ms: 7514.891
    update_time_ms: 32.534
  timestamp: 1602376762
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 88a0a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_88a0a_00000 | RUNNING  | 172.17.0.4:30689 |      8 |           281.41 | 1294336 |  225.588 |              281.323 |              133.293 |            867.409 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_88a0a_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3560.5109536082473
    time_step_min: 3229
  date: 2020-10-11_00-39-58
  done: false
  episode_len_mean: 863.6632911392405
  episode_reward_max: 281.3232323232324
  episode_reward_mean: 226.7992584068532
  episode_reward_min: 133.29292929292936
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 372db4e12b5943daaa30a7e2cec90e32
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0392310278756278
        entropy_coeff: 0.00010000000000000002
        kl: 0.007955889483647687
        model: {}
        policy_loss: -0.018725366398159946
        total_loss: 13.023170811789376
        vf_explained_var: 0.9749749302864075
        vf_loss: 13.040408883775983
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.166666666666668
    gpu_util_percent0: 0.3538095238095238
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497619047619047
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30689
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1567563104025307
    mean_env_wait_ms: 1.1950412803988764
    mean_inference_ms: 4.911430943499614
    mean_raw_obs_processing_ms: 0.41697447106962526
  time_since_restore: 316.49779176712036
  time_this_iter_s: 35.08740830421448
  time_total_s: 316.49779176712036
  timers:
    learn_throughput: 5867.794
    learn_time_ms: 27572.881
    sample_throughput: 21601.977
    sample_time_ms: 7489.685
    update_time_ms: 33.245
  timestamp: 1602376798
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 88a0a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_88a0a_00000 | RUNNING  | 172.17.0.4:30689 |      9 |          316.498 | 1456128 |  226.799 |              281.323 |              133.293 |            863.663 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_88a0a_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3551.8683908045978
    time_step_min: 3187
  date: 2020-10-11_00-40-33
  done: false
  episode_len_mean: 859.5480769230769
  episode_reward_max: 288.2929292929293
  episode_reward_mean: 228.39173979615146
  episode_reward_min: 133.29292929292936
  episodes_this_iter: 188
  episodes_total: 1768
  experiment_id: 372db4e12b5943daaa30a7e2cec90e32
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9984941056796482
        entropy_coeff: 0.00010000000000000002
        kl: 0.00834869300680501
        model: {}
        policy_loss: -0.019255505741706917
        total_loss: 12.995903423854283
        vf_explained_var: 0.9808416962623596
        vf_loss: 13.013589177812849
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.321428571428573
    gpu_util_percent0: 0.3126190476190476
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.485714285714285
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30689
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15619929667663113
    mean_env_wait_ms: 1.1965267959778512
    mean_inference_ms: 4.871335677227667
    mean_raw_obs_processing_ms: 0.41490082041897036
  time_since_restore: 351.3865282535553
  time_this_iter_s: 34.88873648643494
  time_total_s: 351.3865282535553
  timers:
    learn_throughput: 5869.043
    learn_time_ms: 27567.016
    sample_throughput: 21659.135
    sample_time_ms: 7469.92
    update_time_ms: 32.809
  timestamp: 1602376833
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 88a0a_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_88a0a_00000 | RUNNING  | 172.17.0.4:30689 |     10 |          351.387 | 1617920 |  228.392 |              288.293 |              133.293 |            859.548 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_88a0a_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3537.3440276406714
    time_step_min: 3187
  date: 2020-10-11_00-41-07
  done: false
  episode_len_mean: 853.8169425511197
  episode_reward_max: 288.2929292929293
  episode_reward_mean: 230.49535766624362
  episode_reward_min: 133.29292929292936
  episodes_this_iter: 286
  episodes_total: 2054
  experiment_id: 372db4e12b5943daaa30a7e2cec90e32
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.001801073551178
        entropy_coeff: 0.00010000000000000002
        kl: 0.007706852895872933
        model: {}
        policy_loss: -0.019217141623942422
        total_loss: 11.628969601222447
        vf_explained_var: 0.9827467203140259
        vf_loss: 11.646745613643102
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.973809523809525
    gpu_util_percent0: 0.4254761904761905
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.480952380952379
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30689
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1555004621627952
    mean_env_wait_ms: 1.1988857929731254
    mean_inference_ms: 4.823123054713723
    mean_raw_obs_processing_ms: 0.4124721731703912
  time_since_restore: 386.216477394104
  time_this_iter_s: 34.829949140548706
  time_total_s: 386.216477394104
  timers:
    learn_throughput: 5873.727
    learn_time_ms: 27545.033
    sample_throughput: 22376.021
    sample_time_ms: 7230.597
    update_time_ms: 36.292
  timestamp: 1602376867
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 88a0a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_88a0a_00000 | RUNNING  | 172.17.0.4:30689 |     11 |          386.216 | 1779712 |  230.495 |              288.293 |              133.293 |            853.817 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_88a0a_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3531.0251831501832
    time_step_min: 3187
  date: 2020-10-11_00-41-43
  done: false
  episode_len_mean: 850.9339963833635
  episode_reward_max: 288.2929292929293
  episode_reward_mean: 231.51379070999312
  episode_reward_min: 133.29292929292936
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 372db4e12b5943daaa30a7e2cec90e32
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9789184842790876
        entropy_coeff: 0.00010000000000000002
        kl: 0.0077551319263875484
        model: {}
        policy_loss: -0.01940992571014379
        total_loss: 9.683410848890032
        vf_explained_var: 0.981833279132843
        vf_loss: 9.701367514474052
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.14761904761905
    gpu_util_percent0: 0.3311904761904762
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30689
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15518254028688186
    mean_env_wait_ms: 1.2000825527307117
    mean_inference_ms: 4.800251176066109
    mean_raw_obs_processing_ms: 0.4113169336853417
  time_since_restore: 421.23602867126465
  time_this_iter_s: 35.019551277160645
  time_total_s: 421.23602867126465
  timers:
    learn_throughput: 5870.952
    learn_time_ms: 27558.053
    sample_throughput: 22507.387
    sample_time_ms: 7188.395
    update_time_ms: 34.207
  timestamp: 1602376903
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 88a0a_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_88a0a_00000 | RUNNING  | 172.17.0.4:30689 |     12 |          421.236 | 1941504 |  231.514 |              288.293 |              133.293 |            850.934 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_88a0a_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3523.7416737830913
    time_step_min: 3187
  date: 2020-10-11_00-42-18
  done: false
  episode_len_mean: 848.1704641350211
  episode_reward_max: 288.2929292929293
  episode_reward_mean: 232.53286024805
  episode_reward_min: 133.29292929292936
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: 372db4e12b5943daaa30a7e2cec90e32
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9539449768407005
        entropy_coeff: 0.00010000000000000002
        kl: 0.00810233410447836
        model: {}
        policy_loss: -0.019932799939332262
        total_loss: 10.045161247253418
        vf_explained_var: 0.9802576899528503
        vf_loss: 10.063568932669503
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.41190476190476
    gpu_util_percent0: 0.3907142857142858
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.49047619047619
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30689
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15489100635849778
    mean_env_wait_ms: 1.201203043704032
    mean_inference_ms: 4.779485166197183
    mean_raw_obs_processing_ms: 0.41024438502715227
  time_since_restore: 456.1015582084656
  time_this_iter_s: 34.86552953720093
  time_total_s: 456.1015582084656
  timers:
    learn_throughput: 5870.781
    learn_time_ms: 27558.855
    sample_throughput: 22480.728
    sample_time_ms: 7196.92
    update_time_ms: 33.524
  timestamp: 1602376938
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 88a0a_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_88a0a_00000 | RUNNING  | 172.17.0.4:30689 |     13 |          456.102 | 2103296 |  232.533 |              288.293 |              133.293 |             848.17 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_88a0a_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3514.026837806301
    time_step_min: 3187
  date: 2020-10-11_00-42-53
  done: false
  episode_len_mean: 844.9157368218546
  episode_reward_max: 288.2929292929293
  episode_reward_mean: 234.1106680502601
  episode_reward_min: 133.29292929292936
  episodes_this_iter: 229
  episodes_total: 2599
  experiment_id: 372db4e12b5943daaa30a7e2cec90e32
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9152640359742301
        entropy_coeff: 0.00010000000000000002
        kl: 0.007726806947695357
        model: {}
        policy_loss: -0.01826555248615997
        total_loss: 12.28696530205863
        vf_explained_var: 0.9827612042427063
        vf_loss: 12.303777149745397
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.43658536585366
    gpu_util_percent0: 0.37634146341463415
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.485365853658536
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30689
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1545159275761591
    mean_env_wait_ms: 1.2028109533021676
    mean_inference_ms: 4.752590396001857
    mean_raw_obs_processing_ms: 0.40884626062476853
  time_since_restore: 490.93641567230225
  time_this_iter_s: 34.83485746383667
  time_total_s: 490.93641567230225
  timers:
    learn_throughput: 5870.711
    learn_time_ms: 27559.184
    sample_throughput: 22441.456
    sample_time_ms: 7209.515
    update_time_ms: 32.151
  timestamp: 1602376973
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 88a0a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_88a0a_00000 | RUNNING  | 172.17.0.4:30689 |     14 |          490.936 | 2265088 |  234.111 |              288.293 |              133.293 |            844.916 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_88a0a_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3505.67578125
    time_step_min: 3187
  date: 2020-10-11_00-43-27
  done: false
  episode_len_mean: 841.9050632911392
  episode_reward_max: 288.2929292929293
  episode_reward_mean: 235.36379618974544
  episode_reward_min: 133.29292929292936
  episodes_this_iter: 245
  episodes_total: 2844
  experiment_id: 372db4e12b5943daaa30a7e2cec90e32
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9151935492243085
        entropy_coeff: 0.00010000000000000002
        kl: 0.007311811836968575
        model: {}
        policy_loss: -0.017550430776152228
        total_loss: 9.88672229221889
        vf_explained_var: 0.9843529462814331
        vf_loss: 9.902901785714286
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.173809523809524
    gpu_util_percent0: 0.3583333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.492857142857144
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30689
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1541653265832883
    mean_env_wait_ms: 1.2043633692426676
    mean_inference_ms: 4.728050931782381
    mean_raw_obs_processing_ms: 0.40757981708506796
  time_since_restore: 525.74138879776
  time_this_iter_s: 34.804973125457764
  time_total_s: 525.74138879776
  timers:
    learn_throughput: 5871.672
    learn_time_ms: 27554.671
    sample_throughput: 22349.166
    sample_time_ms: 7239.286
    update_time_ms: 32.323
  timestamp: 1602377007
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 88a0a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_88a0a_00000 | RUNNING  | 172.17.0.4:30689 |     15 |          525.741 | 2426880 |  235.364 |              288.293 |              133.293 |            841.905 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_88a0a_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3500.603564223268
    time_step_min: 3187
  date: 2020-10-11_00-44-02
  done: false
  episode_len_mean: 840.0203197868088
  episode_reward_max: 288.2929292929293
  episode_reward_mean: 236.18877650589832
  episode_reward_min: 133.29292929292936
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: 372db4e12b5943daaa30a7e2cec90e32
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8995668632643563
        entropy_coeff: 0.00010000000000000002
        kl: 0.008067028663520302
        model: {}
        policy_loss: -0.020453748891928365
        total_loss: 7.9969489233834405
        vf_explained_var: 0.9848918318748474
        vf_loss: 8.015879222324916
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.733333333333334
    gpu_util_percent0: 0.38761904761904764
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.490476190476191
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30689
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15396182227761102
    mean_env_wait_ms: 1.20526541018423
    mean_inference_ms: 4.7137579460609444
    mean_raw_obs_processing_ms: 0.406848642044442
  time_since_restore: 560.3784937858582
  time_this_iter_s: 34.637104988098145
  time_total_s: 560.3784937858582
  timers:
    learn_throughput: 5873.542
    learn_time_ms: 27545.902
    sample_throughput: 22341.931
    sample_time_ms: 7241.63
    update_time_ms: 32.077
  timestamp: 1602377042
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 88a0a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_88a0a_00000 | RUNNING  | 172.17.0.4:30689 |     16 |          560.378 | 2588672 |  236.189 |              288.293 |              133.293 |             840.02 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_88a0a_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3495.410657306956
    time_step_min: 3187
  date: 2020-10-11_00-44-37
  done: false
  episode_len_mean: 838.286211258697
  episode_reward_max: 288.2929292929293
  episode_reward_mean: 236.93240756713234
  episode_reward_min: 133.29292929292936
  episodes_this_iter: 160
  episodes_total: 3162
  experiment_id: 372db4e12b5943daaa30a7e2cec90e32
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8759100905486515
        entropy_coeff: 0.00010000000000000002
        kl: 0.007772231940180063
        model: {}
        policy_loss: -0.019694595630945905
        total_loss: 8.274282659803118
        vf_explained_var: 0.9844520688056946
        vf_loss: 8.29251057761056
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.090476190476192
    gpu_util_percent0: 0.40928571428571425
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30689
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15377442098588337
    mean_env_wait_ms: 1.2061532624466353
    mean_inference_ms: 4.700321438514388
    mean_raw_obs_processing_ms: 0.40614976222122545
  time_since_restore: 595.270928144455
  time_this_iter_s: 34.8924343585968
  time_total_s: 595.270928144455
  timers:
    learn_throughput: 5874.894
    learn_time_ms: 27539.562
    sample_throughput: 22298.369
    sample_time_ms: 7255.777
    update_time_ms: 33.059
  timestamp: 1602377077
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 88a0a_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_88a0a_00000 | RUNNING  | 172.17.0.4:30689 |     17 |          595.271 | 2750464 |  236.932 |              288.293 |              133.293 |            838.286 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_88a0a_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3486.120538326507
    time_step_min: 3187
  date: 2020-10-11_00-45-12
  done: true
  episode_len_mean: 835.6683110853163
  episode_reward_max: 288.7474747474747
  episode_reward_mean: 238.22666889439952
  episode_reward_min: 133.29292929292936
  episodes_this_iter: 284
  episodes_total: 3446
  experiment_id: 372db4e12b5943daaa30a7e2cec90e32
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8507507741451263
        entropy_coeff: 0.00010000000000000002
        kl: 0.007583330984094313
        model: {}
        policy_loss: -0.017237866330625757
        total_loss: 12.643115997314453
        vf_explained_var: 0.9831448197364807
        vf_loss: 12.65892219543457
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.521428571428572
    gpu_util_percent0: 0.40166666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.480952380952381
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30689
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15347703778794394
    mean_env_wait_ms: 1.207659215350969
    mean_inference_ms: 4.678976770906757
    mean_raw_obs_processing_ms: 0.40507738130343746
  time_since_restore: 630.1840674877167
  time_this_iter_s: 34.91313934326172
  time_total_s: 630.1840674877167
  timers:
    learn_throughput: 5875.242
    learn_time_ms: 27537.928
    sample_throughput: 22372.943
    sample_time_ms: 7231.592
    update_time_ms: 34.328
  timestamp: 1602377112
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 88a0a_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_88a0a_00000 | TERMINATED |       |     18 |          630.184 | 2912256 |  238.227 |              288.747 |              133.293 |            835.668 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_88a0a_00000 | TERMINATED |       |     18 |          630.184 | 2912256 |  238.227 |              288.747 |              133.293 |            835.668 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


