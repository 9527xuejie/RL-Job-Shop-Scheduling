2020-10-11 15:08:32,080	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_a1235_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=35160)[0m 2020-10-11 15:08:34,925	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=35061)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35061)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35121)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35121)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35045)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35045)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35122)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35122)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35140)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35140)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35046)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35046)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35075)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35075)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35055)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35055)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35156)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35156)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35064)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35064)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35053)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35053)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35058)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35058)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35161)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35161)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35167)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35167)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35120)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35120)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35135)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35135)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35136)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35136)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35106)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35106)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35154)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35154)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35102)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35102)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35059)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35059)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35044)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35044)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35070)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35070)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35073)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35073)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35133)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35133)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35151)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35151)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35103)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35103)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35162)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35162)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35128)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35128)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35149)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35149)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35138)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35138)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35096)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35096)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35123)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35123)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35127)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35127)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35066)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35066)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35048)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35048)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35047)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35047)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35054)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35054)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35057)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35057)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35067)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35067)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35150)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35150)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35139)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35139)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35051)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35051)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35179)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35179)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35137)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35137)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35110)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35110)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35052)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35052)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35065)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35065)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35171)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35171)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35116)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35116)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35049)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35049)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35129)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35129)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35158)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35158)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35099)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35099)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35078)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35078)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35144)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35144)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35132)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35132)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35080)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35080)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35146)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35146)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35117)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35117)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35165)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35165)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35153)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35153)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35119)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35119)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35164)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35164)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35108)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35108)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35174)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35174)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35062)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35062)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35063)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35063)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35131)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35131)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35060)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35060)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35076)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35076)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35074)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35074)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35130)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35130)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35101)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35101)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35079)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35079)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35115)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35115)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35118)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35118)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35111)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35111)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35125)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35125)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_a1235_00000:
  custom_metrics: {}
  date: 2020-10-11_15-09-03
  done: false
  episode_len_mean: .nan
  episode_reward_max: .nan
  episode_reward_mean: .nan
  episode_reward_min: .nan
  episodes_this_iter: 0
  episodes_total: 0
  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.19709346975599
        entropy_coeff: 0.00010000000000000002
        kl: 0.006012780392276389
        model: {}
        policy_loss: -0.012594069770005132
        total_loss: 531.4765886579241
        vf_explained_var: -0.1959501951932907
        vf_loss: 531.4880981445312
    num_steps_sampled: 121344
    num_steps_trained: 121344
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.41071428571428
    gpu_util_percent0: 0.42
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.439285714285714
    vram_util_percent0: 0.09704586984022866
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35160
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf: {}
  time_since_restore: 23.542519092559814
  time_this_iter_s: 23.542519092559814
  time_total_s: 23.542519092559814
  timers:
    learn_throughput: 7302.868
    learn_time_ms: 16615.938
    sample_throughput: 17642.292
    sample_time_ms: 6878.018
    update_time_ms: 23.09
  timestamp: 1602428943
  timesteps_since_restore: 0
  timesteps_total: 121344
  training_iteration: 1
  trial_id: a1235_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |      1 |          23.5425 | 121344 |      nan |                  nan |                  nan |                nan |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a1235_00000:
  custom_metrics:
    time_step_max: 4112
    time_step_mean: 3628.184
    time_step_min: 3295
  date: 2020-10-11_15-09-26
  done: false
  episode_len_mean: 892.0759493670886
  episode_reward_max: 266.7777777777774
  episode_reward_mean: 216.28679197033605
  episode_reward_min: 142.98989898989888
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.1605888264519828
        entropy_coeff: 0.00010000000000000002
        kl: 0.005510005168616772
        model: {}
        policy_loss: -0.010740843401955706
        total_loss: 457.9469953264509
        vf_explained_var: 0.5077921152114868
        vf_loss: 457.95674787248885
    num_steps_sampled: 242688
    num_steps_trained: 242688
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.27692307692308
    gpu_util_percent0: 0.28423076923076923
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5807692307692305
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35160
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16446233676361774
    mean_env_wait_ms: 1.162943500295647
    mean_inference_ms: 5.557823582499349
    mean_raw_obs_processing_ms: 0.43066957193408895
  time_since_restore: 46.10712456703186
  time_this_iter_s: 22.564605474472046
  time_total_s: 46.10712456703186
  timers:
    learn_throughput: 7354.362
    learn_time_ms: 16499.596
    sample_throughput: 18711.931
    sample_time_ms: 6484.846
    update_time_ms: 31.635
  timestamp: 1602428966
  timesteps_since_restore: 0
  timesteps_total: 242688
  training_iteration: 2
  trial_id: a1235_00000
  
== Status ==
Memory usage on this node: 27.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |      2 |          46.1071 | 242688 |  216.287 |              266.778 |               142.99 |            892.076 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a1235_00000:
  custom_metrics:
    time_step_max: 4151
    time_step_mean: 3613.0989399293285
    time_step_min: 3295
  date: 2020-10-11_15-09-48
  done: false
  episode_len_mean: 885.8417721518987
  episode_reward_max: 266.7777777777774
  episode_reward_mean: 219.05146400715998
  episode_reward_min: 137.08080808080805
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.1425047261374337
        entropy_coeff: 0.00010000000000000002
        kl: 0.006121054757386446
        model: {}
        policy_loss: -0.010844438403312649
        total_loss: 173.54720851353235
        vf_explained_var: 0.7992362380027771
        vf_loss: 173.55693926130022
    num_steps_sampled: 364032
    num_steps_trained: 364032
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.200000000000006
    gpu_util_percent0: 0.2938461538461538
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.657692307692308
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35160
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16196955022568685
    mean_env_wait_ms: 1.1660414931875447
    mean_inference_ms: 5.382874079182883
    mean_raw_obs_processing_ms: 0.42491766998890496
  time_since_restore: 67.96861171722412
  time_this_iter_s: 21.86148715019226
  time_total_s: 67.96861171722412
  timers:
    learn_throughput: 7379.502
    learn_time_ms: 16443.386
    sample_throughput: 19767.194
    sample_time_ms: 6138.656
    update_time_ms: 32.948
  timestamp: 1602428988
  timesteps_since_restore: 0
  timesteps_total: 364032
  training_iteration: 3
  trial_id: a1235_00000
  
== Status ==
Memory usage on this node: 27.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |      3 |          67.9686 | 364032 |  219.051 |              266.778 |              137.081 |            885.842 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a1235_00000:
  custom_metrics:
    time_step_max: 4151
    time_step_mean: 3602.736961451247
    time_step_min: 3215
  date: 2020-10-11_15-10-09
  done: false
  episode_len_mean: 879.8206751054852
  episode_reward_max: 278.89898989898967
  episode_reward_mean: 220.72548267484962
  episode_reward_min: 137.08080808080805
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.125728794506618
        entropy_coeff: 0.00010000000000000002
        kl: 0.00639094106320824
        model: {}
        policy_loss: -0.01306218234822154
        total_loss: 96.90472303118024
        vf_explained_var: 0.8719539642333984
        vf_loss: 96.91662052699498
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.504
    gpu_util_percent0: 0.3436
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.6200000000000006
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35160
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16011317296980337
    mean_env_wait_ms: 1.1691356112762634
    mean_inference_ms: 5.252999245913915
    mean_raw_obs_processing_ms: 0.42028241781166387
  time_since_restore: 89.6299831867218
  time_this_iter_s: 21.66137146949768
  time_total_s: 89.6299831867218
  timers:
    learn_throughput: 7389.29
    learn_time_ms: 16421.605
    sample_throughput: 20514.598
    sample_time_ms: 5915.007
    update_time_ms: 29.479
  timestamp: 1602429009
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 4
  trial_id: a1235_00000
  
== Status ==
Memory usage on this node: 27.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |      4 |            89.63 | 485376 |  220.725 |              278.899 |              137.081 |            879.821 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a1235_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3605.1502504173623
    time_step_min: 3215
  date: 2020-10-11_15-10-31
  done: false
  episode_len_mean: 875.7405063291139
  episode_reward_max: 278.89898989898967
  episode_reward_mean: 220.5459979542256
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.1141637904303414
        entropy_coeff: 0.00010000000000000002
        kl: 0.006669476495257446
        model: {}
        policy_loss: -0.012190746708906122
        total_loss: 72.5603757585798
        vf_explained_var: 0.9030656814575195
        vf_loss: 72.57134246826172
    num_steps_sampled: 606720
    num_steps_trained: 606720
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.73076923076923
    gpu_util_percent0: 0.2607692307692307
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.619230769230769
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35160
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1586679213940069
    mean_env_wait_ms: 1.1718046862564908
    mean_inference_ms: 5.153834685027547
    mean_raw_obs_processing_ms: 0.4165729405901832
  time_since_restore: 111.46106910705566
  time_this_iter_s: 21.831085920333862
  time_total_s: 111.46106910705566
  timers:
    learn_throughput: 7385.802
    learn_time_ms: 16429.36
    sample_throughput: 21004.437
    sample_time_ms: 5777.065
    update_time_ms: 31.101
  timestamp: 1602429031
  timesteps_since_restore: 0
  timesteps_total: 606720
  training_iteration: 5
  trial_id: a1235_00000
  
== Status ==
Memory usage on this node: 27.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |      5 |          111.461 | 606720 |  220.546 |              278.899 |              115.717 |            875.741 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a1235_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3598.815059445178
    time_step_min: 3215
  date: 2020-10-11_15-10-53
  done: false
  episode_len_mean: 870.0126582278481
  episode_reward_max: 283.4444444444445
  episode_reward_mean: 221.5198184375398
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.1031875269753593
        entropy_coeff: 0.00010000000000000002
        kl: 0.0058455463232738635
        model: {}
        policy_loss: -0.013633016629942827
        total_loss: 56.65061024257115
        vf_explained_var: 0.9194228053092957
        vf_loss: 56.66318348475865
    num_steps_sampled: 728064
    num_steps_trained: 728064
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.671999999999997
    gpu_util_percent0: 0.41
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.676
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35160
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1575500456508179
    mean_env_wait_ms: 1.1743433825778726
    mean_inference_ms: 5.076129067985898
    mean_raw_obs_processing_ms: 0.41371068930947436
  time_since_restore: 133.44550371170044
  time_this_iter_s: 21.984434604644775
  time_total_s: 133.44550371170044
  timers:
    learn_throughput: 7381.676
    learn_time_ms: 16438.543
    sample_throughput: 21215.982
    sample_time_ms: 5719.462
    update_time_ms: 29.754
  timestamp: 1602429053
  timesteps_since_restore: 0
  timesteps_total: 728064
  training_iteration: 6
  trial_id: a1235_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |      6 |          133.446 | 728064 |   221.52 |              283.444 |              115.717 |            870.013 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a1235_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3588.261202185792
    time_step_min: 3215
  date: 2020-10-11_15-11-15
  done: false
  episode_len_mean: 864.6424050632911
  episode_reward_max: 283.4444444444445
  episode_reward_mean: 223.08851169927104
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 158
  episodes_total: 948
  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.0879003490720476
        entropy_coeff: 0.00010000000000000002
        kl: 0.006762735878250429
        model: {}
        policy_loss: -0.013632669695653021
        total_loss: 37.261954171316965
        vf_explained_var: 0.944100022315979
        vf_loss: 37.274344308035715
    num_steps_sampled: 849408
    num_steps_trained: 849408
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.33076923076923
    gpu_util_percent0: 0.35000000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.676923076923077
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35160
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15664822309319318
    mean_env_wait_ms: 1.1764875590147201
    mean_inference_ms: 5.0132356283014055
    mean_raw_obs_processing_ms: 0.4113315160451748
  time_since_restore: 155.2493019104004
  time_this_iter_s: 21.80379819869995
  time_total_s: 155.2493019104004
  timers:
    learn_throughput: 7379.547
    learn_time_ms: 16443.286
    sample_throughput: 21469.831
    sample_time_ms: 5651.838
    update_time_ms: 30.593
  timestamp: 1602429075
  timesteps_since_restore: 0
  timesteps_total: 849408
  training_iteration: 7
  trial_id: a1235_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |      7 |          155.249 | 849408 |  223.089 |              283.444 |              115.717 |            864.642 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a1235_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3578.4057835820895
    time_step_min: 3160
  date: 2020-10-11_15-11-37
  done: false
  episode_len_mean: 861.3013574660633
  episode_reward_max: 287.232323232323
  episode_reward_mean: 224.4733762969056
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 157
  episodes_total: 1105
  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.0726469244275774
        entropy_coeff: 0.00010000000000000002
        kl: 0.0064350370583789685
        model: {}
        policy_loss: -0.01426797326920288
        total_loss: 36.13643755231585
        vf_explained_var: 0.9460744857788086
        vf_loss: 36.14952414376395
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.708000000000002
    gpu_util_percent0: 0.44480000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.6800000000000006
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35160
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15592918975116088
    mean_env_wait_ms: 1.1785108080781528
    mean_inference_ms: 4.961603268618143
    mean_raw_obs_processing_ms: 0.40945494346936523
  time_since_restore: 176.9723105430603
  time_this_iter_s: 21.723008632659912
  time_total_s: 176.9723105430603
  timers:
    learn_throughput: 7387.429
    learn_time_ms: 16425.742
    sample_throughput: 21629.303
    sample_time_ms: 5610.167
    update_time_ms: 31.296
  timestamp: 1602429097
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 8
  trial_id: a1235_00000
  
== Status ==
Memory usage on this node: 27.9/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |      8 |          176.972 | 970752 |  224.473 |              287.232 |              115.717 |            861.301 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a1235_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3568.161316872428
    time_step_min: 3160
  date: 2020-10-11_15-11-59
  done: false
  episode_len_mean: 858.0144230769231
  episode_reward_max: 287.232323232323
  episode_reward_mean: 226.13347416472402
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 143
  episodes_total: 1248
  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.0612812382834298
        entropy_coeff: 0.00010000000000000002
        kl: 0.0064252400770783424
        model: {}
        policy_loss: -0.013670566009490617
        total_loss: 24.85169301714216
        vf_explained_var: 0.9604588150978088
        vf_loss: 24.864185333251953
    num_steps_sampled: 1092096
    num_steps_trained: 1092096
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.88
    gpu_util_percent0: 0.3204
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.716
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35160
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1553689882252152
    mean_env_wait_ms: 1.1800334051653998
    mean_inference_ms: 4.921496393253225
    mean_raw_obs_processing_ms: 0.4079070973587893
  time_since_restore: 198.8754620552063
  time_this_iter_s: 21.903151512145996
  time_total_s: 198.8754620552063
  timers:
    learn_throughput: 7391.084
    learn_time_ms: 16417.619
    sample_throughput: 21685.324
    sample_time_ms: 5595.674
    update_time_ms: 30.585
  timestamp: 1602429119
  timesteps_since_restore: 0
  timesteps_total: 1092096
  training_iteration: 9
  trial_id: a1235_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |      9 |          198.875 | 1092096 |  226.133 |              287.232 |              115.717 |            858.014 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a1235_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3562.0239752513535
    time_step_min: 3160
  date: 2020-10-11_15-12-21
  done: false
  episode_len_mean: 856.1025641025641
  episode_reward_max: 287.232323232323
  episode_reward_mean: 226.98391151332316
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 78
  episodes_total: 1326
  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.0382741349084037
        entropy_coeff: 0.00010000000000000002
        kl: 0.006699717004916498
        model: {}
        policy_loss: -0.015758267204676355
        total_loss: 19.22611209324428
        vf_explained_var: 0.9653859734535217
        vf_loss: 19.240634645734513
    num_steps_sampled: 1213440
    num_steps_trained: 1213440
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.94
    gpu_util_percent0: 0.43320000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.6800000000000006
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35160
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15507451673504405
    mean_env_wait_ms: 1.1807877501396284
    mean_inference_ms: 4.901231582618228
    mean_raw_obs_processing_ms: 0.40704194233638713
  time_since_restore: 220.57692289352417
  time_this_iter_s: 21.70146083831787
  time_total_s: 220.57692289352417
  timers:
    learn_throughput: 7396.911
    learn_time_ms: 16404.686
    sample_throughput: 21782.603
    sample_time_ms: 5570.684
    update_time_ms: 30.062
  timestamp: 1602429141
  timesteps_since_restore: 0
  timesteps_total: 1213440
  training_iteration: 10
  trial_id: a1235_00000
  
== Status ==
Memory usage on this node: 27.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     10 |          220.577 | 1213440 |  226.984 |              287.232 |              115.717 |            856.103 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a1235_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3552.330719885959
    time_step_min: 3160
  date: 2020-10-11_15-12-43
  done: false
  episode_len_mean: 853.9428969359332
  episode_reward_max: 287.232323232323
  episode_reward_mean: 228.58804620016306
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 110
  episodes_total: 1436
  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.0348200968333654
        entropy_coeff: 0.00010000000000000002
        kl: 0.006286287746791329
        model: {}
        policy_loss: -0.014631494147969144
        total_loss: 14.363759994506836
        vf_explained_var: 0.968192994594574
        vf_loss: 14.377237319946289
    num_steps_sampled: 1334784
    num_steps_trained: 1334784
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.97307692307693
    gpu_util_percent0: 0.3607692307692308
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.6615384615384623
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35160
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15474405851865955
    mean_env_wait_ms: 1.182007279150758
    mean_inference_ms: 4.875525574892237
    mean_raw_obs_processing_ms: 0.4059855497358534
  time_since_restore: 242.30754470825195
  time_this_iter_s: 21.730621814727783
  time_total_s: 242.30754470825195
  timers:
    learn_throughput: 7405.477
    learn_time_ms: 16385.71
    sample_throughput: 22442.098
    sample_time_ms: 5406.981
    update_time_ms: 29.414
  timestamp: 1602429163
  timesteps_since_restore: 0
  timesteps_total: 1334784
  training_iteration: 11
  trial_id: a1235_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     11 |          242.308 | 1334784 |  228.588 |              287.232 |              115.717 |            853.943 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a1235_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3540.557493540052
    time_step_min: 3160
  date: 2020-10-11_15-13-04
  done: false
  episode_len_mean: 850.8380771663504
  episode_reward_max: 287.232323232323
  episode_reward_mean: 230.23243823433563
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 145
  episodes_total: 1581
  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.0262405020850045
        entropy_coeff: 0.00010000000000000002
        kl: 0.005980719346553087
        model: {}
        policy_loss: -0.014333377592265606
        total_loss: 13.499579974583217
        vf_explained_var: 0.9717524647712708
        vf_loss: 13.51282024383545
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.668000000000003
    gpu_util_percent0: 0.39159999999999995
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.6600000000000006
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35160
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15429620617145812
    mean_env_wait_ms: 1.1833319060761593
    mean_inference_ms: 4.843988008368151
    mean_raw_obs_processing_ms: 0.40454396907496637
  time_since_restore: 263.8103744983673
  time_this_iter_s: 21.502829790115356
  time_total_s: 263.8103744983673
  timers:
    learn_throughput: 7408.141
    learn_time_ms: 16379.818
    sample_throughput: 22856.872
    sample_time_ms: 5308.863
    update_time_ms: 27.555
  timestamp: 1602429184
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 12
  trial_id: a1235_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     12 |           263.81 | 1456128 |  230.232 |              287.232 |              115.717 |            850.838 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a1235_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3530.9941348973607
    time_step_min: 3160
  date: 2020-10-11_15-13-26
  done: false
  episode_len_mean: 847.584004602992
  episode_reward_max: 287.232323232323
  episode_reward_mean: 231.74273227092547
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 157
  episodes_total: 1738
  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.0086423328944616
        entropy_coeff: 0.00010000000000000002
        kl: 0.006141403956072671
        model: {}
        policy_loss: -0.014106190563844783
        total_loss: 13.797930717468262
        vf_explained_var: 0.9745455980300903
        vf_loss: 13.810909271240234
    num_steps_sampled: 1577472
    num_steps_trained: 1577472
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.456
    gpu_util_percent0: 0.29279999999999995
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.6600000000000006
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35160
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15386821835674025
    mean_env_wait_ms: 1.1847743693546156
    mean_inference_ms: 4.813818277470295
    mean_raw_obs_processing_ms: 0.4032167996556026
  time_since_restore: 285.65070486068726
  time_this_iter_s: 21.840330362319946
  time_total_s: 285.65070486068726
  timers:
    learn_throughput: 7414.726
    learn_time_ms: 16365.271
    sample_throughput: 22797.837
    sample_time_ms: 5322.61
    update_time_ms: 25.914
  timestamp: 1602429206
  timesteps_since_restore: 0
  timesteps_total: 1577472
  training_iteration: 13
  trial_id: a1235_00000
  
== Status ==
Memory usage on this node: 27.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     13 |          285.651 | 1577472 |  231.743 |              287.232 |              115.717 |            847.584 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a1235_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3521.369833601718
    time_step_min: 3160
  date: 2020-10-11_15-13-48
  done: false
  episode_len_mean: 844.5965189873418
  episode_reward_max: 287.232323232323
  episode_reward_mean: 233.0428014320418
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 158
  episodes_total: 1896
  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.9857570443834577
        entropy_coeff: 0.00010000000000000002
        kl: 0.006410458457789251
        model: {}
        policy_loss: -0.013821696629747748
        total_loss: 15.916649545942034
        vf_explained_var: 0.9734243154525757
        vf_loss: 15.92928763798305
    num_steps_sampled: 1698816
    num_steps_trained: 1698816
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.988000000000003
    gpu_util_percent0: 0.37560000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.6600000000000006
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35160
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15349101006112637
    mean_env_wait_ms: 1.1861817431817772
    mean_inference_ms: 4.7871644737859835
    mean_raw_obs_processing_ms: 0.40207297784463586
  time_since_restore: 307.2017602920532
  time_this_iter_s: 21.551055431365967
  time_total_s: 307.2017602920532
  timers:
    learn_throughput: 7423.694
    learn_time_ms: 16345.5
    sample_throughput: 22760.201
    sample_time_ms: 5331.412
    update_time_ms: 25.526
  timestamp: 1602429228
  timesteps_since_restore: 0
  timesteps_total: 1698816
  training_iteration: 14
  trial_id: a1235_00000
  
== Status ==
Memory usage on this node: 27.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     14 |          307.202 | 1698816 |  233.043 |              287.232 |              115.717 |            844.597 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a1235_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3513.2290945076693
    time_step_min: 3160
  date: 2020-10-11_15-14-10
  done: false
  episode_len_mean: 842.1966893865628
  episode_reward_max: 287.232323232323
  episode_reward_mean: 234.1798166671583
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.9603591901915414
        entropy_coeff: 0.00010000000000000002
        kl: 0.005421308800578117
        model: {}
        policy_loss: -0.013045819792231279
        total_loss: 15.805892671857562
        vf_explained_var: 0.9750902056694031
        vf_loss: 15.817950112479073
    num_steps_sampled: 1820160
    num_steps_trained: 1820160
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.016
    gpu_util_percent0: 0.2904
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.6600000000000006
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35160
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15315197911764228
    mean_env_wait_ms: 1.1875165970511823
    mean_inference_ms: 4.76345541623027
    mean_raw_obs_processing_ms: 0.4010729771882032
  time_since_restore: 328.93989777565
  time_this_iter_s: 21.7381374835968
  time_total_s: 328.93989777565
  timers:
    learn_throughput: 7436.89
    learn_time_ms: 16316.498
    sample_throughput: 22649.632
    sample_time_ms: 5357.438
    update_time_ms: 25.23
  timestamp: 1602429250
  timesteps_since_restore: 0
  timesteps_total: 1820160
  training_iteration: 15
  trial_id: a1235_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     15 |           328.94 | 1820160 |   234.18 |              287.232 |              115.717 |            842.197 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a1235_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3504.793483249197
    time_step_min: 3160
  date: 2020-10-11_15-14-32
  done: false
  episode_len_mean: 839.8942133815551
  episode_reward_max: 287.232323232323
  episode_reward_mean: 235.41078506584824
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.9449490819658551
        entropy_coeff: 0.00010000000000000002
        kl: 0.005445404909551144
        model: {}
        policy_loss: -0.011962981628520148
        total_loss: 16.383984565734863
        vf_explained_var: 0.9741386771202087
        vf_loss: 16.39495345524379
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.316
    gpu_util_percent0: 0.2984
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.664
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35160
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1528484315543595
    mean_env_wait_ms: 1.1887911368071282
    mean_inference_ms: 4.74218131957616
    mean_raw_obs_processing_ms: 0.40017344519996434
  time_since_restore: 350.6772770881653
  time_this_iter_s: 21.73737931251526
  time_total_s: 350.6772770881653
  timers:
    learn_throughput: 7450.254
    learn_time_ms: 16287.23
    sample_throughput: 22630.488
    sample_time_ms: 5361.97
    update_time_ms: 24.494
  timestamp: 1602429272
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 16
  trial_id: a1235_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     16 |          350.677 | 1941504 |  235.411 |              287.232 |              115.717 |            839.894 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a1235_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3497.7826272999573
    time_step_min: 3160
  date: 2020-10-11_15-14-53
  done: false
  episode_len_mean: 838.1071729957806
  episode_reward_max: 287.232323232323
  episode_reward_mean: 236.4022503516173
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.9374308075223651
        entropy_coeff: 0.00010000000000000002
        kl: 0.00559737127540367
        model: {}
        policy_loss: -0.013294356209891183
        total_loss: 15.215373992919922
        vf_explained_var: 0.9764556884765625
        vf_loss: 15.227642059326172
    num_steps_sampled: 2062848
    num_steps_trained: 2062848
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.4
    gpu_util_percent0: 0.324
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.664
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35160
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15257724502817518
    mean_env_wait_ms: 1.1899996811690225
    mean_inference_ms: 4.722984159887902
    mean_raw_obs_processing_ms: 0.3993836746575927
  time_since_restore: 372.45178604125977
  time_this_iter_s: 21.774508953094482
  time_total_s: 372.45178604125977
  timers:
    learn_throughput: 7461.078
    learn_time_ms: 16263.601
    sample_throughput: 22537.187
    sample_time_ms: 5384.168
    update_time_ms: 23.077
  timestamp: 1602429293
  timesteps_since_restore: 0
  timesteps_total: 2062848
  training_iteration: 17
  trial_id: a1235_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     17 |          372.452 | 2062848 |  236.402 |              287.232 |              115.717 |            838.107 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a1235_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3491.910621242485
    time_step_min: 3160
  date: 2020-10-11_15-15-15
  done: false
  episode_len_mean: 836.8564082278481
  episode_reward_max: 287.232323232323
  episode_reward_mean: 237.2802111302901
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 158
  episodes_total: 2528
  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.9169140458106995
        entropy_coeff: 0.00010000000000000002
        kl: 0.005850059778562614
        model: {}
        policy_loss: -0.013017413771844335
        total_loss: 16.00598362513951
        vf_explained_var: 0.9751184582710266
        vf_loss: 16.017922810145787
    num_steps_sampled: 2184192
    num_steps_trained: 2184192
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.24
    gpu_util_percent0: 0.39039999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.668
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35160
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15233482988803507
    mean_env_wait_ms: 1.191126424984892
    mean_inference_ms: 4.705623686958995
    mean_raw_obs_processing_ms: 0.39866854001910007
  time_since_restore: 393.76717138290405
  time_this_iter_s: 21.315385341644287
  time_total_s: 393.76717138290405
  timers:
    learn_throughput: 7475.193
    learn_time_ms: 16232.892
    sample_throughput: 22566.407
    sample_time_ms: 5377.196
    update_time_ms: 21.214
  timestamp: 1602429315
  timesteps_since_restore: 0
  timesteps_total: 2184192
  training_iteration: 18
  trial_id: a1235_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     18 |          393.767 | 2184192 |   237.28 |              287.232 |              115.717 |            836.856 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a1235_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3486.705616283453
    time_step_min: 3160
  date: 2020-10-11_15-15-36
  done: false
  episode_len_mean: 835.8983618763962
  episode_reward_max: 287.232323232323
  episode_reward_mean: 238.1144505366395
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 158
  episodes_total: 2686
  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.8977000202451434
        entropy_coeff: 0.00010000000000000002
        kl: 0.005370115794773612
        model: {}
        policy_loss: -0.011884738267066755
        total_loss: 14.289475440979004
        vf_explained_var: 0.977433979511261
        vf_loss: 14.300375665937151
    num_steps_sampled: 2305536
    num_steps_trained: 2305536
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.535999999999998
    gpu_util_percent0: 0.41440000000000005
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.668
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35160
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15211533498846555
    mean_env_wait_ms: 1.1921504369177447
    mean_inference_ms: 4.6898987667105825
    mean_raw_obs_processing_ms: 0.39802764639523003
  time_since_restore: 415.3786497116089
  time_this_iter_s: 21.611478328704834
  time_total_s: 415.3786497116089
  timers:
    learn_throughput: 7486.311
    learn_time_ms: 16208.785
    sample_throughput: 22589.843
    sample_time_ms: 5371.618
    update_time_ms: 20.898
  timestamp: 1602429336
  timesteps_since_restore: 0
  timesteps_total: 2305536
  training_iteration: 19
  trial_id: a1235_00000
  
== Status ==
Memory usage on this node: 27.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     19 |          415.379 | 2305536 |  238.114 |              287.232 |              115.717 |            835.898 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a1235_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3481.1924581999288
    time_step_min: 3160
  date: 2020-10-11_15-15-58
  done: false
  episode_len_mean: 834.8027426160338
  episode_reward_max: 287.232323232323
  episode_reward_mean: 238.9297297873246
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.882460491997855
        entropy_coeff: 0.00010000000000000002
        kl: 0.005906718250896249
        model: {}
        policy_loss: -0.01405173699770655
        total_loss: 12.80661950792585
        vf_explained_var: 0.9789648652076721
        vf_loss: 12.819578034537178
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.484615384615385
    gpu_util_percent0: 0.36038461538461536
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.673076923076923
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35160
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1519120577690361
    mean_env_wait_ms: 1.1930926752877107
    mean_inference_ms: 4.675480897578167
    mean_raw_obs_processing_ms: 0.3974390370694435
  time_since_restore: 436.8603720664978
  time_this_iter_s: 21.481722354888916
  time_total_s: 436.8603720664978
  timers:
    learn_throughput: 7498.562
    learn_time_ms: 16182.302
    sample_throughput: 22600.883
    sample_time_ms: 5368.994
    update_time_ms: 20.624
  timestamp: 1602429358
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 20
  trial_id: a1235_00000
  
== Status ==
Memory usage on this node: 27.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     20 |           436.86 | 2426880 |   238.93 |              287.232 |              115.717 |            834.803 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a1235_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3476.7905018524757
    time_step_min: 3160
  date: 2020-10-11_15-16-20
  done: false
  episode_len_mean: 833.8247834776815
  episode_reward_max: 287.232323232323
  episode_reward_mean: 239.44811876257563
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.8673635806356158
        entropy_coeff: 0.00010000000000000002
        kl: 0.00530183847461428
        model: {}
        policy_loss: -0.013066353276371956
        total_loss: 12.449682371956962
        vf_explained_var: 0.9802118539810181
        vf_loss: 12.46177509852818
    num_steps_sampled: 2548224
    num_steps_trained: 2548224
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.432000000000006
    gpu_util_percent0: 0.3924
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.6800000000000006
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35160
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15172860233482208
    mean_env_wait_ms: 1.1939782753839872
    mean_inference_ms: 4.6623335323887884
    mean_raw_obs_processing_ms: 0.39690189844466195
  time_since_restore: 458.4210512638092
  time_this_iter_s: 21.5606791973114
  time_total_s: 458.4210512638092
  timers:
    learn_throughput: 7518.615
    learn_time_ms: 16139.143
    sample_throughput: 22508.453
    sample_time_ms: 5391.041
    update_time_ms: 22.393
  timestamp: 1602429380
  timesteps_since_restore: 0
  timesteps_total: 2548224
  training_iteration: 21
  trial_id: a1235_00000
  
== Status ==
Memory usage on this node: 27.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     21 |          458.421 | 2548224 |  239.448 |              287.232 |              115.717 |            833.825 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a1235_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3473.221618164375
    time_step_min: 3160
  date: 2020-10-11_15-16-42
  done: false
  episode_len_mean: 832.7841772151899
  episode_reward_max: 287.232323232323
  episode_reward_mean: 240.0985487789284
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 158
  episodes_total: 3160
  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.8546512126922607
        entropy_coeff: 0.00010000000000000002
        kl: 0.005708524624684027
        model: {}
        policy_loss: -0.012896726040967874
        total_loss: 13.318900789533343
        vf_explained_var: 0.9785168766975403
        vf_loss: 13.330741064889091
    num_steps_sampled: 2669568
    num_steps_trained: 2669568
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.732000000000003
    gpu_util_percent0: 0.3812
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.676
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35160
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1515593391654816
    mean_env_wait_ms: 1.1948021353136944
    mean_inference_ms: 4.6502269982439834
    mean_raw_obs_processing_ms: 0.3964146444561648
  time_since_restore: 480.10277342796326
  time_this_iter_s: 21.681722164154053
  time_total_s: 480.10277342796326
  timers:
    learn_throughput: 7527.616
    learn_time_ms: 16119.844
    sample_throughput: 22356.062
    sample_time_ms: 5427.79
    update_time_ms: 22.418
  timestamp: 1602429402
  timesteps_since_restore: 0
  timesteps_total: 2669568
  training_iteration: 22
  trial_id: a1235_00000
  
== Status ==
Memory usage on this node: 27.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     22 |          480.103 | 2669568 |  240.099 |              287.232 |              115.717 |            832.784 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a1235_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3468.681887366819
    time_step_min: 3160
  date: 2020-10-11_15-17-03
  done: false
  episode_len_mean: 831.6208559373116
  episode_reward_max: 287.232323232323
  episode_reward_mean: 240.76306464281137
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 158
  episodes_total: 3318
  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.8429547377995082
        entropy_coeff: 0.00010000000000000002
        kl: 0.005444437265396118
        model: {}
        policy_loss: -0.013345049694180489
        total_loss: 12.22777053288051
        vf_explained_var: 0.979284405708313
        vf_loss: 12.240111078534808
    num_steps_sampled: 2790912
    num_steps_trained: 2790912
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.77692307692308
    gpu_util_percent0: 0.35500000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.673076923076923
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35160
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.151402365872835
    mean_env_wait_ms: 1.195593929805584
    mean_inference_ms: 4.639032297927149
    mean_raw_obs_processing_ms: 0.39596820923444437
  time_since_restore: 501.7664008140564
  time_this_iter_s: 21.66362738609314
  time_total_s: 501.7664008140564
  timers:
    learn_throughput: 7523.043
    learn_time_ms: 16129.642
    sample_throughput: 22470.793
    sample_time_ms: 5400.077
    update_time_ms: 22.47
  timestamp: 1602429423
  timesteps_since_restore: 0
  timesteps_total: 2790912
  training_iteration: 23
  trial_id: a1235_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     23 |          501.766 | 2790912 |  240.763 |              287.232 |              115.717 |            831.621 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a1235_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3465.0403952339434
    time_step_min: 3160
  date: 2020-10-11_15-17-25
  done: false
  episode_len_mean: 830.4363845710996
  episode_reward_max: 290.5656565656564
  episode_reward_mean: 241.39702726749348
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 156
  episodes_total: 3474
  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.8283182467733111
        entropy_coeff: 0.00010000000000000002
        kl: 0.005241083912551403
        model: {}
        policy_loss: -0.012423754736248935
        total_loss: 11.81918443952288
        vf_explained_var: 0.9798650741577148
        vf_loss: 11.830643245152064
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.39230769230769
    gpu_util_percent0: 0.35923076923076913
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.673076923076923
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35160
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15126197705114475
    mean_env_wait_ms: 1.1963604561138745
    mean_inference_ms: 4.628844870479084
    mean_raw_obs_processing_ms: 0.395573502939486
  time_since_restore: 523.427011013031
  time_this_iter_s: 21.66061019897461
  time_total_s: 523.427011013031
  timers:
    learn_throughput: 7522.297
    learn_time_ms: 16131.242
    sample_throughput: 22463.458
    sample_time_ms: 5401.84
    update_time_ms: 22.776
  timestamp: 1602429445
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 24
  trial_id: a1235_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     24 |          523.427 | 2912256 |  241.397 |              290.566 |              115.717 |            830.436 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a1235_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3460.9023372287147
    time_step_min: 3153
  date: 2020-10-11_15-17-47
  done: false
  episode_len_mean: 829.4948993658671
  episode_reward_max: 290.5656565656564
  episode_reward_mean: 241.90840581163147
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 153
  episodes_total: 3627
  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.8223013026373727
        entropy_coeff: 0.00010000000000000002
        kl: 0.005043058589633022
        model: {}
        policy_loss: -0.01201772882736155
        total_loss: 13.969212940761022
        vf_explained_var: 0.9765128493309021
        vf_loss: 13.98030458177839
    num_steps_sampled: 3033600
    num_steps_trained: 3033600
  iterations_since_restore: 25
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.528000000000002
    gpu_util_percent0: 0.376
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.676
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35160
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1511289350629235
    mean_env_wait_ms: 1.1970657157663167
    mean_inference_ms: 4.619344182754572
    mean_raw_obs_processing_ms: 0.3951966731956858
  time_since_restore: 544.9810814857483
  time_this_iter_s: 21.554070472717285
  time_total_s: 544.9810814857483
  timers:
    learn_throughput: 7529.301
    learn_time_ms: 16116.237
    sample_throughput: 22475.002
    sample_time_ms: 5399.065
    update_time_ms: 21.135
  timestamp: 1602429467
  timesteps_since_restore: 0
  timesteps_total: 3033600
  training_iteration: 25
  trial_id: a1235_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     25 |          544.981 | 3033600 |  241.908 |              290.566 |              115.717 |            829.495 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a1235_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3457.9705960973
    time_step_min: 3153
  date: 2020-10-11_15-18-09
  done: false
  episode_len_mean: 828.4104398516163
  episode_reward_max: 290.5656565656564
  episode_reward_mean: 242.37127234186048
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 147
  episodes_total: 3774
  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.8078862173216683
        entropy_coeff: 0.00010000000000000002
        kl: 0.005040723165231091
        model: {}
        policy_loss: -0.011561505563024963
        total_loss: 11.968094280787877
        vf_explained_var: 0.9794151186943054
        vf_loss: 11.978727749415807
    num_steps_sampled: 3154944
    num_steps_trained: 3154944
  iterations_since_restore: 26
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.244
    gpu_util_percent0: 0.39640000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.676
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35160
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15101266406896607
    mean_env_wait_ms: 1.1977560560323717
    mean_inference_ms: 4.610893338816044
    mean_raw_obs_processing_ms: 0.3948661709355843
  time_since_restore: 566.7003345489502
  time_this_iter_s: 21.719253063201904
  time_total_s: 566.7003345489502
  timers:
    learn_throughput: 7531.457
    learn_time_ms: 16111.625
    sample_throughput: 22464.259
    sample_time_ms: 5401.647
    update_time_ms: 21.315
  timestamp: 1602429489
  timesteps_since_restore: 0
  timesteps_total: 3154944
  training_iteration: 26
  trial_id: a1235_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     26 |            566.7 | 3154944 |  242.371 |              290.566 |              115.717 |             828.41 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a1235_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3454.131240349974
    time_step_min: 3147
  date: 2020-10-11_15-18-31
  done: false
  episode_len_mean: 827.2209747384537
  episode_reward_max: 290.5656565656564
  episode_reward_mean: 242.9242127836156
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 145
  episodes_total: 3919
  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.7926655837467739
        entropy_coeff: 0.00010000000000000002
        kl: 0.005787588655948639
        model: {}
        policy_loss: -0.013243382131414754
        total_loss: 10.253864560808454
        vf_explained_var: 0.9815097451210022
        vf_loss: 10.266029494149345
    num_steps_sampled: 3276288
    num_steps_trained: 3276288
  iterations_since_restore: 27
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.54615384615385
    gpu_util_percent0: 0.42153846153846164
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.676923076923077
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35160
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15090275323815575
    mean_env_wait_ms: 1.198396149093764
    mean_inference_ms: 4.602908536633501
    mean_raw_obs_processing_ms: 0.39454760886513374
  time_since_restore: 588.3199353218079
  time_this_iter_s: 21.619600772857666
  time_total_s: 588.3199353218079
  timers:
    learn_throughput: 7530.042
    learn_time_ms: 16114.651
    sample_throughput: 22550.089
    sample_time_ms: 5381.087
    update_time_ms: 20.923
  timestamp: 1602429511
  timesteps_since_restore: 0
  timesteps_total: 3276288
  training_iteration: 27
  trial_id: a1235_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     27 |           588.32 | 3276288 |  242.924 |              290.566 |              115.717 |            827.221 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a1235_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3450.2483822797412
    time_step_min: 3147
  date: 2020-10-11_15-18-52
  done: true
  episode_len_mean: 826.2327820291287
  episode_reward_max: 290.5656565656564
  episode_reward_mean: 243.47436597522983
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 132
  episodes_total: 4051
  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.780083451952253
        entropy_coeff: 0.00010000000000000002
        kl: 0.005220116049583469
        model: {}
        policy_loss: -0.014391705651567983
        total_loss: 7.889552388872419
        vf_explained_var: 0.9851317405700684
        vf_loss: 7.90297760282244
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 28
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.296
    gpu_util_percent0: 0.3863999999999999
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.676
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35160
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.150802969938926
    mean_env_wait_ms: 1.198978183822521
    mean_inference_ms: 4.596044766607328
    mean_raw_obs_processing_ms: 0.39428733205890293
  time_since_restore: 609.900298833847
  time_this_iter_s: 21.580363512039185
  time_total_s: 609.900298833847
  timers:
    learn_throughput: 7518.391
    learn_time_ms: 16139.623
    sample_throughput: 22544.979
    sample_time_ms: 5382.307
    update_time_ms: 21.19
  timestamp: 1602429532
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 28
  trial_id: a1235_00000
  
== Status ==
Memory usage on this node: 27.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a1235_00000 | TERMINATED |       |     28 |            609.9 | 3397632 |  243.474 |              290.566 |              115.717 |            826.233 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 27.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a1235_00000 | TERMINATED |       |     28 |            609.9 | 3397632 |  243.474 |              290.566 |              115.717 |            826.233 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Traceback (most recent call last):
  File "/root/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py", line 2895, in get_loc
    return self._engine.get_loc(casted_key)
  File "pandas/_libs/index.pyx", line 70, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index.pyx", line 101, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 1675, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 1683, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'custom_metrics/time_step_min'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "train.py", line 72, in <module>
    train_func()
  File "train.py", line 57, in train_func
    result = analysis.dataframe(metric='custom_metrics/time_step_min', mode='min').to_dict('index')[0]
  File "/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py", line 92, in dataframe
    rows = self._retrieve_rows(metric=metric, mode=mode)
  File "/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py", line 254, in _retrieve_rows
    idx = df[metric].idxmin()
  File "/root/miniconda3/lib/python3.8/site-packages/pandas/core/frame.py", line 2902, in __getitem__
    indexer = self.columns.get_loc(key)
  File "/root/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py", line 2897, in get_loc
    raise KeyError(key) from err
KeyError: 'custom_metrics/time_step_min'
