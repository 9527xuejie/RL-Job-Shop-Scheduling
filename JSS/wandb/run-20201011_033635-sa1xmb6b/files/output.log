2020-10-11 03:36:37,178	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_f85b2_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=61262)[0m 2020-10-11 03:36:40,151	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=61186)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61186)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61268)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61268)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61149)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61149)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61127)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61127)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61133)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61133)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61224)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61224)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61147)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61147)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61219)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61219)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61151)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61151)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61255)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61255)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61204)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61204)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61226)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61226)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61199)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61199)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61214)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61214)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61228)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61228)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61259)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61259)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61187)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61187)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61131)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61131)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61162)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61162)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61260)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61260)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61189)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61189)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61143)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61143)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61138)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61138)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61207)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61207)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61197)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61197)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61154)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61154)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61208)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61208)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61211)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61211)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61249)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61249)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61159)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61159)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61270)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61270)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61158)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61158)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61233)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61233)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61165)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61165)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61198)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61198)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61135)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61135)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61130)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61130)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61137)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61137)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61140)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61140)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61141)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61141)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61167)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61167)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61212)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61212)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61250)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61250)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61217)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61217)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61257)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61257)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61183)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61183)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61220)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61220)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61132)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61132)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61152)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61152)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61190)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61190)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61136)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61136)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61200)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61200)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61163)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61163)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61209)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61209)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61128)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61128)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61215)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61215)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61191)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61191)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61229)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61229)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61205)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61205)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61144)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61144)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61166)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61166)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61247)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61247)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61206)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61206)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61202)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61202)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61240)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61240)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61231)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61231)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61169)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61169)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61237)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61237)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61145)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61145)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61234)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61234)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61210)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61210)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61221)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61221)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61139)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61139)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61213)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61213)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61195)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61195)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61223)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61223)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61129)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61129)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61264)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61264)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61241)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61241)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_f85b2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_03-37-17
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 28c0231037404781a19589d1493aab3c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1781676752226693
        entropy_coeff: 0.00010000000000000002
        kl: 0.011411722150764294
        model: {}
        policy_loss: -0.013402055824242
        total_loss: 9.507761137826103
        vf_explained_var: 0.7608073353767395
        vf_loss: 9.518998350415911
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.134210526315787
    gpu_util_percent0: 0.29552631578947364
    gpu_util_percent1: 0.0002631578947368421
    gpu_util_percent2: 0.0002631578947368421
    ram_util_percent: 6.273684210526317
    vram_util_percent0: 0.19071826828468355
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 61262
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17627505838006097
    mean_env_wait_ms: 1.2158076311931745
    mean_inference_ms: 6.24566951774086
    mean_raw_obs_processing_ms: 0.47832104187388597
  time_since_restore: 31.97628903388977
  time_this_iter_s: 31.97628903388977
  time_total_s: 31.97628903388977
  timers:
    learn_throughput: 7217.318
    learn_time_ms: 22417.192
    sample_throughput: 17076.876
    sample_time_ms: 9474.333
    update_time_ms: 44.669
  timestamp: 1602387437
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: f85b2_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f85b2_00000 | RUNNING  | 172.17.0.4:61262 |      1 |          31.9763 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f85b2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3629.465277777778
    time_step_min: 3311
  date: 2020-10-11_03-37-48
  done: false
  episode_len_mean: 878.6044303797469
  episode_reward_max: 264.35353535353516
  episode_reward_mean: 215.80971103439435
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 28c0231037404781a19589d1493aab3c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.141499093600682
        entropy_coeff: 0.00010000000000000002
        kl: 0.012650819894458567
        model: {}
        policy_loss: -0.01348399237862655
        total_loss: 8.796412059238978
        vf_explained_var: 0.8943076729774475
        vf_loss: 8.807480335235596
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.14324324324324
    gpu_util_percent0: 0.37594594594594594
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4702702702702695
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 61262
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17062315879716086
    mean_env_wait_ms: 1.2116229933243758
    mean_inference_ms: 5.900977209999859
    mean_raw_obs_processing_ms: 0.4611026287829458
  time_since_restore: 62.482203006744385
  time_this_iter_s: 30.505913972854614
  time_total_s: 62.482203006744385
  timers:
    learn_throughput: 7241.101
    learn_time_ms: 22343.562
    sample_throughput: 18352.931
    sample_time_ms: 8815.595
    update_time_ms: 38.291
  timestamp: 1602387468
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: f85b2_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f85b2_00000 | RUNNING  | 172.17.0.4:61262 |      2 |          62.4822 | 323584 |   215.81 |              264.354 |              145.717 |            878.604 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f85b2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3622.0650224215246
    time_step_min: 3284
  date: 2020-10-11_03-38-18
  done: false
  episode_len_mean: 867.2362869198312
  episode_reward_max: 268.44444444444485
  episode_reward_mean: 218.09410561309278
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 28c0231037404781a19589d1493aab3c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1169013381004333
        entropy_coeff: 0.00010000000000000002
        kl: 0.012539237271994352
        model: {}
        policy_loss: -0.01680817687468204
        total_loss: 7.114015579223633
        vf_explained_var: 0.9454495310783386
        vf_loss: 7.1284275736127585
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.05142857142857
    gpu_util_percent0: 0.3768571428571429
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488571428571428
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 61262
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16715635864249723
    mean_env_wait_ms: 1.2116700764467292
    mean_inference_ms: 5.658082633476958
    mean_raw_obs_processing_ms: 0.4491845603870654
  time_since_restore: 92.25545883178711
  time_this_iter_s: 29.773255825042725
  time_total_s: 92.25545883178711
  timers:
    learn_throughput: 7231.077
    learn_time_ms: 22374.539
    sample_throughput: 19510.398
    sample_time_ms: 8292.604
    update_time_ms: 39.722
  timestamp: 1602387498
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: f85b2_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f85b2_00000 | RUNNING  | 172.17.0.4:61262 |      3 |          92.2555 | 485376 |  218.094 |              268.444 |              145.717 |            867.236 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f85b2_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3621.9354304635763
    time_step_min: 3284
  date: 2020-10-11_03-38-47
  done: false
  episode_len_mean: 859.6882911392405
  episode_reward_max: 268.44444444444485
  episode_reward_mean: 218.7261379618973
  episode_reward_min: 115.71717171717144
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 28c0231037404781a19589d1493aab3c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0816823414393835
        entropy_coeff: 0.00010000000000000002
        kl: 0.01164373050310782
        model: {}
        policy_loss: -0.01731702309500958
        total_loss: 7.739458492824009
        vf_explained_var: 0.9616319537162781
        vf_loss: 7.754554850714547
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.75
    gpu_util_percent0: 0.32888888888888884
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.480555555555555
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 61262
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16475979461267706
    mean_env_wait_ms: 1.213501557004702
    mean_inference_ms: 5.485983774653999
    mean_raw_obs_processing_ms: 0.44060243289620904
  time_since_restore: 121.86947059631348
  time_this_iter_s: 29.614011764526367
  time_total_s: 121.86947059631348
  timers:
    learn_throughput: 7224.725
    learn_time_ms: 22394.209
    sample_throughput: 20245.698
    sample_time_ms: 7991.426
    update_time_ms: 37.006
  timestamp: 1602387527
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: f85b2_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f85b2_00000 | RUNNING  | 172.17.0.4:61262 |      4 |          121.869 | 647168 |  218.726 |              268.444 |              115.717 |            859.688 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f85b2_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3613.4362637362638
    time_step_min: 3284
  date: 2020-10-11_03-39-17
  done: false
  episode_len_mean: 845.4445628997868
  episode_reward_max: 268.44444444444485
  episode_reward_mean: 219.459822101613
  episode_reward_min: 95.71717171717164
  episodes_this_iter: 306
  episodes_total: 938
  experiment_id: 28c0231037404781a19589d1493aab3c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0512555752481734
        entropy_coeff: 0.00010000000000000002
        kl: 0.012501361979437726
        model: {}
        policy_loss: -0.01640211108938924
        total_loss: 11.29714550290789
        vf_explained_var: 0.9746953845024109
        vf_loss: 11.311152458190918
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.805714285714288
    gpu_util_percent0: 0.3302857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.485714285714286
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 61262
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16178184444601995
    mean_env_wait_ms: 1.219541173922486
    mean_inference_ms: 5.2732448403176235
    mean_raw_obs_processing_ms: 0.4304885649857023
  time_since_restore: 151.38592052459717
  time_this_iter_s: 29.51644992828369
  time_total_s: 151.38592052459717
  timers:
    learn_throughput: 7227.114
    learn_time_ms: 22386.807
    sample_throughput: 20715.845
    sample_time_ms: 7810.06
    update_time_ms: 34.697
  timestamp: 1602387557
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: f85b2_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f85b2_00000 | RUNNING  | 172.17.0.4:61262 |      5 |          151.386 | 808960 |   219.46 |              268.444 |              95.7172 |            845.445 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f85b2_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3605.3933209647494
    time_step_min: 3284
  date: 2020-10-11_03-39-47
  done: false
  episode_len_mean: 839.7142857142857
  episode_reward_max: 274.0505050505051
  episode_reward_mean: 221.08212322136362
  episode_reward_min: 95.71717171717164
  episodes_this_iter: 168
  episodes_total: 1106
  experiment_id: 28c0231037404781a19589d1493aab3c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0309728724615914
        entropy_coeff: 0.00010000000000000002
        kl: 0.01194529521412083
        model: {}
        policy_loss: -0.0174285397598786
        total_loss: 5.384829146521432
        vf_explained_var: 0.9832424521446228
        vf_loss: 5.3999717235565186
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.8
    gpu_util_percent0: 0.2788571428571428
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494285714285714
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 61262
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16066285674424943
    mean_env_wait_ms: 1.2220347858480307
    mean_inference_ms: 5.195232183944337
    mean_raw_obs_processing_ms: 0.4266543240329463
  time_since_restore: 181.08729767799377
  time_this_iter_s: 29.701377153396606
  time_total_s: 181.08729767799377
  timers:
    learn_throughput: 7224.594
    learn_time_ms: 22394.614
    sample_throughput: 20992.083
    sample_time_ms: 7707.287
    update_time_ms: 32.465
  timestamp: 1602387587
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: f85b2_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f85b2_00000 | RUNNING  | 172.17.0.4:61262 |      6 |          181.087 | 970752 |  221.082 |              274.051 |              95.7172 |            839.714 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f85b2_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3595.0501618122976
    time_step_min: 3284
  date: 2020-10-11_03-40-16
  done: false
  episode_len_mean: 834.8354430379746
  episode_reward_max: 274.0505050505051
  episode_reward_mean: 222.59301080424484
  episode_reward_min: 95.71717171717164
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 28c0231037404781a19589d1493aab3c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.987716372523989
        entropy_coeff: 0.00010000000000000002
        kl: 0.012805715269808258
        model: {}
        policy_loss: -0.018782496186239377
        total_loss: 4.529112713677542
        vf_explained_var: 0.9876767992973328
        vf_loss: 4.545432806015015
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.99142857142857
    gpu_util_percent0: 0.3697142857142857
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.482857142857142
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 61262
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15979365320796587
    mean_env_wait_ms: 1.2241463765920608
    mean_inference_ms: 5.132309485844978
    mean_raw_obs_processing_ms: 0.4235800176209415
  time_since_restore: 210.75480484962463
  time_this_iter_s: 29.66750717163086
  time_total_s: 210.75480484962463
  timers:
    learn_throughput: 7219.497
    learn_time_ms: 22410.424
    sample_throughput: 21236.046
    sample_time_ms: 7618.744
    update_time_ms: 31.162
  timestamp: 1602387616
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: f85b2_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f85b2_00000 | RUNNING  | 172.17.0.4:61262 |      7 |          210.755 | 1132544 |  222.593 |              274.051 |              95.7172 |            834.835 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f85b2_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3584.8810035842293
    time_step_min: 3284
  date: 2020-10-11_03-40-46
  done: false
  episode_len_mean: 831.0864371047084
  episode_reward_max: 274.0505050505051
  episode_reward_mean: 224.07978591253354
  episode_reward_min: 95.71717171717164
  episodes_this_iter: 159
  episodes_total: 1423
  experiment_id: 28c0231037404781a19589d1493aab3c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9331145116261074
        entropy_coeff: 0.00010000000000000002
        kl: 0.011445465830287762
        model: {}
        policy_loss: -0.018381188191207393
        total_loss: 4.198788455554417
        vf_explained_var: 0.9911924004554749
        vf_loss: 4.214973977633885
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.57222222222222
    gpu_util_percent0: 0.3177777777777778
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4833333333333325
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 61262
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15904397676797138
    mean_env_wait_ms: 1.2262437748497061
    mean_inference_ms: 5.077668141486099
    mean_raw_obs_processing_ms: 0.42089808500510933
  time_since_restore: 240.33692979812622
  time_this_iter_s: 29.582124948501587
  time_total_s: 240.33692979812622
  timers:
    learn_throughput: 7229.871
    learn_time_ms: 22378.269
    sample_throughput: 21328.923
    sample_time_ms: 7585.568
    update_time_ms: 30.088
  timestamp: 1602387646
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: f85b2_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f85b2_00000 | RUNNING  | 172.17.0.4:61262 |      8 |          240.337 | 1294336 |   224.08 |              274.051 |              95.7172 |            831.086 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f85b2_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3570.595321637427
    time_step_min: 3256
  date: 2020-10-11_03-41-16
  done: false
  episode_len_mean: 825.470080552359
  episode_reward_max: 275.1111111111111
  episode_reward_mean: 225.93206518580502
  episode_reward_min: 95.71717171717164
  episodes_this_iter: 315
  episodes_total: 1738
  experiment_id: 28c0231037404781a19589d1493aab3c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8930432541029794
        entropy_coeff: 0.00010000000000000002
        kl: 0.010903582043413605
        model: {}
        policy_loss: -0.014028964663988777
        total_loss: 5.350602354322161
        vf_explained_var: 0.9919620156288147
        vf_loss: 5.362539904458182
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.385714285714286
    gpu_util_percent0: 0.3402857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4799999999999995
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 61262
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15788799141368542
    mean_env_wait_ms: 1.230090987119559
    mean_inference_ms: 4.9923916611656844
    mean_raw_obs_processing_ms: 0.4168654732250026
  time_since_restore: 270.0015003681183
  time_this_iter_s: 29.664570569992065
  time_total_s: 270.0015003681183
  timers:
    learn_throughput: 7231.422
    learn_time_ms: 22373.471
    sample_throughput: 21433.628
    sample_time_ms: 7548.512
    update_time_ms: 29.214
  timestamp: 1602387676
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: f85b2_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f85b2_00000 | RUNNING  | 172.17.0.4:61262 |      9 |          270.002 | 1456128 |  225.932 |              275.111 |              95.7172 |             825.47 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f85b2_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3565.7462526766594
    time_step_min: 3256
  date: 2020-10-11_03-41-45
  done: false
  episode_len_mean: 824.0121308016878
  episode_reward_max: 278.1414141414141
  episode_reward_mean: 226.63449367088597
  episode_reward_min: 95.71717171717164
  episodes_this_iter: 158
  episodes_total: 1896
  experiment_id: 28c0231037404781a19589d1493aab3c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8582396294389453
        entropy_coeff: 0.00010000000000000002
        kl: 0.01111948084352272
        model: {}
        policy_loss: -0.017128409718030264
        total_loss: 3.2653451647077287
        vf_explained_var: 0.993364155292511
        vf_loss: 3.280335477420262
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.945714285714285
    gpu_util_percent0: 0.3928571428571429
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494285714285714
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 61262
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1574198423805372
    mean_env_wait_ms: 1.231620357975314
    mean_inference_ms: 4.9577428882921435
    mean_raw_obs_processing_ms: 0.4152262802287756
  time_since_restore: 299.3278217315674
  time_this_iter_s: 29.326321363449097
  time_total_s: 299.3278217315674
  timers:
    learn_throughput: 7240.178
    learn_time_ms: 22346.412
    sample_throughput: 21548.299
    sample_time_ms: 7508.342
    update_time_ms: 28.561
  timestamp: 1602387705
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: f85b2_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f85b2_00000 | RUNNING  | 172.17.0.4:61262 |     10 |          299.328 | 1617920 |  226.634 |              278.141 |              95.7172 |            824.012 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f85b2_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3558.486673247779
    time_step_min: 3256
  date: 2020-10-11_03-42-15
  done: false
  episode_len_mean: 822.5783836416748
  episode_reward_max: 278.1414141414141
  episode_reward_mean: 227.6261593540074
  episode_reward_min: 95.71717171717164
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 28c0231037404781a19589d1493aab3c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8269567234175546
        entropy_coeff: 0.00010000000000000002
        kl: 0.0102892399632505
        model: {}
        policy_loss: -0.016177076547007476
        total_loss: 2.9080046585627963
        vf_explained_var: 0.9937753081321716
        vf_loss: 2.9222065721239363
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.29142857142857
    gpu_util_percent0: 0.35485714285714287
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497142857142856
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 61262
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15699942902815262
    mean_env_wait_ms: 1.2329888688533222
    mean_inference_ms: 4.926741003036493
    mean_raw_obs_processing_ms: 0.41372181207633535
  time_since_restore: 328.98929500579834
  time_this_iter_s: 29.661473274230957
  time_total_s: 328.98929500579834
  timers:
    learn_throughput: 7242.522
    learn_time_ms: 22339.178
    sample_throughput: 22211.621
    sample_time_ms: 7284.115
    update_time_ms: 27.24
  timestamp: 1602387735
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: f85b2_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f85b2_00000 | RUNNING  | 172.17.0.4:61262 |     11 |          328.989 | 1779712 |  227.626 |              278.141 |              95.7172 |            822.578 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f85b2_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3550.894713460684
    time_step_min: 3235
  date: 2020-10-11_03-42-45
  done: false
  episode_len_mean: 820.5616498464238
  episode_reward_max: 278.1414141414141
  episode_reward_mean: 228.87877901436474
  episode_reward_min: 95.71717171717164
  episodes_this_iter: 225
  episodes_total: 2279
  experiment_id: 28c0231037404781a19589d1493aab3c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.786286473274231
        entropy_coeff: 0.00010000000000000002
        kl: 0.009501454220818622
        model: {}
        policy_loss: -0.013954969189528908
        total_loss: 3.3197045496531894
        vf_explained_var: 0.9950272440910339
        vf_loss: 3.331837841442653
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.916666666666668
    gpu_util_percent0: 0.36
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486111111111111
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 61262
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15649175580569696
    mean_env_wait_ms: 1.2348297961161658
    mean_inference_ms: 4.887763608058729
    mean_raw_obs_processing_ms: 0.4118532637870141
  time_since_restore: 358.57941150665283
  time_this_iter_s: 29.590116500854492
  time_total_s: 358.57941150665283
  timers:
    learn_throughput: 7245.553
    learn_time_ms: 22329.835
    sample_throughput: 22466.37
    sample_time_ms: 7201.519
    update_time_ms: 26.786
  timestamp: 1602387765
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: f85b2_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f85b2_00000 | RUNNING  | 172.17.0.4:61262 |     12 |          358.579 | 1941504 |  228.879 |              278.141 |              95.7172 |            820.562 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f85b2_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3543.5124
    time_step_min: 3235
  date: 2020-10-11_03-43-15
  done: false
  episode_len_mean: 818.5150316455696
  episode_reward_max: 278.1414141414141
  episode_reward_mean: 229.79741241529211
  episode_reward_min: 95.71717171717164
  episodes_this_iter: 249
  episodes_total: 2528
  experiment_id: 28c0231037404781a19589d1493aab3c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.7446841256959098
        entropy_coeff: 0.00010000000000000002
        kl: 0.009407795566533293
        model: {}
        policy_loss: -0.012486937289525355
        total_loss: 3.5997407606669833
        vf_explained_var: 0.993655264377594
        vf_loss: 3.6104206698281422
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.125714285714285
    gpu_util_percent0: 0.3625714285714285
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.482857142857143
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 61262
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15599282545107473
    mean_env_wait_ms: 1.23670657058901
    mean_inference_ms: 4.851617422641366
    mean_raw_obs_processing_ms: 0.41010778892817457
  time_since_restore: 388.48282861709595
  time_this_iter_s: 29.903417110443115
  time_total_s: 388.48282861709595
  timers:
    learn_throughput: 7242.616
    learn_time_ms: 22338.888
    sample_throughput: 22455.018
    sample_time_ms: 7205.16
    update_time_ms: 26.359
  timestamp: 1602387795
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: f85b2_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f85b2_00000 | RUNNING  | 172.17.0.4:61262 |     13 |          388.483 | 2103296 |  229.797 |              278.141 |              95.7172 |            818.515 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f85b2_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3539.0079006772007
    time_step_min: 3235
  date: 2020-10-11_03-43-44
  done: false
  episode_len_mean: 817.3626209977662
  episode_reward_max: 278.1414141414141
  episode_reward_mean: 230.50050392232072
  episode_reward_min: 95.71717171717164
  episodes_this_iter: 158
  episodes_total: 2686
  experiment_id: 28c0231037404781a19589d1493aab3c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.733506977558136
        entropy_coeff: 0.00010000000000000002
        kl: 0.009504473701651608
        model: {}
        policy_loss: -0.014711189050493496
        total_loss: 2.319406202861241
        vf_explained_var: 0.9950905442237854
        vf_loss: 2.332289831978934
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.005714285714284
    gpu_util_percent0: 0.35200000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488571428571428
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 61262
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1557157295938352
    mean_env_wait_ms: 1.2377471992604971
    mean_inference_ms: 4.831136004644459
    mean_raw_obs_processing_ms: 0.4091351792935249
  time_since_restore: 417.84500074386597
  time_this_iter_s: 29.36217212677002
  time_total_s: 417.84500074386597
  timers:
    learn_throughput: 7251.379
    learn_time_ms: 22311.893
    sample_throughput: 22453.893
    sample_time_ms: 7205.521
    update_time_ms: 26.495
  timestamp: 1602387824
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: f85b2_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f85b2_00000 | RUNNING  | 172.17.0.4:61262 |     14 |          417.845 | 2265088 |  230.501 |              278.141 |              95.7172 |            817.363 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f85b2_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3533.334043308484
    time_step_min: 3235
  date: 2020-10-11_03-44-14
  done: false
  episode_len_mean: 816.4685413005272
  episode_reward_max: 278.1414141414141
  episode_reward_mean: 231.25948412064398
  episode_reward_min: 95.71717171717164
  episodes_this_iter: 159
  episodes_total: 2845
  experiment_id: 28c0231037404781a19589d1493aab3c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.7139610775879451
        entropy_coeff: 0.00010000000000000002
        kl: 0.009093102067708969
        model: {}
        policy_loss: -0.015159160264634661
        total_loss: 2.0786518454551697
        vf_explained_var: 0.9957866668701172
        vf_loss: 2.092063767569406
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.959999999999997
    gpu_util_percent0: 0.3211428571428572
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497142857142857
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 61262
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15546609946087306
    mean_env_wait_ms: 1.2387686121514654
    mean_inference_ms: 4.812177206781712
    mean_raw_obs_processing_ms: 0.40821673681502824
  time_since_restore: 447.241824388504
  time_this_iter_s: 29.39682364463806
  time_total_s: 447.241824388504
  timers:
    learn_throughput: 7258.769
    learn_time_ms: 22289.179
    sample_throughput: 22422.456
    sample_time_ms: 7215.623
    update_time_ms: 25.871
  timestamp: 1602387854
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: f85b2_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f85b2_00000 | RUNNING  | 172.17.0.4:61262 |     15 |          447.242 | 2426880 |  231.259 |              278.141 |              95.7172 |            816.469 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f85b2_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3524.9295774647885
    time_step_min: 3235
  date: 2020-10-11_03-44-43
  done: false
  episode_len_mean: 814.3172588832488
  episode_reward_max: 278.1414141414141
  episode_reward_mean: 232.45781738706856
  episode_reward_min: 95.71717171717164
  episodes_this_iter: 307
  episodes_total: 3152
  experiment_id: 28c0231037404781a19589d1493aab3c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.666072245155062
        entropy_coeff: 0.00010000000000000002
        kl: 0.007759728036554796
        model: {}
        policy_loss: -0.012669259066959577
        total_loss: 3.031968423298427
        vf_explained_var: 0.9954391717910767
        vf_loss: 3.043152298246111
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.477777777777774
    gpu_util_percent0: 0.39833333333333326
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.477777777777778
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 61262
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1550395235690265
    mean_env_wait_ms: 1.2406637685007083
    mean_inference_ms: 4.77994562340378
    mean_raw_obs_processing_ms: 0.40670547442793753
  time_since_restore: 476.789443731308
  time_this_iter_s: 29.547619342803955
  time_total_s: 476.789443731308
  timers:
    learn_throughput: 7264.619
    learn_time_ms: 22271.229
    sample_throughput: 22436.623
    sample_time_ms: 7211.067
    update_time_ms: 25.64
  timestamp: 1602387883
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: f85b2_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f85b2_00000 | RUNNING  | 172.17.0.4:61262 |     16 |          476.789 | 2588672 |  232.458 |              278.141 |              95.7172 |            814.317 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f85b2_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3522.8313069908813
    time_step_min: 3228
  date: 2020-10-11_03-45-13
  done: false
  episode_len_mean: 813.1015672091621
  episode_reward_max: 278.1414141414141
  episode_reward_mean: 232.85719765466595
  episode_reward_min: 95.71717171717164
  episodes_this_iter: 166
  episodes_total: 3318
  experiment_id: 28c0231037404781a19589d1493aab3c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.6489920275551933
        entropy_coeff: 0.00010000000000000002
        kl: 0.00814367225393653
        model: {}
        policy_loss: -0.01514917507302016
        total_loss: 2.2479094862937927
        vf_explained_var: 0.9952462911605835
        vf_loss: 2.261494823864528
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.12857142857143
    gpu_util_percent0: 0.37914285714285717
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497142857142856
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 61262
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15483099033739098
    mean_env_wait_ms: 1.2416057545017372
    mean_inference_ms: 4.764557651997886
    mean_raw_obs_processing_ms: 0.4059787940347518
  time_since_restore: 506.15562868118286
  time_this_iter_s: 29.366184949874878
  time_total_s: 506.15562868118286
  timers:
    learn_throughput: 7276.338
    learn_time_ms: 22235.362
    sample_throughput: 22421.777
    sample_time_ms: 7215.842
    update_time_ms: 25.705
  timestamp: 1602387913
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: f85b2_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f85b2_00000 | RUNNING  | 172.17.0.4:61262 |     17 |          506.156 | 2750464 |  232.857 |              278.141 |              95.7172 |            813.102 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f85b2_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3520.576856148492
    time_step_min: 3228
  date: 2020-10-11_03-45-43
  done: false
  episode_len_mean: 812.2865362485616
  episode_reward_max: 278.1414141414141
  episode_reward_mean: 233.1204914507561
  episode_reward_min: 95.71717171717164
  episodes_this_iter: 158
  episodes_total: 3476
  experiment_id: 28c0231037404781a19589d1493aab3c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.6464332129274096
        entropy_coeff: 0.00010000000000000002
        kl: 0.008854503676827465
        model: {}
        policy_loss: -0.013760537516126143
        total_loss: 2.1017288395336697
        vf_explained_var: 0.9952325820922852
        vf_loss: 2.113783129623958
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.017142857142858
    gpu_util_percent0: 0.3791428571428571
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497142857142857
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 61262
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15465064366589237
    mean_env_wait_ms: 1.242474858957656
    mean_inference_ms: 4.75089757563706
    mean_raw_obs_processing_ms: 0.40533629898859724
  time_since_restore: 535.6637859344482
  time_this_iter_s: 29.50815725326538
  time_total_s: 535.6637859344482
  timers:
    learn_throughput: 7274.062
    learn_time_ms: 22242.318
    sample_throughput: 22469.099
    sample_time_ms: 7200.645
    update_time_ms: 25.698
  timestamp: 1602387943
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: f85b2_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f85b2_00000 | RUNNING  | 172.17.0.4:61262 |     18 |          535.664 | 2912256 |   233.12 |              278.141 |              95.7172 |            812.287 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f85b2_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3516.6616725687823
    time_step_min: 3228
  date: 2020-10-11_03-46-12
  done: false
  episode_len_mean: 811.5093268450933
  episode_reward_max: 278.1414141414141
  episode_reward_mean: 233.76041845871526
  episode_reward_min: 95.71717171717164
  episodes_this_iter: 223
  episodes_total: 3699
  experiment_id: 28c0231037404781a19589d1493aab3c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.6158933298928397
        entropy_coeff: 0.00010000000000000002
        kl: 0.008257304052157062
        model: {}
        policy_loss: -0.013553785035453205
        total_loss: 2.369402834347316
        vf_explained_var: 0.996073305606842
        vf_loss: 2.3813667637961253
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.945714285714285
    gpu_util_percent0: 0.3242857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4799999999999995
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 61262
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1544065141205009
    mean_env_wait_ms: 1.2435859970220517
    mean_inference_ms: 4.732972177684642
    mean_raw_obs_processing_ms: 0.4044864654914
  time_since_restore: 565.1413264274597
  time_this_iter_s: 29.477540493011475
  time_total_s: 565.1413264274597
  timers:
    learn_throughput: 7277.065
    learn_time_ms: 22233.14
    sample_throughput: 22502.173
    sample_time_ms: 7190.061
    update_time_ms: 25.458
  timestamp: 1602387972
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: f85b2_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f85b2_00000 | RUNNING  | 172.17.0.4:61262 |     19 |          565.141 | 3074048 |   233.76 |              278.141 |              95.7172 |            811.509 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f85b2_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3511.792909971946
    time_step_min: 3228
  date: 2020-10-11_03-46-42
  done: false
  episode_len_mean: 810.9848062800709
  episode_reward_max: 278.1414141414141
  episode_reward_mean: 234.41538453668102
  episode_reward_min: 95.71717171717164
  episodes_this_iter: 250
  episodes_total: 3949
  experiment_id: 28c0231037404781a19589d1493aab3c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.575169712305069
        entropy_coeff: 0.00010000000000000002
        kl: 0.007640133046412042
        model: {}
        policy_loss: -0.012798943523583668
        total_loss: 2.187897869518825
        vf_explained_var: 0.9960740804672241
        vf_loss: 2.199226345334734
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.6
    gpu_util_percent0: 0.37457142857142856
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488571428571429
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 61262
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.154177493486456
    mean_env_wait_ms: 1.2448240652354368
    mean_inference_ms: 4.715126681343152
    mean_raw_obs_processing_ms: 0.4036754815793311
  time_since_restore: 594.4795758724213
  time_this_iter_s: 29.338249444961548
  time_total_s: 594.4795758724213
  timers:
    learn_throughput: 7276.332
    learn_time_ms: 22235.38
    sample_throughput: 22508.067
    sample_time_ms: 7188.178
    update_time_ms: 25.177
  timestamp: 1602388002
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: f85b2_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f85b2_00000 | RUNNING  | 172.17.0.4:61262 |     20 |           594.48 | 3235840 |  234.415 |              278.141 |              95.7172 |            810.985 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f85b2_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3508.9223039215685
    time_step_min: 3228
  date: 2020-10-11_03-47-12
  done: true
  episode_len_mean: 810.8627069133398
  episode_reward_max: 278.1414141414141
  episode_reward_mean: 234.80070421842566
  episode_reward_min: 95.71717171717164
  episodes_this_iter: 159
  episodes_total: 4108
  experiment_id: 28c0231037404781a19589d1493aab3c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.5808451558862414
        entropy_coeff: 0.00010000000000000002
        kl: 0.008233448922900217
        model: {}
        policy_loss: -0.014858095025244569
        total_loss: 1.748440146446228
        vf_explained_var: 0.9962044358253479
        vf_loss: 1.7617096645491463
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.177142857142854
    gpu_util_percent0: 0.34285714285714286
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497142857142856
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 61262
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15403860593473884
    mean_env_wait_ms: 1.2455011365022841
    mean_inference_ms: 4.704591962045625
    mean_raw_obs_processing_ms: 0.4031863637350377
  time_since_restore: 624.2178218364716
  time_this_iter_s: 29.738245964050293
  time_total_s: 624.2178218364716
  timers:
    learn_throughput: 7272.86
    learn_time_ms: 22245.995
    sample_throughput: 22520.43
    sample_time_ms: 7184.232
    update_time_ms: 25.264
  timestamp: 1602388032
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: f85b2_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f85b2_00000 | TERMINATED |       |     21 |          624.218 | 3397632 |  234.801 |              278.141 |              95.7172 |            810.863 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f85b2_00000 | TERMINATED |       |     21 |          624.218 | 3397632 |  234.801 |              278.141 |              95.7172 |            810.863 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


