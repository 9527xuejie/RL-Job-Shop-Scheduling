2020-10-12 02:31:20,876	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.86 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_04634_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=25488)[0m 2020-10-12 02:31:23,566	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=25537)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25537)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25523)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25523)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25551)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25551)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25515)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25515)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25496)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25496)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25536)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25536)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25538)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25538)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25456)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25456)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25534)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25534)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25486)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25486)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25510)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25510)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25508)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25508)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25492)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25492)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25522)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25522)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25437)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25437)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25430)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25430)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25427)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25427)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25543)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25543)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25446)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25446)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25517)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25517)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25553)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25553)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25502)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25502)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25540)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25540)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25501)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25501)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25442)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25442)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25477)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25477)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25489)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25489)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25495)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25495)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25482)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25482)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25531)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25531)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25504)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25504)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25480)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25480)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25550)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25550)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25485)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25485)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25524)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25524)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25507)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25507)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25532)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25532)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25424)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25424)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25463)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25463)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25432)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25432)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25466)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25466)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25493)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25493)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25452)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25452)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25425)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25425)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25512)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25512)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25440)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25440)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25506)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25506)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25436)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25436)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25528)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25528)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25527)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25527)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25434)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25434)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25441)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25441)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25449)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25449)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25433)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25433)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25494)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25494)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25518)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25518)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25541)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25541)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25509)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25509)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25526)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25526)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25444)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25444)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25439)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25439)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25500)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25500)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25498)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25498)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25465)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25465)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25457)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25457)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25428)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25428)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25503)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25503)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25448)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25448)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25505)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25505)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25443)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25443)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25546)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25546)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25530)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25530)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25426)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25426)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25514)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25514)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25519)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25519)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25423)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25423)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25429)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25429)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25461)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25461)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25431)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25431)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_04634_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_02-32-03
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 9594026ebe42479bb40ce04e9160597c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.1818179488182068
        entropy_coeff: 0.0001
        kl: 0.007158378488384187
        model: {}
        policy_loss: -0.013911522672666857
        total_loss: 500.4124170939128
        vf_explained_var: 0.5819632411003113
        vf_loss: 500.42430623372394
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.48139534883721
    gpu_util_percent0: 0.38046511627906976
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5906976744186037
    vram_util_percent0: 0.09002761103526129
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25488
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16645360559767947
    mean_env_wait_ms: 1.1594896560909203
    mean_inference_ms: 5.376994420658406
    mean_raw_obs_processing_ms: 0.44105479436805495
  time_since_restore: 34.698333501815796
  time_this_iter_s: 34.698333501815796
  time_total_s: 34.698333501815796
  timers:
    learn_throughput: 6278.939
    learn_time_ms: 25767.41
    sample_throughput: 18273.346
    sample_time_ms: 8853.989
    update_time_ms: 45.261
  timestamp: 1602469923
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: '04634_00000'
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.86 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_04634_00000 | RUNNING  | 172.17.0.4:25488 |      1 |          34.6983 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_04634_00000:
  custom_metrics:
    time_step_max: 4267
    time_step_mean: 3628.3993055555557
    time_step_min: 3337
  date: 2020-10-12_02-32-36
  done: false
  episode_len_mean: 890.9556962025316
  episode_reward_max: 262.8383838383838
  episode_reward_mean: 215.5599028257254
  episode_reward_min: 119.50505050505036
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 9594026ebe42479bb40ce04e9160597c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.1497800052165985
        entropy_coeff: 0.0001
        kl: 0.00921400209578375
        model: {}
        policy_loss: -0.017824087059125304
        total_loss: 128.11587270100912
        vf_explained_var: 0.814457356929779
        vf_loss: 128.13105074564615
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.9075
    gpu_util_percent0: 0.42299999999999993
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7625
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25488
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16341614957478096
    mean_env_wait_ms: 1.158139316301705
    mean_inference_ms: 5.2814191817011
    mean_raw_obs_processing_ms: 0.43457655332722667
  time_since_restore: 67.84118628501892
  time_this_iter_s: 33.142852783203125
  time_total_s: 67.84118628501892
  timers:
    learn_throughput: 6340.013
    learn_time_ms: 25519.192
    sample_throughput: 19436.175
    sample_time_ms: 8324.271
    update_time_ms: 36.355
  timestamp: 1602469956
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: '04634_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.86 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_04634_00000 | RUNNING  | 172.17.0.4:25488 |      2 |          67.8412 | 323584 |   215.56 |              262.838 |              119.505 |            890.956 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_04634_00000:
  custom_metrics:
    time_step_max: 4267
    time_step_mean: 3628.607623318386
    time_step_min: 3337
  date: 2020-10-12_02-33-09
  done: false
  episode_len_mean: 890.909282700422
  episode_reward_max: 262.8383838383838
  episode_reward_mean: 216.6157141030557
  episode_reward_min: 117.38383838383798
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 9594026ebe42479bb40ce04e9160597c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.1388974885145824
        entropy_coeff: 0.0001
        kl: 0.009639433274666468
        model: {}
        policy_loss: -0.020037402166053653
        total_loss: 46.516541163126625
        vf_explained_var: 0.9186521172523499
        vf_loss: 46.533800760904946
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.810000000000002
    gpu_util_percent0: 0.42074999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7800000000000002
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25488
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16102386312036696
    mean_env_wait_ms: 1.1571378208189067
    mean_inference_ms: 5.159978501852111
    mean_raw_obs_processing_ms: 0.4277025885190011
  time_since_restore: 100.56116151809692
  time_this_iter_s: 32.719975233078
  time_total_s: 100.56116151809692
  timers:
    learn_throughput: 6338.091
    learn_time_ms: 25526.928
    sample_throughput: 20454.291
    sample_time_ms: 7909.93
    update_time_ms: 39.849
  timestamp: 1602469989
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: '04634_00000'
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.86 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_04634_00000 | RUNNING  | 172.17.0.4:25488 |      3 |          100.561 | 485376 |  216.616 |              262.838 |              117.384 |            890.909 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_04634_00000:
  custom_metrics:
    time_step_max: 4267
    time_step_mean: 3617.2566225165565
    time_step_min: 3315
  date: 2020-10-12_02-33-42
  done: false
  episode_len_mean: 888.9715189873418
  episode_reward_max: 271.47474747474735
  episode_reward_mean: 217.86307697225396
  episode_reward_min: 117.38383838383798
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 9594026ebe42479bb40ce04e9160597c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.1274578372637432
        entropy_coeff: 0.0001
        kl: 0.010328288190066814
        model: {}
        policy_loss: -0.018168509394551318
        total_loss: 27.586466948191326
        vf_explained_var: 0.9503366947174072
        vf_loss: 27.601649284362793
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.230769230769234
    gpu_util_percent0: 0.3853846153846154
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7743589743589756
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25488
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15923572181242626
    mean_env_wait_ms: 1.1571244500611735
    mean_inference_ms: 5.060165828897545
    mean_raw_obs_processing_ms: 0.4220145615978136
  time_since_restore: 133.22063565254211
  time_this_iter_s: 32.65947413444519
  time_total_s: 133.22063565254211
  timers:
    learn_throughput: 6331.348
    learn_time_ms: 25554.117
    sample_throughput: 21101.773
    sample_time_ms: 7667.223
    update_time_ms: 39.467
  timestamp: 1602470022
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: '04634_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.86 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_04634_00000 | RUNNING  | 172.17.0.4:25488 |      4 |          133.221 | 647168 |  217.863 |              271.475 |              117.384 |            888.972 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_04634_00000:
  custom_metrics:
    time_step_max: 4267
    time_step_mean: 3609.209973753281
    time_step_min: 3315
  date: 2020-10-12_02-34-15
  done: false
  episode_len_mean: 885.1177215189873
  episode_reward_max: 271.47474747474735
  episode_reward_mean: 219.4141414141412
  episode_reward_min: 117.38383838383798
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 9594026ebe42479bb40ce04e9160597c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.1031465133031209
        entropy_coeff: 0.0001
        kl: 0.010020139627158642
        model: {}
        policy_loss: -0.018114043516106904
        total_loss: 24.01350434621175
        vf_explained_var: 0.9561968445777893
        vf_loss: 24.02872323989868
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.095121951219515
    gpu_util_percent0: 0.40560975609756095
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7780487804878056
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25488
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15785481200466203
    mean_env_wait_ms: 1.1578253821412012
    mean_inference_ms: 4.979927697145451
    mean_raw_obs_processing_ms: 0.41733170031776373
  time_since_restore: 166.28967928886414
  time_this_iter_s: 33.06904363632202
  time_total_s: 166.28967928886414
  timers:
    learn_throughput: 6312.454
    learn_time_ms: 25630.603
    sample_throughput: 21476.715
    sample_time_ms: 7533.368
    update_time_ms: 48.086
  timestamp: 1602470055
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: '04634_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.86 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_04634_00000 | RUNNING  | 172.17.0.4:25488 |      5 |           166.29 | 808960 |  219.414 |              271.475 |              117.384 |            885.118 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_04634_00000:
  custom_metrics:
    time_step_max: 4267
    time_step_mean: 3595.698318496538
    time_step_min: 3252
  date: 2020-10-12_02-34-48
  done: false
  episode_len_mean: 878.4850818094321
  episode_reward_max: 273.2929292929291
  episode_reward_mean: 221.62261692964273
  episode_reward_min: 117.38383838383798
  episodes_this_iter: 249
  episodes_total: 1039
  experiment_id: 9594026ebe42479bb40ce04e9160597c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.075523426135381
        entropy_coeff: 0.0001
        kl: 0.01005798097078999
        model: {}
        policy_loss: -0.018884733396892745
        total_loss: 26.887240091959637
        vf_explained_var: 0.9663748741149902
        vf_loss: 26.90321445465088
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.13589743589743
    gpu_util_percent0: 0.40974358974358976
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7743589743589756
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25488
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15626898288634075
    mean_env_wait_ms: 1.160715923730924
    mean_inference_ms: 4.887362343816808
    mean_raw_obs_processing_ms: 0.4120334474207205
  time_since_restore: 198.95321393013
  time_this_iter_s: 32.66353464126587
  time_total_s: 198.95321393013
  timers:
    learn_throughput: 6313.366
    learn_time_ms: 25626.9
    sample_throughput: 21750.27
    sample_time_ms: 7438.62
    update_time_ms: 46.568
  timestamp: 1602470088
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: '04634_00000'
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.86 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_04634_00000 | RUNNING  | 172.17.0.4:25488 |      6 |          198.953 | 970752 |  221.623 |              273.293 |              117.384 |            878.485 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_04634_00000:
  custom_metrics:
    time_step_max: 4267
    time_step_mean: 3589.148867313916
    time_step_min: 3252
  date: 2020-10-12_02-35-21
  done: false
  episode_len_mean: 874.0814873417721
  episode_reward_max: 273.2929292929291
  episode_reward_mean: 222.76778065464757
  episode_reward_min: 117.38383838383798
  episodes_this_iter: 225
  episodes_total: 1264
  experiment_id: 9594026ebe42479bb40ce04e9160597c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.0889890491962433
        entropy_coeff: 0.0001
        kl: 0.010133635330324372
        model: {}
        policy_loss: -0.019151590609302122
        total_loss: 17.99896510442098
        vf_explained_var: 0.9711014628410339
        vf_loss: 18.015185515085857
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.494999999999997
    gpu_util_percent0: 0.36500000000000005
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25488
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15522815951754715
    mean_env_wait_ms: 1.1622929986622197
    mean_inference_ms: 4.824614609813308
    mean_raw_obs_processing_ms: 0.40860915771955336
  time_since_restore: 231.76901030540466
  time_this_iter_s: 32.81579637527466
  time_total_s: 231.76901030540466
  timers:
    learn_throughput: 6312.72
    learn_time_ms: 25629.524
    sample_throughput: 21892.667
    sample_time_ms: 7390.237
    update_time_ms: 43.144
  timestamp: 1602470121
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: '04634_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.86 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_04634_00000 | RUNNING  | 172.17.0.4:25488 |      7 |          231.769 | 1132544 |  222.768 |              273.293 |              117.384 |            874.081 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_04634_00000:
  custom_metrics:
    time_step_max: 4267
    time_step_mean: 3579.7539454806315
    time_step_min: 3226
  date: 2020-10-12_02-35-53
  done: false
  episode_len_mean: 870.6153305203939
  episode_reward_max: 277.2323232323233
  episode_reward_mean: 224.29834207049382
  episode_reward_min: 117.38383838383798
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 9594026ebe42479bb40ce04e9160597c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.0605666935443878
        entropy_coeff: 0.0001
        kl: 0.010858146008104086
        model: {}
        policy_loss: -0.021757268308040995
        total_loss: 12.911786317825317
        vf_explained_var: 0.9761471152305603
        vf_loss: 12.930391629536947
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.209999999999997
    gpu_util_percent0: 0.42424999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7875
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25488
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15463893963184033
    mean_env_wait_ms: 1.1635287277014463
    mean_inference_ms: 4.789032377241611
    mean_raw_obs_processing_ms: 0.40664826468876125
  time_since_restore: 264.29369473457336
  time_this_iter_s: 32.5246844291687
  time_total_s: 264.29369473457336
  timers:
    learn_throughput: 6314.37
    learn_time_ms: 25622.826
    sample_throughput: 22096.79
    sample_time_ms: 7321.969
    update_time_ms: 43.303
  timestamp: 1602470153
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: '04634_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.86 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_04634_00000 | RUNNING  | 172.17.0.4:25488 |      8 |          264.294 | 1294336 |  224.298 |              277.232 |              117.384 |            870.615 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_04634_00000:
  custom_metrics:
    time_step_max: 4267
    time_step_mean: 3569.681056701031
    time_step_min: 3226
  date: 2020-10-12_02-36-26
  done: false
  episode_len_mean: 867.3803797468354
  episode_reward_max: 277.2323232323233
  episode_reward_mean: 225.7275284490473
  episode_reward_min: 117.38383838383798
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 9594026ebe42479bb40ce04e9160597c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.0291423002878826
        entropy_coeff: 0.0001
        kl: 0.011260832116628686
        model: {}
        policy_loss: -0.022134215338155627
        total_loss: 12.439600706100464
        vf_explained_var: 0.9755335450172424
        vf_loss: 12.45845913887024
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.85641025641026
    gpu_util_percent0: 0.37025641025641026
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7820512820512837
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25488
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1541203502011092
    mean_env_wait_ms: 1.1647067672776252
    mean_inference_ms: 4.757713163852682
    mean_raw_obs_processing_ms: 0.4048950286563345
  time_since_restore: 296.99500155448914
  time_this_iter_s: 32.70130681991577
  time_total_s: 296.99500155448914
  timers:
    learn_throughput: 6311.683
    learn_time_ms: 25633.735
    sample_throughput: 22237.09
    sample_time_ms: 7275.772
    update_time_ms: 40.728
  timestamp: 1602470186
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: '04634_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.86 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_04634_00000 | RUNNING  | 172.17.0.4:25488 |      9 |          296.995 | 1456128 |  225.728 |              277.232 |              117.384 |             867.38 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_04634_00000:
  custom_metrics:
    time_step_max: 4267
    time_step_mean: 3560.9433411214955
    time_step_min: 3226
  date: 2020-10-12_02-36-58
  done: false
  episode_len_mean: 864.8241379310344
  episode_reward_max: 277.2323232323233
  episode_reward_mean: 226.97918843608483
  episode_reward_min: 117.38383838383798
  episodes_this_iter: 160
  episodes_total: 1740
  experiment_id: 9594026ebe42479bb40ce04e9160597c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 0.9874311884244283
        entropy_coeff: 0.0001
        kl: 0.010641903228436908
        model: {}
        policy_loss: -0.02132187473277251
        total_loss: 12.843633731206259
        vf_explained_var: 0.9783155918121338
        vf_loss: 12.86186146736145
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.7925
    gpu_util_percent0: 0.36449999999999994
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7825
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25488
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15365984369570002
    mean_env_wait_ms: 1.1658562421393104
    mean_inference_ms: 4.729842542631228
    mean_raw_obs_processing_ms: 0.40329851440327386
  time_since_restore: 329.38394951820374
  time_this_iter_s: 32.3889479637146
  time_total_s: 329.38394951820374
  timers:
    learn_throughput: 6315.374
    learn_time_ms: 25618.751
    sample_throughput: 22381.55
    sample_time_ms: 7228.811
    update_time_ms: 40.874
  timestamp: 1602470218
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: '04634_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.86 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_04634_00000 | RUNNING  | 172.17.0.4:25488 |     10 |          329.384 | 1617920 |  226.979 |              277.232 |              117.384 |            864.824 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_04634_00000:
  custom_metrics:
    time_step_max: 4267
    time_step_mean: 3544.378968253968
    time_step_min: 3226
  date: 2020-10-12_02-37-31
  done: false
  episode_len_mean: 860.4779843444227
  episode_reward_max: 277.2323232323233
  episode_reward_mean: 229.38659590029442
  episode_reward_min: 117.38383838383798
  episodes_this_iter: 304
  episodes_total: 2044
  experiment_id: 9594026ebe42479bb40ce04e9160597c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 0.9730392346779505
        entropy_coeff: 0.0001
        kl: 0.00959281351727744
        model: {}
        policy_loss: -0.018805188514913123
        total_loss: 14.70823868115743
        vf_explained_var: 0.9802653193473816
        vf_loss: 14.724262952804565
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.71282051282051
    gpu_util_percent0: 0.40615384615384614
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.771794871794873
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25488
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15293985719507533
    mean_env_wait_ms: 1.1679821377866542
    mean_inference_ms: 4.686033818974766
    mean_raw_obs_processing_ms: 0.40089302327161197
  time_since_restore: 361.8903148174286
  time_this_iter_s: 32.50636529922485
  time_total_s: 361.8903148174286
  timers:
    learn_throughput: 6323.674
    learn_time_ms: 25585.128
    sample_throughput: 22972.36
    sample_time_ms: 7042.898
    update_time_ms: 38.721
  timestamp: 1602470251
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: '04634_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.86 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_04634_00000 | RUNNING  | 172.17.0.4:25488 |     11 |           361.89 | 1779712 |  229.387 |              277.232 |              117.384 |            860.478 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_04634_00000:
  custom_metrics:
    time_step_max: 4267
    time_step_mean: 3534.789835164835
    time_step_min: 3215
  date: 2020-10-12_02-38-04
  done: false
  episode_len_mean: 858.0370705244123
  episode_reward_max: 279.50505050505006
  episode_reward_mean: 230.85615193526573
  episode_reward_min: 117.38383838383798
  episodes_this_iter: 168
  episodes_total: 2212
  experiment_id: 9594026ebe42479bb40ce04e9160597c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 0.9672126322984695
        entropy_coeff: 0.0001
        kl: 0.010228981574376425
        model: {}
        policy_loss: -0.022099798312410712
        total_loss: 9.655503829320272
        vf_explained_var: 0.9814350605010986
        vf_loss: 9.674631675084433
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.700000000000003
    gpu_util_percent0: 0.3871794871794872
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7871794871794893
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25488
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1525993865610632
    mean_env_wait_ms: 1.1689091902022994
    mean_inference_ms: 4.665535634920005
    mean_raw_obs_processing_ms: 0.39973556233900065
  time_since_restore: 394.3434684276581
  time_this_iter_s: 32.45315361022949
  time_total_s: 394.3434684276581
  timers:
    learn_throughput: 6320.933
    learn_time_ms: 25596.221
    sample_throughput: 23241.26
    sample_time_ms: 6961.413
    update_time_ms: 39.792
  timestamp: 1602470284
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: '04634_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.86 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_04634_00000 | RUNNING  | 172.17.0.4:25488 |     12 |          394.343 | 1941504 |  230.856 |              279.505 |              117.384 |            858.037 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_04634_00000:
  custom_metrics:
    time_step_max: 4267
    time_step_mean: 3526.5140905209223
    time_step_min: 3215
  date: 2020-10-12_02-38-37
  done: false
  episode_len_mean: 856.1991561181435
  episode_reward_max: 279.50505050505006
  episode_reward_mean: 232.0226313770616
  episode_reward_min: 117.38383838383798
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: 9594026ebe42479bb40ce04e9160597c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 0.9421690205732981
        entropy_coeff: 0.0001
        kl: 0.010538411404316625
        model: {}
        policy_loss: -0.019926233876806993
        total_loss: 9.599429845809937
        vf_explained_var: 0.9812543988227844
        vf_loss: 9.616288741429647
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.358536585365854
    gpu_util_percent0: 0.41829268292682925
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7829268292682934
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25488
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15231547789962174
    mean_env_wait_ms: 1.1697544304872622
    mean_inference_ms: 4.64843900332665
    mean_raw_obs_processing_ms: 0.39877957202368686
  time_since_restore: 427.3665065765381
  time_this_iter_s: 33.023038148880005
  time_total_s: 427.3665065765381
  timers:
    learn_throughput: 6310.493
    learn_time_ms: 25638.566
    sample_throughput: 23285.073
    sample_time_ms: 6948.314
    update_time_ms: 39.597
  timestamp: 1602470317
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: '04634_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.86 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_04634_00000 | RUNNING  | 172.17.0.4:25488 |     13 |          427.367 | 2103296 |  232.023 |              279.505 |              117.384 |            856.199 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_04634_00000:
  custom_metrics:
    time_step_max: 4267
    time_step_mean: 3520.2107157137143
    time_step_min: 3188
  date: 2020-10-12_02-39-09
  done: false
  episode_len_mean: 854.898774219059
  episode_reward_max: 282.98989898989885
  episode_reward_mean: 232.9596438884694
  episode_reward_min: 117.38383838383798
  episodes_this_iter: 159
  episodes_total: 2529
  experiment_id: 9594026ebe42479bb40ce04e9160597c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 0.9098296711842219
        entropy_coeff: 0.0001
        kl: 0.0097438619316866
        model: {}
        policy_loss: -0.019212192622944713
        total_loss: 13.602580547332764
        vf_explained_var: 0.9753875136375427
        vf_loss: 13.618960301081339
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.861538461538462
    gpu_util_percent0: 0.4182051282051283
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.784615384615386
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25488
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.152053391440911
    mean_env_wait_ms: 1.1704897386065194
    mean_inference_ms: 4.632719265236576
    mean_raw_obs_processing_ms: 0.39788943253252496
  time_since_restore: 460.0319895744324
  time_this_iter_s: 32.66548299789429
  time_total_s: 460.0319895744324
  timers:
    learn_throughput: 6311.345
    learn_time_ms: 25635.105
    sample_throughput: 23272.051
    sample_time_ms: 6952.202
    update_time_ms: 39.341
  timestamp: 1602470349
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: '04634_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.86 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_04634_00000 | RUNNING  | 172.17.0.4:25488 |     14 |          460.032 | 2265088 |   232.96 |               282.99 |              117.384 |            854.899 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_04634_00000:
  custom_metrics:
    time_step_max: 4267
    time_step_mean: 3509.6923636363636
    time_step_min: 3138
  date: 2020-10-12_02-39-42
  done: false
  episode_len_mean: 852.7469402447804
  episode_reward_max: 290.56565656565675
  episode_reward_mean: 234.56210048650644
  episode_reward_min: 117.38383838383798
  episodes_this_iter: 249
  episodes_total: 2778
  experiment_id: 9594026ebe42479bb40ce04e9160597c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 0.880094513297081
        entropy_coeff: 0.0001
        kl: 0.009974174899980426
        model: {}
        policy_loss: -0.018482706606543314
        total_loss: 13.17027759552002
        vf_explained_var: 0.981635570526123
        vf_loss: 13.185855865478516
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.425
    gpu_util_percent0: 0.4165
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7800000000000002
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25488
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15168530167737493
    mean_env_wait_ms: 1.1716094849114187
    mean_inference_ms: 4.610838236033144
    mean_raw_obs_processing_ms: 0.3966596289058002
  time_since_restore: 492.608779668808
  time_this_iter_s: 32.57679009437561
  time_total_s: 492.608779668808
  timers:
    learn_throughput: 6321.038
    learn_time_ms: 25595.795
    sample_throughput: 23287.931
    sample_time_ms: 6947.461
    update_time_ms: 34.03
  timestamp: 1602470382
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: '04634_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.86 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_04634_00000 | RUNNING  | 172.17.0.4:25488 |     15 |          492.609 | 2426880 |  234.562 |              290.566 |              117.384 |            852.747 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_04634_00000:
  custom_metrics:
    time_step_max: 4267
    time_step_mean: 3500.102555480834
    time_step_min: 3138
  date: 2020-10-12_02-40-15
  done: false
  episode_len_mean: 850.9780146568954
  episode_reward_max: 290.56565656565675
  episode_reward_mean: 235.78899252350274
  episode_reward_min: 117.38383838383798
  episodes_this_iter: 224
  episodes_total: 3002
  experiment_id: 9594026ebe42479bb40ce04e9160597c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 0.8922951320807139
        entropy_coeff: 0.0001
        kl: 0.009141753738125166
        model: {}
        policy_loss: -0.020260217832401395
        total_loss: 10.51387333869934
        vf_explained_var: 0.9828965663909912
        vf_loss: 10.531480232874552
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.285
    gpu_util_percent0: 0.399
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25488
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15140891654384234
    mean_env_wait_ms: 1.1724604578770743
    mean_inference_ms: 4.593926338585083
    mean_raw_obs_processing_ms: 0.39573615336645535
  time_since_restore: 525.6930921077728
  time_this_iter_s: 33.084312438964844
  time_total_s: 525.6930921077728
  timers:
    learn_throughput: 6313.263
    learn_time_ms: 25627.316
    sample_throughput: 23259.709
    sample_time_ms: 6955.891
    update_time_ms: 33.719
  timestamp: 1602470415
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: '04634_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.86 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_04634_00000 | RUNNING  | 172.17.0.4:25488 |     16 |          525.693 | 2588672 |  235.789 |              290.566 |              117.384 |            850.978 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_04634_00000:
  custom_metrics:
    time_step_max: 4267
    time_step_mean: 3494.8777139208173
    time_step_min: 3138
  date: 2020-10-12_02-40-48
  done: false
  episode_len_mean: 849.5101265822785
  episode_reward_max: 290.56565656565675
  episode_reward_mean: 236.61729638153676
  episode_reward_min: 117.38383838383798
  episodes_this_iter: 158
  episodes_total: 3160
  experiment_id: 9594026ebe42479bb40ce04e9160597c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 0.8803216566642126
        entropy_coeff: 0.0001
        kl: 0.010315927444025874
        model: {}
        policy_loss: -0.019423029152676463
        total_loss: 8.688657681147257
        vf_explained_var: 0.9836332201957703
        vf_loss: 8.705074310302734
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.6275
    gpu_util_percent0: 0.40675
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7875
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25488
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1512283488391603
    mean_env_wait_ms: 1.1730535269783449
    mean_inference_ms: 4.583115828234729
    mean_raw_obs_processing_ms: 0.39514445027245537
  time_since_restore: 558.680890083313
  time_this_iter_s: 32.98779797554016
  time_total_s: 558.680890083313
  timers:
    learn_throughput: 6309.032
    learn_time_ms: 25644.504
    sample_throughput: 23269.487
    sample_time_ms: 6952.968
    update_time_ms: 35.585
  timestamp: 1602470448
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: '04634_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.86 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_04634_00000 | RUNNING  | 172.17.0.4:25488 |     17 |          558.681 | 2750464 |  236.617 |              290.566 |              117.384 |             849.51 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_04634_00000:
  custom_metrics:
    time_step_max: 4267
    time_step_mean: 3490.054407294833
    time_step_min: 3138
  date: 2020-10-12_02-41-21
  done: false
  episode_len_mean: 848.5858951175406
  episode_reward_max: 290.56565656565675
  episode_reward_mean: 237.36484190914558
  episode_reward_min: 117.38383838383798
  episodes_this_iter: 158
  episodes_total: 3318
  experiment_id: 9594026ebe42479bb40ce04e9160597c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 0.8513980706532797
        entropy_coeff: 0.0001
        kl: 0.010258898682271441
        model: {}
        policy_loss: -0.020022251410409808
        total_loss: 8.182681759198507
        vf_explained_var: 0.9848158955574036
        vf_loss: 8.199711402257284
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.615
    gpu_util_percent0: 0.41200000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7825
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25488
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15106087695427983
    mean_env_wait_ms: 1.1735825325560545
    mean_inference_ms: 4.573091965864722
    mean_raw_obs_processing_ms: 0.39458787749432
  time_since_restore: 591.3826324939728
  time_this_iter_s: 32.70174241065979
  time_total_s: 591.3826324939728
  timers:
    learn_throughput: 6310.238
    learn_time_ms: 25639.603
    sample_throughput: 23190.044
    sample_time_ms: 6976.787
    update_time_ms: 33.475
  timestamp: 1602470481
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: '04634_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.86 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_04634_00000 | RUNNING  | 172.17.0.4:25488 |     18 |          591.383 | 2912256 |  237.365 |              290.566 |              117.384 |            848.586 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_04634_00000:
  custom_metrics:
    time_step_max: 4267
    time_step_mean: 3483.254131054131
    time_step_min: 3138
  date: 2020-10-12_02-41-55
  done: true
  episode_len_mean: 847.1526286037309
  episode_reward_max: 290.56565656565675
  episode_reward_mean: 238.4579771713745
  episode_reward_min: 117.38383838383798
  episodes_this_iter: 220
  episodes_total: 3538
  experiment_id: 9594026ebe42479bb40ce04e9160597c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 0.814190203944842
        entropy_coeff: 0.0001
        kl: 0.0097156196522216
        model: {}
        policy_loss: -0.018056636113518227
        total_loss: 10.73428455988566
        vf_explained_var: 0.9843921065330505
        vf_loss: 10.749508380889893
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.7475
    gpu_util_percent0: 0.37475
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7725
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25488
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15085343350557176
    mean_env_wait_ms: 1.174345735787012
    mean_inference_ms: 4.560704837625474
    mean_raw_obs_processing_ms: 0.3939066860265151
  time_since_restore: 624.7120363712311
  time_this_iter_s: 33.3294038772583
  time_total_s: 624.7120363712311
  timers:
    learn_throughput: 6299.907
    learn_time_ms: 25681.65
    sample_throughput: 23128.115
    sample_time_ms: 6995.469
    update_time_ms: 35.081
  timestamp: 1602470515
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: '04634_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.86 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_04634_00000 | TERMINATED |       |     19 |          624.712 | 3074048 |  238.458 |              290.566 |              117.384 |            847.153 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.86 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_04634_00000 | TERMINATED |       |     19 |          624.712 | 3074048 |  238.458 |              290.566 |              117.384 |            847.153 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


