2020-10-11 12:22:04,578	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_60207_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=24723)[0m 2020-10-11 12:22:07,435	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=24717)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24717)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24728)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24728)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24701)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24701)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24746)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24746)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24711)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24711)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24748)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24748)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24702)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24702)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24764)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24764)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24727)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24727)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24721)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24721)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24757)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24757)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24742)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24742)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24737)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24737)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24713)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24713)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24712)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24712)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24724)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24724)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24763)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24763)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24719)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24719)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24725)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24725)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24730)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24730)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24753)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24753)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24735)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24735)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24708)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24708)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24718)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24718)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24744)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24744)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24647)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24647)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24669)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24669)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24643)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24643)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24699)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24699)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24715)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24715)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24645)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24645)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24654)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24654)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24637)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24637)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24655)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24655)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24707)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24707)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24704)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24704)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24697)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24697)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24720)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24720)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24662)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24662)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24671)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24671)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24732)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24732)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24716)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24716)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24649)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24649)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24664)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24664)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24660)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24660)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24672)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24672)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24759)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24759)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24656)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24656)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24729)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24729)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24638)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24638)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24636)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24636)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24705)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24705)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24641)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24641)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24657)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24657)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24653)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24653)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24639)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24639)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24659)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24659)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24710)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24710)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24640)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24640)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24731)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24731)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24651)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24651)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24714)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24714)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24762)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24762)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24722)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24722)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24709)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24709)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24733)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24733)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24673)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24673)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24739)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24739)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24770)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24770)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24749)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24749)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24642)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24642)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24754)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24754)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24665)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24665)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24652)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24652)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24675)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24675)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24644)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24644)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24648)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24648)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24726)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24726)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24706)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24706)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_60207_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_12-23-00
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 11bf409037db440aa32ca30c6b8be456
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.1785331567128499
        entropy_coeff: 0.00010000000000000002
        kl: 0.009703281273444494
        model: {}
        policy_loss: -0.0215853006268541
        total_loss: 541.3763712565104
        vf_explained_var: 0.6928540468215942
        vf_loss: 541.396142578125
    num_steps_sampled: 242688
    num_steps_trained: 242688
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.494642857142853
    gpu_util_percent0: 0.3201785714285714
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.6839285714285714
    vram_util_percent0: 0.09299301878836154
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24723
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1647015643200513
    mean_env_wait_ms: 1.146934563439554
    mean_inference_ms: 5.645910351672031
    mean_raw_obs_processing_ms: 0.43658967786773717
  time_since_restore: 47.84396433830261
  time_this_iter_s: 47.84396433830261
  time_total_s: 47.84396433830261
  timers:
    learn_throughput: 6985.338
    learn_time_ms: 34742.483
    sample_throughput: 18717.464
    sample_time_ms: 12965.859
    update_time_ms: 103.817
  timestamp: 1602418980
  timesteps_since_restore: 0
  timesteps_total: 242688
  training_iteration: 1
  trial_id: '60207_00000'
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_60207_00000 | RUNNING  | 172.17.0.4:24723 |      1 |           47.844 | 242688 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_60207_00000:
  custom_metrics:
    time_step_max: 4114
    time_step_mean: 3613.885650224215
    time_step_min: 3315
  date: 2020-10-11_12-23-46
  done: false
  episode_len_mean: 893.3206751054852
  episode_reward_max: 264.20202020202
  episode_reward_mean: 217.87002940800386
  episode_reward_min: 142.6868686868684
  episodes_this_iter: 316
  episodes_total: 474
  experiment_id: 11bf409037db440aa32ca30c6b8be456
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.1370140473047892
        entropy_coeff: 0.00010000000000000002
        kl: 0.011597078666090966
        model: {}
        policy_loss: -0.023119703742365043
        total_loss: 74.84580078125
        vf_explained_var: 0.9044364094734192
        vf_loss: 74.86671651204428
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.043396226415098
    gpu_util_percent0: 0.36169811320754713
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.952830188679245
    vram_util_percent0: 0.10897015414890125
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24723
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15942767721041637
    mean_env_wait_ms: 1.1542603819625665
    mean_inference_ms: 5.231026463598114
    mean_raw_obs_processing_ms: 0.42291296527776623
  time_since_restore: 93.41324877738953
  time_this_iter_s: 45.569284439086914
  time_total_s: 93.41324877738953
  timers:
    learn_throughput: 6989.131
    learn_time_ms: 34723.628
    sample_throughput: 20440.572
    sample_time_ms: 11872.857
    update_time_ms: 62.049
  timestamp: 1602419026
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 2
  trial_id: '60207_00000'
  
== Status ==
Memory usage on this node: 29.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_60207_00000 | RUNNING  | 172.17.0.4:24723 |      2 |          93.4132 | 485376 |   217.87 |              264.202 |              142.687 |            893.321 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_60207_00000:
  custom_metrics:
    time_step_max: 4339
    time_step_mean: 3615.702099737533
    time_step_min: 3286
  date: 2020-10-11_12-24-31
  done: false
  episode_len_mean: 891.0164556962026
  episode_reward_max: 268.14141414141375
  episode_reward_mean: 218.5900140646974
  episode_reward_min: 108.59595959595947
  episodes_this_iter: 316
  episodes_total: 790
  experiment_id: 11bf409037db440aa32ca30c6b8be456
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.1186737616856892
        entropy_coeff: 0.00010000000000000002
        kl: 0.011554974007109801
        model: {}
        policy_loss: -0.025184800600012144
        total_loss: 35.76453475952148
        vf_explained_var: 0.9509251117706299
        vf_loss: 35.78751958211263
    num_steps_sampled: 728064
    num_steps_trained: 728064
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.847169811320757
    gpu_util_percent0: 0.3847169811320755
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.981132075471698
    vram_util_percent0: 0.10897015414890125
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24723
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1571504634451441
    mean_env_wait_ms: 1.1573468464711665
    mean_inference_ms: 5.053115129361257
    mean_raw_obs_processing_ms: 0.41631872560019667
  time_since_restore: 138.68520307540894
  time_this_iter_s: 45.27195429801941
  time_total_s: 138.68520307540894
  timers:
    learn_throughput: 6997.491
    learn_time_ms: 34682.146
    sample_throughput: 21263.565
    sample_time_ms: 11413.326
    update_time_ms: 53.605
  timestamp: 1602419071
  timesteps_since_restore: 0
  timesteps_total: 728064
  training_iteration: 3
  trial_id: '60207_00000'
  
== Status ==
Memory usage on this node: 29.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_60207_00000 | RUNNING  | 172.17.0.4:24723 |      3 |          138.685 | 728064 |   218.59 |              268.141 |              108.596 |            891.016 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_60207_00000:
  custom_metrics:
    time_step_max: 4339
    time_step_mean: 3609.300646551724
    time_step_min: 3286
  date: 2020-10-11_12-25-16
  done: false
  episode_len_mean: 888.9905857740586
  episode_reward_max: 271.17171717171664
  episode_reward_mean: 219.96831283546746
  episode_reward_min: 108.59595959595947
  episodes_this_iter: 166
  episodes_total: 956
  experiment_id: 11bf409037db440aa32ca30c6b8be456
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.1003620624542236
        entropy_coeff: 0.00010000000000000002
        kl: 0.01205604753146569
        model: {}
        policy_loss: -0.027256086841225623
        total_loss: 18.616845067342123
        vf_explained_var: 0.9654419422149658
        vf_loss: 18.641800181070963
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.5173076923077
    gpu_util_percent0: 0.3586538461538462
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.9846153846153842
    vram_util_percent0: 0.10897015414890127
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24723
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15628667215807202
    mean_env_wait_ms: 1.1579845943882416
    mean_inference_ms: 4.985068111214509
    mean_raw_obs_processing_ms: 0.413238262700363
  time_since_restore: 183.66942238807678
  time_this_iter_s: 44.98421931266785
  time_total_s: 183.66942238807678
  timers:
    learn_throughput: 7003.063
    learn_time_ms: 34654.55
    sample_throughput: 21788.554
    sample_time_ms: 11138.325
    update_time_ms: 49.756
  timestamp: 1602419116
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 4
  trial_id: '60207_00000'
  
== Status ==
Memory usage on this node: 29.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_60207_00000 | RUNNING  | 172.17.0.4:24723 |      4 |          183.669 | 970752 |  219.968 |              271.172 |              108.596 |            888.991 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_60207_00000:
  custom_metrics:
    time_step_max: 4339
    time_step_mean: 3595.0226537216827
    time_step_min: 3286
  date: 2020-10-11_12-26-02
  done: false
  episode_len_mean: 883.9414556962025
  episode_reward_max: 271.17171717171664
  episode_reward_mean: 222.25545806162876
  episode_reward_min: 108.59595959595947
  episodes_this_iter: 308
  episodes_total: 1264
  experiment_id: 11bf409037db440aa32ca30c6b8be456
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.103766401608785
        entropy_coeff: 0.00010000000000000002
        kl: 0.01182380442818006
        model: {}
        policy_loss: -0.02653528337056438
        total_loss: 18.421818033854166
        vf_explained_var: 0.9681008458137512
        vf_loss: 18.446098836263022
    num_steps_sampled: 1213440
    num_steps_trained: 1213440
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.709433962264153
    gpu_util_percent0: 0.40584905660377363
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.979245283018868
    vram_util_percent0: 0.10897015414890125
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24723
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15502207883334554
    mean_env_wait_ms: 1.1591975218831851
    mean_inference_ms: 4.8872845391791335
    mean_raw_obs_processing_ms: 0.4086659149910924
  time_since_restore: 228.99537706375122
  time_this_iter_s: 45.32595467567444
  time_total_s: 228.99537706375122
  timers:
    learn_throughput: 6997.326
    learn_time_ms: 34682.964
    sample_throughput: 22075.399
    sample_time_ms: 10993.595
    update_time_ms: 47.664
  timestamp: 1602419162
  timesteps_since_restore: 0
  timesteps_total: 1213440
  training_iteration: 5
  trial_id: '60207_00000'
  
== Status ==
Memory usage on this node: 29.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_60207_00000 | RUNNING  | 172.17.0.4:24723 |      5 |          228.995 | 1213440 |  222.255 |              271.172 |              108.596 |            883.941 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_60207_00000:
  custom_metrics:
    time_step_max: 4339
    time_step_mean: 3581.728737113402
    time_step_min: 3199
  date: 2020-10-11_12-26-47
  done: false
  episode_len_mean: 878.9829113924051
  episode_reward_max: 281.32323232323193
  episode_reward_mean: 224.28794271832228
  episode_reward_min: 108.59595959595947
  episodes_this_iter: 316
  episodes_total: 1580
  experiment_id: 11bf409037db440aa32ca30c6b8be456
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.068799630800883
        entropy_coeff: 0.00010000000000000002
        kl: 0.01157887162019809
        model: {}
        policy_loss: -0.02626730762422085
        total_loss: 18.932293955485026
        vf_explained_var: 0.9730924963951111
        vf_loss: 18.95635248819987
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.530188679245285
    gpu_util_percent0: 0.3547169811320755
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.9811320754716975
    vram_util_percent0: 0.10897015414890125
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24723
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15412358325388856
    mean_env_wait_ms: 1.160989039505026
    mean_inference_ms: 4.816753311349561
    mean_raw_obs_processing_ms: 0.40536959420666074
  time_since_restore: 274.32117319107056
  time_this_iter_s: 45.325796127319336
  time_total_s: 274.32117319107056
  timers:
    learn_throughput: 6996.477
    learn_time_ms: 34687.17
    sample_throughput: 22236.051
    sample_time_ms: 10914.168
    update_time_ms: 45.466
  timestamp: 1602419207
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 6
  trial_id: '60207_00000'
  
== Status ==
Memory usage on this node: 29.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_60207_00000 | RUNNING  | 172.17.0.4:24723 |      6 |          274.321 | 1456128 |  224.288 |              281.323 |              108.596 |            878.983 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_60207_00000:
  custom_metrics:
    time_step_max: 4339
    time_step_mean: 3567.8490364025697
    time_step_min: 3199
  date: 2020-10-11_12-27-32
  done: false
  episode_len_mean: 874.6782700421941
  episode_reward_max: 281.32323232323193
  episode_reward_mean: 226.37301815624582
  episode_reward_min: 108.59595959595947
  episodes_this_iter: 316
  episodes_total: 1896
  experiment_id: 11bf409037db440aa32ca30c6b8be456
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.0433175086975097
        entropy_coeff: 0.00010000000000000002
        kl: 0.011342725902795791
        model: {}
        policy_loss: -0.027109035787483058
        total_loss: 18.605763244628907
        vf_explained_var: 0.9720326066017151
        vf_loss: 18.63070805867513
    num_steps_sampled: 1698816
    num_steps_trained: 1698816
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.969230769230776
    gpu_util_percent0: 0.39749999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.9788461538461535
    vram_util_percent0: 0.10897015414890127
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24723
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15344891818003023
    mean_env_wait_ms: 1.1626725172915837
    mean_inference_ms: 4.763532445867935
    mean_raw_obs_processing_ms: 0.40286813957185796
  time_since_restore: 319.51678109169006
  time_this_iter_s: 45.19560790061951
  time_total_s: 319.51678109169006
  timers:
    learn_throughput: 6998.263
    learn_time_ms: 34678.319
    sample_throughput: 22376.841
    sample_time_ms: 10845.499
    update_time_ms: 45.903
  timestamp: 1602419252
  timesteps_since_restore: 0
  timesteps_total: 1698816
  training_iteration: 7
  trial_id: '60207_00000'
  
== Status ==
Memory usage on this node: 29.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_60207_00000 | RUNNING  | 172.17.0.4:24723 |      7 |          319.517 | 1698816 |  226.373 |              281.323 |              108.596 |            874.678 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_60207_00000:
  custom_metrics:
    time_step_max: 4339
    time_step_mean: 3555.4487827285257
    time_step_min: 3199
  date: 2020-10-11_12-28-17
  done: false
  episode_len_mean: 870.275283446712
  episode_reward_max: 281.32323232323193
  episode_reward_mean: 228.14113928399624
  episode_reward_min: 108.59595959595947
  episodes_this_iter: 309
  episodes_total: 2205
  experiment_id: 11bf409037db440aa32ca30c6b8be456
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.0262808640797934
        entropy_coeff: 0.00010000000000000002
        kl: 0.011036948362986247
        model: {}
        policy_loss: -0.02763973573843638
        total_loss: 15.606512959798177
        vf_explained_var: 0.9763622283935547
        vf_loss: 15.632048098246257
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.50188679245283
    gpu_util_percent0: 0.37094339622641515
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.983018867924528
    vram_util_percent0: 0.10897015414890125
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24723
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15291768367294453
    mean_env_wait_ms: 1.1642051481585078
    mean_inference_ms: 4.722268510464603
    mean_raw_obs_processing_ms: 0.400929713180977
  time_since_restore: 364.61337423324585
  time_this_iter_s: 45.096593141555786
  time_total_s: 364.61337423324585
  timers:
    learn_throughput: 6994.91
    learn_time_ms: 34694.944
    sample_throughput: 22551.248
    sample_time_ms: 10761.622
    update_time_ms: 45.386
  timestamp: 1602419297
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 8
  trial_id: '60207_00000'
  
== Status ==
Memory usage on this node: 29.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_60207_00000 | RUNNING  | 172.17.0.4:24723 |      8 |          364.613 | 1941504 |  228.141 |              281.323 |              108.596 |            870.275 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_60207_00000:
  custom_metrics:
    time_step_max: 4339
    time_step_mean: 3547.1714763697196
    time_step_min: 3199
  date: 2020-10-11_12-29-02
  done: false
  episode_len_mean: 867.0177759404713
  episode_reward_max: 281.32323232323193
  episode_reward_mean: 229.32384615063387
  episode_reward_min: 108.59595959595947
  episodes_this_iter: 214
  episodes_total: 2419
  experiment_id: 11bf409037db440aa32ca30c6b8be456
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.006065583229065
        entropy_coeff: 0.00010000000000000002
        kl: 0.011206284227470557
        model: {}
        policy_loss: -0.028538186103105545
        total_loss: 14.03896821339925
        vf_explained_var: 0.9762758016586304
        vf_loss: 14.065365918477376
    num_steps_sampled: 2184192
    num_steps_trained: 2184192
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.83653846153846
    gpu_util_percent0: 0.3744230769230769
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.9884615384615385
    vram_util_percent0: 0.10897015414890127
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24723
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15262584084694672
    mean_env_wait_ms: 1.1652843747784416
    mean_inference_ms: 4.69769584851114
    mean_raw_obs_processing_ms: 0.3997621503219276
  time_since_restore: 409.58726978302
  time_this_iter_s: 44.97389554977417
  time_total_s: 409.58726978302
  timers:
    learn_throughput: 6998.364
    learn_time_ms: 34677.818
    sample_throughput: 22649.462
    sample_time_ms: 10714.956
    update_time_ms: 42.864
  timestamp: 1602419342
  timesteps_since_restore: 0
  timesteps_total: 2184192
  training_iteration: 9
  trial_id: '60207_00000'
  
== Status ==
Memory usage on this node: 29.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_60207_00000 | RUNNING  | 172.17.0.4:24723 |      9 |          409.587 | 2184192 |  229.324 |              281.323 |              108.596 |            867.018 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_60207_00000:
  custom_metrics:
    time_step_max: 4339
    time_step_mean: 3536.8085585585586
    time_step_min: 3144
  date: 2020-10-11_12-29-48
  done: false
  episode_len_mean: 863.4052748885587
  episode_reward_max: 289.65656565656553
  episode_reward_mean: 230.86953112101682
  episode_reward_min: 108.59595959595947
  episodes_this_iter: 273
  episodes_total: 2692
  experiment_id: 11bf409037db440aa32ca30c6b8be456
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 0.9910439252853394
        entropy_coeff: 0.00010000000000000002
        kl: 0.010941853746771812
        model: {}
        policy_loss: -0.028751616304119428
        total_loss: 12.532614771525065
        vf_explained_var: 0.9770954847335815
        vf_loss: 12.559277089436849
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.728301886792444
    gpu_util_percent0: 0.3520754716981132
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.9792452830188676
    vram_util_percent0: 0.10897015414890125
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24723
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15228093323797098
    mean_env_wait_ms: 1.1665452020442
    mean_inference_ms: 4.670692388322805
    mean_raw_obs_processing_ms: 0.39837756266910185
  time_since_restore: 454.6991717815399
  time_this_iter_s: 45.1119019985199
  time_total_s: 454.6991717815399
  timers:
    learn_throughput: 6997.39
    learn_time_ms: 34682.644
    sample_throughput: 22742.267
    sample_time_ms: 10671.232
    update_time_ms: 42.459
  timestamp: 1602419388
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 10
  trial_id: '60207_00000'
  
== Status ==
Memory usage on this node: 29.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_60207_00000 | RUNNING  | 172.17.0.4:24723 |     10 |          454.699 | 2426880 |   230.87 |              289.657 |              108.596 |            863.405 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_60207_00000:
  custom_metrics:
    time_step_max: 4339
    time_step_mean: 3525.8164088769336
    time_step_min: 3144
  date: 2020-10-11_12-30-33
  done: false
  episode_len_mean: 859.3950699533644
  episode_reward_max: 289.65656565656553
  episode_reward_mean: 232.49093870079864
  episode_reward_min: 108.59595959595947
  episodes_this_iter: 310
  episodes_total: 3002
  experiment_id: 11bf409037db440aa32ca30c6b8be456
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 0.9689094622929891
        entropy_coeff: 0.00010000000000000002
        kl: 0.010751755225161712
        model: {}
        policy_loss: -0.028239394476016363
        total_loss: 13.124561500549316
        vf_explained_var: 0.9791122674942017
        vf_loss: 13.150747426350911
    num_steps_sampled: 2669568
    num_steps_trained: 2669568
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.674999999999997
    gpu_util_percent0: 0.3442307692307693
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.9826923076923078
    vram_util_percent0: 0.10897015414890127
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24723
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15194008460421055
    mean_env_wait_ms: 1.167983342967676
    mean_inference_ms: 4.644211554760929
    mean_raw_obs_processing_ms: 0.39702084626696577
  time_since_restore: 499.857479095459
  time_this_iter_s: 45.15830731391907
  time_total_s: 499.857479095459
  timers:
    learn_throughput: 7001.666
    learn_time_ms: 34661.467
    sample_throughput: 23273.608
    sample_time_ms: 10427.606
    update_time_ms: 34.76
  timestamp: 1602419433
  timesteps_since_restore: 0
  timesteps_total: 2669568
  training_iteration: 11
  trial_id: '60207_00000'
  
== Status ==
Memory usage on this node: 29.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_60207_00000 | RUNNING  | 172.17.0.4:24723 |     11 |          499.857 | 2669568 |  232.491 |              289.657 |              108.596 |            859.395 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_60207_00000:
  custom_metrics:
    time_step_max: 4339
    time_step_mean: 3515.4729483282676
    time_step_min: 3144
  date: 2020-10-11_12-31-18
  done: false
  episode_len_mean: 855.5883062085594
  episode_reward_max: 289.65656565656553
  episode_reward_mean: 233.8761119330738
  episode_reward_min: 108.59595959595947
  episodes_this_iter: 316
  episodes_total: 3318
  experiment_id: 11bf409037db440aa32ca30c6b8be456
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 0.9466409881909689
        entropy_coeff: 0.00010000000000000002
        kl: 0.009840698850651582
        model: {}
        policy_loss: -0.02788116621474425
        total_loss: 14.470320065816244
        vf_explained_var: 0.9785919189453125
        vf_loss: 14.496328035990397
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.690384615384612
    gpu_util_percent0: 0.38
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.984615384615384
    vram_util_percent0: 0.10897015414890127
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24723
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1516477375834777
    mean_env_wait_ms: 1.1694615044902779
    mean_inference_ms: 4.6210802764529895
    mean_raw_obs_processing_ms: 0.3958471308967242
  time_since_restore: 545.2246460914612
  time_this_iter_s: 45.3671669960022
  time_total_s: 545.2246460914612
  timers:
    learn_throughput: 6992.713
    learn_time_ms: 34705.844
    sample_throughput: 23428.841
    sample_time_ms: 10358.515
    update_time_ms: 36.366
  timestamp: 1602419478
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 12
  trial_id: '60207_00000'
  
== Status ==
Memory usage on this node: 29.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_60207_00000 | RUNNING  | 172.17.0.4:24723 |     12 |          545.225 | 2912256 |  233.876 |              289.657 |              108.596 |            855.588 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_60207_00000:
  custom_metrics:
    time_step_max: 4339
    time_step_mean: 3506.5249584026624
    time_step_min: 3144
  date: 2020-10-11_12-32-03
  done: false
  episode_len_mean: 851.9463401210787
  episode_reward_max: 289.65656565656553
  episode_reward_mean: 235.14004658583622
  episode_reward_min: 108.59595959595947
  episodes_this_iter: 316
  episodes_total: 3634
  experiment_id: 11bf409037db440aa32ca30c6b8be456
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 0.928343653678894
        entropy_coeff: 0.00010000000000000002
        kl: 0.010319908646245797
        model: {}
        policy_loss: -0.029418420791625977
        total_loss: 11.454197629292805
        vf_explained_var: 0.9825493097305298
        vf_loss: 11.48164513905843
    num_steps_sampled: 3154944
    num_steps_trained: 3154944
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.198076923076922
    gpu_util_percent0: 0.35846153846153855
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.9826923076923078
    vram_util_percent0: 0.10897015414890127
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24723
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15139041764850283
    mean_env_wait_ms: 1.17089136309069
    mean_inference_ms: 4.600876162222171
    mean_raw_obs_processing_ms: 0.3948243084244098
  time_since_restore: 590.1113173961639
  time_this_iter_s: 44.88667130470276
  time_total_s: 590.1113173961639
  timers:
    learn_throughput: 6992.048
    learn_time_ms: 34709.142
    sample_throughput: 23510.589
    sample_time_ms: 10322.498
    update_time_ms: 37.113
  timestamp: 1602419523
  timesteps_since_restore: 0
  timesteps_total: 3154944
  training_iteration: 13
  trial_id: '60207_00000'
  
== Status ==
Memory usage on this node: 29.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_60207_00000 | RUNNING  | 172.17.0.4:24723 |     13 |          590.111 | 3154944 |   235.14 |              289.657 |              108.596 |            851.946 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_60207_00000:
  custom_metrics:
    time_step_max: 4339
    time_step_mean: 3498.1568077511474
    time_step_min: 3144
  date: 2020-10-11_12-32-49
  done: true
  episode_len_mean: 848.4182278481013
  episode_reward_max: 289.65656565656553
  episode_reward_mean: 236.51759365809986
  episode_reward_min: 108.59595959595947
  episodes_this_iter: 316
  episodes_total: 3950
  experiment_id: 11bf409037db440aa32ca30c6b8be456
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 0.9053958853085836
        entropy_coeff: 0.00010000000000000002
        kl: 0.010636517529686291
        model: {}
        policy_loss: -0.02897819404800733
        total_loss: 10.63316764831543
        vf_explained_var: 0.9833887815475464
        vf_loss: 10.660109011332194
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.72692307692307
    gpu_util_percent0: 0.37269230769230766
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.988461538461538
    vram_util_percent0: 0.10897015414890127
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 24723
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1511657935691339
    mean_env_wait_ms: 1.1722958963298666
    mean_inference_ms: 4.583117342299063
    mean_raw_obs_processing_ms: 0.3939264689666121
  time_since_restore: 635.2885541915894
  time_this_iter_s: 45.177236795425415
  time_total_s: 635.2885541915894
  timers:
    learn_throughput: 6986.459
    learn_time_ms: 34736.913
    sample_throughput: 23533.959
    sample_time_ms: 10312.247
    update_time_ms: 37.09
  timestamp: 1602419569
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 14
  trial_id: '60207_00000'
  
== Status ==
Memory usage on this node: 29.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_60207_00000 | TERMINATED |       |     14 |          635.289 | 3397632 |  236.518 |              289.657 |              108.596 |            848.418 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 29.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_60207_00000 | TERMINATED |       |     14 |          635.289 | 3397632 |  236.518 |              289.657 |              108.596 |            848.418 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


