2020-10-11 19:26:02,153	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_9a133_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=58014)[0m 2020-10-11 19:26:04,958	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=57999)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57999)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57975)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57975)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57989)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57989)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57966)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57966)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57916)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57916)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57977)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57977)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57998)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57998)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57949)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57949)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57902)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57902)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57913)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57913)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57969)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57969)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57984)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57984)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57908)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57908)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57940)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57940)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=58010)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=58010)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57988)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57988)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57897)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57897)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57885)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57885)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57962)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57962)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=58006)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=58006)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57943)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57943)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57954)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57954)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57996)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57996)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57981)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57981)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57995)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57995)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57955)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57955)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57961)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57961)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=58016)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=58016)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57906)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57906)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57907)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57907)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57896)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57896)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57953)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57953)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57980)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57980)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57890)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57890)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57956)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57956)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57971)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57971)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57879)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57879)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=58009)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=58009)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57911)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57911)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57919)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57919)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57909)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57909)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57992)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57992)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57888)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57888)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57881)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57881)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57887)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57887)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57965)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57965)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57983)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57983)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57951)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57951)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57883)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57883)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57991)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57991)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57895)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57895)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57892)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57892)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57964)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57964)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57893)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57893)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57973)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57973)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57878)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57878)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57914)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57914)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=58008)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=58008)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57968)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57968)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57950)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57950)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57945)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57945)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57978)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57978)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57900)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57900)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57986)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57986)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57944)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57944)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57936)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57936)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57904)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57904)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57884)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57884)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57979)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57979)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57894)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57894)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57891)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57891)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57967)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57967)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57948)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57948)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57880)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57880)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57882)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57882)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57987)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57987)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57942)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57942)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=58003)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=58003)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57963)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57963)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_9a133_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_19-26-42
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: a630c131dc3c444a80213f1ef2f66a47
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.184286585220924
        entropy_coeff: 0.00010000000000000002
        kl: 0.004264753831263918
        model: {}
        policy_loss: -0.008546667518273283
        total_loss: 501.46584848257214
        vf_explained_var: 0.5741308331489563
        vf_loss: 501.47366098257214
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.615789473684213
    gpu_util_percent0: 0.2805263157894736
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.589473684210526
    vram_util_percent0: 0.08672386114515547
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 58014
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16523059999254538
    mean_env_wait_ms: 1.161690282394725
    mean_inference_ms: 5.274300043801534
    mean_raw_obs_processing_ms: 0.4353659548263338
  time_since_restore: 32.29039025306702
  time_this_iter_s: 32.29039025306702
  time_total_s: 32.29039025306702
  timers:
    learn_throughput: 6889.56
    learn_time_ms: 23483.648
    sample_throughput: 18514.528
    sample_time_ms: 8738.651
    update_time_ms: 30.604
  timestamp: 1602444402
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 9a133_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9a133_00000 | RUNNING  | 172.17.0.4:58014 |      1 |          32.2904 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9a133_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3621.1875
    time_step_min: 3342
  date: 2020-10-11_19-27-14
  done: false
  episode_len_mean: 888.1424050632911
  episode_reward_max: 280.71717171717154
  episode_reward_mean: 216.232131440992
  episode_reward_min: 142.535353535353
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: a630c131dc3c444a80213f1ef2f66a47
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.155174264541039
        entropy_coeff: 0.00010000000000000002
        kl: 0.00864438322157814
        model: {}
        policy_loss: -0.007475179669339783
        total_loss: 124.2291019146259
        vf_explained_var: 0.8200795650482178
        vf_loss: 124.23582575871394
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.76216216216216
    gpu_util_percent0: 0.27513513513513516
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7648648648648653
    vram_util_percent0: 0.10027877992784522
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 58014
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16255185939049532
    mean_env_wait_ms: 1.1609771727307423
    mean_inference_ms: 5.224584726436003
    mean_raw_obs_processing_ms: 0.43052255963642483
  time_since_restore: 64.04267859458923
  time_this_iter_s: 31.752288341522217
  time_total_s: 64.04267859458923
  timers:
    learn_throughput: 6882.943
    learn_time_ms: 23506.223
    sample_throughput: 19180.006
    sample_time_ms: 8435.451
    update_time_ms: 37.018
  timestamp: 1602444434
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 9a133_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9a133_00000 | RUNNING  | 172.17.0.4:58014 |      2 |          64.0427 | 323584 |  216.232 |              280.717 |              142.535 |            888.142 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9a133_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3613.681614349776
    time_step_min: 3325
  date: 2020-10-11_19-27-45
  done: false
  episode_len_mean: 882.7320675105485
  episode_reward_max: 280.71717171717154
  episode_reward_mean: 217.34516046541341
  episode_reward_min: 115.71717171717155
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: a630c131dc3c444a80213f1ef2f66a47
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.1432621754132783
        entropy_coeff: 0.00010000000000000002
        kl: 0.00951677503494116
        model: {}
        policy_loss: -0.013418936636298895
        total_loss: 55.58785981398363
        vf_explained_var: 0.9046525359153748
        vf_loss: 55.600442739633415
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.147222222222222
    gpu_util_percent0: 0.4258333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775000000000001
    vram_util_percent0: 0.10027877992784522
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 58014
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16044341198494805
    mean_env_wait_ms: 1.162097486108314
    mean_inference_ms: 5.128390550100245
    mean_raw_obs_processing_ms: 0.4249914107000096
  time_since_restore: 95.00940108299255
  time_this_iter_s: 30.96672248840332
  time_total_s: 95.00940108299255
  timers:
    learn_throughput: 6883.234
    learn_time_ms: 23505.23
    sample_throughput: 20014.273
    sample_time_ms: 8083.831
    update_time_ms: 37.0
  timestamp: 1602444465
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 9a133_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9a133_00000 | RUNNING  | 172.17.0.4:58014 |      3 |          95.0094 | 485376 |  217.345 |              280.717 |              115.717 |            882.732 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9a133_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3618.6026490066224
    time_step_min: 3177
  date: 2020-10-11_19-28-16
  done: false
  episode_len_mean: 878.8259493670886
  episode_reward_max: 284.6565656565659
  episode_reward_mean: 217.19828027106485
  episode_reward_min: 115.71717171717155
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: a630c131dc3c444a80213f1ef2f66a47
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.1290647983551025
        entropy_coeff: 0.00010000000000000002
        kl: 0.008608200444051852
        model: {}
        policy_loss: -0.014146136282271562
        total_loss: 38.79349664541391
        vf_explained_var: 0.9365471601486206
        vf_loss: 38.80689503596379
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.447222222222223
    gpu_util_percent0: 0.37083333333333335
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775000000000001
    vram_util_percent0: 0.10027877992784522
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 58014
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15877917286783383
    mean_env_wait_ms: 1.163353276257557
    mean_inference_ms: 5.041453998990147
    mean_raw_obs_processing_ms: 0.41991300828589256
  time_since_restore: 125.64037585258484
  time_this_iter_s: 30.630974769592285
  time_total_s: 125.64037585258484
  timers:
    learn_throughput: 6887.039
    learn_time_ms: 23492.243
    sample_throughput: 20638.988
    sample_time_ms: 7839.144
    update_time_ms: 32.383
  timestamp: 1602444496
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 9a133_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9a133_00000 | RUNNING  | 172.17.0.4:58014 |      4 |           125.64 | 647168 |  217.198 |              284.657 |              115.717 |            878.826 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9a133_00000:
  custom_metrics:
    time_step_max: 4183
    time_step_mean: 3608.910878112713
    time_step_min: 3177
  date: 2020-10-11_19-28-46
  done: false
  episode_len_mean: 874.9582806573957
  episode_reward_max: 284.6565656565659
  episode_reward_mean: 219.32212133982026
  episode_reward_min: 115.71717171717155
  episodes_this_iter: 159
  episodes_total: 791
  experiment_id: a630c131dc3c444a80213f1ef2f66a47
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.09566841675685
        entropy_coeff: 0.00010000000000000002
        kl: 0.008351633683420144
        model: {}
        policy_loss: -0.014522410803832687
        total_loss: 31.850455064039963
        vf_explained_var: 0.9470422267913818
        vf_loss: 31.864252383892353
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.051428571428577
    gpu_util_percent0: 0.3842857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774285714285715
    vram_util_percent0: 0.10027877992784522
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 58014
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15747620000954507
    mean_env_wait_ms: 1.1649373482262726
    mean_inference_ms: 4.969680221767326
    mean_raw_obs_processing_ms: 0.4157669936377494
  time_since_restore: 156.0934739112854
  time_this_iter_s: 30.45309805870056
  time_total_s: 156.0934739112854
  timers:
    learn_throughput: 6892.04
    learn_time_ms: 23475.197
    sample_throughput: 21115.988
    sample_time_ms: 7662.061
    update_time_ms: 34.725
  timestamp: 1602444526
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 9a133_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9a133_00000 | RUNNING  | 172.17.0.4:58014 |      5 |          156.093 | 808960 |  219.322 |              284.657 |              115.717 |            874.958 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9a133_00000:
  custom_metrics:
    time_step_max: 4183
    time_step_mean: 3590.373259052925
    time_step_min: 3177
  date: 2020-10-11_19-29-17
  done: false
  episode_len_mean: 865.3004524886878
  episode_reward_max: 284.6565656565659
  episode_reward_mean: 221.9617898441426
  episode_reward_min: 115.71717171717155
  episodes_this_iter: 314
  episodes_total: 1105
  experiment_id: a630c131dc3c444a80213f1ef2f66a47
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.086941306407635
        entropy_coeff: 0.00010000000000000002
        kl: 0.008141169288697151
        model: {}
        policy_loss: -0.007942042680672156
        total_loss: 36.82587168766902
        vf_explained_var: 0.9579781293869019
        vf_loss: 36.83310758150541
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.563888888888886
    gpu_util_percent0: 0.34833333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666675
    vram_util_percent0: 0.10027877992784522
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 58014
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15572126048107582
    mean_env_wait_ms: 1.1690112382568387
    mean_inference_ms: 4.870307236505605
    mean_raw_obs_processing_ms: 0.41030255295450335
  time_since_restore: 186.71835827827454
  time_this_iter_s: 30.624884366989136
  time_total_s: 186.71835827827454
  timers:
    learn_throughput: 6887.759
    learn_time_ms: 23489.789
    sample_throughput: 21432.903
    sample_time_ms: 7548.767
    update_time_ms: 33.711
  timestamp: 1602444557
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 9a133_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9a133_00000 | RUNNING  | 172.17.0.4:58014 |      6 |          186.718 | 970752 |  221.962 |              284.657 |              115.717 |              865.3 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9a133_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3584.1173139158577
    time_step_min: 3177
  date: 2020-10-11_19-29-47
  done: false
  episode_len_mean: 861.1273734177215
  episode_reward_max: 284.6565656565659
  episode_reward_mean: 223.0275380386138
  episode_reward_min: 115.71717171717155
  episodes_this_iter: 159
  episodes_total: 1264
  experiment_id: a630c131dc3c444a80213f1ef2f66a47
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.078303676385146
        entropy_coeff: 0.00010000000000000002
        kl: 0.007187338116077276
        model: {}
        policy_loss: -0.013383333920501173
        total_loss: 21.701288369985726
        vf_explained_var: 0.9637593030929565
        vf_loss: 21.71406026986929
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.422857142857143
    gpu_util_percent0: 0.33142857142857146
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7857142857142865
    vram_util_percent0: 0.10027877992784522
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 58014
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1550696386237329
    mean_env_wait_ms: 1.1706863063856974
    mean_inference_ms: 4.832305388780926
    mean_raw_obs_processing_ms: 0.40821870481639383
  time_since_restore: 216.906809091568
  time_this_iter_s: 30.188450813293457
  time_total_s: 216.906809091568
  timers:
    learn_throughput: 6900.179
    learn_time_ms: 23447.507
    sample_throughput: 21694.374
    sample_time_ms: 7457.786
    update_time_ms: 33.967
  timestamp: 1602444587
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 9a133_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9a133_00000 | RUNNING  | 172.17.0.4:58014 |      7 |          216.907 | 1132544 |  223.028 |              284.657 |              115.717 |            861.127 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9a133_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3576.993543758967
    time_step_min: 3177
  date: 2020-10-11_19-30-18
  done: false
  episode_len_mean: 857.4205344585091
  episode_reward_max: 284.6565656565659
  episode_reward_mean: 224.3554532668455
  episode_reward_min: 115.71717171717155
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: a630c131dc3c444a80213f1ef2f66a47
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.0642571999476507
        entropy_coeff: 0.00010000000000000002
        kl: 0.007387791008043747
        model: {}
        policy_loss: -0.016371603410404462
        total_loss: 18.69626632103553
        vf_explained_var: 0.96588134765625
        vf_loss: 18.712005028357872
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.33888888888889
    gpu_util_percent0: 0.39555555555555555
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7722222222222235
    vram_util_percent0: 0.10027877992784522
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 58014
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15450504648371524
    mean_env_wait_ms: 1.1722631303508029
    mean_inference_ms: 4.799041406195383
    mean_raw_obs_processing_ms: 0.40636357681968366
  time_since_restore: 247.6922471523285
  time_this_iter_s: 30.785438060760498
  time_total_s: 247.6922471523285
  timers:
    learn_throughput: 6889.827
    learn_time_ms: 23482.739
    sample_throughput: 21870.879
    sample_time_ms: 7397.599
    update_time_ms: 32.577
  timestamp: 1602444618
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 9a133_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9a133_00000 | RUNNING  | 172.17.0.4:58014 |      8 |          247.692 | 1294336 |  224.355 |              284.657 |              115.717 |            857.421 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9a133_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3566.7487113402062
    time_step_min: 3177
  date: 2020-10-11_19-30-49
  done: false
  episode_len_mean: 853.926582278481
  episode_reward_max: 284.6565656565659
  episode_reward_mean: 225.78429868303266
  episode_reward_min: 115.71717171717155
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: a630c131dc3c444a80213f1ef2f66a47
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.0350324557377741
        entropy_coeff: 0.00010000000000000002
        kl: 0.007420117572809641
        model: {}
        policy_loss: -0.011925454347734697
        total_loss: 16.73961404653696
        vf_explained_var: 0.9693112969398499
        vf_loss: 16.75090085543119
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.025000000000006
    gpu_util_percent0: 0.41555555555555557
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775000000000001
    vram_util_percent0: 0.10027877992784522
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 58014
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15400877767944357
    mean_env_wait_ms: 1.1738128977644438
    mean_inference_ms: 4.76955231344736
    mean_raw_obs_processing_ms: 0.4046784731936677
  time_since_restore: 278.0523579120636
  time_this_iter_s: 30.360110759735107
  time_total_s: 278.0523579120636
  timers:
    learn_throughput: 6894.485
    learn_time_ms: 23466.872
    sample_throughput: 22023.217
    sample_time_ms: 7346.429
    update_time_ms: 31.263
  timestamp: 1602444649
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 9a133_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9a133_00000 | RUNNING  | 172.17.0.4:58014 |      9 |          278.052 | 1456128 |  225.784 |              284.657 |              115.717 |            853.927 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9a133_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3549.169263836647
    time_step_min: 3177
  date: 2020-10-11_19-31-19
  done: false
  episode_len_mean: 846.0042350449974
  episode_reward_max: 284.6565656565659
  episode_reward_mean: 228.42471298479754
  episode_reward_min: 115.71717171717155
  episodes_this_iter: 309
  episodes_total: 1889
  experiment_id: a630c131dc3c444a80213f1ef2f66a47
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.0107664328355055
        entropy_coeff: 0.00010000000000000002
        kl: 0.007591017199536929
        model: {}
        policy_loss: -0.009955493146732736
        total_loss: 22.29716990544246
        vf_explained_var: 0.9718471169471741
        vf_loss: 22.306467202993538
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.477777777777778
    gpu_util_percent0: 0.3097222222222222
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775000000000001
    vram_util_percent0: 0.10027877992784522
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 58014
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15321897368831217
    mean_env_wait_ms: 1.1771204789340277
    mean_inference_ms: 4.7221614372056
    mean_raw_obs_processing_ms: 0.40205611126362895
  time_since_restore: 308.74820494651794
  time_this_iter_s: 30.695847034454346
  time_total_s: 308.74820494651794
  timers:
    learn_throughput: 6893.916
    learn_time_ms: 23468.808
    sample_throughput: 22088.164
    sample_time_ms: 7324.828
    update_time_ms: 30.454
  timestamp: 1602444679
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 9a133_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9a133_00000 | RUNNING  | 172.17.0.4:58014 |     10 |          308.748 | 1617920 |  228.425 |              284.657 |              115.717 |            846.004 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9a133_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3541.6707798617967
    time_step_min: 3177
  date: 2020-10-11_19-31-50
  done: false
  episode_len_mean: 842.5905550146057
  episode_reward_max: 284.6565656565659
  episode_reward_mean: 229.58722571380787
  episode_reward_min: 115.71717171717155
  episodes_this_iter: 165
  episodes_total: 2054
  experiment_id: a630c131dc3c444a80213f1ef2f66a47
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.994169336098891
        entropy_coeff: 0.00010000000000000002
        kl: 0.006877143007631485
        model: {}
        policy_loss: -0.013025647091965836
        total_loss: 13.081224294809195
        vf_explained_var: 0.976027250289917
        vf_loss: 13.093661895165077
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.717142857142857
    gpu_util_percent0: 0.316
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.791428571428572
    vram_util_percent0: 0.10027877992784522
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 58014
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15287229551373913
    mean_env_wait_ms: 1.178682651575398
    mean_inference_ms: 4.70112343414986
    mean_raw_obs_processing_ms: 0.4008770083279027
  time_since_restore: 339.0498938560486
  time_this_iter_s: 30.30168890953064
  time_total_s: 339.0498938560486
  timers:
    learn_throughput: 6898.857
    learn_time_ms: 23452.002
    sample_throughput: 22652.733
    sample_time_ms: 7142.273
    update_time_ms: 29.241
  timestamp: 1602444710
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 9a133_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9a133_00000 | RUNNING  | 172.17.0.4:58014 |     11 |           339.05 | 1779712 |  229.587 |              284.657 |              115.717 |            842.591 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9a133_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3533.5421245421244
    time_step_min: 3177
  date: 2020-10-11_19-32-21
  done: false
  episode_len_mean: 839.4489150090416
  episode_reward_max: 284.6565656565659
  episode_reward_mean: 230.84258954828562
  episode_reward_min: 115.71717171717155
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: a630c131dc3c444a80213f1ef2f66a47
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.9832459137989924
        entropy_coeff: 0.00010000000000000002
        kl: 0.0068484065839304374
        model: {}
        policy_loss: -0.013663620007439302
        total_loss: 10.534804564255934
        vf_explained_var: 0.9785252809524536
        vf_loss: 10.547881566561186
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.966666666666665
    gpu_util_percent0: 0.3022222222222222
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7861111111111123
    vram_util_percent0: 0.10027877992784522
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 58014
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15256817063190803
    mean_env_wait_ms: 1.1801084960899406
    mean_inference_ms: 4.682719759767449
    mean_raw_obs_processing_ms: 0.3998331636522081
  time_since_restore: 369.7957923412323
  time_this_iter_s: 30.745898485183716
  time_total_s: 369.7957923412323
  timers:
    learn_throughput: 6898.852
    learn_time_ms: 23452.017
    sample_throughput: 22971.86
    sample_time_ms: 7043.052
    update_time_ms: 27.123
  timestamp: 1602444741
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 9a133_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9a133_00000 | RUNNING  | 172.17.0.4:58014 |     12 |          369.796 | 1941504 |  230.843 |              284.657 |              115.717 |            839.449 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9a133_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3525.2688758389263
    time_step_min: 3177
  date: 2020-10-11_19-32-51
  done: false
  episode_len_mean: 835.7354892205639
  episode_reward_max: 284.6565656565659
  episode_reward_mean: 232.1768556208854
  episode_reward_min: 115.71717171717155
  episodes_this_iter: 200
  episodes_total: 2412
  experiment_id: a630c131dc3c444a80213f1ef2f66a47
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.9394059502161466
        entropy_coeff: 0.00010000000000000002
        kl: 0.006894647752722869
        model: {}
        policy_loss: -0.014330393813837033
        total_loss: 13.805552776043232
        vf_explained_var: 0.9797898530960083
        vf_loss: 13.819287446828989
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.677142857142854
    gpu_util_percent0: 0.2902857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774285714285715
    vram_util_percent0: 0.10027877992784522
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 58014
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15221443962176848
    mean_env_wait_ms: 1.182011065307648
    mean_inference_ms: 4.661665898249985
    mean_raw_obs_processing_ms: 0.3986260909950954
  time_since_restore: 400.1509048938751
  time_this_iter_s: 30.355112552642822
  time_total_s: 400.1509048938751
  timers:
    learn_throughput: 6903.381
    learn_time_ms: 23436.632
    sample_throughput: 23126.476
    sample_time_ms: 6995.964
    update_time_ms: 27.318
  timestamp: 1602444771
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 9a133_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9a133_00000 | RUNNING  | 172.17.0.4:58014 |     13 |          400.151 | 2103296 |  232.177 |              284.657 |              115.717 |            835.735 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9a133_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3512.129796839729
    time_step_min: 3177
  date: 2020-10-11_19-33-21
  done: false
  episode_len_mean: 831.180193596426
  episode_reward_max: 284.6565656565659
  episode_reward_mean: 234.26029092112478
  episode_reward_min: 115.71717171717155
  episodes_this_iter: 274
  episodes_total: 2686
  experiment_id: a630c131dc3c444a80213f1ef2f66a47
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.9376368797742404
        entropy_coeff: 0.00010000000000000002
        kl: 0.007433912286964746
        model: {}
        policy_loss: -0.014163680517902741
        total_loss: 10.810278965876652
        vf_explained_var: 0.9824769496917725
        vf_loss: 10.823793117816631
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.061111111111114
    gpu_util_percent0: 0.3877777777777778
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666666
    vram_util_percent0: 0.10027877992784522
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 58014
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15180494970196057
    mean_env_wait_ms: 1.1842002498670208
    mean_inference_ms: 4.636398192085508
    mean_raw_obs_processing_ms: 0.39717164695986
  time_since_restore: 430.40017104148865
  time_this_iter_s: 30.249266147613525
  time_total_s: 430.40017104148865
  timers:
    learn_throughput: 6913.752
    learn_time_ms: 23401.477
    sample_throughput: 23164.97
    sample_time_ms: 6984.339
    update_time_ms: 27.607
  timestamp: 1602444801
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 9a133_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9a133_00000 | RUNNING  | 172.17.0.4:58014 |     14 |            430.4 | 2265088 |   234.26 |              284.657 |              115.717 |             831.18 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9a133_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3504.877840909091
    time_step_min: 3177
  date: 2020-10-11_19-33-52
  done: false
  episode_len_mean: 828.9226441631505
  episode_reward_max: 284.6565656565659
  episode_reward_mean: 235.21233431360002
  episode_reward_min: 115.71717171717155
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: a630c131dc3c444a80213f1ef2f66a47
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.9177294052564181
        entropy_coeff: 0.00010000000000000002
        kl: 0.005983758789415543
        model: {}
        policy_loss: -0.013227576770497343
        total_loss: 10.211126914391151
        vf_explained_var: 0.9804474115371704
        vf_loss: 10.223847682659443
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.582857142857144
    gpu_util_percent0: 0.4154285714285715
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7857142857142865
    vram_util_percent0: 0.10027877992784522
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 58014
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1515920345545912
    mean_env_wait_ms: 1.1853470512470279
    mean_inference_ms: 4.62342030476944
    mean_raw_obs_processing_ms: 0.39642496977846065
  time_since_restore: 460.40040159225464
  time_this_iter_s: 30.00023055076599
  time_total_s: 460.40040159225464
  timers:
    learn_throughput: 6921.467
    learn_time_ms: 23375.392
    sample_throughput: 23224.77
    sample_time_ms: 6966.355
    update_time_ms: 25.241
  timestamp: 1602444832
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 9a133_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9a133_00000 | RUNNING  | 172.17.0.4:58014 |     15 |            460.4 | 2426880 |  235.212 |              284.657 |              115.717 |            828.923 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9a133_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3498.329637096774
    time_step_min: 3177
  date: 2020-10-11_19-34-22
  done: false
  episode_len_mean: 827.2646471371505
  episode_reward_max: 284.6565656565659
  episode_reward_mean: 236.0977753567633
  episode_reward_min: 115.71717171717155
  episodes_this_iter: 160
  episodes_total: 3004
  experiment_id: a630c131dc3c444a80213f1ef2f66a47
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.8884624334482046
        entropy_coeff: 0.00010000000000000002
        kl: 0.007146015906563172
        model: {}
        policy_loss: -0.010416251284858355
        total_loss: 10.040320323063778
        vf_explained_var: 0.9817863702774048
        vf_loss: 10.050110816955566
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.337142857142858
    gpu_util_percent0: 0.36114285714285715
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774285714285715
    vram_util_percent0: 0.10027877992784522
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 58014
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1513916406361925
    mean_env_wait_ms: 1.1864360921415158
    mean_inference_ms: 4.611075647067827
    mean_raw_obs_processing_ms: 0.3956955466040456
  time_since_restore: 490.30317211151123
  time_this_iter_s: 29.902770519256592
  time_total_s: 490.30317211151123
  timers:
    learn_throughput: 6939.796
    learn_time_ms: 23313.653
    sample_throughput: 23287.647
    sample_time_ms: 6947.546
    update_time_ms: 32.141
  timestamp: 1602444862
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 9a133_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9a133_00000 | RUNNING  | 172.17.0.4:58014 |     16 |          490.303 | 2588672 |  236.098 |              284.657 |              115.717 |            827.265 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9a133_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3487.58615431534
    time_step_min: 3177
  date: 2020-10-11_19-34-51
  done: false
  episode_len_mean: 824.3979437556698
  episode_reward_max: 284.6565656565659
  episode_reward_mean: 237.67738467224396
  episode_reward_min: 115.71717171717155
  episodes_this_iter: 303
  episodes_total: 3307
  experiment_id: a630c131dc3c444a80213f1ef2f66a47
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.8747198123198289
        entropy_coeff: 0.00010000000000000002
        kl: 0.00624232474141396
        model: {}
        policy_loss: -0.013681852670672994
        total_loss: 13.868704942556528
        vf_explained_var: 0.9820327162742615
        vf_loss: 13.881850462693434
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.870588235294118
    gpu_util_percent0: 0.38323529411764706
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7735294117647062
    vram_util_percent0: 0.1002787799278452
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 58014
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15105419497031286
    mean_env_wait_ms: 1.1883924699940698
    mean_inference_ms: 4.590246008190482
    mean_raw_obs_processing_ms: 0.39450366322453395
  time_since_restore: 519.9242262840271
  time_this_iter_s: 29.62105417251587
  time_total_s: 519.9242262840271
  timers:
    learn_throughput: 6956.52
    learn_time_ms: 23257.605
    sample_throughput: 23290.571
    sample_time_ms: 6946.674
    update_time_ms: 30.706
  timestamp: 1602444891
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 9a133_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9a133_00000 | RUNNING  | 172.17.0.4:58014 |     17 |          519.924 | 2750464 |  237.677 |              284.657 |              115.717 |            824.398 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9a133_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3482.7363689095127
    time_step_min: 3177
  date: 2020-10-11_19-35-21
  done: false
  episode_len_mean: 823.0189873417721
  episode_reward_max: 284.6565656565659
  episode_reward_mean: 238.42369610954185
  episode_reward_min: 115.71717171717155
  episodes_this_iter: 169
  episodes_total: 3476
  experiment_id: a630c131dc3c444a80213f1ef2f66a47
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.8711711993584266
        entropy_coeff: 0.00010000000000000002
        kl: 0.0066577081138697956
        model: {}
        policy_loss: -0.012268734800342757
        total_loss: 10.78620800605187
        vf_explained_var: 0.980709969997406
        vf_loss: 10.797898072462816
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.417142857142856
    gpu_util_percent0: 0.29542857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.791428571428572
    vram_util_percent0: 0.10027877992784522
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 58014
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15088526715914144
    mean_env_wait_ms: 1.1893303060449267
    mean_inference_ms: 4.5797470319106495
    mean_raw_obs_processing_ms: 0.39390200342845855
  time_since_restore: 549.9327096939087
  time_this_iter_s: 30.008483409881592
  time_total_s: 549.9327096939087
  timers:
    learn_throughput: 6973.454
    learn_time_ms: 23201.13
    sample_throughput: 23369.282
    sample_time_ms: 6923.277
    update_time_ms: 32.459
  timestamp: 1602444921
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 9a133_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9a133_00000 | RUNNING  | 172.17.0.4:58014 |     18 |          549.933 | 2912256 |  238.424 |              284.657 |              115.717 |            823.019 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9a133_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3477.861619523017
    time_step_min: 3143
  date: 2020-10-11_19-35-52
  done: false
  episode_len_mean: 821.9014859658778
  episode_reward_max: 289.80808080808083
  episode_reward_mean: 239.11233690787896
  episode_reward_min: 115.71717171717155
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: a630c131dc3c444a80213f1ef2f66a47
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.8534938372098483
        entropy_coeff: 0.00010000000000000002
        kl: 0.006808838842866512
        model: {}
        policy_loss: -0.013249450327398686
        total_loss: 9.260023337144117
        vf_explained_var: 0.9814625978469849
        vf_loss: 9.272677348210262
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.994444444444447
    gpu_util_percent0: 0.44833333333333336
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7916666666666674
    vram_util_percent0: 0.10027877992784522
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 58014
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15073692152917542
    mean_env_wait_ms: 1.190154759364277
    mean_inference_ms: 4.57055158358897
    mean_raw_obs_processing_ms: 0.39336073066497806
  time_since_restore: 580.209244966507
  time_this_iter_s: 30.276535272598267
  time_total_s: 580.209244966507
  timers:
    learn_throughput: 6974.837
    learn_time_ms: 23196.527
    sample_throughput: 23414.709
    sample_time_ms: 6909.844
    update_time_ms: 40.387
  timestamp: 1602444952
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 9a133_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9a133_00000 | RUNNING  | 172.17.0.4:58014 |     19 |          580.209 | 3074048 |  239.112 |              289.808 |              115.717 |            821.901 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9a133_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3472.163964435146
    time_step_min: 3143
  date: 2020-10-11_19-36-22
  done: true
  episode_len_mean: 820.5373831775701
  episode_reward_max: 289.80808080808083
  episode_reward_mean: 239.9739922590389
  episode_reward_min: 115.71717171717155
  episodes_this_iter: 218
  episodes_total: 3852
  experiment_id: a630c131dc3c444a80213f1ef2f66a47
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.8158316979041467
        entropy_coeff: 0.00010000000000000002
        kl: 0.006350714355134047
        model: {}
        policy_loss: -0.010566194483544677
        total_loss: 12.290809337909405
        vf_explained_var: 0.9819645285606384
        vf_loss: 12.300821891197792
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.365714285714287
    gpu_util_percent0: 0.4042857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7714285714285714
    vram_util_percent0: 0.10027877992784522
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 58014
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15054349954826532
    mean_env_wait_ms: 1.191297496032556
    mean_inference_ms: 4.558678843201687
    mean_raw_obs_processing_ms: 0.3926616739660287
  time_since_restore: 610.0707452297211
  time_this_iter_s: 29.86150026321411
  time_total_s: 610.0707452297211
  timers:
    learn_throughput: 6991.392
    learn_time_ms: 23141.602
    sample_throughput: 23534.442
    sample_time_ms: 6874.69
    update_time_ms: 41.722
  timestamp: 1602444982
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 9a133_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9a133_00000 | TERMINATED |       |     20 |          610.071 | 3235840 |  239.974 |              289.808 |              115.717 |            820.537 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 27.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9a133_00000 | TERMINATED |       |     20 |          610.071 | 3235840 |  239.974 |              289.808 |              115.717 |            820.537 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


