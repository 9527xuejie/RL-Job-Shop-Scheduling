2020-10-10 18:11:09,651	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_f9fdd_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=10952)[0m 2020-10-10 18:11:12,645	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=10861)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10861)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10822)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10822)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10827)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10827)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10941)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10941)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10848)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10848)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10849)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10849)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10838)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10838)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10891)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10891)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10828)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10828)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10833)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10833)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10835)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10835)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10938)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10938)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10899)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10899)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10943)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10943)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10915)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10915)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10921)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10921)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10930)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10930)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10918)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10918)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10859)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10859)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10906)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10906)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10908)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10908)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10896)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10896)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10903)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10903)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10934)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10934)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10900)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10900)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10826)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10826)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10897)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10897)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10840)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10840)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10895)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10895)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10912)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10912)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10939)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10939)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10923)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10923)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10948)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10948)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10925)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10925)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10926)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10926)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10929)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10929)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10902)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10902)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10927)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10927)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10856)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10856)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10913)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10913)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10956)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10956)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10845)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10845)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10875)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10875)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10963)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10963)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10843)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10843)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10901)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10901)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10865)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10865)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10882)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10882)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10889)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10889)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10836)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10836)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10904)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10904)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10894)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10894)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10873)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10873)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10851)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10851)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10839)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10839)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10909)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10909)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10830)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10830)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10824)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10824)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10886)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10886)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10854)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10854)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10831)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10831)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10857)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10857)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10837)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10837)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10841)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10841)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10911)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10911)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10832)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10832)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10879)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10879)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10823)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10823)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10932)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10932)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10877)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10877)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10937)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10937)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10825)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10825)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10928)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10928)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10863)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10863)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10883)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10883)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10907)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10907)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10905)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10905)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10916)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10916)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10914)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10914)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_f9fdd_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-10_18-11-55
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 63302949403f45dcbae4f5e4d98fd778
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1851969276155745
        entropy_coeff: 0.0
        kl: 0.0037352575454860926
        model: {}
        policy_loss: -0.013090697840587901
        total_loss: 498.0819614955357
        vf_explained_var: 0.5928232073783875
        vf_loss: 498.09429931640625
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.21627906976744
    gpu_util_percent0: 0.24720930232558141
    gpu_util_percent1: 0.00023255813953488373
    gpu_util_percent2: 0.00023255813953488373
    ram_util_percent: 6.29767441860465
    vram_util_percent0: 0.1926289214153325
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 10952
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17429110664539624
    mean_env_wait_ms: 1.2060744175759315
    mean_inference_ms: 5.750870688456964
    mean_raw_obs_processing_ms: 0.46571269599182
  time_since_restore: 37.04094743728638
  time_this_iter_s: 37.04094743728638
  time_total_s: 37.04094743728638
  timers:
    learn_throughput: 5792.996
    learn_time_ms: 27928.9
    sample_throughput: 17909.751
    sample_time_ms: 9033.738
    update_time_ms: 38.721
  timestamp: 1602353515
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: f9fdd_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f9fdd_00000 | RUNNING  | 172.17.0.4:10952 |      1 |          37.0409 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f9fdd_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3619.4375
    time_step_min: 3310
  date: 2020-10-10_18-12-31
  done: false
  episode_len_mean: 892.0949367088608
  episode_reward_max: 264.50505050505035
  episode_reward_mean: 217.19492392277184
  episode_reward_min: 134.80808080808083
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 63302949403f45dcbae4f5e4d98fd778
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.1565611107008797
        entropy_coeff: 0.0
        kl: 0.00494929073777582
        model: {}
        policy_loss: -0.014617739157984033
        total_loss: 110.5993537902832
        vf_explained_var: 0.8335238099098206
        vf_loss: 110.61347688947406
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.71395348837209
    gpu_util_percent0: 0.36093023255813955
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.467441860465114
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 10952
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16952975145254648
    mean_env_wait_ms: 1.1978804676108443
    mean_inference_ms: 5.542699710776655
    mean_raw_obs_processing_ms: 0.45579933488950386
  time_since_restore: 72.89136552810669
  time_this_iter_s: 35.85041809082031
  time_total_s: 72.89136552810669
  timers:
    learn_throughput: 5809.143
    learn_time_ms: 27851.269
    sample_throughput: 19022.922
    sample_time_ms: 8505.108
    update_time_ms: 39.425
  timestamp: 1602353551
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: f9fdd_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f9fdd_00000 | RUNNING  | 172.17.0.4:10952 |      2 |          72.8914 | 323584 |  217.195 |              264.505 |              134.808 |            892.095 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f9fdd_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3624.7062780269057
    time_step_min: 3279
  date: 2020-10-10_18-13-06
  done: false
  episode_len_mean: 890.6350210970464
  episode_reward_max: 269.20202020201975
  episode_reward_mean: 216.99610024293548
  episode_reward_min: 134.80808080808083
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 63302949403f45dcbae4f5e4d98fd778
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 1.149620030607496
        entropy_coeff: 0.0
        kl: 0.006003097764083317
        model: {}
        policy_loss: -0.016527669414894523
        total_loss: 43.051615306309294
        vf_explained_var: 0.9296110272407532
        vf_loss: 43.06784193856375
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.96829268292683
    gpu_util_percent0: 0.29878048780487804
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.490243902439025
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 10952
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1663873204466298
    mean_env_wait_ms: 1.193478468799118
    mean_inference_ms: 5.377758241419082
    mean_raw_obs_processing_ms: 0.4480145971803444
  time_since_restore: 108.14544010162354
  time_this_iter_s: 35.254074573516846
  time_total_s: 108.14544010162354
  timers:
    learn_throughput: 5813.675
    learn_time_ms: 27829.556
    sample_throughput: 19889.346
    sample_time_ms: 8134.606
    update_time_ms: 33.147
  timestamp: 1602353586
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: f9fdd_00000
  
== Status ==
Memory usage on this node: 48.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f9fdd_00000 | RUNNING  | 172.17.0.4:10952 |      3 |          108.145 | 485376 |  216.996 |              269.202 |              134.808 |            890.635 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f9fdd_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3622.1291390728475
    time_step_min: 3279
  date: 2020-10-10_18-13-41
  done: false
  episode_len_mean: 889.4462025316456
  episode_reward_max: 269.20202020201975
  episode_reward_mean: 217.83526722925436
  episode_reward_min: 134.80808080808083
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 63302949403f45dcbae4f5e4d98fd778
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 1.1358228410993303
        entropy_coeff: 0.0
        kl: 0.0060796034854969806
        model: {}
        policy_loss: -0.015901170754139975
        total_loss: 26.76067270551409
        vf_explained_var: 0.9541420936584473
        vf_loss: 26.776270048958914
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.18780487804878
    gpu_util_percent0: 0.32707317073170733
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.482926829268293
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 10952
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1641811994460752
    mean_env_wait_ms: 1.1908401071568406
    mean_inference_ms: 5.254612624677386
    mean_raw_obs_processing_ms: 0.441672724293299
  time_since_restore: 143.1517791748047
  time_this_iter_s: 35.00633907318115
  time_total_s: 143.1517791748047
  timers:
    learn_throughput: 5821.795
    learn_time_ms: 27790.742
    sample_throughput: 20439.522
    sample_time_ms: 7915.645
    update_time_ms: 30.214
  timestamp: 1602353621
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: f9fdd_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f9fdd_00000 | RUNNING  | 172.17.0.4:10952 |      4 |          143.152 | 647168 |  217.835 |              269.202 |              134.808 |            889.446 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f9fdd_00000:
  custom_metrics:
    time_step_max: 4075
    time_step_mean: 3614.0892388451443
    time_step_min: 3214
  date: 2020-10-10_18-14-17
  done: false
  episode_len_mean: 886.8329113924051
  episode_reward_max: 279.05050505050457
  episode_reward_mean: 219.16155223117227
  episode_reward_min: 134.80808080808083
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 63302949403f45dcbae4f5e4d98fd778
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 1.1137242317199707
        entropy_coeff: 0.0
        kl: 0.0061262670372213635
        model: {}
        policy_loss: -0.017462593388959897
        total_loss: 23.885904720851354
        vf_explained_var: 0.9580110311508179
        vf_loss: 23.903061049325125
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.426190476190477
    gpu_util_percent0: 0.2835714285714286
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.485714285714285
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 10952
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16247693284665773
    mean_env_wait_ms: 1.1892511328223416
    mean_inference_ms: 5.159385771881661
    mean_raw_obs_processing_ms: 0.4363368767506989
  time_since_restore: 178.46985268592834
  time_this_iter_s: 35.31807351112366
  time_total_s: 178.46985268592834
  timers:
    learn_throughput: 5825.398
    learn_time_ms: 27773.551
    sample_throughput: 20687.928
    sample_time_ms: 7820.6
    update_time_ms: 32.905
  timestamp: 1602353657
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: f9fdd_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f9fdd_00000 | RUNNING  | 172.17.0.4:10952 |      5 |           178.47 | 808960 |  219.162 |              279.051 |              134.808 |            886.833 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f9fdd_00000:
  custom_metrics:
    time_step_max: 4075
    time_step_mean: 3604.520438683948
    time_step_min: 3214
  date: 2020-10-10_18-14-52
  done: false
  episode_len_mean: 879.8360814742967
  episode_reward_max: 279.05050505050457
  episode_reward_mean: 220.7373051563156
  episode_reward_min: 134.80808080808083
  episodes_this_iter: 241
  episodes_total: 1031
  experiment_id: 63302949403f45dcbae4f5e4d98fd778
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 1.0925145660127913
        entropy_coeff: 0.0
        kl: 0.005795996669413788
        model: {}
        policy_loss: -0.014690097072161734
        total_loss: 26.127950395856583
        vf_explained_var: 0.9697983860969543
        vf_loss: 26.14235074179513
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.95365853658537
    gpu_util_percent0: 0.34682926829268296
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.482926829268293
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 10952
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1606120671825574
    mean_env_wait_ms: 1.1894795316500357
    mean_inference_ms: 5.052926794035738
    mean_raw_obs_processing_ms: 0.43038198569563746
  time_since_restore: 213.5107409954071
  time_this_iter_s: 35.04088830947876
  time_total_s: 213.5107409954071
  timers:
    learn_throughput: 5831.037
    learn_time_ms: 27746.695
    sample_throughput: 20906.017
    sample_time_ms: 7739.016
    update_time_ms: 33.738
  timestamp: 1602353692
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: f9fdd_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f9fdd_00000 | RUNNING  | 172.17.0.4:10952 |      6 |          213.511 | 970752 |  220.737 |              279.051 |              134.808 |            879.836 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f9fdd_00000:
  custom_metrics:
    time_step_max: 4075
    time_step_mean: 3595.6173139158577
    time_step_min: 3214
  date: 2020-10-10_18-15-27
  done: false
  episode_len_mean: 873.1542721518987
  episode_reward_max: 279.05050505050457
  episode_reward_mean: 222.4100898222732
  episode_reward_min: 134.80808080808083
  episodes_this_iter: 233
  episodes_total: 1264
  experiment_id: 63302949403f45dcbae4f5e4d98fd778
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 1.1047902703285217
        entropy_coeff: 0.0
        kl: 0.006014264055660793
        model: {}
        policy_loss: -0.01559294038452208
        total_loss: 18.62956060682024
        vf_explained_var: 0.9723853468894958
        vf_loss: 18.644853046962194
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.95609756097561
    gpu_util_percent0: 0.3029268292682927
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4853658536585375
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 10952
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15931607739450465
    mean_env_wait_ms: 1.190412734523273
    mean_inference_ms: 4.9785899305893455
    mean_raw_obs_processing_ms: 0.42616657824189125
  time_since_restore: 249.0002944469452
  time_this_iter_s: 35.489553451538086
  time_total_s: 249.0002944469452
  timers:
    learn_throughput: 5825.955
    learn_time_ms: 27770.895
    sample_throughput: 21006.458
    sample_time_ms: 7702.012
    update_time_ms: 35.098
  timestamp: 1602353727
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: f9fdd_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f9fdd_00000 | RUNNING  | 172.17.0.4:10952 |      7 |              249 | 1132544 |   222.41 |              279.051 |              134.808 |            873.154 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f9fdd_00000:
  custom_metrics:
    time_step_max: 4075
    time_step_mean: 3588.9045911047347
    time_step_min: 3214
  date: 2020-10-10_18-16-03
  done: false
  episode_len_mean: 868.6244725738396
  episode_reward_max: 279.05050505050457
  episode_reward_mean: 223.43687934194247
  episode_reward_min: 134.80808080808083
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 63302949403f45dcbae4f5e4d98fd778
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 1.0866109217916216
        entropy_coeff: 0.0
        kl: 0.005545566490452204
        model: {}
        policy_loss: -0.015451295334579689
        total_loss: 14.982959338596888
        vf_explained_var: 0.974897563457489
        vf_loss: 14.998132910047259
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.04390243902439
    gpu_util_percent0: 0.326829268292683
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.495121951219512
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 10952
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15860712337707888
    mean_env_wait_ms: 1.1912025290546229
    mean_inference_ms: 4.937514730452526
    mean_raw_obs_processing_ms: 0.4237916884737916
  time_since_restore: 284.1343538761139
  time_this_iter_s: 35.1340594291687
  time_total_s: 284.1343538761139
  timers:
    learn_throughput: 5825.034
    learn_time_ms: 27775.287
    sample_throughput: 21168.812
    sample_time_ms: 7642.942
    update_time_ms: 36.15
  timestamp: 1602353763
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: f9fdd_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f9fdd_00000 | RUNNING  | 172.17.0.4:10952 |      8 |          284.134 | 1294336 |  223.437 |              279.051 |              134.808 |            868.624 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f9fdd_00000:
  custom_metrics:
    time_step_max: 4075
    time_step_mean: 3579.391108247423
    time_step_min: 3214
  date: 2020-10-10_18-16-38
  done: false
  episode_len_mean: 864.6841772151898
  episode_reward_max: 279.05050505050457
  episode_reward_mean: 224.7312683800024
  episode_reward_min: 134.80808080808083
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 63302949403f45dcbae4f5e4d98fd778
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 1.0651659199169703
        entropy_coeff: 0.0
        kl: 0.005603759848911848
        model: {}
        policy_loss: -0.017090381322694675
        total_loss: 13.36875867843628
        vf_explained_var: 0.9754810929298401
        vf_loss: 13.385568959372383
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.55609756097561
    gpu_util_percent0: 0.42707317073170736
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.492682926829268
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 10952
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1579900731546551
    mean_env_wait_ms: 1.1920411377364903
    mean_inference_ms: 4.901502200766564
    mean_raw_obs_processing_ms: 0.42163922963407185
  time_since_restore: 319.34791564941406
  time_this_iter_s: 35.21356177330017
  time_total_s: 319.34791564941406
  timers:
    learn_throughput: 5825.882
    learn_time_ms: 27771.247
    sample_throughput: 21246.703
    sample_time_ms: 7614.923
    update_time_ms: 35.444
  timestamp: 1602353798
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: f9fdd_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f9fdd_00000 | RUNNING  | 172.17.0.4:10952 |      9 |          319.348 | 1456128 |  224.731 |              279.051 |              134.808 |            864.684 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f9fdd_00000:
  custom_metrics:
    time_step_max: 4075
    time_step_mean: 3568.6989619377164
    time_step_min: 3214
  date: 2020-10-10_18-17-13
  done: false
  episode_len_mean: 860.2786606129398
  episode_reward_max: 279.05050505050457
  episode_reward_mean: 226.0308648344969
  episode_reward_min: 134.80808080808083
  episodes_this_iter: 182
  episodes_total: 1762
  experiment_id: 63302949403f45dcbae4f5e4d98fd778
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 1.0296232104301453
        entropy_coeff: 0.0
        kl: 0.005627406960619348
        model: {}
        policy_loss: -0.015739225915500095
        total_loss: 16.21814932141985
        vf_explained_var: 0.9773330092430115
        vf_loss: 16.233607087816512
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.753658536585366
    gpu_util_percent0: 0.31634146341463415
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.485365853658536
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 10952
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15737239779651516
    mean_env_wait_ms: 1.1933633851138719
    mean_inference_ms: 4.865425137368793
    mean_raw_obs_processing_ms: 0.41946895958077074
  time_since_restore: 354.2940511703491
  time_this_iter_s: 34.94613552093506
  time_total_s: 354.2940511703491
  timers:
    learn_throughput: 5827.249
    learn_time_ms: 27764.729
    sample_throughput: 21378.451
    sample_time_ms: 7567.995
    update_time_ms: 35.803
  timestamp: 1602353833
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: f9fdd_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f9fdd_00000 | RUNNING  | 172.17.0.4:10952 |     10 |          354.294 | 1617920 |  226.031 |              279.051 |              134.808 |            860.279 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f9fdd_00000:
  custom_metrics:
    time_step_max: 4075
    time_step_mean: 3554.5276406712733
    time_step_min: 3214
  date: 2020-10-10_18-17-48
  done: false
  episode_len_mean: 854.0447906523856
  episode_reward_max: 282.08080808080837
  episode_reward_mean: 228.27197977830872
  episode_reward_min: 134.80808080808083
  episodes_this_iter: 292
  episodes_total: 2054
  experiment_id: 63302949403f45dcbae4f5e4d98fd778
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 1.0358297654560633
        entropy_coeff: 0.0
        kl: 0.005223342184243458
        model: {}
        policy_loss: -0.016286779885246818
        total_loss: 14.245336260114398
        vf_explained_var: 0.9802085161209106
        vf_loss: 14.261361939566475
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.887804878048783
    gpu_util_percent0: 0.27780487804878046
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.480487804878049
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 10952
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15655901763940636
    mean_env_wait_ms: 1.195397378110003
    mean_inference_ms: 4.817311164707536
    mean_raw_obs_processing_ms: 0.41658929042693504
  time_since_restore: 389.0615382194519
  time_this_iter_s: 34.76748704910278
  time_total_s: 389.0615382194519
  timers:
    learn_throughput: 5833.152
    learn_time_ms: 27736.633
    sample_throughput: 21956.594
    sample_time_ms: 7368.72
    update_time_ms: 33.869
  timestamp: 1602353868
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: f9fdd_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f9fdd_00000 | RUNNING  | 172.17.0.4:10952 |     11 |          389.062 | 1779712 |  228.272 |              282.081 |              134.808 |            854.045 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f9fdd_00000:
  custom_metrics:
    time_step_max: 4075
    time_step_mean: 3545.7655677655675
    time_step_min: 3214
  date: 2020-10-10_18-18-23
  done: false
  episode_len_mean: 850.505424954792
  episode_reward_max: 282.8383838383838
  episode_reward_mean: 229.5144345808901
  episode_reward_min: 134.80808080808083
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 63302949403f45dcbae4f5e4d98fd778
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 1.0170109186853682
        entropy_coeff: 0.0
        kl: 0.005199252162128687
        model: {}
        policy_loss: -0.016733833143786927
        total_loss: 9.796358449118477
        vf_explained_var: 0.9821501970291138
        vf_loss: 9.812832423618861
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.44390243902439
    gpu_util_percent0: 0.4151219512195121
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.495121951219511
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 10952
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15618910850230078
    mean_env_wait_ms: 1.1964798106771382
    mean_inference_ms: 4.795309958404076
    mean_raw_obs_processing_ms: 0.4152859068839846
  time_since_restore: 424.3789472579956
  time_this_iter_s: 35.3174090385437
  time_total_s: 424.3789472579956
  timers:
    learn_throughput: 5834.209
    learn_time_ms: 27731.609
    sample_throughput: 22103.61
    sample_time_ms: 7319.709
    update_time_ms: 34.566
  timestamp: 1602353903
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: f9fdd_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f9fdd_00000 | RUNNING  | 172.17.0.4:10952 |     12 |          424.379 | 1941504 |  229.514 |              282.838 |              134.808 |            850.505 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f9fdd_00000:
  custom_metrics:
    time_step_max: 4075
    time_step_mean: 3537.9137489325362
    time_step_min: 3214
  date: 2020-10-10_18-18-58
  done: false
  episode_len_mean: 847.2818565400844
  episode_reward_max: 282.8383838383838
  episode_reward_mean: 230.49744278225273
  episode_reward_min: 134.80808080808083
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: 63302949403f45dcbae4f5e4d98fd778
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 0.9947364415441241
        entropy_coeff: 0.0
        kl: 0.005370665873800006
        model: {}
        policy_loss: -0.013783725460858218
        total_loss: 13.160553182874407
        vf_explained_var: 0.9759066700935364
        vf_loss: 13.174068314688546
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.617073170731707
    gpu_util_percent0: 0.3075609756097561
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.502439024390244
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 10952
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1558572794017578
    mean_env_wait_ms: 1.1975358270035747
    mean_inference_ms: 4.775218069240457
    mean_raw_obs_processing_ms: 0.4140670233824823
  time_since_restore: 459.4075736999512
  time_this_iter_s: 35.028626441955566
  time_total_s: 459.4075736999512
  timers:
    learn_throughput: 5835.973
    learn_time_ms: 27723.227
    sample_throughput: 22155.319
    sample_time_ms: 7302.626
    update_time_ms: 36.999
  timestamp: 1602353938
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: f9fdd_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f9fdd_00000 | RUNNING  | 172.17.0.4:10952 |     13 |          459.408 | 2103296 |  230.497 |              282.838 |              134.808 |            847.282 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f9fdd_00000:
  custom_metrics:
    time_step_max: 4075
    time_step_mean: 3526.277456647399
    time_step_min: 3214
  date: 2020-10-10_18-19-33
  done: false
  episode_len_mean: 843.336637438048
  episode_reward_max: 282.8383838383838
  episode_reward_mean: 232.1591939216795
  episode_reward_min: 134.80808080808083
  episodes_this_iter: 253
  episodes_total: 2623
  experiment_id: 63302949403f45dcbae4f5e4d98fd778
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 0.9739615874631065
        entropy_coeff: 0.0
        kl: 0.005443380580150655
        model: {}
        policy_loss: -0.015015187299078596
        total_loss: 14.596694878169469
        vf_explained_var: 0.9811634421348572
        vf_loss: 14.611438138144356
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.95609756097561
    gpu_util_percent0: 0.3624390243902439
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.482926829268291
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 10952
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15539441140923965
    mean_env_wait_ms: 1.1993025401628505
    mean_inference_ms: 4.746800032793992
    mean_raw_obs_processing_ms: 0.41234995976077016
  time_since_restore: 494.38751339912415
  time_this_iter_s: 34.979939699172974
  time_total_s: 494.38751339912415
  timers:
    learn_throughput: 5834.175
    learn_time_ms: 27731.768
    sample_throughput: 22201.212
    sample_time_ms: 7287.53
    update_time_ms: 38.803
  timestamp: 1602353973
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: f9fdd_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f9fdd_00000 | RUNNING  | 172.17.0.4:10952 |     14 |          494.388 | 2265088 |  232.159 |              282.838 |              134.808 |            843.337 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f9fdd_00000:
  custom_metrics:
    time_step_max: 4075
    time_step_mean: 3518.2649147727275
    time_step_min: 3152
  date: 2020-10-10_18-20-09
  done: false
  episode_len_mean: 840.1642053445851
  episode_reward_max: 288.44444444444395
  episode_reward_mean: 233.37795678301995
  episode_reward_min: 134.80808080808083
  episodes_this_iter: 221
  episodes_total: 2844
  experiment_id: 63302949403f45dcbae4f5e4d98fd778
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 0.9696369171142578
        entropy_coeff: 0.0
        kl: 0.005254409142902919
        model: {}
        policy_loss: -0.015570559572162372
        total_loss: 9.858553273337227
        vf_explained_var: 0.9836249351501465
        vf_loss: 9.873861517224993
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.453658536585365
    gpu_util_percent0: 0.3292682926829268
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.490243902439025
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 10952
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.155037304501251
    mean_env_wait_ms: 1.200672385476494
    mean_inference_ms: 4.725112245357354
    mean_raw_obs_processing_ms: 0.41102193975065376
  time_since_restore: 529.6032705307007
  time_this_iter_s: 35.21575713157654
  time_total_s: 529.6032705307007
  timers:
    learn_throughput: 5831.984
    learn_time_ms: 27742.187
    sample_throughput: 22263.014
    sample_time_ms: 7267.3
    update_time_ms: 44.735
  timestamp: 1602354009
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: f9fdd_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f9fdd_00000 | RUNNING  | 172.17.0.4:10952 |     15 |          529.603 | 2426880 |  233.378 |              288.444 |              134.808 |            840.164 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f9fdd_00000:
  custom_metrics:
    time_step_max: 4075
    time_step_mean: 3512.7605917955616
    time_step_min: 3152
  date: 2020-10-10_18-20-44
  done: false
  episode_len_mean: 838.136908727515
  episode_reward_max: 288.44444444444395
  episode_reward_mean: 234.1524572843692
  episode_reward_min: 134.80808080808083
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: 63302949403f45dcbae4f5e4d98fd778
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 0.9662972475801196
        entropy_coeff: 0.0
        kl: 0.005043585984302419
        model: {}
        policy_loss: -0.016768112870132818
        total_loss: 8.99367720740182
        vf_explained_var: 0.9831265807151794
        vf_loss: 9.010193075452532
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.834146341463413
    gpu_util_percent0: 0.29585365853658535
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497560975609756
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 10952
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15480727147874515
    mean_env_wait_ms: 1.2016317916309556
    mean_inference_ms: 4.711099150476548
    mean_raw_obs_processing_ms: 0.41016906543384646
  time_since_restore: 564.7828395366669
  time_this_iter_s: 35.17956900596619
  time_total_s: 564.7828395366669
  timers:
    learn_throughput: 5824.436
    learn_time_ms: 27778.14
    sample_throughput: 22332.159
    sample_time_ms: 7244.799
    update_time_ms: 45.104
  timestamp: 1602354044
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: f9fdd_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f9fdd_00000 | RUNNING  | 172.17.0.4:10952 |     16 |          564.783 | 2588672 |  234.152 |              288.444 |              134.808 |            838.137 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f9fdd_00000:
  custom_metrics:
    time_step_max: 4075
    time_step_mean: 3506.606311762831
    time_step_min: 3152
  date: 2020-10-10_18-21-19
  done: true
  episode_len_mean: 836.1706161137441
  episode_reward_max: 288.44444444444395
  episode_reward_mean: 235.00416487146333
  episode_reward_min: 134.80808080808083
  episodes_this_iter: 163
  episodes_total: 3165
  experiment_id: 63302949403f45dcbae4f5e4d98fd778
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 0.9363962624754224
        entropy_coeff: 0.0
        kl: 0.005416209742959056
        model: {}
        policy_loss: -0.017514817084052732
        total_loss: 8.179870775767736
        vf_explained_var: 0.9857000112533569
        vf_loss: 8.19711514881679
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.214634146341464
    gpu_util_percent0: 0.29121951219512193
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.490243902439025
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 10952
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1545912142601141
    mean_env_wait_ms: 1.2026239295601548
    mean_inference_ms: 4.69774635687468
    mean_raw_obs_processing_ms: 0.4093459539421462
  time_since_restore: 600.0913429260254
  time_this_iter_s: 35.30850338935852
  time_total_s: 600.0913429260254
  timers:
    learn_throughput: 5823.864
    learn_time_ms: 27780.869
    sample_throughput: 22394.25
    sample_time_ms: 7224.712
    update_time_ms: 42.963
  timestamp: 1602354079
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: f9fdd_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f9fdd_00000 | TERMINATED |       |     17 |          600.091 | 2750464 |  235.004 |              288.444 |              134.808 |            836.171 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f9fdd_00000 | TERMINATED |       |     17 |          600.091 | 2750464 |  235.004 |              288.444 |              134.808 |            836.171 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


