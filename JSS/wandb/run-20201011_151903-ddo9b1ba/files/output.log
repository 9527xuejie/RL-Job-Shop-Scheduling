2020-10-11 15:19:07,625	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_1be98_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=65857)[0m 2020-10-11 15:19:10,369	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=65898)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65898)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65844)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65844)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65891)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65891)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65887)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65887)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65821)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65821)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65864)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65864)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65869)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65869)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65896)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65896)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65894)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65894)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65826)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65826)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65885)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65885)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65872)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65872)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65837)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65837)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65867)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65867)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65882)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65882)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65877)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65877)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65828)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65828)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65893)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65893)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65840)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65840)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65878)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65878)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65760)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65760)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65900)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65900)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65879)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65879)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65832)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65832)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65889)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65889)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65883)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65883)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65856)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65856)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65771)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65771)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65836)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65836)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65830)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65830)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65838)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65838)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65758)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65758)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65769)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65769)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65831)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65831)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65765)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65765)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65774)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65774)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65798)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65798)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65829)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65829)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65854)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65854)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65773)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65773)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65772)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65772)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65763)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65763)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65775)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65775)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65842)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65842)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65859)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65859)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65797)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65797)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65761)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65761)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65770)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65770)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65841)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65841)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65847)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65847)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65834)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65834)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65824)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65824)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65781)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65781)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65833)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65833)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65757)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65757)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65835)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65835)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65793)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65793)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65788)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65788)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65764)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65764)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65767)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65767)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65759)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65759)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65843)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65843)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65792)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65792)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65768)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65768)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65779)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65779)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65776)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65776)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65762)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65762)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65795)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65795)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65863)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65863)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65778)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65778)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65851)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65851)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65855)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65855)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65839)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65839)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65823)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65823)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65800)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65800)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65783)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65783)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65825)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65825)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65827)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65827)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65822)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65822)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_1be98_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_15-19-46
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 90bce87df92943afaf0f4551ae7003ad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.1843508349524603
        entropy_coeff: 0.0001
        kl: 0.004721578572773271
        model: {}
        policy_loss: -0.00988805560498602
        total_loss: 509.25912136501734
        vf_explained_var: 0.5215201377868652
        vf_loss: 509.2681816948785
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.719444444444445
    gpu_util_percent0: 0.34666666666666673
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5888888888888895
    vram_util_percent0: 0.09758208520097665
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65857
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16456120541965052
    mean_env_wait_ms: 1.1688175419297766
    mean_inference_ms: 5.193630932804685
    mean_raw_obs_processing_ms: 0.42884296383081894
  time_since_restore: 30.783287525177002
  time_this_iter_s: 30.783287525177002
  time_total_s: 30.783287525177002
  timers:
    learn_throughput: 7254.476
    learn_time_ms: 22302.369
    sample_throughput: 19224.824
    sample_time_ms: 8415.786
    update_time_ms: 33.256
  timestamp: 1602429586
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 1be98_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |      1 |          30.7833 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1be98_00000:
  custom_metrics:
    time_step_max: 4187
    time_step_mean: 3618.434027777778
    time_step_min: 3345
  date: 2020-10-11_15-20-16
  done: false
  episode_len_mean: 889.7056962025316
  episode_reward_max: 259.20202020201975
  episode_reward_mean: 217.59145249968014
  episode_reward_min: 131.62626262626236
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 90bce87df92943afaf0f4551ae7003ad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.1520691580242581
        entropy_coeff: 0.0001
        kl: 0.008920241250760026
        model: {}
        policy_loss: -0.011849463710354434
        total_loss: 136.11983066134982
        vf_explained_var: 0.7991345524787903
        vf_loss: 136.13090345594617
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.855882352941176
    gpu_util_percent0: 0.3320588235294118
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.761764705882353
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65857
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16161816766198941
    mean_env_wait_ms: 1.169883329663526
    mean_inference_ms: 5.108560094604808
    mean_raw_obs_processing_ms: 0.4238600081063736
  time_since_restore: 60.439977407455444
  time_this_iter_s: 29.656689882278442
  time_total_s: 60.439977407455444
  timers:
    learn_throughput: 7328.983
    learn_time_ms: 22075.642
    sample_throughput: 20049.63
    sample_time_ms: 8069.575
    update_time_ms: 35.988
  timestamp: 1602429616
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 1be98_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |      2 |            60.44 | 323584 |  217.591 |              259.202 |              131.626 |            889.706 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1be98_00000:
  custom_metrics:
    time_step_max: 4219
    time_step_mean: 3615.634529147982
    time_step_min: 3345
  date: 2020-10-11_15-20-45
  done: false
  episode_len_mean: 887.3122362869199
  episode_reward_max: 266.929292929293
  episode_reward_mean: 217.47238204833118
  episode_reward_min: 126.77777777777789
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 90bce87df92943afaf0f4551ae7003ad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.1390231847763062
        entropy_coeff: 0.0001
        kl: 0.009641255355543561
        model: {}
        policy_loss: -0.013636472686711285
        total_loss: 66.86244625515408
        vf_explained_var: 0.8877179026603699
        vf_loss: 66.87523227267795
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.97941176470588
    gpu_util_percent0: 0.3370588235294118
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7764705882352945
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65857
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1595873958810886
    mean_env_wait_ms: 1.1713297641295495
    mean_inference_ms: 5.010924163714069
    mean_raw_obs_processing_ms: 0.41869709445317627
  time_since_restore: 89.61038947105408
  time_this_iter_s: 29.170412063598633
  time_total_s: 89.61038947105408
  timers:
    learn_throughput: 7366.34
    learn_time_ms: 21963.689
    sample_throughput: 20670.18
    sample_time_ms: 7827.314
    update_time_ms: 36.589
  timestamp: 1602429645
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 1be98_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |      3 |          89.6104 | 485376 |  217.472 |              266.929 |              126.778 |            887.312 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1be98_00000:
  custom_metrics:
    time_step_max: 4219
    time_step_mean: 3610.9387417218545
    time_step_min: 3280
  date: 2020-10-11_15-21-14
  done: false
  episode_len_mean: 882.4398734177215
  episode_reward_max: 269.050505050505
  episode_reward_mean: 218.5214007160208
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 90bce87df92943afaf0f4551ae7003ad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.1255579259660509
        entropy_coeff: 0.0001
        kl: 0.00822751068820556
        model: {}
        policy_loss: -0.014474232939796315
        total_loss: 55.75923114352756
        vf_explained_var: 0.9051828384399414
        vf_loss: 55.77299499511719
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.644117647058824
    gpu_util_percent0: 0.3864705882352942
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7764705882352945
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65857
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1581072968672028
    mean_env_wait_ms: 1.173243947815016
    mean_inference_ms: 4.933548653646772
    mean_raw_obs_processing_ms: 0.41465706793439805
  time_since_restore: 118.89508557319641
  time_this_iter_s: 29.284696102142334
  time_total_s: 118.89508557319641
  timers:
    learn_throughput: 7359.442
    learn_time_ms: 21984.274
    sample_throughput: 21123.54
    sample_time_ms: 7659.322
    update_time_ms: 36.04
  timestamp: 1602429674
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 1be98_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |      4 |          118.895 | 647168 |  218.521 |              269.051 |              119.202 |             882.44 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1be98_00000:
  custom_metrics:
    time_step_max: 4219
    time_step_mean: 3602.5643044619424
    time_step_min: 3235
  date: 2020-10-11_15-21-44
  done: false
  episode_len_mean: 876.9202531645569
  episode_reward_max: 275.8686868686872
  episode_reward_mean: 219.68801943485468
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 90bce87df92943afaf0f4551ae7003ad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0947299003601074
        entropy_coeff: 0.0001
        kl: 0.008854356697864003
        model: {}
        policy_loss: -0.01442181184473965
        total_loss: 41.541700998942055
        vf_explained_var: 0.932768702507019
        vf_loss: 41.5553470187717
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.435294117647057
    gpu_util_percent0: 0.3161764705882353
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7735294117647062
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65857
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15701984706993521
    mean_env_wait_ms: 1.175463461146301
    mean_inference_ms: 4.87283679887187
    mean_raw_obs_processing_ms: 0.41124197946070606
  time_since_restore: 148.34783554077148
  time_this_iter_s: 29.452749967575073
  time_total_s: 148.34783554077148
  timers:
    learn_throughput: 7353.467
    learn_time_ms: 22002.139
    sample_throughput: 21362.296
    sample_time_ms: 7573.718
    update_time_ms: 35.704
  timestamp: 1602429704
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 1be98_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |      5 |          148.348 | 808960 |  219.688 |              275.869 |              119.202 |             876.92 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1be98_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3587.8841121495325
    time_step_min: 3235
  date: 2020-10-11_15-22-13
  done: false
  episode_len_mean: 867.9408014571949
  episode_reward_max: 275.8686868686872
  episode_reward_mean: 221.79695865761423
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 308
  episodes_total: 1098
  experiment_id: 90bce87df92943afaf0f4551ae7003ad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0886027548048232
        entropy_coeff: 0.0001
        kl: 0.007741722743958235
        model: {}
        policy_loss: -0.012663001556777291
        total_loss: 46.83814027574327
        vf_explained_var: 0.9481419324874878
        vf_loss: 46.85013749864366
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.66470588235294
    gpu_util_percent0: 0.33617647058823535
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.761764705882353
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65857
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15550204764237266
    mean_env_wait_ms: 1.1802493365620226
    mean_inference_ms: 4.790761944738492
    mean_raw_obs_processing_ms: 0.40703604829577444
  time_since_restore: 177.72296500205994
  time_this_iter_s: 29.375129461288452
  time_total_s: 177.72296500205994
  timers:
    learn_throughput: 7353.221
    learn_time_ms: 22002.876
    sample_throughput: 21535.233
    sample_time_ms: 7512.898
    update_time_ms: 35.895
  timestamp: 1602429733
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 1be98_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |      6 |          177.723 | 970752 |  221.797 |              275.869 |              119.202 |            867.941 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1be98_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3581.128640776699
    time_step_min: 3233
  date: 2020-10-11_15-22-43
  done: false
  episode_len_mean: 863.0419303797469
  episode_reward_max: 278.44444444444446
  episode_reward_mean: 223.4365330520392
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 166
  episodes_total: 1264
  experiment_id: 90bce87df92943afaf0f4551ae7003ad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0738010009129841
        entropy_coeff: 0.0001
        kl: 0.00765216676518321
        model: {}
        policy_loss: -0.013023157115336895
        total_loss: 22.13796827528212
        vf_explained_var: 0.9615828394889832
        vf_loss: 22.150333616468643
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.26969696969697
    gpu_util_percent0: 0.3409090909090909
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.781818181818182
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65857
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1549404218308153
    mean_env_wait_ms: 1.182370029417135
    mean_inference_ms: 4.75812694195196
    mean_raw_obs_processing_ms: 0.4053290215921129
  time_since_restore: 206.7824604511261
  time_this_iter_s: 29.059495449066162
  time_total_s: 206.7824604511261
  timers:
    learn_throughput: 7359.145
    learn_time_ms: 21985.163
    sample_throughput: 21709.437
    sample_time_ms: 7452.611
    update_time_ms: 36.345
  timestamp: 1602429763
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 1be98_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |      7 |          206.782 | 1132544 |  223.437 |              278.444 |              119.202 |            863.042 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1be98_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3572.0466284074605
    time_step_min: 3233
  date: 2020-10-11_15-23-12
  done: false
  episode_len_mean: 859.0126582278481
  episode_reward_max: 278.44444444444446
  episode_reward_mean: 224.67052380343503
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 90bce87df92943afaf0f4551ae7003ad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0556381013658311
        entropy_coeff: 0.0001
        kl: 0.00822339134497775
        model: {}
        policy_loss: -0.014104325013856093
        total_loss: 21.331751505533855
        vf_explained_var: 0.9627946019172668
        vf_loss: 21.34513897365994
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.385294117647057
    gpu_util_percent0: 0.35529411764705876
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7764705882352945
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65857
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15446333710769417
    mean_env_wait_ms: 1.1841968341830276
    mean_inference_ms: 4.731311657999268
    mean_raw_obs_processing_ms: 0.4039583724826134
  time_since_restore: 236.22041082382202
  time_this_iter_s: 29.437950372695923
  time_total_s: 236.22041082382202
  timers:
    learn_throughput: 7362.57
    learn_time_ms: 21974.935
    sample_throughput: 21711.898
    sample_time_ms: 7451.767
    update_time_ms: 36.734
  timestamp: 1602429792
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 1be98_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |      8 |           236.22 | 1294336 |  224.671 |              278.444 |              119.202 |            859.013 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1be98_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3562.9194587628867
    time_step_min: 3217
  date: 2020-10-11_15-23-41
  done: false
  episode_len_mean: 855.1715189873418
  episode_reward_max: 278.59595959595987
  episode_reward_mean: 225.94051272215813
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 90bce87df92943afaf0f4551ae7003ad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0263097021314833
        entropy_coeff: 0.0001
        kl: 0.008362756990310218
        model: {}
        policy_loss: -0.014461110244155861
        total_loss: 18.91820780436198
        vf_explained_var: 0.9667680263519287
        vf_loss: 18.931934992472332
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.258823529411767
    gpu_util_percent0: 0.3485294117647059
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7735294117647062
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65857
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15404355226013447
    mean_env_wait_ms: 1.1859455812362794
    mean_inference_ms: 4.707736199052138
    mean_raw_obs_processing_ms: 0.4026928459348835
  time_since_restore: 265.2343361377716
  time_this_iter_s: 29.013925313949585
  time_total_s: 265.2343361377716
  timers:
    learn_throughput: 7365.516
    learn_time_ms: 21966.146
    sample_throughput: 21844.175
    sample_time_ms: 7406.643
    update_time_ms: 35.04
  timestamp: 1602429821
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 1be98_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |      9 |          265.234 | 1456128 |  225.941 |              278.596 |              119.202 |            855.172 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1be98_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3549.151024811219
    time_step_min: 3217
  date: 2020-10-11_15-24-10
  done: false
  episode_len_mean: 848.3198724760892
  episode_reward_max: 278.59595959595987
  episode_reward_mean: 228.1208847239664
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 302
  episodes_total: 1882
  experiment_id: 90bce87df92943afaf0f4551ae7003ad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9993236263593038
        entropy_coeff: 0.0001
        kl: 0.007044322685235077
        model: {}
        policy_loss: -0.012485993327572942
        total_loss: 29.24024200439453
        vf_explained_var: 0.9663772583007812
        vf_loss: 29.252121183607315
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.0
    gpu_util_percent0: 0.35000000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770588235294117
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65857
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15336961968425208
    mean_env_wait_ms: 1.189351411446074
    mean_inference_ms: 4.670526206343917
    mean_raw_obs_processing_ms: 0.4008527112604744
  time_since_restore: 294.3171832561493
  time_this_iter_s: 29.082847118377686
  time_total_s: 294.3171832561493
  timers:
    learn_throughput: 7365.132
    learn_time_ms: 21967.291
    sample_throughput: 21962.183
    sample_time_ms: 7366.845
    update_time_ms: 36.172
  timestamp: 1602429850
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 1be98_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |     10 |          294.317 | 1617920 |  228.121 |              278.596 |              119.202 |             848.32 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1be98_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3540.383514313919
    time_step_min: 3194
  date: 2020-10-11_15-24-39
  done: false
  episode_len_mean: 845.0628042843233
  episode_reward_max: 282.0808080808081
  episode_reward_mean: 229.41741661994814
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 172
  episodes_total: 2054
  experiment_id: 90bce87df92943afaf0f4551ae7003ad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9859415888786316
        entropy_coeff: 0.0001
        kl: 0.006805953466229969
        model: {}
        policy_loss: -0.013446049040390385
        total_loss: 17.021724277072483
        vf_explained_var: 0.9711102247238159
        vf_loss: 17.0345884958903
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.384848484848483
    gpu_util_percent0: 0.3778787878787879
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.784848484848485
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65857
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1530649231494302
    mean_env_wait_ms: 1.1910014023910334
    mean_inference_ms: 4.652815302256331
    mean_raw_obs_processing_ms: 0.3999651508223004
  time_since_restore: 323.0978810787201
  time_this_iter_s: 28.7806978225708
  time_total_s: 323.0978810787201
  timers:
    learn_throughput: 7388.022
    learn_time_ms: 21899.23
    sample_throughput: 22369.159
    sample_time_ms: 7232.815
    update_time_ms: 36.15
  timestamp: 1602429879
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 1be98_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |     11 |          323.098 | 1779712 |  229.417 |              282.081 |              119.202 |            845.063 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1be98_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3534.3695054945056
    time_step_min: 3194
  date: 2020-10-11_15-25-08
  done: false
  episode_len_mean: 842.0660036166365
  episode_reward_max: 282.0808080808081
  episode_reward_mean: 230.48243282736942
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 90bce87df92943afaf0f4551ae7003ad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9706595540046692
        entropy_coeff: 0.0001
        kl: 0.006862661490837733
        model: {}
        policy_loss: -0.01380531924466292
        total_loss: 14.500430425008139
        vf_explained_var: 0.9731002449989319
        vf_loss: 14.513646549648708
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.955882352941178
    gpu_util_percent0: 0.3208823529411765
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7823529411764705
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65857
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15280917733305144
    mean_env_wait_ms: 1.1924356879286742
    mean_inference_ms: 4.638104602450027
    mean_raw_obs_processing_ms: 0.3992163874407778
  time_since_restore: 352.18300914764404
  time_this_iter_s: 29.08512806892395
  time_total_s: 352.18300914764404
  timers:
    learn_throughput: 7390.357
    learn_time_ms: 21892.312
    sample_throughput: 22528.85
    sample_time_ms: 7181.547
    update_time_ms: 35.898
  timestamp: 1602429908
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 1be98_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |     12 |          352.183 | 1941504 |  230.482 |              282.081 |              119.202 |            842.066 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1be98_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3527.7171331636982
    time_step_min: 3194
  date: 2020-10-11_15-25-37
  done: false
  episode_len_mean: 839.0037720033529
  episode_reward_max: 282.0808080808081
  episode_reward_mean: 231.58327194831799
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 174
  episodes_total: 2386
  experiment_id: 90bce87df92943afaf0f4551ae7003ad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9348431163363986
        entropy_coeff: 0.0001
        kl: 0.0074637361491719885
        model: {}
        policy_loss: -0.0140232573935969
        total_loss: 14.015959527757433
        vf_explained_var: 0.9776356816291809
        vf_loss: 14.029329829745823
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.527272727272727
    gpu_util_percent0: 0.36090909090909096
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.76969696969697
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65857
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15253892630491492
    mean_env_wait_ms: 1.1940210509052362
    mean_inference_ms: 4.623096785385588
    mean_raw_obs_processing_ms: 0.39841018082699414
  time_since_restore: 381.02371287345886
  time_this_iter_s: 28.84070372581482
  time_total_s: 381.02371287345886
  timers:
    learn_throughput: 7395.168
    learn_time_ms: 21878.068
    sample_throughput: 22586.16
    sample_time_ms: 7163.325
    update_time_ms: 34.045
  timestamp: 1602429937
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 1be98_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |     13 |          381.024 | 2103296 |  231.583 |              282.081 |              119.202 |            839.004 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1be98_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3516.135867519759
    time_step_min: 3193
  date: 2020-10-11_15-26-06
  done: false
  episode_len_mean: 834.3154562383613
  episode_reward_max: 286.17171717171715
  episode_reward_mean: 233.5126685852942
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 299
  episodes_total: 2685
  experiment_id: 90bce87df92943afaf0f4551ae7003ad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9252206219567193
        entropy_coeff: 0.0001
        kl: 0.006078497661898534
        model: {}
        policy_loss: -0.01180143483603994
        total_loss: 17.539153416951496
        vf_explained_var: 0.9762699604034424
        vf_loss: 17.5504396226671
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.326470588235292
    gpu_util_percent0: 0.35058823529411764
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770588235294118
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65857
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1521706762239558
    mean_env_wait_ms: 1.1965162552179502
    mean_inference_ms: 4.601095490431229
    mean_raw_obs_processing_ms: 0.3972797722917041
  time_since_restore: 410.0753722190857
  time_this_iter_s: 29.05165934562683
  time_total_s: 410.0753722190857
  timers:
    learn_throughput: 7399.833
    learn_time_ms: 21864.276
    sample_throughput: 22616.992
    sample_time_ms: 7153.56
    update_time_ms: 33.942
  timestamp: 1602429966
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 1be98_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |     14 |          410.075 | 2265088 |  233.513 |              286.172 |              119.202 |            834.315 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1be98_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3509.3366477272725
    time_step_min: 3183
  date: 2020-10-11_15-26-35
  done: false
  episode_len_mean: 831.9680028129395
  episode_reward_max: 286.17171717171715
  episode_reward_mean: 234.53616332097343
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 159
  episodes_total: 2844
  experiment_id: 90bce87df92943afaf0f4551ae7003ad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9084723525577121
        entropy_coeff: 0.0001
        kl: 0.0066332718253963524
        model: {}
        policy_loss: -0.013506995410554938
        total_loss: 11.586083518134224
        vf_explained_var: 0.9771859645843506
        vf_loss: 11.599017884996202
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.027272727272727
    gpu_util_percent0: 0.39333333333333337
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7818181818181817
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65857
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15199983061906228
    mean_env_wait_ms: 1.1977310835234722
    mean_inference_ms: 4.590799177793186
    mean_raw_obs_processing_ms: 0.3967386029773961
  time_since_restore: 439.0162863731384
  time_this_iter_s: 28.940914154052734
  time_total_s: 439.0162863731384
  timers:
    learn_throughput: 7408.097
    learn_time_ms: 21839.886
    sample_throughput: 22679.859
    sample_time_ms: 7133.73
    update_time_ms: 32.755
  timestamp: 1602429995
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 1be98_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |     15 |          439.016 | 2426880 |  234.536 |              286.172 |              119.202 |            831.968 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1be98_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3502.817417619368
    time_step_min: 3183
  date: 2020-10-11_15-27-05
  done: false
  episode_len_mean: 829.9267155229846
  episode_reward_max: 287.0808080808082
  episode_reward_mean: 235.3969306657514
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: 90bce87df92943afaf0f4551ae7003ad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8938175174925063
        entropy_coeff: 0.0001
        kl: 0.006722591403457854
        model: {}
        policy_loss: -0.014099026991364857
        total_loss: 11.053231239318848
        vf_explained_var: 0.9781302213668823
        vf_loss: 11.06674755944146
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.494117647058818
    gpu_util_percent0: 0.2885294117647059
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7911764705882356
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65857
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15183763086038113
    mean_env_wait_ms: 1.198890494877079
    mean_inference_ms: 4.58125844432332
    mean_raw_obs_processing_ms: 0.3962246267416918
  time_since_restore: 468.0653805732727
  time_this_iter_s: 29.049094200134277
  time_total_s: 468.0653805732727
  timers:
    learn_throughput: 7412.462
    learn_time_ms: 21827.025
    sample_throughput: 22719.248
    sample_time_ms: 7121.362
    update_time_ms: 32.132
  timestamp: 1602430025
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 1be98_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |     16 |          468.065 | 2588672 |  235.397 |              287.081 |              119.202 |            829.927 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1be98_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3492.750997850783
    time_step_min: 3183
  date: 2020-10-11_15-27-34
  done: false
  episode_len_mean: 826.7564687975647
  episode_reward_max: 287.0808080808082
  episode_reward_mean: 236.85245145519113
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 283
  episodes_total: 3285
  experiment_id: 90bce87df92943afaf0f4551ae7003ad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8706453177664015
        entropy_coeff: 0.0001
        kl: 0.006674821436819103
        model: {}
        policy_loss: -0.0120168204108874
        total_loss: 15.801198323567709
        vf_explained_var: 0.9784578680992126
        vf_loss: 15.812634997897678
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.008823529411767
    gpu_util_percent0: 0.34441176470588236
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.764705882352941
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65857
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1515732315284015
    mean_env_wait_ms: 1.2008966098221894
    mean_inference_ms: 4.565916896703251
    mean_raw_obs_processing_ms: 0.39541875143280103
  time_since_restore: 497.09780168533325
  time_this_iter_s: 29.032421112060547
  time_total_s: 497.09780168533325
  timers:
    learn_throughput: 7419.719
    learn_time_ms: 21805.677
    sample_throughput: 22685.067
    sample_time_ms: 7132.093
    update_time_ms: 32.003
  timestamp: 1602430054
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 1be98_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |     17 |          497.098 | 2750464 |  236.852 |              287.081 |              119.202 |            826.756 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1be98_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3486.8764501160094
    time_step_min: 3183
  date: 2020-10-11_15-28-03
  done: false
  episode_len_mean: 824.9016110471807
  episode_reward_max: 287.0808080808082
  episode_reward_mean: 237.82521997884479
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 191
  episodes_total: 3476
  experiment_id: 90bce87df92943afaf0f4551ae7003ad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8568403522173563
        entropy_coeff: 0.0001
        kl: 0.006638096076332861
        model: {}
        policy_loss: -0.012599811336258426
        total_loss: 11.889694531758627
        vf_explained_var: 0.9782626032829285
        vf_loss: 11.901715914408365
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.569696969696967
    gpu_util_percent0: 0.43909090909090903
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7818181818181817
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65857
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1514188696067548
    mean_env_wait_ms: 1.202118269845257
    mean_inference_ms: 4.556750849396632
    mean_raw_obs_processing_ms: 0.39495096638506755
  time_since_restore: 525.8596270084381
  time_this_iter_s: 28.76182532310486
  time_total_s: 525.8596270084381
  timers:
    learn_throughput: 7434.198
    learn_time_ms: 21763.208
    sample_throughput: 22767.002
    sample_time_ms: 7106.425
    update_time_ms: 31.623
  timestamp: 1602430083
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 1be98_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |     18 |           525.86 | 2912256 |  237.825 |              287.081 |              119.202 |            824.902 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1be98_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3481.9750415973376
    time_step_min: 3183
  date: 2020-10-11_15-28-32
  done: false
  episode_len_mean: 823.6560264171711
  episode_reward_max: 287.0808080808082
  episode_reward_mean: 238.62281038230398
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: 90bce87df92943afaf0f4551ae7003ad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8560408817397224
        entropy_coeff: 0.0001
        kl: 0.00649417657405138
        model: {}
        policy_loss: -0.014412520097620372
        total_loss: 9.365952597724068
        vf_explained_var: 0.9802858829498291
        vf_loss: 9.379801114400228
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.221212121212123
    gpu_util_percent0: 0.32878787878787885
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.784848484848485
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65857
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15130027023513612
    mean_env_wait_ms: 1.20305092969869
    mean_inference_ms: 4.549724630292726
    mean_raw_obs_processing_ms: 0.39457568970198686
  time_since_restore: 554.8013496398926
  time_this_iter_s: 28.941722631454468
  time_total_s: 554.8013496398926
  timers:
    learn_throughput: 7439.245
    learn_time_ms: 21748.443
    sample_throughput: 22750.103
    sample_time_ms: 7111.704
    update_time_ms: 33.645
  timestamp: 1602430112
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 1be98_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |     19 |          554.801 | 3074048 |  238.623 |              287.081 |              119.202 |            823.656 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1be98_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3475.8040451799316
    time_step_min: 3157
  date: 2020-10-11_15-29-01
  done: false
  episode_len_mean: 821.9382007822686
  episode_reward_max: 287.6868686868686
  episode_reward_mean: 239.55439663914234
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 201
  episodes_total: 3835
  experiment_id: 90bce87df92943afaf0f4551ae7003ad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8144117461310493
        entropy_coeff: 0.0001
        kl: 0.006672416244530016
        model: {}
        policy_loss: -0.013254672651075654
        total_loss: 11.530830277336968
        vf_explained_var: 0.9809316992759705
        vf_loss: 11.543498675028482
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.841176470588234
    gpu_util_percent0: 0.32264705882352945
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7735294117647062
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65857
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15115897495826155
    mean_env_wait_ms: 1.2042481161848355
    mean_inference_ms: 4.541267252470054
    mean_raw_obs_processing_ms: 0.39412942712694293
  time_since_restore: 583.5348660945892
  time_this_iter_s: 28.733516454696655
  time_total_s: 583.5348660945892
  timers:
    learn_throughput: 7454.506
    learn_time_ms: 21703.919
    sample_throughput: 22722.886
    sample_time_ms: 7120.222
    update_time_ms: 33.668
  timestamp: 1602430141
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 1be98_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |     20 |          583.535 | 3235840 |  239.554 |              287.687 |              119.202 |            821.938 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1be98_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3467.278009316009
    time_step_min: 3157
  date: 2020-10-11_15-29-30
  done: true
  episode_len_mean: 819.8220112003896
  episode_reward_max: 287.6868686868686
  episode_reward_mean: 240.7451357991898
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 272
  episodes_total: 4107
  experiment_id: 90bce87df92943afaf0f4551ae7003ad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8046955797407362
        entropy_coeff: 0.0001
        kl: 0.006084833345893357
        model: {}
        policy_loss: -0.01188867363250918
        total_loss: 10.848699569702148
        vf_explained_var: 0.9828770160675049
        vf_loss: 10.860060373942057
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.684848484848487
    gpu_util_percent0: 0.44393939393939397
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7727272727272734
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65857
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15098582425107557
    mean_env_wait_ms: 1.2057127682094804
    mean_inference_ms: 4.531110743744905
    mean_raw_obs_processing_ms: 0.39359864507090275
  time_since_restore: 612.7916913032532
  time_this_iter_s: 29.25682520866394
  time_total_s: 612.7916913032532
  timers:
    learn_throughput: 7442.898
    learn_time_ms: 21737.768
    sample_throughput: 22678.856
    sample_time_ms: 7134.046
    update_time_ms: 32.66
  timestamp: 1602430170
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 1be98_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1be98_00000 | TERMINATED |       |     21 |          612.792 | 3397632 |  240.745 |              287.687 |              119.202 |            819.822 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1be98_00000 | TERMINATED |       |     21 |          612.792 | 3397632 |  240.745 |              287.687 |              119.202 |            819.822 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


