2020-10-11 19:36:38,577	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_156b1_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=79845)[0m 2020-10-11 19:36:41,391	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=79789)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79789)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79784)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79784)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79796)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79796)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79778)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79778)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79711)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79711)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79824)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79824)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79808)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79808)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79720)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79720)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79746)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79746)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79785)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79785)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79795)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79795)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79801)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79801)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79823)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79823)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79783)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79783)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79807)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79807)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79834)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79834)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79810)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79810)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79723)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79723)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79762)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79762)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79794)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79794)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79741)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79741)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79800)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79800)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79729)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79729)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79769)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79769)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79804)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79804)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79819)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79819)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79799)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79799)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79771)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79771)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79809)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79809)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79765)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79765)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79714)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79714)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79721)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79721)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79787)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79787)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79731)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79731)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79726)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79726)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79710)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79710)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79790)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79790)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79716)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79716)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79793)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79793)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79749)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79749)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79713)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79713)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79828)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79828)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79814)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79814)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79719)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79719)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79815)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79815)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79728)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79728)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79791)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79791)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79743)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79743)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79712)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79712)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79727)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79727)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79725)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79725)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79803)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79803)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79768)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79768)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79788)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79788)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79821)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79821)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79825)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79825)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79735)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79735)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79817)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79817)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79781)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79781)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79792)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79792)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79732)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79732)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79718)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79718)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79722)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79722)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79740)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79740)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79831)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79831)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79776)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79776)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79775)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79775)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79715)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79715)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79837)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79837)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79841)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79841)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79806)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79806)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79822)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79822)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79738)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79738)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79813)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79813)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79737)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79737)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79766)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79766)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79747)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79747)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79730)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79730)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79797)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79797)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_156b1_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_19-37-17
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: e0f6bd451c9440e09b5993f48de46dcf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1845979293187459
        entropy_coeff: 0.0001
        kl: 0.004941714345477521
        model: {}
        policy_loss: -0.010662895229567463
        total_loss: 502.23693593343097
        vf_explained_var: 0.5664147734642029
        vf_loss: 502.24672444661456
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.957894736842107
    gpu_util_percent0: 0.34078947368421053
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.573684210526315
    vram_util_percent0: 0.08813933817817753
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79845
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17112946282127972
    mean_env_wait_ms: 1.180837718967156
    mean_inference_ms: 5.777800560880863
    mean_raw_obs_processing_ms: 0.4571735450388952
  time_since_restore: 31.225910663604736
  time_this_iter_s: 31.225910663604736
  time_total_s: 31.225910663604736
  timers:
    learn_throughput: 7317.72
    learn_time_ms: 22109.619
    sample_throughput: 17864.242
    sample_time_ms: 9056.752
    update_time_ms: 32.06
  timestamp: 1602445037
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 156b1_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_156b1_00000 | RUNNING  | 172.17.0.4:79845 |      1 |          31.2259 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_156b1_00000:
  custom_metrics:
    time_step_max: 4055
    time_step_mean: 3620.9201388888887
    time_step_min: 3341
  date: 2020-10-11_19-37-47
  done: false
  episode_len_mean: 890.6012658227849
  episode_reward_max: 262.6868686868683
  episode_reward_mean: 215.81786216596322
  episode_reward_min: 116.4747474747471
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: e0f6bd451c9440e09b5993f48de46dcf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1522138218084972
        entropy_coeff: 0.0001
        kl: 0.007931098264331618
        model: {}
        policy_loss: -0.011280511661122242
        total_loss: 126.10309092203777
        vf_explained_var: 0.8166090846061707
        vf_loss: 126.1136926015218
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.8
    gpu_util_percent0: 0.35944444444444446
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7583333333333337
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79845
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1666418633942105
    mean_env_wait_ms: 1.1750984804344782
    mean_inference_ms: 5.575272322833489
    mean_raw_obs_processing_ms: 0.44654908510852326
  time_since_restore: 60.78584599494934
  time_this_iter_s: 29.559935331344604
  time_total_s: 60.78584599494934
  timers:
    learn_throughput: 7376.703
    learn_time_ms: 21932.834
    sample_throughput: 19270.789
    sample_time_ms: 8395.712
    update_time_ms: 27.58
  timestamp: 1602445067
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 156b1_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_156b1_00000 | RUNNING  | 172.17.0.4:79845 |      2 |          60.7858 | 323584 |  215.818 |              262.687 |              116.475 |            890.601 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_156b1_00000:
  custom_metrics:
    time_step_max: 4055
    time_step_mean: 3616.4058295964123
    time_step_min: 3341
  date: 2020-10-11_19-38-16
  done: false
  episode_len_mean: 884.4451476793249
  episode_reward_max: 262.6868686868683
  episode_reward_mean: 218.03752717043835
  episode_reward_min: 116.4747474747471
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: e0f6bd451c9440e09b5993f48de46dcf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1405681769053142
        entropy_coeff: 0.0001
        kl: 0.009609605185687542
        model: {}
        policy_loss: -0.0148115831737717
        total_loss: 52.60168711344401
        vf_explained_var: 0.9039597511291504
        vf_loss: 52.61565113067627
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.30857142857143
    gpu_util_percent0: 0.34771428571428575
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774285714285715
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79845
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16347069553853588
    mean_env_wait_ms: 1.1731561417701426
    mean_inference_ms: 5.393182006465403
    mean_raw_obs_processing_ms: 0.43743616831822785
  time_since_restore: 89.87308716773987
  time_this_iter_s: 29.087241172790527
  time_total_s: 89.87308716773987
  timers:
    learn_throughput: 7378.439
    learn_time_ms: 21927.674
    sample_throughput: 20319.348
    sample_time_ms: 7962.46
    update_time_ms: 24.945
  timestamp: 1602445096
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 156b1_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_156b1_00000 | RUNNING  | 172.17.0.4:79845 |      3 |          89.8731 | 485376 |  218.038 |              262.687 |              116.475 |            884.445 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_156b1_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3615.4139072847684
    time_step_min: 3304
  date: 2020-10-11_19-38-45
  done: false
  episode_len_mean: 879.493670886076
  episode_reward_max: 265.41414141414066
  episode_reward_mean: 217.98894003324364
  episode_reward_min: 110.4141414141415
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: e0f6bd451c9440e09b5993f48de46dcf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1268143057823181
        entropy_coeff: 0.0001
        kl: 0.008136198157444596
        model: {}
        policy_loss: -0.01660729798216683
        total_loss: 42.11880366007487
        vf_explained_var: 0.9290847182273865
        vf_loss: 42.13470904032389
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.433333333333334
    gpu_util_percent0: 0.3655555555555556
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7777777777777786
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79845
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1611862384038592
    mean_env_wait_ms: 1.1727058242343016
    mean_inference_ms: 5.255811841113437
    mean_raw_obs_processing_ms: 0.4302781620899413
  time_since_restore: 119.05854439735413
  time_this_iter_s: 29.185457229614258
  time_total_s: 119.05854439735413
  timers:
    learn_throughput: 7369.391
    learn_time_ms: 21954.597
    sample_throughput: 20898.889
    sample_time_ms: 7741.656
    update_time_ms: 23.899
  timestamp: 1602445125
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 156b1_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_156b1_00000 | RUNNING  | 172.17.0.4:79845 |      4 |          119.059 | 647168 |  217.989 |              265.414 |              110.414 |            879.494 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_156b1_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3611.709973753281
    time_step_min: 3304
  date: 2020-10-11_19-39-14
  done: false
  episode_len_mean: 874.4481012658227
  episode_reward_max: 274.0505050505043
  episode_reward_mean: 218.87674210459
  episode_reward_min: 110.4141414141415
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: e0f6bd451c9440e09b5993f48de46dcf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0861701965332031
        entropy_coeff: 0.0001
        kl: 0.007670978588672976
        model: {}
        policy_loss: -0.013802881830542901
        total_loss: 30.548245588938396
        vf_explained_var: 0.9537122845649719
        vf_loss: 30.561390558878582
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.002857142857142
    gpu_util_percent0: 0.4000000000000001
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7714285714285722
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79845
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15949683103906714
    mean_env_wait_ms: 1.1734249298913242
    mean_inference_ms: 5.150619753583412
    mean_raw_obs_processing_ms: 0.42462725095159193
  time_since_restore: 147.94688510894775
  time_this_iter_s: 28.888340711593628
  time_total_s: 147.94688510894775
  timers:
    learn_throughput: 7382.322
    learn_time_ms: 21916.138
    sample_throughput: 21277.64
    sample_time_ms: 7603.851
    update_time_ms: 23.467
  timestamp: 1602445154
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 156b1_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_156b1_00000 | RUNNING  | 172.17.0.4:79845 |      5 |          147.947 | 808960 |  218.877 |              274.051 |              110.414 |            874.448 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_156b1_00000:
  custom_metrics:
    time_step_max: 4336
    time_step_mean: 3603.586592178771
    time_step_min: 3234
  date: 2020-10-11_19-39-44
  done: false
  episode_len_mean: 865.5980036297641
  episode_reward_max: 276.0202020202017
  episode_reward_mean: 220.3214724376247
  episode_reward_min: 109.05050505050495
  episodes_this_iter: 312
  episodes_total: 1102
  experiment_id: e0f6bd451c9440e09b5993f48de46dcf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0862921973069508
        entropy_coeff: 0.0001
        kl: 0.007875574054196477
        model: {}
        policy_loss: -0.013222926047092187
        total_loss: 36.798745473225914
        vf_explained_var: 0.9591273665428162
        vf_loss: 36.811290423075356
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.928571428571427
    gpu_util_percent0: 0.4
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765714285714286
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79845
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1572569782240398
    mean_env_wait_ms: 1.1762528877599951
    mean_inference_ms: 5.010028623816002
    mean_raw_obs_processing_ms: 0.41738531786231264
  time_since_restore: 177.17254996299744
  time_this_iter_s: 29.225664854049683
  time_total_s: 177.17254996299744
  timers:
    learn_throughput: 7374.821
    learn_time_ms: 21938.43
    sample_throughput: 21515.375
    sample_time_ms: 7519.832
    update_time_ms: 23.502
  timestamp: 1602445184
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 156b1_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_156b1_00000 | RUNNING  | 172.17.0.4:79845 |      6 |          177.173 | 970752 |  220.321 |               276.02 |              109.051 |            865.598 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_156b1_00000:
  custom_metrics:
    time_step_max: 4336
    time_step_mean: 3596.4053398058254
    time_step_min: 3234
  date: 2020-10-11_19-40-13
  done: false
  episode_len_mean: 861.0213607594936
  episode_reward_max: 276.0202020202017
  episode_reward_mean: 221.51969856795785
  episode_reward_min: 109.05050505050495
  episodes_this_iter: 162
  episodes_total: 1264
  experiment_id: e0f6bd451c9440e09b5993f48de46dcf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0740437110265095
        entropy_coeff: 0.0001
        kl: 0.008695898888011774
        model: {}
        policy_loss: -0.015221895941067487
        total_loss: 17.440695921579998
        vf_explained_var: 0.9710730910301208
        vf_loss: 17.45515553156535
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.66388888888889
    gpu_util_percent0: 0.35805555555555557
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7861111111111123
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79845
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1564223548164673
    mean_env_wait_ms: 1.1775301781648821
    mean_inference_ms: 4.9563478394003075
    mean_raw_obs_processing_ms: 0.4146384798682442
  time_since_restore: 206.2938003540039
  time_this_iter_s: 29.12125039100647
  time_total_s: 206.2938003540039
  timers:
    learn_throughput: 7366.812
    learn_time_ms: 21962.281
    sample_throughput: 21754.933
    sample_time_ms: 7437.026
    update_time_ms: 23.101
  timestamp: 1602445213
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 156b1_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_156b1_00000 | RUNNING  | 172.17.0.4:79845 |      7 |          206.294 | 1132544 |   221.52 |               276.02 |              109.051 |            861.021 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_156b1_00000:
  custom_metrics:
    time_step_max: 4336
    time_step_mean: 3589.5918220946915
    time_step_min: 3234
  date: 2020-10-11_19-40-42
  done: false
  episode_len_mean: 856.4817158931083
  episode_reward_max: 276.0202020202017
  episode_reward_mean: 222.6242168520648
  episode_reward_min: 109.05050505050495
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: e0f6bd451c9440e09b5993f48de46dcf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0498243769009907
        entropy_coeff: 0.0001
        kl: 0.007762666131990652
        model: {}
        policy_loss: -0.01506129972403869
        total_loss: 18.5674090385437
        vf_explained_var: 0.9686254858970642
        vf_loss: 18.581799030303955
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.165714285714284
    gpu_util_percent0: 0.3891428571428572
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774285714285715
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79845
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15572720760568318
    mean_env_wait_ms: 1.17873537919373
    mean_inference_ms: 4.911473627342662
    mean_raw_obs_processing_ms: 0.4122361402666125
  time_since_restore: 235.56526851654053
  time_this_iter_s: 29.27146816253662
  time_total_s: 235.56526851654053
  timers:
    learn_throughput: 7359.98
    learn_time_ms: 21982.67
    sample_throughput: 21894.123
    sample_time_ms: 7389.746
    update_time_ms: 24.943
  timestamp: 1602445242
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 156b1_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_156b1_00000 | RUNNING  | 172.17.0.4:79845 |      8 |          235.565 | 1294336 |  222.624 |               276.02 |              109.051 |            856.482 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_156b1_00000:
  custom_metrics:
    time_step_max: 4336
    time_step_mean: 3583.8647778493237
    time_step_min: 3234
  date: 2020-10-11_19-41-11
  done: false
  episode_len_mean: 852.1638203668564
  episode_reward_max: 276.0202020202017
  episode_reward_mean: 223.5045329959939
  episode_reward_min: 109.05050505050495
  episodes_this_iter: 159
  episodes_total: 1581
  experiment_id: e0f6bd451c9440e09b5993f48de46dcf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0068772335847218
        entropy_coeff: 0.0001
        kl: 0.009047625819221139
        model: {}
        policy_loss: -0.015237496777748069
        total_loss: 19.367111682891846
        vf_explained_var: 0.9707355499267578
        vf_loss: 19.381545066833496
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.18333333333333
    gpu_util_percent0: 0.3988888888888889
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333337
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79845
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1551244878856522
    mean_env_wait_ms: 1.180055260680638
    mean_inference_ms: 4.872070194086405
    mean_raw_obs_processing_ms: 0.4100494320160732
  time_since_restore: 264.6823332309723
  time_this_iter_s: 29.117064714431763
  time_total_s: 264.6823332309723
  timers:
    learn_throughput: 7359.969
    learn_time_ms: 21982.702
    sample_throughput: 22010.252
    sample_time_ms: 7350.756
    update_time_ms: 26.458
  timestamp: 1602445271
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 156b1_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_156b1_00000 | RUNNING  | 172.17.0.4:79845 |      9 |          264.682 | 1456128 |  223.505 |               276.02 |              109.051 |            852.164 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_156b1_00000:
  custom_metrics:
    time_step_max: 4336
    time_step_mean: 3569.9983905579397
    time_step_min: 3234
  date: 2020-10-11_19-41-41
  done: false
  episode_len_mean: 844.4392177589853
  episode_reward_max: 276.92929292929244
  episode_reward_mean: 225.801978559378
  episode_reward_min: 109.05050505050495
  episodes_this_iter: 311
  episodes_total: 1892
  experiment_id: e0f6bd451c9440e09b5993f48de46dcf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9910648465156555
        entropy_coeff: 0.0001
        kl: 0.007140809126819174
        model: {}
        policy_loss: -0.012344766136569282
        total_loss: 26.632726192474365
        vf_explained_var: 0.9699724316596985
        vf_loss: 26.64445622762044
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.671428571428574
    gpu_util_percent0: 0.38571428571428573
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774285714285715
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79845
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15415469393620823
    mean_env_wait_ms: 1.182946350896942
    mean_inference_ms: 4.809218233491555
    mean_raw_obs_processing_ms: 0.40663644597822934
  time_since_restore: 293.8117482662201
  time_this_iter_s: 29.129415035247803
  time_total_s: 293.8117482662201
  timers:
    learn_throughput: 7355.415
    learn_time_ms: 21996.311
    sample_throughput: 22138.997
    sample_time_ms: 7308.01
    update_time_ms: 27.421
  timestamp: 1602445301
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 156b1_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_156b1_00000 | RUNNING  | 172.17.0.4:79845 |     10 |          293.812 | 1617920 |  225.802 |              276.929 |              109.051 |            844.439 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_156b1_00000:
  custom_metrics:
    time_step_max: 4336
    time_step_mean: 3561.7685093780847
    time_step_min: 3234
  date: 2020-10-11_19-42-10
  done: false
  episode_len_mean: 840.8851022395327
  episode_reward_max: 276.929292929293
  episode_reward_mean: 227.08811090456646
  episode_reward_min: 109.05050505050495
  episodes_this_iter: 162
  episodes_total: 2054
  experiment_id: e0f6bd451c9440e09b5993f48de46dcf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9775462100903193
        entropy_coeff: 0.0001
        kl: 0.007571308485542734
        model: {}
        policy_loss: -0.017289329320192337
        total_loss: 13.902438004811605
        vf_explained_var: 0.9763643145561218
        vf_loss: 13.919067939122518
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.41428571428571
    gpu_util_percent0: 0.3937142857142857
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7800000000000002
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79845
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15373504962693438
    mean_env_wait_ms: 1.184196655774678
    mean_inference_ms: 4.782139096269421
    mean_raw_obs_processing_ms: 0.40514747989768085
  time_since_restore: 322.9606418609619
  time_this_iter_s: 29.14889359474182
  time_total_s: 322.9606418609619
  timers:
    learn_throughput: 7357.001
    learn_time_ms: 21991.57
    sample_throughput: 22777.857
    sample_time_ms: 7103.039
    update_time_ms: 26.811
  timestamp: 1602445330
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 156b1_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_156b1_00000 | RUNNING  | 172.17.0.4:79845 |     11 |          322.961 | 1779712 |  227.088 |              276.929 |              109.051 |            840.885 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_156b1_00000:
  custom_metrics:
    time_step_max: 4336
    time_step_mean: 3553.1080586080584
    time_step_min: 3198
  date: 2020-10-11_19-42-39
  done: false
  episode_len_mean: 837.8318264014466
  episode_reward_max: 281.4747474747478
  episode_reward_mean: 228.27409264434567
  episode_reward_min: 109.05050505050495
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: e0f6bd451c9440e09b5993f48de46dcf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9627491434415182
        entropy_coeff: 0.0001
        kl: 0.007169151833901803
        model: {}
        policy_loss: -0.014201596456890305
        total_loss: 13.748513221740723
        vf_explained_var: 0.9749014377593994
        vf_loss: 13.762094418207804
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.771428571428572
    gpu_util_percent0: 0.386
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7800000000000002
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79845
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15337239364365787
    mean_env_wait_ms: 1.1853782338344343
    mean_inference_ms: 4.758558983873189
    mean_raw_obs_processing_ms: 0.40380872295330017
  time_since_restore: 352.25551295280457
  time_this_iter_s: 29.29487109184265
  time_total_s: 352.25551295280457
  timers:
    learn_throughput: 7343.031
    learn_time_ms: 22033.41
    sample_throughput: 23006.437
    sample_time_ms: 7032.467
    update_time_ms: 28.057
  timestamp: 1602445359
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 156b1_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_156b1_00000 | RUNNING  | 172.17.0.4:79845 |     12 |          352.256 | 1941504 |  228.274 |              281.475 |              109.051 |            837.832 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_156b1_00000:
  custom_metrics:
    time_step_max: 4336
    time_step_mean: 3540.2184145334436
    time_step_min: 3159
  date: 2020-10-11_19-43-09
  done: false
  episode_len_mean: 833.4930612244898
  episode_reward_max: 287.383838383838
  episode_reward_mean: 230.2338693052978
  episode_reward_min: 109.05050505050495
  episodes_this_iter: 238
  episodes_total: 2450
  experiment_id: e0f6bd451c9440e09b5993f48de46dcf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9222608854373296
        entropy_coeff: 0.0001
        kl: 0.007358024129644036
        model: {}
        policy_loss: -0.012704586464678869
        total_loss: 16.081321795781452
        vf_explained_var: 0.9782974123954773
        vf_loss: 16.093383073806763
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.185714285714287
    gpu_util_percent0: 0.3851428571428571
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7685714285714287
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79845
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1528984384890432
    mean_env_wait_ms: 1.1872287760316351
    mean_inference_ms: 4.727254625445834
    mean_raw_obs_processing_ms: 0.40198975940501785
  time_since_restore: 381.53641414642334
  time_this_iter_s: 29.280901193618774
  time_total_s: 381.53641414642334
  timers:
    learn_throughput: 7334.141
    learn_time_ms: 22060.114
    sample_throughput: 23033.732
    sample_time_ms: 7024.133
    update_time_ms: 29.188
  timestamp: 1602445389
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 156b1_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_156b1_00000 | RUNNING  | 172.17.0.4:79845 |     13 |          381.536 | 2103296 |  230.234 |              287.384 |              109.051 |            833.493 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_156b1_00000:
  custom_metrics:
    time_step_max: 4336
    time_step_mean: 3529.1568848758466
    time_step_min: 3159
  date: 2020-10-11_19-43-38
  done: false
  episode_len_mean: 829.5833953834698
  episode_reward_max: 287.383838383838
  episode_reward_mean: 231.85658145114576
  episode_reward_min: 109.05050505050495
  episodes_this_iter: 236
  episodes_total: 2686
  experiment_id: e0f6bd451c9440e09b5993f48de46dcf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9192133545875549
        entropy_coeff: 0.0001
        kl: 0.006822101616611083
        model: {}
        policy_loss: -0.016151844184302416
        total_loss: 12.465920289357504
        vf_explained_var: 0.9800860285758972
        vf_loss: 12.481482028961182
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.244444444444447
    gpu_util_percent0: 0.365
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7722222222222235
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79845
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15248981197512812
    mean_env_wait_ms: 1.1889241077993966
    mean_inference_ms: 4.701276015867029
    mean_raw_obs_processing_ms: 0.40054359618742
  time_since_restore: 410.991770029068
  time_this_iter_s: 29.455355882644653
  time_total_s: 410.991770029068
  timers:
    learn_throughput: 7329.947
    learn_time_ms: 22072.739
    sample_throughput: 22991.859
    sample_time_ms: 7036.926
    update_time_ms: 30.141
  timestamp: 1602445418
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 156b1_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_156b1_00000 | RUNNING  | 172.17.0.4:79845 |     14 |          410.992 | 2265088 |  231.857 |              287.384 |              109.051 |            829.583 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_156b1_00000:
  custom_metrics:
    time_step_max: 4336
    time_step_mean: 3521.4108664772725
    time_step_min: 3159
  date: 2020-10-11_19-44-07
  done: false
  episode_len_mean: 827.1944444444445
  episode_reward_max: 287.383838383838
  episode_reward_mean: 233.05580062225619
  episode_reward_min: 109.05050505050495
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: e0f6bd451c9440e09b5993f48de46dcf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9072132706642151
        entropy_coeff: 0.0001
        kl: 0.007571491063572466
        model: {}
        policy_loss: -0.014775883017743277
        total_loss: 10.67902167638143
        vf_explained_var: 0.9788177013397217
        vf_loss: 10.693131049474081
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.64285714285714
    gpu_util_percent0: 0.39085714285714285
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.782857142857143
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79845
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15224701567182328
    mean_env_wait_ms: 1.189940024488819
    mean_inference_ms: 4.685629162781126
    mean_raw_obs_processing_ms: 0.3996326571790262
  time_since_restore: 440.1166570186615
  time_this_iter_s: 29.124886989593506
  time_total_s: 440.1166570186615
  timers:
    learn_throughput: 7321.398
    learn_time_ms: 22098.511
    sample_throughput: 23001.377
    sample_time_ms: 7034.014
    update_time_ms: 30.117
  timestamp: 1602445447
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 156b1_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_156b1_00000 | RUNNING  | 172.17.0.4:79845 |     15 |          440.117 | 2426880 |  233.056 |              287.384 |              109.051 |            827.194 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_156b1_00000:
  custom_metrics:
    time_step_max: 4336
    time_step_mean: 3513.1579826319307
    time_step_min: 3159
  date: 2020-10-11_19-44-37
  done: false
  episode_len_mean: 824.6796823295831
  episode_reward_max: 287.383838383838
  episode_reward_mean: 234.19615412898
  episode_reward_min: 109.05050505050495
  episodes_this_iter: 178
  episodes_total: 3022
  experiment_id: e0f6bd451c9440e09b5993f48de46dcf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8721793442964554
        entropy_coeff: 0.0001
        kl: 0.006953845770719151
        model: {}
        policy_loss: -0.013813901699904818
        total_loss: 13.542894045511881
        vf_explained_var: 0.977494478225708
        vf_loss: 13.55609941482544
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.608571428571427
    gpu_util_percent0: 0.40085714285714286
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.782857142857143
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79845
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.151996422865199
    mean_env_wait_ms: 1.1910773597677973
    mean_inference_ms: 4.669415279370685
    mean_raw_obs_processing_ms: 0.3986518734427781
  time_since_restore: 469.2333128452301
  time_this_iter_s: 29.116655826568604
  time_total_s: 469.2333128452301
  timers:
    learn_throughput: 7320.763
    learn_time_ms: 22100.43
    sample_throughput: 23044.903
    sample_time_ms: 7020.728
    update_time_ms: 30.065
  timestamp: 1602445477
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 156b1_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_156b1_00000 | RUNNING  | 172.17.0.4:79845 |     16 |          469.233 | 2588672 |  234.196 |              287.384 |              109.051 |             824.68 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_156b1_00000:
  custom_metrics:
    time_step_max: 4336
    time_step_mean: 3499.5743387047737
    time_step_min: 3159
  date: 2020-10-11_19-45-06
  done: false
  episode_len_mean: 820.9131745553211
  episode_reward_max: 287.383838383838
  episode_reward_mean: 236.24466552775257
  episode_reward_min: 109.05050505050495
  episodes_this_iter: 295
  episodes_total: 3317
  experiment_id: e0f6bd451c9440e09b5993f48de46dcf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8561922212441763
        entropy_coeff: 0.0001
        kl: 0.006693084452611704
        model: {}
        policy_loss: -0.013814363735339915
        total_loss: 11.206264972686768
        vf_explained_var: 0.9836785793304443
        vf_loss: 11.219495217005411
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.06571428571429
    gpu_util_percent0: 0.3697142857142858
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774285714285715
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79845
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15162425923609904
    mean_env_wait_ms: 1.1929109221422114
    mean_inference_ms: 4.645464550145581
    mean_raw_obs_processing_ms: 0.3972719855984311
  time_since_restore: 498.19723320007324
  time_this_iter_s: 28.96392035484314
  time_total_s: 498.19723320007324
  timers:
    learn_throughput: 7325.343
    learn_time_ms: 22086.609
    sample_throughput: 23054.067
    sample_time_ms: 7017.937
    update_time_ms: 30.127
  timestamp: 1602445506
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 156b1_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_156b1_00000 | RUNNING  | 172.17.0.4:79845 |     17 |          498.197 | 2750464 |  236.245 |              287.384 |              109.051 |            820.913 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_156b1_00000:
  custom_metrics:
    time_step_max: 4336
    time_step_mean: 3494.1809744779584
    time_step_min: 3159
  date: 2020-10-11_19-45-35
  done: false
  episode_len_mean: 819.0002876869966
  episode_reward_max: 287.383838383838
  episode_reward_mean: 237.06808011065772
  episode_reward_min: 109.05050505050495
  episodes_this_iter: 159
  episodes_total: 3476
  experiment_id: e0f6bd451c9440e09b5993f48de46dcf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8518367956082026
        entropy_coeff: 0.0001
        kl: 0.006655753046895067
        model: {}
        policy_loss: -0.012292408112746974
        total_loss: 10.00081737836202
        vf_explained_var: 0.9804852604866028
        vf_loss: 10.012529214223227
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.694285714285716
    gpu_util_percent0: 0.38971428571428574
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7857142857142865
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79845
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1514457767866175
    mean_env_wait_ms: 1.1938197876032333
    mean_inference_ms: 4.633845927625138
    mean_raw_obs_processing_ms: 0.3965915569356676
  time_since_restore: 527.317476272583
  time_this_iter_s: 29.120243072509766
  time_total_s: 527.317476272583
  timers:
    learn_throughput: 7325.32
    learn_time_ms: 22086.681
    sample_throughput: 23101.469
    sample_time_ms: 7003.537
    update_time_ms: 28.02
  timestamp: 1602445535
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 156b1_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_156b1_00000 | RUNNING  | 172.17.0.4:79845 |     18 |          527.317 | 2912256 |  237.068 |              287.384 |              109.051 |                819 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_156b1_00000:
  custom_metrics:
    time_step_max: 4336
    time_step_mean: 3487.922949002217
    time_step_min: 3159
  date: 2020-10-11_19-46-04
  done: false
  episode_len_mean: 817.3264576457645
  episode_reward_max: 288.89898989898944
  episode_reward_mean: 238.01173450678394
  episode_reward_min: 109.05050505050495
  episodes_this_iter: 160
  episodes_total: 3636
  experiment_id: e0f6bd451c9440e09b5993f48de46dcf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8309680372476578
        entropy_coeff: 0.0001
        kl: 0.0074748302189012366
        model: {}
        policy_loss: -0.012168505093238005
        total_loss: 9.40784764289856
        vf_explained_var: 0.9818739295005798
        vf_loss: 9.41935165723165
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.36
    gpu_util_percent0: 0.3828571428571429
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7857142857142856
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79845
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15127986637647745
    mean_env_wait_ms: 1.1946966311161025
    mean_inference_ms: 4.622871029978122
    mean_raw_obs_processing_ms: 0.39592940406212607
  time_since_restore: 556.3180286884308
  time_this_iter_s: 29.00055241584778
  time_total_s: 556.3180286884308
  timers:
    learn_throughput: 7323.547
    learn_time_ms: 22092.026
    sample_throughput: 23157.103
    sample_time_ms: 6986.711
    update_time_ms: 27.246
  timestamp: 1602445564
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 156b1_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_156b1_00000 | RUNNING  | 172.17.0.4:79845 |     19 |          556.318 | 3074048 |  238.012 |              288.899 |              109.051 |            817.326 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_156b1_00000:
  custom_metrics:
    time_step_max: 4336
    time_step_mean: 3477.6596016343206
    time_step_min: 3086
  date: 2020-10-11_19-46-33
  done: false
  episode_len_mean: 814.6970081135903
  episode_reward_max: 298.4444444444441
  episode_reward_mean: 239.52641014608554
  episode_reward_min: 109.05050505050495
  episodes_this_iter: 308
  episodes_total: 3944
  experiment_id: e0f6bd451c9440e09b5993f48de46dcf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8081399450699488
        entropy_coeff: 0.0001
        kl: 0.006784297137831648
        model: {}
        policy_loss: -0.01104643041617237
        total_loss: 11.86494255065918
        vf_explained_var: 0.9839428067207336
        vf_loss: 11.875391324361166
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.33714285714286
    gpu_util_percent0: 0.39285714285714285
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7714285714285722
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79845
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15098561709285446
    mean_env_wait_ms: 1.1963437137879191
    mean_inference_ms: 4.603521483855082
    mean_raw_obs_processing_ms: 0.39479329900994464
  time_since_restore: 585.0241253376007
  time_this_iter_s: 28.706096649169922
  time_total_s: 585.0241253376007
  timers:
    learn_throughput: 7336.263
    learn_time_ms: 22053.735
    sample_throughput: 23169.668
    sample_time_ms: 6982.923
    update_time_ms: 25.97
  timestamp: 1602445593
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 156b1_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_156b1_00000 | RUNNING  | 172.17.0.4:79845 |     20 |          585.024 | 3235840 |  239.526 |              298.444 |              109.051 |            814.697 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_156b1_00000:
  custom_metrics:
    time_step_max: 4336
    time_step_mean: 3472.3325980392156
    time_step_min: 3086
  date: 2020-10-11_19-47-02
  done: true
  episode_len_mean: 813.5421129503408
  episode_reward_max: 298.4444444444441
  episode_reward_mean: 240.3138197948324
  episode_reward_min: 109.05050505050495
  episodes_this_iter: 164
  episodes_total: 4108
  experiment_id: e0f6bd451c9440e09b5993f48de46dcf
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.791996826728185
        entropy_coeff: 0.0001
        kl: 0.007390244165435433
        model: {}
        policy_loss: -0.014146684533140311
        total_loss: 7.371609568595886
        vf_explained_var: 0.985375702381134
        vf_loss: 7.385096549987793
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.70571428571429
    gpu_util_percent0: 0.38057142857142856
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.788571428571429
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79845
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15084264654691645
    mean_env_wait_ms: 1.1971294514925317
    mean_inference_ms: 4.594206784938845
    mean_raw_obs_processing_ms: 0.39425392293906275
  time_since_restore: 614.0480110645294
  time_this_iter_s: 29.02388572692871
  time_total_s: 614.0480110645294
  timers:
    learn_throughput: 7336.538
    learn_time_ms: 22052.91
    sample_throughput: 23210.227
    sample_time_ms: 6970.72
    update_time_ms: 25.175
  timestamp: 1602445622
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 156b1_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_156b1_00000 | TERMINATED |       |     21 |          614.048 | 3397632 |  240.314 |              298.444 |              109.051 |            813.542 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_156b1_00000 | TERMINATED |       |     21 |          614.048 | 3397632 |  240.314 |              298.444 |              109.051 |            813.542 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


