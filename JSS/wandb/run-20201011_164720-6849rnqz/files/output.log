2020-10-11 16:47:24,105	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_70e29_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=46522)[0m 2020-10-11 16:47:26,938	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=46552)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46552)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46515)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46515)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46523)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46523)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46432)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46432)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46565)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46565)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46525)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46525)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46562)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46562)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46542)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46542)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46561)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46561)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46534)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46534)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46517)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46517)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46528)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46528)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46531)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46531)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46519)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46519)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46447)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46447)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46495)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46495)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46555)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46555)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46513)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46513)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46526)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46526)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46563)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46563)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46512)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46512)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46539)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46539)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46530)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46530)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46546)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46546)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46518)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46518)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46545)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46545)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46463)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46463)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46448)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46448)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46450)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46450)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46429)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46429)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46460)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46460)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46566)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46566)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46430)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46430)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46550)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46550)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46553)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46553)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46524)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46524)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46511)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46511)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46578)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46578)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46537)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46537)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46434)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46434)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46541)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46541)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46457)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46457)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46452)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46452)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46503)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46503)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46521)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46521)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46551)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46551)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46451)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46451)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46514)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46514)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46510)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46510)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46461)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46461)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46441)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46441)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46509)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46509)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46493)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46493)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46557)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46557)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46465)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46465)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46501)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46501)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46508)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46508)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46431)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46431)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46506)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46506)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46444)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46444)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46435)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46435)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46491)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46491)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46436)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46436)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46466)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46466)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46449)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46449)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46442)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46442)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46438)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46438)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46446)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46446)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46433)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46433)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46505)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46505)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46494)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46494)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46440)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46440)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46464)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46464)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46507)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46507)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46500)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46500)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46445)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46445)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46453)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46453)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46516)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46516)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46437)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46437)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_70e29_00000:
  custom_metrics: {}
  date: 2020-10-11_16-47-55
  done: false
  episode_len_mean: .nan
  episode_reward_max: .nan
  episode_reward_mean: .nan
  episode_reward_min: .nan
  episodes_this_iter: 0
  episodes_total: 0
  experiment_id: 655be50386114bca8e235891fc50fda8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.19709346975599
        entropy_coeff: 0.00010000000000000002
        kl: 0.006012780392276389
        model: {}
        policy_loss: -0.012594069770005132
        total_loss: 531.4765886579241
        vf_explained_var: -0.1959501951932907
        vf_loss: 531.4880981445312
    num_steps_sampled: 121344
    num_steps_trained: 121344
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.70689655172414
    gpu_util_percent0: 0.3417241379310345
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.458620689655172
    vram_util_percent0: 0.09538175320342454
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46522
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf: {}
  time_since_restore: 23.260881900787354
  time_this_iter_s: 23.260881900787354
  time_total_s: 23.260881900787354
  timers:
    learn_throughput: 7422.3
    learn_time_ms: 16348.572
    sample_throughput: 17702.36
    sample_time_ms: 6854.679
    update_time_ms: 29.688
  timestamp: 1602434875
  timesteps_since_restore: 0
  timesteps_total: 121344
  training_iteration: 1
  trial_id: 70e29_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_70e29_00000 | RUNNING  | 172.17.0.4:46522 |      1 |          23.2609 | 121344 |      nan |                  nan |                  nan |                nan |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_70e29_00000:
  custom_metrics:
    time_step_max: 4112
    time_step_mean: 3628.184
    time_step_min: 3295
  date: 2020-10-11_16-48-18
  done: false
  episode_len_mean: 892.0759493670886
  episode_reward_max: 266.7777777777774
  episode_reward_mean: 216.28679197033605
  episode_reward_min: 142.98989898989888
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 655be50386114bca8e235891fc50fda8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.1605888264519828
        entropy_coeff: 0.00010000000000000002
        kl: 0.005510005168616772
        model: {}
        policy_loss: -0.010740843401955706
        total_loss: 457.9469953264509
        vf_explained_var: 0.5077921152114868
        vf_loss: 457.95674787248885
    num_steps_sampled: 242688
    num_steps_trained: 242688
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.585185185185182
    gpu_util_percent0: 0.36074074074074075
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.566666666666666
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46522
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1610432529758131
    mean_env_wait_ms: 1.145893258420837
    mean_inference_ms: 5.40526001224628
    mean_raw_obs_processing_ms: 0.41846264396614635
  time_since_restore: 45.7019567489624
  time_this_iter_s: 22.44107484817505
  time_total_s: 45.7019567489624
  timers:
    learn_throughput: 7502.325
    learn_time_ms: 16174.187
    sample_throughput: 18369.873
    sample_time_ms: 6605.598
    update_time_ms: 36.363
  timestamp: 1602434898
  timesteps_since_restore: 0
  timesteps_total: 242688
  training_iteration: 2
  trial_id: 70e29_00000
  
== Status ==
Memory usage on this node: 27.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_70e29_00000 | RUNNING  | 172.17.0.4:46522 |      2 |           45.702 | 242688 |  216.287 |              266.778 |               142.99 |            892.076 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_70e29_00000:
  custom_metrics:
    time_step_max: 4151
    time_step_mean: 3613.0989399293285
    time_step_min: 3295
  date: 2020-10-11_16-48-39
  done: false
  episode_len_mean: 885.8417721518987
  episode_reward_max: 266.7777777777774
  episode_reward_mean: 219.05146400715998
  episode_reward_min: 137.08080808080805
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 655be50386114bca8e235891fc50fda8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.1425047261374337
        entropy_coeff: 0.00010000000000000002
        kl: 0.006121054757386446
        model: {}
        policy_loss: -0.010844438403312649
        total_loss: 173.54720851353235
        vf_explained_var: 0.7992362380027771
        vf_loss: 173.55693926130022
    num_steps_sampled: 364032
    num_steps_trained: 364032
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.11851851851852
    gpu_util_percent0: 0.4122222222222223
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.6555555555555563
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46522
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15889453611529636
    mean_env_wait_ms: 1.1513634334926286
    mean_inference_ms: 5.235233694508393
    mean_raw_obs_processing_ms: 0.4132458362945646
  time_since_restore: 67.38917994499207
  time_this_iter_s: 21.687223196029663
  time_total_s: 67.38917994499207
  timers:
    learn_throughput: 7500.076
    learn_time_ms: 16179.037
    sample_throughput: 19548.415
    sample_time_ms: 6207.357
    update_time_ms: 39.449
  timestamp: 1602434919
  timesteps_since_restore: 0
  timesteps_total: 364032
  training_iteration: 3
  trial_id: 70e29_00000
  
== Status ==
Memory usage on this node: 27.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_70e29_00000 | RUNNING  | 172.17.0.4:46522 |      3 |          67.3892 | 364032 |  219.051 |              266.778 |              137.081 |            885.842 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_70e29_00000:
  custom_metrics:
    time_step_max: 4151
    time_step_mean: 3602.736961451247
    time_step_min: 3215
  date: 2020-10-11_16-49-01
  done: false
  episode_len_mean: 879.8206751054852
  episode_reward_max: 278.89898989898967
  episode_reward_mean: 220.72548267484962
  episode_reward_min: 137.08080808080805
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 655be50386114bca8e235891fc50fda8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.125728794506618
        entropy_coeff: 0.00010000000000000002
        kl: 0.00639094106320824
        model: {}
        policy_loss: -0.01306218234822154
        total_loss: 96.90472303118024
        vf_explained_var: 0.8719539642333984
        vf_loss: 96.91662052699498
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.53846153846154
    gpu_util_percent0: 0.45884615384615385
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.6653846153846157
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46522
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15730152576930456
    mean_env_wait_ms: 1.1560406618484977
    mean_inference_ms: 5.11383820242486
    mean_raw_obs_processing_ms: 0.40941305667226624
  time_since_restore: 88.69091987609863
  time_this_iter_s: 21.301739931106567
  time_total_s: 88.69091987609863
  timers:
    learn_throughput: 7510.334
    learn_time_ms: 16156.937
    sample_throughput: 20419.276
    sample_time_ms: 5942.62
    update_time_ms: 35.585
  timestamp: 1602434941
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 4
  trial_id: 70e29_00000
  
== Status ==
Memory usage on this node: 27.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_70e29_00000 | RUNNING  | 172.17.0.4:46522 |      4 |          88.6909 | 485376 |  220.725 |              278.899 |              137.081 |            879.821 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_70e29_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3605.1502504173623
    time_step_min: 3215
  date: 2020-10-11_16-49-22
  done: false
  episode_len_mean: 875.7405063291139
  episode_reward_max: 278.89898989898967
  episode_reward_mean: 220.5459979542256
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 655be50386114bca8e235891fc50fda8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.1141637904303414
        entropy_coeff: 0.00010000000000000002
        kl: 0.006669476495257446
        model: {}
        policy_loss: -0.012190746708906122
        total_loss: 72.5603757585798
        vf_explained_var: 0.9030656814575195
        vf_loss: 72.57134246826172
    num_steps_sampled: 606720
    num_steps_trained: 606720
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.46153846153846
    gpu_util_percent0: 0.38884615384615395
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.592307692307692
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46522
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15610525537033723
    mean_env_wait_ms: 1.1597871163236981
    mean_inference_ms: 5.0228501520427535
    mean_raw_obs_processing_ms: 0.4064465360852276
  time_since_restore: 110.06777286529541
  time_this_iter_s: 21.376852989196777
  time_total_s: 110.06777286529541
  timers:
    learn_throughput: 7508.18
    learn_time_ms: 16161.573
    sample_throughput: 20999.375
    sample_time_ms: 5778.458
    update_time_ms: 32.975
  timestamp: 1602434962
  timesteps_since_restore: 0
  timesteps_total: 606720
  training_iteration: 5
  trial_id: 70e29_00000
  
== Status ==
Memory usage on this node: 27.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_70e29_00000 | RUNNING  | 172.17.0.4:46522 |      5 |          110.068 | 606720 |  220.546 |              278.899 |              115.717 |            875.741 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_70e29_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3598.815059445178
    time_step_min: 3215
  date: 2020-10-11_16-49-44
  done: false
  episode_len_mean: 870.0126582278481
  episode_reward_max: 283.4444444444445
  episode_reward_mean: 221.5198184375398
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 655be50386114bca8e235891fc50fda8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.1031875269753593
        entropy_coeff: 0.00010000000000000002
        kl: 0.0058455463232738635
        model: {}
        policy_loss: -0.013633016629942827
        total_loss: 56.65061024257115
        vf_explained_var: 0.9194228053092957
        vf_loss: 56.66318348475865
    num_steps_sampled: 728064
    num_steps_trained: 728064
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.446153846153848
    gpu_util_percent0: 0.3880769230769231
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.673076923076923
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46522
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15516212968187676
    mean_env_wait_ms: 1.1630827384936795
    mean_inference_ms: 4.951589654147202
    mean_raw_obs_processing_ms: 0.4040882196929536
  time_since_restore: 131.31407475471497
  time_this_iter_s: 21.246301889419556
  time_total_s: 131.31407475471497
  timers:
    learn_throughput: 7512.987
    learn_time_ms: 16151.233
    sample_throughput: 21429.472
    sample_time_ms: 5662.482
    update_time_ms: 30.74
  timestamp: 1602434984
  timesteps_since_restore: 0
  timesteps_total: 728064
  training_iteration: 6
  trial_id: 70e29_00000
  
== Status ==
Memory usage on this node: 27.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_70e29_00000 | RUNNING  | 172.17.0.4:46522 |      6 |          131.314 | 728064 |   221.52 |              283.444 |              115.717 |            870.013 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_70e29_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3588.261202185792
    time_step_min: 3215
  date: 2020-10-11_16-50-05
  done: false
  episode_len_mean: 864.6424050632911
  episode_reward_max: 283.4444444444445
  episode_reward_mean: 223.08851169927104
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 158
  episodes_total: 948
  experiment_id: 655be50386114bca8e235891fc50fda8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.0879003490720476
        entropy_coeff: 0.00010000000000000002
        kl: 0.006762735878250429
        model: {}
        policy_loss: -0.013632669695653021
        total_loss: 37.261954171316965
        vf_explained_var: 0.944100022315979
        vf_loss: 37.274344308035715
    num_steps_sampled: 849408
    num_steps_trained: 849408
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.64230769230769
    gpu_util_percent0: 0.36769230769230776
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.673076923076923
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46522
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15441375069404872
    mean_env_wait_ms: 1.16591607611793
    mean_inference_ms: 4.893912320192252
    mean_raw_obs_processing_ms: 0.4022341509844003
  time_since_restore: 152.45410013198853
  time_this_iter_s: 21.14002537727356
  time_total_s: 152.45410013198853
  timers:
    learn_throughput: 7524.505
    learn_time_ms: 16126.51
    sample_throughput: 21769.897
    sample_time_ms: 5573.936
    update_time_ms: 29.598
  timestamp: 1602435005
  timesteps_since_restore: 0
  timesteps_total: 849408
  training_iteration: 7
  trial_id: 70e29_00000
  
== Status ==
Memory usage on this node: 27.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_70e29_00000 | RUNNING  | 172.17.0.4:46522 |      7 |          152.454 | 849408 |  223.089 |              283.444 |              115.717 |            864.642 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_70e29_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3578.4057835820895
    time_step_min: 3160
  date: 2020-10-11_16-50-26
  done: false
  episode_len_mean: 861.3013574660633
  episode_reward_max: 287.232323232323
  episode_reward_mean: 224.4733762969056
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 157
  episodes_total: 1105
  experiment_id: 655be50386114bca8e235891fc50fda8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.0726469244275774
        entropy_coeff: 0.00010000000000000002
        kl: 0.0064350370583789685
        model: {}
        policy_loss: -0.01426797326920288
        total_loss: 36.13643755231585
        vf_explained_var: 0.9460744857788086
        vf_loss: 36.14952414376395
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.60769230769231
    gpu_util_percent0: 0.4269230769230769
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.676923076923077
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46522
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15379411621027744
    mean_env_wait_ms: 1.1681951251153022
    mean_inference_ms: 4.846637424724014
    mean_raw_obs_processing_ms: 0.4006889972621277
  time_since_restore: 173.89805030822754
  time_this_iter_s: 21.443950176239014
  time_total_s: 173.89805030822754
  timers:
    learn_throughput: 7516.321
    learn_time_ms: 16144.069
    sample_throughput: 22000.02
    sample_time_ms: 5515.631
    update_time_ms: 28.781
  timestamp: 1602435026
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 8
  trial_id: 70e29_00000
  
== Status ==
Memory usage on this node: 27.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_70e29_00000 | RUNNING  | 172.17.0.4:46522 |      8 |          173.898 | 970752 |  224.473 |              287.232 |              115.717 |            861.301 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_70e29_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3568.161316872428
    time_step_min: 3160
  date: 2020-10-11_16-50-48
  done: false
  episode_len_mean: 858.0144230769231
  episode_reward_max: 287.232323232323
  episode_reward_mean: 226.13347416472402
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 143
  episodes_total: 1248
  experiment_id: 655be50386114bca8e235891fc50fda8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.0612812382834298
        entropy_coeff: 0.00010000000000000002
        kl: 0.0064252400770783424
        model: {}
        policy_loss: -0.013670566009490617
        total_loss: 24.85169301714216
        vf_explained_var: 0.9604588150978088
        vf_loss: 24.864185333251953
    num_steps_sampled: 1092096
    num_steps_trained: 1092096
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.550000000000004
    gpu_util_percent0: 0.3692307692307692
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.676923076923077
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46522
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1533197975755475
    mean_env_wait_ms: 1.1700346997337725
    mean_inference_ms: 4.810191912883778
    mean_raw_obs_processing_ms: 0.3994589039595156
  time_since_restore: 195.36916041374207
  time_this_iter_s: 21.471110105514526
  time_total_s: 195.36916041374207
  timers:
    learn_throughput: 7513.241
    learn_time_ms: 16150.686
    sample_throughput: 22148.821
    sample_time_ms: 5478.576
    update_time_ms: 30.431
  timestamp: 1602435048
  timesteps_since_restore: 0
  timesteps_total: 1092096
  training_iteration: 9
  trial_id: 70e29_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_70e29_00000 | RUNNING  | 172.17.0.4:46522 |      9 |          195.369 | 1092096 |  226.133 |              287.232 |              115.717 |            858.014 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_70e29_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3562.0239752513535
    time_step_min: 3160
  date: 2020-10-11_16-51-09
  done: false
  episode_len_mean: 856.1025641025641
  episode_reward_max: 287.232323232323
  episode_reward_mean: 226.98391151332316
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 78
  episodes_total: 1326
  experiment_id: 655be50386114bca8e235891fc50fda8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.0382741349084037
        entropy_coeff: 0.00010000000000000002
        kl: 0.006699717004916498
        model: {}
        policy_loss: -0.015758267204676355
        total_loss: 19.22611209324428
        vf_explained_var: 0.9653859734535217
        vf_loss: 19.240634645734513
    num_steps_sampled: 1213440
    num_steps_trained: 1213440
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.81153846153846
    gpu_util_percent0: 0.44423076923076926
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.676923076923077
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46522
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15308442664302369
    mean_env_wait_ms: 1.171141145251643
    mean_inference_ms: 4.7917143614733915
    mean_raw_obs_processing_ms: 0.398879929547879
  time_since_restore: 216.6954927444458
  time_this_iter_s: 21.326332330703735
  time_total_s: 216.6954927444458
  timers:
    learn_throughput: 7510.787
    learn_time_ms: 16155.963
    sample_throughput: 22319.655
    sample_time_ms: 5436.643
    update_time_ms: 29.572
  timestamp: 1602435069
  timesteps_since_restore: 0
  timesteps_total: 1213440
  training_iteration: 10
  trial_id: 70e29_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_70e29_00000 | RUNNING  | 172.17.0.4:46522 |     10 |          216.695 | 1213440 |  226.984 |              287.232 |              115.717 |            856.103 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_70e29_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3552.330719885959
    time_step_min: 3160
  date: 2020-10-11_16-51-30
  done: false
  episode_len_mean: 853.9428969359332
  episode_reward_max: 287.232323232323
  episode_reward_mean: 228.58804620016306
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 110
  episodes_total: 1436
  experiment_id: 655be50386114bca8e235891fc50fda8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.0348200968333654
        entropy_coeff: 0.00010000000000000002
        kl: 0.006286287746791329
        model: {}
        policy_loss: -0.014631494147969144
        total_loss: 14.363759994506836
        vf_explained_var: 0.968192994594574
        vf_loss: 14.377237319946289
    num_steps_sampled: 1334784
    num_steps_trained: 1334784
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.415384615384617
    gpu_util_percent0: 0.3734615384615385
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.657692307692308
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46522
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1527519866653376
    mean_env_wait_ms: 1.1723648245686165
    mean_inference_ms: 4.767294670166017
    mean_raw_obs_processing_ms: 0.3979008990767629
  time_since_restore: 237.80835247039795
  time_this_iter_s: 21.11285972595215
  time_total_s: 237.80835247039795
  timers:
    learn_throughput: 7528.176
    learn_time_ms: 16118.645
    sample_throughput: 23076.868
    sample_time_ms: 5258.252
    update_time_ms: 28.658
  timestamp: 1602435090
  timesteps_since_restore: 0
  timesteps_total: 1334784
  training_iteration: 11
  trial_id: 70e29_00000
  
== Status ==
Memory usage on this node: 27.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_70e29_00000 | RUNNING  | 172.17.0.4:46522 |     11 |          237.808 | 1334784 |  228.588 |              287.232 |              115.717 |            853.943 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_70e29_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3540.557493540052
    time_step_min: 3160
  date: 2020-10-11_16-51-52
  done: false
  episode_len_mean: 850.8380771663504
  episode_reward_max: 287.232323232323
  episode_reward_mean: 230.23243823433563
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 145
  episodes_total: 1581
  experiment_id: 655be50386114bca8e235891fc50fda8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.0262405020850045
        entropy_coeff: 0.00010000000000000002
        kl: 0.005980719346553087
        model: {}
        policy_loss: -0.014333377592265606
        total_loss: 13.499579974583217
        vf_explained_var: 0.9717524647712708
        vf_loss: 13.51282024383545
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.503846153846155
    gpu_util_percent0: 0.3669230769230769
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.657692307692308
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46522
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15237023474181802
    mean_env_wait_ms: 1.1739559306174252
    mean_inference_ms: 4.738617323827214
    mean_raw_obs_processing_ms: 0.39678509586354177
  time_since_restore: 259.28895115852356
  time_this_iter_s: 21.48059868812561
  time_total_s: 259.28895115852356
  timers:
    learn_throughput: 7513.919
    learn_time_ms: 16149.229
    sample_throughput: 23645.6
    sample_time_ms: 5131.779
    update_time_ms: 28.043
  timestamp: 1602435112
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 12
  trial_id: 70e29_00000
  
== Status ==
Memory usage on this node: 27.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_70e29_00000 | RUNNING  | 172.17.0.4:46522 |     12 |          259.289 | 1456128 |  230.232 |              287.232 |              115.717 |            850.838 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_70e29_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3530.9941348973607
    time_step_min: 3160
  date: 2020-10-11_16-52-13
  done: false
  episode_len_mean: 847.584004602992
  episode_reward_max: 287.232323232323
  episode_reward_mean: 231.74273227092547
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 157
  episodes_total: 1738
  experiment_id: 655be50386114bca8e235891fc50fda8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.0086423328944616
        entropy_coeff: 0.00010000000000000002
        kl: 0.006141403956072671
        model: {}
        policy_loss: -0.014106190563844783
        total_loss: 13.797930717468262
        vf_explained_var: 0.9745455980300903
        vf_loss: 13.810909271240234
    num_steps_sampled: 1577472
    num_steps_trained: 1577472
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.71153846153846
    gpu_util_percent0: 0.35
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.653846153846154
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46522
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15200611527184904
    mean_env_wait_ms: 1.1756095730005225
    mean_inference_ms: 4.711486322109243
    mean_raw_obs_processing_ms: 0.3956935370415849
  time_since_restore: 280.630380153656
  time_this_iter_s: 21.341428995132446
  time_total_s: 280.630380153656
  timers:
    learn_throughput: 7519.374
    learn_time_ms: 16137.513
    sample_throughput: 23741.218
    sample_time_ms: 5111.111
    update_time_ms: 25.526
  timestamp: 1602435133
  timesteps_since_restore: 0
  timesteps_total: 1577472
  training_iteration: 13
  trial_id: 70e29_00000
  
== Status ==
Memory usage on this node: 27.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_70e29_00000 | RUNNING  | 172.17.0.4:46522 |     13 |           280.63 | 1577472 |  231.743 |              287.232 |              115.717 |            847.584 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_70e29_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3521.369833601718
    time_step_min: 3160
  date: 2020-10-11_16-52-35
  done: false
  episode_len_mean: 844.5965189873418
  episode_reward_max: 287.232323232323
  episode_reward_mean: 233.0428014320418
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 158
  episodes_total: 1896
  experiment_id: 655be50386114bca8e235891fc50fda8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.9857570443834577
        entropy_coeff: 0.00010000000000000002
        kl: 0.006410458457789251
        model: {}
        policy_loss: -0.013821696629747748
        total_loss: 15.916649545942034
        vf_explained_var: 0.9734243154525757
        vf_loss: 15.92928763798305
    num_steps_sampled: 1698816
    num_steps_trained: 1698816
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.646153846153847
    gpu_util_percent0: 0.36346153846153845
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.657692307692308
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46522
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15168419466331665
    mean_env_wait_ms: 1.1771663246452142
    mean_inference_ms: 4.687509970451693
    mean_raw_obs_processing_ms: 0.3947126629367032
  time_since_restore: 301.8901162147522
  time_this_iter_s: 21.25973606109619
  time_total_s: 301.8901162147522
  timers:
    learn_throughput: 7517.849
    learn_time_ms: 16140.787
    sample_throughput: 23783.316
    sample_time_ms: 5102.064
    update_time_ms: 26.563
  timestamp: 1602435155
  timesteps_since_restore: 0
  timesteps_total: 1698816
  training_iteration: 14
  trial_id: 70e29_00000
  
== Status ==
Memory usage on this node: 27.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_70e29_00000 | RUNNING  | 172.17.0.4:46522 |     14 |           301.89 | 1698816 |  233.043 |              287.232 |              115.717 |            844.597 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_70e29_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3513.2290945076693
    time_step_min: 3160
  date: 2020-10-11_16-52-56
  done: false
  episode_len_mean: 842.1966893865628
  episode_reward_max: 287.232323232323
  episode_reward_mean: 234.1798166671583
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 655be50386114bca8e235891fc50fda8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.9603591901915414
        entropy_coeff: 0.00010000000000000002
        kl: 0.005421308800578117
        model: {}
        policy_loss: -0.013045819792231279
        total_loss: 15.805892671857562
        vf_explained_var: 0.9750902056694031
        vf_loss: 15.817950112479073
    num_steps_sampled: 1820160
    num_steps_trained: 1820160
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.519230769230774
    gpu_util_percent0: 0.37692307692307686
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.657692307692308
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46522
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15140165335002817
    mean_env_wait_ms: 1.178609439156241
    mean_inference_ms: 4.666290528280844
    mean_raw_obs_processing_ms: 0.3938227983851235
  time_since_restore: 323.2892870903015
  time_this_iter_s: 21.399170875549316
  time_total_s: 323.2892870903015
  timers:
    learn_throughput: 7520.055
    learn_time_ms: 16136.053
    sample_throughput: 23748.262
    sample_time_ms: 5109.595
    update_time_ms: 26.56
  timestamp: 1602435176
  timesteps_since_restore: 0
  timesteps_total: 1820160
  training_iteration: 15
  trial_id: 70e29_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_70e29_00000 | RUNNING  | 172.17.0.4:46522 |     15 |          323.289 | 1820160 |   234.18 |              287.232 |              115.717 |            842.197 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_70e29_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3504.793483249197
    time_step_min: 3160
  date: 2020-10-11_16-53-18
  done: false
  episode_len_mean: 839.8942133815551
  episode_reward_max: 287.232323232323
  episode_reward_mean: 235.41078506584824
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 655be50386114bca8e235891fc50fda8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.9449490819658551
        entropy_coeff: 0.00010000000000000002
        kl: 0.005445404909551144
        model: {}
        policy_loss: -0.011962981628520148
        total_loss: 16.383984565734863
        vf_explained_var: 0.9741386771202087
        vf_loss: 16.39495345524379
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.303846153846152
    gpu_util_percent0: 0.40807692307692306
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.657692307692308
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46522
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1511479404903834
    mean_env_wait_ms: 1.1799223553164437
    mean_inference_ms: 4.6474063052505405
    mean_raw_obs_processing_ms: 0.3930196908482222
  time_since_restore: 344.552827835083
  time_this_iter_s: 21.263540744781494
  time_total_s: 344.552827835083
  timers:
    learn_throughput: 7522.466
    learn_time_ms: 16130.881
    sample_throughput: 23719.378
    sample_time_ms: 5115.817
    update_time_ms: 26.777
  timestamp: 1602435198
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 16
  trial_id: 70e29_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_70e29_00000 | RUNNING  | 172.17.0.4:46522 |     16 |          344.553 | 1941504 |  235.411 |              287.232 |              115.717 |            839.894 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_70e29_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3497.7826272999573
    time_step_min: 3160
  date: 2020-10-11_16-53-39
  done: false
  episode_len_mean: 838.1071729957806
  episode_reward_max: 287.232323232323
  episode_reward_mean: 236.4022503516173
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: 655be50386114bca8e235891fc50fda8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.9374308075223651
        entropy_coeff: 0.00010000000000000002
        kl: 0.00559737127540367
        model: {}
        policy_loss: -0.013294356209891183
        total_loss: 15.215373992919922
        vf_explained_var: 0.9764556884765625
        vf_loss: 15.227642059326172
    num_steps_sampled: 2062848
    num_steps_trained: 2062848
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.74444444444444
    gpu_util_percent0: 0.39999999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.674074074074074
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46522
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15091746078801363
    mean_env_wait_ms: 1.1810945355890925
    mean_inference_ms: 4.630404973453004
    mean_raw_obs_processing_ms: 0.39228412078727687
  time_since_restore: 366.12318301200867
  time_this_iter_s: 21.57035517692566
  time_total_s: 366.12318301200867
  timers:
    learn_throughput: 7504.177
    learn_time_ms: 16170.193
    sample_throughput: 23690.054
    sample_time_ms: 5122.15
    update_time_ms: 28.612
  timestamp: 1602435219
  timesteps_since_restore: 0
  timesteps_total: 2062848
  training_iteration: 17
  trial_id: 70e29_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_70e29_00000 | RUNNING  | 172.17.0.4:46522 |     17 |          366.123 | 2062848 |  236.402 |              287.232 |              115.717 |            838.107 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_70e29_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3491.910621242485
    time_step_min: 3160
  date: 2020-10-11_16-54-01
  done: false
  episode_len_mean: 836.8564082278481
  episode_reward_max: 287.232323232323
  episode_reward_mean: 237.2802111302901
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 158
  episodes_total: 2528
  experiment_id: 655be50386114bca8e235891fc50fda8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.9169140458106995
        entropy_coeff: 0.00010000000000000002
        kl: 0.005850059778562614
        model: {}
        policy_loss: -0.013017413771844335
        total_loss: 16.00598362513951
        vf_explained_var: 0.9751184582710266
        vf_loss: 16.017922810145787
    num_steps_sampled: 2184192
    num_steps_trained: 2184192
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.247999999999998
    gpu_util_percent0: 0.39
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.676
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46522
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15070807037326334
    mean_env_wait_ms: 1.1821437394583343
    mean_inference_ms: 4.61495988709412
    mean_raw_obs_processing_ms: 0.39160924494774285
  time_since_restore: 387.25285506248474
  time_this_iter_s: 21.129672050476074
  time_total_s: 387.25285506248474
  timers:
    learn_throughput: 7516.309
    learn_time_ms: 16144.093
    sample_throughput: 23715.045
    sample_time_ms: 5116.752
    update_time_ms: 28.285
  timestamp: 1602435241
  timesteps_since_restore: 0
  timesteps_total: 2184192
  training_iteration: 18
  trial_id: 70e29_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_70e29_00000 | RUNNING  | 172.17.0.4:46522 |     18 |          387.253 | 2184192 |   237.28 |              287.232 |              115.717 |            836.856 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_70e29_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3486.705616283453
    time_step_min: 3160
  date: 2020-10-11_16-54-22
  done: false
  episode_len_mean: 835.8983618763962
  episode_reward_max: 287.232323232323
  episode_reward_mean: 238.1144505366395
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 158
  episodes_total: 2686
  experiment_id: 655be50386114bca8e235891fc50fda8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.8977000202451434
        entropy_coeff: 0.00010000000000000002
        kl: 0.005370115794773612
        model: {}
        policy_loss: -0.011884738267066755
        total_loss: 14.289475440979004
        vf_explained_var: 0.977433979511261
        vf_loss: 14.300375665937151
    num_steps_sampled: 2305536
    num_steps_trained: 2305536
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.065384615384616
    gpu_util_percent0: 0.3453846153846154
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.673076923076923
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46522
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15051582019623522
    mean_env_wait_ms: 1.1830885862683116
    mean_inference_ms: 4.600822598321099
    mean_raw_obs_processing_ms: 0.39098920684764027
  time_since_restore: 408.45776629447937
  time_this_iter_s: 21.20491123199463
  time_total_s: 408.45776629447937
  timers:
    learn_throughput: 7521.212
    learn_time_ms: 16133.571
    sample_throughput: 23784.227
    sample_time_ms: 5101.868
    update_time_ms: 25.734
  timestamp: 1602435262
  timesteps_since_restore: 0
  timesteps_total: 2305536
  training_iteration: 19
  trial_id: 70e29_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_70e29_00000 | RUNNING  | 172.17.0.4:46522 |     19 |          408.458 | 2305536 |  238.114 |              287.232 |              115.717 |            835.898 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_70e29_00000:
  custom_metrics:
    time_step_max: 4292
    time_step_mean: 3481.1924581999288
    time_step_min: 3160
  date: 2020-10-11_16-54-43
  done: false
  episode_len_mean: 834.8027426160338
  episode_reward_max: 287.232323232323
  episode_reward_mean: 238.9297297873246
  episode_reward_min: 115.7171717171713
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 655be50386114bca8e235891fc50fda8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.882460491997855
        entropy_coeff: 0.00010000000000000002
        kl: 0.005906718250896249
        model: {}
        policy_loss: -0.01405173699770655
        total_loss: 12.80661950792585
        vf_explained_var: 0.9789648652076721
        vf_loss: 12.819578034537178
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.18846153846154
    gpu_util_percent0: 0.3896153846153846
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.676923076923077
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46522
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15033981247583086
    mean_env_wait_ms: 1.18396339662342
    mean_inference_ms: 4.587854109000009
    mean_raw_obs_processing_ms: 0.3904308342217064
  time_since_restore: 429.61490774154663
  time_this_iter_s: 21.15714144706726
  time_total_s: 429.61490774154663
  timers:
    learn_throughput: 7529.991
    learn_time_ms: 16114.759
    sample_throughput: 23784.428
    sample_time_ms: 5101.825
    update_time_ms: 26.841
  timestamp: 1602435283
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 20
  trial_id: 70e29_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_70e29_00000 | RUNNING  | 172.17.0.4:46522 |     20 |          429.615 | 2426880 |   238.93 |              287.232 |              115.717 |            834.803 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


