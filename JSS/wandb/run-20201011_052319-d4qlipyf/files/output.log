2020-10-11 05:23:21,188	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_e15dd_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=29111)[0m 2020-10-11 05:23:24,052	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=29091)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29091)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29065)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29065)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29068)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29068)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29073)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29073)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29098)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29098)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29081)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29081)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29063)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29063)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29082)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29082)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29066)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29066)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29078)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29078)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29120)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29120)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29048)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29048)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29072)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29072)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29054)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29054)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29125)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29125)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29077)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29077)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29104)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29104)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29037)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29037)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29092)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29092)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=28997)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=28997)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=28986)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=28986)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29095)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29095)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29074)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29074)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29011)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29011)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29070)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29070)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29084)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29084)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29119)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29119)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=28990)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=28990)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=28998)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=28998)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29060)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29060)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29000)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29000)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29020)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29020)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29023)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29023)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29061)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29061)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29043)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29043)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29012)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29012)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29027)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29027)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=28987)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=28987)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29051)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29051)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29087)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29087)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29025)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29025)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29004)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29004)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29117)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29117)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29064)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29064)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=28985)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=28985)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29080)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29080)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=28999)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=28999)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29059)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29059)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29007)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29007)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=28994)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=28994)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29016)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29016)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=28993)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=28993)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=28991)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=28991)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29062)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29062)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29106)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29106)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29046)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29046)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29056)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29056)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29096)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29096)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29039)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29039)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=28988)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=28988)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29036)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29036)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29021)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29021)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29018)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29018)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29003)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29003)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29001)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29001)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29050)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29050)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=28996)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=28996)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29009)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29009)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29089)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29089)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29067)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29067)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=28984)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=28984)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29069)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29069)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29103)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29103)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29041)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29041)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29114)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29114)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=28989)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=28989)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29090)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29090)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29108)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29108)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29013)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29013)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_e15dd_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_05-24-05
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 7c62b3283e944fff9a57f0ee583fe65e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1838282091276986
        entropy_coeff: 0.00010000000000000002
        kl: 0.005120943200641445
        model: {}
        policy_loss: -0.0038369044237437527
        total_loss: 660.8491080147879
        vf_explained_var: 0.0902143344283104
        vf_loss: 660.8520377022879
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.004545454545454
    gpu_util_percent0: 0.32159090909090915
    gpu_util_percent1: 0.00022727272727272727
    gpu_util_percent2: 0.00022727272727272727
    ram_util_percent: 6.293181818181816
    vram_util_percent0: 0.19261904051999162
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 29111
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16755435304091132
    mean_env_wait_ms: 1.1789319661709583
    mean_inference_ms: 5.599897719710356
    mean_raw_obs_processing_ms: 0.44538406944451564
  time_since_restore: 36.11841011047363
  time_this_iter_s: 36.11841011047363
  time_total_s: 36.11841011047363
  timers:
    learn_throughput: 6002.375
    learn_time_ms: 26954.662
    sample_throughput: 17785.33
    sample_time_ms: 9096.936
    update_time_ms: 27.63
  timestamp: 1602393845
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: e15dd_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e15dd_00000 | RUNNING  | 172.17.0.4:29111 |      1 |          36.1184 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e15dd_00000:
  custom_metrics:
    time_step_max: 4080
    time_step_mean: 3594.9479166666665
    time_step_min: 3325
  date: 2020-10-11_05-24-40
  done: false
  episode_len_mean: 889.6962025316456
  episode_reward_max: 262.23232323232264
  episode_reward_mean: 218.78391510037062
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 7c62b3283e944fff9a57f0ee583fe65e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1571864230292184
        entropy_coeff: 0.00010000000000000002
        kl: 0.007001370291358658
        model: {}
        policy_loss: -0.005956932888823628
        total_loss: 312.1098959786551
        vf_explained_var: 0.5083410739898682
        vf_loss: 312.11457388741627
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.452380952380953
    gpu_util_percent0: 0.38023809523809526
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.471428571428571
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 29111
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16366870590924443
    mean_env_wait_ms: 1.1771388632727138
    mean_inference_ms: 5.382355599190501
    mean_raw_obs_processing_ms: 0.43514442149671506
  time_since_restore: 71.03319764137268
  time_this_iter_s: 34.91478753089905
  time_total_s: 71.03319764137268
  timers:
    learn_throughput: 6000.104
    learn_time_ms: 26964.867
    sample_throughput: 19075.203
    sample_time_ms: 8481.797
    update_time_ms: 24.443
  timestamp: 1602393880
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: e15dd_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e15dd_00000 | RUNNING  | 172.17.0.4:29111 |      2 |          71.0332 | 323584 |  218.784 |              262.232 |              145.717 |            889.696 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e15dd_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3605.3094170403588
    time_step_min: 3325
  date: 2020-10-11_05-25-15
  done: false
  episode_len_mean: 884.8206751054852
  episode_reward_max: 266.17171717171703
  episode_reward_mean: 219.73008566679428
  episode_reward_min: 136.17171717171695
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 7c62b3283e944fff9a57f0ee583fe65e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1542861121041434
        entropy_coeff: 0.00010000000000000002
        kl: 0.005855743008266602
        model: {}
        policy_loss: -0.005670554071132626
        total_loss: 133.66425105503626
        vf_explained_var: 0.7644914984703064
        vf_loss: 133.66886465890067
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.990243902439026
    gpu_util_percent0: 0.3897560975609757
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.490243902439025
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 29111
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16125417725204655
    mean_env_wait_ms: 1.1780904735132984
    mean_inference_ms: 5.219752665081332
    mean_raw_obs_processing_ms: 0.427726895716052
  time_since_restore: 105.30194139480591
  time_this_iter_s: 34.26874375343323
  time_total_s: 105.30194139480591
  timers:
    learn_throughput: 6000.578
    learn_time_ms: 26962.737
    sample_throughput: 20057.511
    sample_time_ms: 8066.405
    update_time_ms: 24.842
  timestamp: 1602393915
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: e15dd_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e15dd_00000 | RUNNING  | 172.17.0.4:29111 |      3 |          105.302 | 485376 |   219.73 |              266.172 |              136.172 |            884.821 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e15dd_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3601.3576158940396
    time_step_min: 3251
  date: 2020-10-11_05-25-49
  done: false
  episode_len_mean: 880.2167721518987
  episode_reward_max: 273.4444444444441
  episode_reward_mean: 221.08229446362338
  episode_reward_min: 136.17171717171695
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 7c62b3283e944fff9a57f0ee583fe65e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.148564602647509
        entropy_coeff: 0.00010000000000000002
        kl: 0.004059552447870374
        model: {}
        policy_loss: -0.0035514034576148595
        total_loss: 82.07058007376534
        vf_explained_var: 0.843746542930603
        vf_loss: 82.07343510219029
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.409756097560976
    gpu_util_percent0: 0.39512195121951216
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.487804878048781
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 29111
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15952210057056945
    mean_env_wait_ms: 1.1795136721655095
    mean_inference_ms: 5.102605086371509
    mean_raw_obs_processing_ms: 0.42216043620525356
  time_since_restore: 139.55469346046448
  time_this_iter_s: 34.25275206565857
  time_total_s: 139.55469346046448
  timers:
    learn_throughput: 5996.321
    learn_time_ms: 26981.876
    sample_throughput: 20655.786
    sample_time_ms: 7832.769
    update_time_ms: 27.176
  timestamp: 1602393949
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: e15dd_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e15dd_00000 | RUNNING  | 172.17.0.4:29111 |      4 |          139.555 | 647168 |  221.082 |              273.444 |              136.172 |            880.217 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e15dd_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3591.737532808399
    time_step_min: 3251
  date: 2020-10-11_05-26-23
  done: false
  episode_len_mean: 876.4746835443038
  episode_reward_max: 273.4444444444441
  episode_reward_mean: 222.4231556066997
  episode_reward_min: 136.17171717171695
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 7c62b3283e944fff9a57f0ee583fe65e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.119062568460192
        entropy_coeff: 0.00010000000000000002
        kl: 0.008517497884375709
        model: {}
        policy_loss: -0.003827034720286195
        total_loss: 67.39681570870536
        vf_explained_var: 0.8748982548713684
        vf_loss: 67.39990125383649
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.2175
    gpu_util_percent0: 0.39099999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4975000000000005
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 29111
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15825948206373613
    mean_env_wait_ms: 1.181431095211274
    mean_inference_ms: 5.0155351829650545
    mean_raw_obs_processing_ms: 0.41788030031119644
  time_since_restore: 173.33046555519104
  time_this_iter_s: 33.77577209472656
  time_total_s: 173.33046555519104
  timers:
    learn_throughput: 6015.737
    learn_time_ms: 26894.792
    sample_throughput: 21018.981
    sample_time_ms: 7697.424
    update_time_ms: 26.092
  timestamp: 1602393983
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: e15dd_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e15dd_00000 | RUNNING  | 172.17.0.4:29111 |      5 |           173.33 | 808960 |  222.423 |              273.444 |              136.172 |            876.475 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e15dd_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3580.9172862453534
    time_step_min: 3225
  date: 2020-10-11_05-26-57
  done: false
  episode_len_mean: 868.4673913043479
  episode_reward_max: 277.3838383838382
  episode_reward_mean: 224.1620827843652
  episode_reward_min: 136.17171717171695
  episodes_this_iter: 314
  episodes_total: 1104
  experiment_id: 7c62b3283e944fff9a57f0ee583fe65e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1093968323298864
        entropy_coeff: 0.00010000000000000002
        kl: 0.008510861279708999
        model: {}
        policy_loss: -0.005161636604628127
        total_loss: 76.34651129586356
        vf_explained_var: 0.9077752232551575
        vf_loss: 76.35093307495117
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.817073170731707
    gpu_util_percent0: 0.3846341463414634
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.487804878048781
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 29111
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15655891566198538
    mean_env_wait_ms: 1.1867190759017678
    mean_inference_ms: 4.899366996662394
    mean_raw_obs_processing_ms: 0.41255622838024475
  time_since_restore: 207.3391342163086
  time_this_iter_s: 34.008668661117554
  time_total_s: 207.3391342163086
  timers:
    learn_throughput: 6017.205
    learn_time_ms: 26888.23
    sample_throughput: 21304.391
    sample_time_ms: 7594.303
    update_time_ms: 25.231
  timestamp: 1602394017
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: e15dd_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e15dd_00000 | RUNNING  | 172.17.0.4:29111 |      6 |          207.339 | 970752 |  224.162 |              277.384 |              136.172 |            868.467 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e15dd_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3574.4506472491908
    time_step_min: 3225
  date: 2020-10-11_05-27-31
  done: false
  episode_len_mean: 863.9034810126582
  episode_reward_max: 277.3838383838382
  episode_reward_mean: 225.31980405318996
  episode_reward_min: 136.17171717171695
  episodes_this_iter: 160
  episodes_total: 1264
  experiment_id: 7c62b3283e944fff9a57f0ee583fe65e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.111093955380576
        entropy_coeff: 0.00010000000000000002
        kl: 0.011040758740689074
        model: {}
        policy_loss: -0.005653655081654766
        total_loss: 50.62591743469238
        vf_explained_var: 0.9037092924118042
        vf_loss: 50.63058008466448
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.16829268292683
    gpu_util_percent0: 0.3807317073170732
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.495121951219511
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 29111
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15593650747153479
    mean_env_wait_ms: 1.1887717228028438
    mean_inference_ms: 4.857088279583241
    mean_raw_obs_processing_ms: 0.41059846004035344
  time_since_restore: 241.48467874526978
  time_this_iter_s: 34.14554452896118
  time_total_s: 241.48467874526978
  timers:
    learn_throughput: 6016.11
    learn_time_ms: 26893.127
    sample_throughput: 21509.414
    sample_time_ms: 7521.916
    update_time_ms: 25.159
  timestamp: 1602394051
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: e15dd_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e15dd_00000 | RUNNING  | 172.17.0.4:29111 |      7 |          241.485 | 1132544 |   225.32 |              277.384 |              136.172 |            863.903 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e15dd_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3568.0050215208034
    time_step_min: 3225
  date: 2020-10-11_05-28-05
  done: false
  episode_len_mean: 859.4535864978903
  episode_reward_max: 277.3838383838382
  episode_reward_mean: 226.19995311767443
  episode_reward_min: 136.17171717171695
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 7c62b3283e944fff9a57f0ee583fe65e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0900099532944816
        entropy_coeff: 0.00010000000000000002
        kl: 0.010358261742762156
        model: {}
        policy_loss: -0.005662367953066548
        total_loss: 46.75223459516253
        vf_explained_var: 0.9123027920722961
        vf_loss: 46.75696890694754
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.6125
    gpu_util_percent0: 0.33999999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.495
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 29111
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1554160438448657
    mean_env_wait_ms: 1.1907329610932877
    mean_inference_ms: 4.821488351745278
    mean_raw_obs_processing_ms: 0.40889306189260105
  time_since_restore: 275.6526618003845
  time_this_iter_s: 34.167983055114746
  time_total_s: 275.6526618003845
  timers:
    learn_throughput: 6016.168
    learn_time_ms: 26892.864
    sample_throughput: 21623.429
    sample_time_ms: 7482.255
    update_time_ms: 24.674
  timestamp: 1602394085
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: e15dd_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e15dd_00000 | RUNNING  | 172.17.0.4:29111 |      8 |          275.653 | 1294336 |    226.2 |              277.384 |              136.172 |            859.454 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e15dd_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3559.067654639175
    time_step_min: 3225
  date: 2020-10-11_05-28-40
  done: false
  episode_len_mean: 854.7924050632911
  episode_reward_max: 277.3838383838382
  episode_reward_mean: 227.4228679197032
  episode_reward_min: 136.17171717171695
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 7c62b3283e944fff9a57f0ee583fe65e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0525360533169337
        entropy_coeff: 0.00010000000000000002
        kl: 0.010059997838522707
        model: {}
        policy_loss: -0.004822240672573181
        total_loss: 37.87817028590611
        vf_explained_var: 0.9270617365837097
        vf_loss: 37.88209043230329
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.460975609756098
    gpu_util_percent0: 0.335609756097561
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.490243902439025
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 29111
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15497100164463326
    mean_env_wait_ms: 1.1927595220578717
    mean_inference_ms: 4.790546654600095
    mean_raw_obs_processing_ms: 0.40737956295421746
  time_since_restore: 309.62278604507446
  time_this_iter_s: 33.97012424468994
  time_total_s: 309.62278604507446
  timers:
    learn_throughput: 6015.42
    learn_time_ms: 26896.208
    sample_throughput: 21788.081
    sample_time_ms: 7425.711
    update_time_ms: 24.185
  timestamp: 1602394120
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: e15dd_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e15dd_00000 | RUNNING  | 172.17.0.4:29111 |      9 |          309.623 | 1456128 |  227.423 |              277.384 |              136.172 |            854.792 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e15dd_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3544.0096411355116
    time_step_min: 3225
  date: 2020-10-11_05-29-14
  done: false
  episode_len_mean: 846.068073878628
  episode_reward_max: 283.89898989898944
  episode_reward_mean: 229.6034753871164
  episode_reward_min: 136.17171717171695
  episodes_this_iter: 315
  episodes_total: 1895
  experiment_id: 7c62b3283e944fff9a57f0ee583fe65e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0252152255603246
        entropy_coeff: 0.00010000000000000002
        kl: 0.009290601858603103
        model: {}
        policy_loss: -0.004380860831588507
        total_loss: 40.92146110534668
        vf_explained_var: 0.9500911831855774
        vf_loss: 40.92501531328474
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.45609756097561
    gpu_util_percent0: 0.4026829268292683
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.485365853658536
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 29111
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1542546900670736
    mean_env_wait_ms: 1.197076679746057
    mean_inference_ms: 4.740756430045791
    mean_raw_obs_processing_ms: 0.4050683751080236
  time_since_restore: 343.7074635028839
  time_this_iter_s: 34.08467745780945
  time_total_s: 343.7074635028839
  timers:
    learn_throughput: 6015.805
    learn_time_ms: 26894.489
    sample_throughput: 21876.979
    sample_time_ms: 7395.537
    update_time_ms: 23.91
  timestamp: 1602394154
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: e15dd_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e15dd_00000 | RUNNING  | 172.17.0.4:29111 |     10 |          343.707 | 1617920 |  229.603 |              283.899 |              136.172 |            846.068 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e15dd_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3536.815399802567
    time_step_min: 3225
  date: 2020-10-11_05-29-48
  done: false
  episode_len_mean: 841.8164556962025
  episode_reward_max: 283.89898989898944
  episode_reward_mean: 230.6792560463445
  episode_reward_min: 136.17171717171695
  episodes_this_iter: 159
  episodes_total: 2054
  experiment_id: 7c62b3283e944fff9a57f0ee583fe65e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.008800676890782
        entropy_coeff: 0.00010000000000000002
        kl: 0.008312776618238007
        model: {}
        policy_loss: -0.0035792635670597
        total_loss: 24.9351293018886
        vf_explained_var: 0.9530462622642517
        vf_loss: 24.937977654593332
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.95365853658537
    gpu_util_percent0: 0.3814634146341463
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.492682926829268
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 29111
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15395039559386575
    mean_env_wait_ms: 1.1989993919977904
    mean_inference_ms: 4.719996651379931
    mean_raw_obs_processing_ms: 0.4040925248747199
  time_since_restore: 378.02246379852295
  time_this_iter_s: 34.31500029563904
  time_total_s: 378.02246379852295
  timers:
    learn_throughput: 6015.196
    learn_time_ms: 26897.214
    sample_throughput: 22455.889
    sample_time_ms: 7204.881
    update_time_ms: 23.206
  timestamp: 1602394188
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: e15dd_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e15dd_00000 | RUNNING  | 172.17.0.4:29111 |     11 |          378.022 | 1779712 |  230.679 |              283.899 |              136.172 |            841.816 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e15dd_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3530.0457875457873
    time_step_min: 3223
  date: 2020-10-11_05-30-22
  done: false
  episode_len_mean: 837.9000904159132
  episode_reward_max: 283.89898989898944
  episode_reward_mean: 231.86442636126165
  episode_reward_min: 136.17171717171695
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 7c62b3283e944fff9a57f0ee583fe65e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.9860578221934182
        entropy_coeff: 0.00010000000000000002
        kl: 0.008146724896505475
        model: {}
        policy_loss: -0.003898282934512411
        total_loss: 22.8188111441476
        vf_explained_var: 0.9515373110771179
        vf_loss: 22.821993555341447
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.285
    gpu_util_percent0: 0.34175
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.505
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 29111
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15367609732903922
    mean_env_wait_ms: 1.2008177320484013
    mean_inference_ms: 4.701470522549823
    mean_raw_obs_processing_ms: 0.4031934763067753
  time_since_restore: 412.15693044662476
  time_this_iter_s: 34.13446664810181
  time_total_s: 412.15693044662476
  timers:
    learn_throughput: 6015.039
    learn_time_ms: 26897.912
    sample_throughput: 22705.191
    sample_time_ms: 7125.771
    update_time_ms: 23.388
  timestamp: 1602394222
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: e15dd_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e15dd_00000 | RUNNING  | 172.17.0.4:29111 |     12 |          412.157 | 1941504 |  231.864 |              283.899 |              136.172 |              837.9 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e15dd_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3518.1126016260164
    time_step_min: 3223
  date: 2020-10-11_05-30-57
  done: false
  episode_len_mean: 831.4131832797427
  episode_reward_max: 284.35353535353516
  episode_reward_mean: 233.6897430900645
  episode_reward_min: 136.17171717171695
  episodes_this_iter: 276
  episodes_total: 2488
  experiment_id: 7c62b3283e944fff9a57f0ee583fe65e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.9370324441364833
        entropy_coeff: 0.00010000000000000002
        kl: 0.006905458435150129
        model: {}
        policy_loss: -0.0050145269384042224
        total_loss: 25.559224401201522
        vf_explained_var: 0.9634825587272644
        vf_loss: 25.563641684395925
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.478048780487807
    gpu_util_percent0: 0.3285365853658537
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.495121951219511
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 29111
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15326182159500226
    mean_env_wait_ms: 1.2043409112049637
    mean_inference_ms: 4.673663024510824
    mean_raw_obs_processing_ms: 0.4018628507997814
  time_since_restore: 446.3415515422821
  time_this_iter_s: 34.18462109565735
  time_total_s: 446.3415515422821
  timers:
    learn_throughput: 6015.964
    learn_time_ms: 26893.777
    sample_throughput: 22720.68
    sample_time_ms: 7120.914
    update_time_ms: 23.242
  timestamp: 1602394257
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: e15dd_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e15dd_00000 | RUNNING  | 172.17.0.4:29111 |     13 |          446.342 | 2103296 |   233.69 |              284.354 |              136.172 |            831.413 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e15dd_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3511.489089541008
    time_step_min: 3223
  date: 2020-10-11_05-31-31
  done: false
  episode_len_mean: 827.5967982129561
  episode_reward_max: 284.35353535353516
  episode_reward_mean: 234.61798175349912
  episode_reward_min: 136.17171717171695
  episodes_this_iter: 198
  episodes_total: 2686
  experiment_id: 7c62b3283e944fff9a57f0ee583fe65e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.9339202003819602
        entropy_coeff: 0.00010000000000000002
        kl: 0.010307770288948501
        model: {}
        policy_loss: -0.005611554309975223
        total_loss: 19.428793089730398
        vf_explained_var: 0.9645479321479797
        vf_loss: 19.433467183794296
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.136585365853662
    gpu_util_percent0: 0.3339024390243902
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.507317073170732
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 29111
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15300379982212198
    mean_env_wait_ms: 1.2064049134479053
    mean_inference_ms: 4.656095520947229
    mean_raw_obs_processing_ms: 0.4010124737149504
  time_since_restore: 480.67782258987427
  time_this_iter_s: 34.33627104759216
  time_total_s: 480.67782258987427
  timers:
    learn_throughput: 6019.954
    learn_time_ms: 26875.954
    sample_throughput: 22637.475
    sample_time_ms: 7147.087
    update_time_ms: 21.806
  timestamp: 1602394291
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: e15dd_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e15dd_00000 | RUNNING  | 172.17.0.4:29111 |     14 |          480.678 | 2265088 |  234.618 |              284.354 |              136.172 |            827.597 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e15dd_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3506.68359375
    time_step_min: 3223
  date: 2020-10-11_05-32-05
  done: false
  episode_len_mean: 824.7974683544304
  episode_reward_max: 284.35353535353516
  episode_reward_mean: 235.2570856241741
  episode_reward_min: 136.17171717171695
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 7c62b3283e944fff9a57f0ee583fe65e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.9119350569588798
        entropy_coeff: 0.00010000000000000002
        kl: 0.008627663299973522
        model: {}
        policy_loss: -0.004301293317569487
        total_loss: 17.139017581939697
        vf_explained_var: 0.9646182060241699
        vf_loss: 17.142547334943497
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.539024390243902
    gpu_util_percent0: 0.3675609756097561
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4975609756097565
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 29111
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1528183354174277
    mean_env_wait_ms: 1.2080685043172879
    mean_inference_ms: 4.643490635192709
    mean_raw_obs_processing_ms: 0.40040912957175745
  time_since_restore: 514.9485993385315
  time_this_iter_s: 34.27077674865723
  time_total_s: 514.9485993385315
  timers:
    learn_throughput: 6014.301
    learn_time_ms: 26901.213
    sample_throughput: 22562.885
    sample_time_ms: 7170.714
    update_time_ms: 21.646
  timestamp: 1602394325
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: e15dd_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e15dd_00000 | RUNNING  | 172.17.0.4:29111 |     15 |          514.949 | 2426880 |  235.257 |              284.354 |              136.172 |            824.797 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e15dd_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3499.5595394736843
    time_step_min: 3223
  date: 2020-10-11_05-32-40
  done: false
  episode_len_mean: 821.2112125162972
  episode_reward_max: 284.35353535353516
  episode_reward_mean: 236.2430794252827
  episode_reward_min: 136.17171717171695
  episodes_this_iter: 224
  episodes_total: 3068
  experiment_id: 7c62b3283e944fff9a57f0ee583fe65e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.8641640969685146
        entropy_coeff: 0.00010000000000000002
        kl: 0.00796071403393788
        model: {}
        policy_loss: -0.003802479016095666
        total_loss: 19.03225953238351
        vf_explained_var: 0.9716145396232605
        vf_loss: 19.035352161952428
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.500000000000004
    gpu_util_percent0: 0.399047619047619
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.49047619047619
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 29111
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15259774107006868
    mean_env_wait_ms: 1.210506209570814
    mean_inference_ms: 4.627504730986013
    mean_raw_obs_processing_ms: 0.3996604711280423
  time_since_restore: 549.2953987121582
  time_this_iter_s: 34.34679937362671
  time_total_s: 549.2953987121582
  timers:
    learn_throughput: 6015.036
    learn_time_ms: 26897.927
    sample_throughput: 22449.462
    sample_time_ms: 7206.943
    update_time_ms: 21.806
  timestamp: 1602394360
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: e15dd_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e15dd_00000 | RUNNING  | 172.17.0.4:29111 |     16 |          549.295 | 2588672 |  236.243 |              284.354 |              136.172 |            821.211 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e15dd_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3491.456838905775
    time_step_min: 3169
  date: 2020-10-11_05-33-14
  done: false
  episode_len_mean: 817.5967450271248
  episode_reward_max: 285.86868686868684
  episode_reward_mean: 237.42502785540748
  episode_reward_min: 136.17171717171695
  episodes_this_iter: 250
  episodes_total: 3318
  experiment_id: 7c62b3283e944fff9a57f0ee583fe65e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.8666947952338627
        entropy_coeff: 0.00010000000000000002
        kl: 0.007978467869439296
        model: {}
        policy_loss: -0.004038691765994632
        total_loss: 15.092013495309013
        vf_explained_var: 0.9742318987846375
        vf_loss: 15.09534113747733
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.4625
    gpu_util_percent0: 0.392
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.49
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 29111
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1523542500144406
    mean_env_wait_ms: 1.2128827075749746
    mean_inference_ms: 4.611489757580131
    mean_raw_obs_processing_ms: 0.39891373435424404
  time_since_restore: 583.474936246872
  time_this_iter_s: 34.179537534713745
  time_total_s: 583.474936246872
  timers:
    learn_throughput: 6018.396
    learn_time_ms: 26882.912
    sample_throughput: 22376.945
    sample_time_ms: 7230.299
    update_time_ms: 21.757
  timestamp: 1602394394
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: e15dd_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e15dd_00000 | RUNNING  | 172.17.0.4:29111 |     17 |          583.475 | 2750464 |  237.425 |              285.869 |              136.172 |            817.597 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e15dd_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3487.5980278422276
    time_step_min: 3169
  date: 2020-10-11_05-33-48
  done: true
  episode_len_mean: 815.4663406214039
  episode_reward_max: 285.86868686868684
  episode_reward_mean: 238.06482837581788
  episode_reward_min: 136.17171717171695
  episodes_this_iter: 158
  episodes_total: 3476
  experiment_id: 7c62b3283e944fff9a57f0ee583fe65e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.8566352384431022
        entropy_coeff: 0.00010000000000000002
        kl: 0.007921622234529682
        model: {}
        policy_loss: -0.005004141469336381
        total_loss: 13.640143190111433
        vf_explained_var: 0.9714521765708923
        vf_loss: 13.644440514700753
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.7219512195122
    gpu_util_percent0: 0.33780487804878045
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497560975609756
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 29111
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15222359411644906
    mean_env_wait_ms: 1.2143012224758016
    mean_inference_ms: 4.602419614912239
    mean_raw_obs_processing_ms: 0.3984912346757304
  time_since_restore: 617.4735391139984
  time_this_iter_s: 33.998602867126465
  time_total_s: 617.4735391139984
  timers:
    learn_throughput: 6021.805
    learn_time_ms: 26867.691
    sample_throughput: 22385.774
    sample_time_ms: 7227.447
    update_time_ms: 21.668
  timestamp: 1602394428
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: e15dd_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e15dd_00000 | TERMINATED |       |     18 |          617.474 | 2912256 |  238.065 |              285.869 |              136.172 |            815.466 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e15dd_00000 | TERMINATED |       |     18 |          617.474 | 2912256 |  238.065 |              285.869 |              136.172 |            815.466 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


