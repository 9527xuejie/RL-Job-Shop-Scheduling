program: train_wandb.py
method: bayes
metric:
  name: episode_reward_mean
  goal: maximize
early_terminate:
  type: hyperband
  min_iter: 20
parameters:
  sgd_minibatch_size:
    min: 4096
    max: 16000
  num_envs_per_worker:
    min: 1
    max: 8
  rollout_fragment_length:
    min: 512
    max: 1256
  layer_size:
    min: 768
    max: 1256
  lr_start:
    min: 1-e6
    max: 1-e3
  lr_end:
    min: 1-e7
    max: 1-e4
  entropy_coeff_start:
    min: 0.0
    max: 1-e3
  entropy_coeff_end:
    min: 0.0
    max: 1-e4
  clip_param:
    min: 0.2
    max: 0.4
  vf_clip_param:
    min: 10.0
    max: 20.0
  kl_target:
    min: 0.1
    max: 0.5
  num_sgd_iter:
    min: 20
    max: 30
  vf_loss_coeff:
    min: 0.5
    max: 1.0
  kl_coeff:
    min: 0.2
    max: 0.6
  batch_mode:
    values:
      - 'truncate_episodes'
      - 'complete_episodes'
  activation_fn:
    values:
      - 'tanh'
      - 'relu'
  model_net:
    values:
      - "fc_masked_model_v1"
      - "fc_masked_model_v2"